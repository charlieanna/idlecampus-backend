slug: lesson-22
title: Lesson 22
sequence_order: 22
estimated_minutes: 2
difficulty: easy
content_md: "# Microlesson \U0001F680\n\n# Introduction to Goroutines\n\n    ### What\
  \ is a Goroutine?\n\n    A **goroutine** is a lightweight thread managed by the\
  \ Go runtime. Think of it as a function that runs concurrently with other functions.\n\
  \n    **The magic word:** `go`\n\n    Adding `go` before a function call makes it\
  \ run in a new goroutine!\n\n    ```go\n    func sayHello() {\n        fmt.Println(\"\
  Hello from goroutine!\")\n    }\n\n    func main() {\n        go sayHello()  //\
  \ Runs concurrently!\n        fmt.Println(\"Hello from main!\")\n    }\n    ```\n\
  \n    ### Why Goroutines Matter\n\n    **Traditional threading (OS threads):**\n\
  \    - Heavy (1-2 MB stack per thread)\n    - Expensive to create (~milliseconds)\n\
  \    - Limited count (thousands max)\n    - Managed by OS kernel\n\n    **Goroutines:**\n\
  \    - Lightweight (2 KB initial stack)\n    - Cheap to create (~microseconds)\n\
  \    - Can create millions\n    - Managed by Go runtime\n\n    **Real-world impact:**\n\
  \    ```\n    C++ with OS threads:  1,000 concurrent tasks   = ~1-2 GB memory\n\
  \    Go with goroutines:   1,000,000 concurrent tasks = ~2 GB memory\n    ```\n\n\
  \    Go lets you create **1000x more** concurrent tasks!\n\n    ### Creating Goroutines\n\
  \n    **Basic syntax:**\n    ```go\n    go functionName()        // Call existing\
  \ function\n    go methodName()          // Call method\n    go func() {       \
  \       // Anonymous function\n        fmt.Println(\"Hi!\")\n    }()           \
  \           // Note the () to call it\n    ```\n\n    **Complete example:**\n  \
  \  ```go\n    package main\n\n    import (\n        \"fmt\"\n        \"time\"\n\
  \    )\n\n    func printNumbers() {\n        for i := 1; i <= 5; i++ {\n       \
  \     fmt.Printf(\"Number: %d\\\\n\", i)\n            time.Sleep(100 * time.Millisecond)\n\
  \        }\n    }\n\n    func printLetters() {\n        for i := 'A'; i <= 'E';\
  \ i++ {\n            fmt.Printf(\"Letter: %c\\\\n\", i)\n            time.Sleep(150\
  \ * time.Millisecond)\n        }\n    }\n\n    func main() {\n        go printNumbers()\
  \  // Runs concurrently\n        go printLetters()  // Runs concurrently\n\n   \
  \     // Wait for goroutines to finish\n        time.Sleep(1 * time.Second)\n  \
  \      fmt.Println(\"Done!\")\n    }\n    ```\n\n    **Output (interleaved!):**\n\
  \    ```\n    Number: 1\n    Letter: A\n    Number: 2\n    Number: 3\n    Letter:\
  \ B\n    Number: 4\n    Letter: C\n    Number: 5\n    Letter: D\n    Letter: E\n\
  \    Done!\n    ```\n\n    Notice: Numbers and letters print in an **interleaved**\
  \ pattern because both goroutines run concurrently!\n\n    ### How Goroutines Work\n\
  \n    **The Go Runtime Scheduler:**\n\n    Go uses an M:N scheduler (M goroutines\
  \ on N OS threads):\n\n    ```\n    Goroutines: [G1][G2][G3][G4][G5][G6][G7][G8]...millions\n\
  \                      ↓       ↓       ↓       ↓\n    OS Threads:    [T1]    [T2]\
  \    [T3]    [T4]\n                      ↓       ↓       ↓       ↓\n    CPU Cores:\
  \     [C1]    [C2]    [C3]    [C4]\n    ```\n\n    **How it works:**\n    1. Go\
  \ creates a few OS threads (usually = number of CPU cores)\n    2. Scheduler multiplexes\
  \ goroutines onto these threads\n    3. When a goroutine blocks (I/O, channel),\
  \ scheduler runs another\n    4. Goroutines cooperatively yield (automatic context\
  \ switching)\n\n    **Why this is fast:**\n    - Context switching happens in user\
  \ space (no kernel involvement)\n    - Goroutines have tiny stacks that grow/shrink\
  \ dynamically\n    - Scheduler is built into Go runtime (optimized for Go code)\n\
  \n    ### Common Goroutine Patterns\n\n    **1. Fire and forget:**\n    ```go\n\
  \    func logEvent(msg string) {\n        // Log to file/database\n        fmt.Println(\"\
  Logged:\", msg)\n    }\n\n    func handleRequest() {\n        go logEvent(\"User\
  \ logged in\")  // Don't wait for logging\n        // Continue handling request\
  \ immediately\n    }\n    ```\n\n    **2. Anonymous goroutines with closures:**\n\
  \    ```go\n    for i := 0; i < 5; i++ {\n        go func(n int) {  // Pass i as\
  \ parameter!\n            fmt.Println(\"Goroutine\", n)\n        }(i)\n    }\n \
  \   ```\n\n    ⚠️ **Common mistake - closure bug:**\n    ```go\n    // ❌ WRONG:\
  \ All goroutines see final value of i\n    for i := 0; i < 5; i++ {\n        go\
  \ func() {\n            fmt.Println(i)  // All print 5!\n        }()\n    }\n\n\
  \    // ✅ CORRECT: Pass i as parameter\n    for i := 0; i < 5; i++ {\n        go\
  \ func(n int) {\n            fmt.Println(n)  // Each prints its own value\n    \
  \    }(i)\n    }\n    ```\n\n    **3. Parallel processing:**\n    ```go\n    func\
  \ processFile(filename string) {\n        // Process file...\n    }\n\n    files\
  \ := []string{\"file1.txt\", \"file2.txt\", \"file3.txt\"}\n\n    for _, file :=\
  \ range files {\n        go processFile(file)  // Process all files concurrently!\n\
  \    }\n    ```\n\n    ### WaitGroups: Waiting for Goroutines\n\n    **The Problem:**\n\
  \    ```go\n    go doWork()\n    // Program exits immediately - goroutine may not\
  \ finish!\n    ```\n\n    **The Solution: sync.WaitGroup**\n    ```go\n    import\
  \ \"sync\"\n\n    var wg sync.WaitGroup\n\n    func worker(id int) {\n        defer\
  \ wg.Done()  // Signal we're done\n        fmt.Printf(\"Worker %d starting\\\\n\"\
  , id)\n        time.Sleep(time.Second)\n        fmt.Printf(\"Worker %d done\\\\\
  n\", id)\n    }\n\n    func main() {\n        for i := 1; i <= 5; i++ {\n      \
  \      wg.Add(1)  // Add 1 to wait group\n            go worker(i)\n        }\n\n\
  \        wg.Wait()  // Block until all Done() called\n        fmt.Println(\"All\
  \ workers finished!\")\n    }\n    ```\n\n    **How WaitGroup works:**\n    1. `wg.Add(1)`\
  \ - Increment counter\n    2. `wg.Done()` - Decrement counter (inside goroutine)\n\
  \    3. `wg.Wait()` - Block until counter reaches 0\n\n    ### Real-World Example:\
  \ Concurrent HTTP Requests\n\n    **Sequential (slow):**\n    ```go\n    urls :=\
  \ []string{\n        \"https://api1.example.com\",\n        \"https://api2.example.com\"\
  ,\n        \"https://api3.example.com\",\n    }\n\n    for _, url := range urls\
  \ {\n        resp, _ := http.Get(url)  // Wait for each\n        // ... process\
  \ response\n    }\n    // Total time: 3 seconds (1 sec per request)\n    ```\n\n\
  \    **Concurrent (fast):**\n    ```go\n    var wg sync.WaitGroup\n\n    for _,\
  \ url := range urls {\n        wg.Add(1)\n        go func(u string) {\n        \
  \    defer wg.Done()\n            resp, _ := http.Get(u)  // All run in parallel\n\
  \            // ... process response\n        }(url)\n    }\n\n    wg.Wait()\n \
  \   // Total time: ~1 second (all requests at once)\n    ```\n\n    **3x speed improvement!**\n\
  \n    ### Goroutine Lifecycle\n\n    **Created:**\n    ```go\n    go myFunction()\
  \  // New goroutine created\n    ```\n\n    **Running:**\n    - Goroutine executes\
  \ code\n    - Can yield to other goroutines (I/O, channel ops)\n\n    **Blocked:**\n\
  \    - Waiting for channel\n    - Waiting for lock\n    - Sleeping (time.Sleep)\n\
  \n    **Finished:**\n    - Function returns\n    - Goroutine is garbage collected\n\
  \n    **Important:** Main goroutine exiting kills all other goroutines!\n\n    ```go\n\
  \    func main() {\n        go longRunningTask()\n        // Main exits - longRunningTask()\
  \ is killed!\n    }\n    ```\n\n    ### Goroutine Best Practices\n\n    **1. Always\
  \ have a way to stop goroutines:**\n    ```go\n    // Use context for cancellation\n\
  \    ctx, cancel := context.WithCancel(context.Background())\n    defer cancel()\n\
  \n    go func(ctx context.Context) {\n        for {\n            select {\n    \
  \        case <-ctx.Done():\n                return  // Stop goroutine\n       \
  \     default:\n                // Do work\n            }\n        }\n    }(ctx)\n\
  \    ```\n\n    **2. Use WaitGroups or channels for synchronization:**\n    ```go\n\
  \    // Don't use sleep to wait!\n    // ❌ time.Sleep(1 * time.Second)  // Guessing!\n\
  \n    // ✅ Use WaitGroup\n    wg.Wait()\n    ```\n\n    **3. Avoid goroutine leaks:**\n\
  \    ```go\n    // ❌ BAD: Goroutine never exits\n    go func() {\n        for {\n\
  \            // Infinite loop with no exit condition\n        }\n    }()\n\n   \
  \ // ✅ GOOD: Can be stopped\n    done := make(chan bool)\n    go func() {\n    \
  \    for {\n            select {\n            case <-done:\n                return\n\
  \            default:\n                // Do work\n            }\n        }\n  \
  \  }()\n\n    // Later: stop the goroutine\n    done <- true\n    ```\n\n    **4.\
  \ Pass parameters, don't rely on closures in loops:**\n    ```go\n    // ❌ WRONG\n\
  \    for i := 0; i < 10; i++ {\n        go func() { fmt.Println(i) }()  // All print\
  \ 10!\n    }\n\n    // ✅ CORRECT\n    for i := 0; i < 10; i++ {\n        go func(n\
  \ int) { fmt.Println(n) }(i)\n    }\n    ```\n\n    ### Performance Characteristics\n\
  \n    **Memory:**\n    - Initial stack: 2 KB\n    - Grows/shrinks dynamically\n\
  \    - 1 million goroutines ≈ 2 GB\n\n    **Creation time:**\n    - ~1-2 microseconds\n\
  \    - Can create thousands per second\n\n    **Context switch:**\n    - ~10-50\
  \ nanoseconds (in user space)\n    - OS thread: ~1-2 microseconds (kernel space)\n\
  \n    ### Common Pitfalls\n\n    **1. Forgetting to wait:**\n    ```go\n    func\
  \ main() {\n        go fmt.Println(\"Hello\")\n        // Program exits before goroutine\
  \ runs!\n    }\n    ```\n\n    **2. Data races (accessing shared variables):**\n\
  \    ```go\n    counter := 0\n    for i := 0; i < 1000; i++ {\n        go func()\
  \ {\n            counter++  // RACE CONDITION!\n        }()\n    }\n    ```\n\n\
  \    Use `-race` flag: `go run -race main.go` to detect races.\n\n    **3. Too many\
  \ goroutines:**\n    ```go\n    // Creating millions of goroutines for CPU-bound\
  \ tasks\n    // Better to use worker pool pattern\n    ```\n\n    ### Key Takeaways\n\
  \n    1. Goroutines are lightweight threads (2 KB vs 1-2 MB)\n    2. Created with\
  \ `go` keyword: `go function()`\n    3. Use WaitGroups to wait for goroutines to\
  \ finish\n    4. Pass parameters to avoid closure bugs in loops\n    5. Always have\
  \ a way to stop goroutines (avoid leaks)\n    6. Use `-race` flag to detect data\
  \ races\n    7. Perfect for I/O-bound tasks (network, file operations)\n\n    Next:\
  \ Learn about **Channels** for safe communication between goroutines!"
exercises:
- type: mcq
  slug: lesson-22-mcq
  sequence_order: 1
  question: What is a key consideration when working with Introduction to Goroutines?
  options:
  - Understanding the core principles and best practices of Introduction to Goroutines
  - Ignoring documentation
  - Skipping testing
  - Avoiding industry standards
  correct_answer_index: 0
  explanation: When working with Introduction to Goroutines, it's essential to understand
    the fundamental principles, follow best practices, and stay updated with current
    standards to ensure effective implementation and maintenance.
objectives:
- Understand the fundamental concepts and mechanisms of lesson 22
- Apply chemical principles to solve related problems
- Identify key reactions, equations, and chemical behaviors
next_recommended: []

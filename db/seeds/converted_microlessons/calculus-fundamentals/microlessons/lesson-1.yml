slug: lesson-1
title: Lesson 1
difficulty: easy
sequence_order: 1
estimated_minutes: 2
key_concepts: []
prerequisites: []
content_md: "# Microlesson \U0001F680\n\n# Derivatives and Gradients\n\n    Calculus\
  \ is the foundation of machine learning optimization. Understanding derivatives\
  \ is essential for gradient descent and backpropagation.\n\n    ## What is a Derivative?\n\
  \n    **The rate of change of a function**\n\n    ```\n    f'(x) = lim(h→0) [f(x+h)\
  \ - f(x)] / h\n    ```\n\n    ### Geometric Interpretation\n    - **Slope** of the\
  \ tangent line at a point\n    - **Instantaneous rate** of change\n\n    ### Notation\n\
  \    ```\n    f'(x)    Newton's notation\n    df/dx    Leibniz's notation\n    ∂f/∂x\
  \    Partial derivative\n    ∇f       Gradient (vector of partial derivatives)\n\
  \    ```\n\n    ## Basic Derivative Rules\n\n    ### Power Rule\n    ```\n    f(x)\
  \ = x^n\n    f'(x) = nx^(n-1)\n\n    Examples:\n    f(x) = x^3       →  f'(x) =\
  \ 3x^2\n    f(x) = x^2       →  f'(x) = 2x\n    f(x) = x         →  f'(x) = 1\n\
  \    f(x) = 1         →  f'(x) = 0\n    ```\n\n    ### Sum Rule\n    ```\n    [f(x)\
  \ + g(x)]' = f'(x) + g'(x)\n\n    Example:\n    f(x) = x^2 + 3x + 5\n    f'(x) =\
  \ 2x + 3 + 0 = 2x + 3\n    ```\n\n    ### Product Rule\n    ```\n    [f(x)·g(x)]'\
  \ = f'(x)·g(x) + f(x)·g'(x)\n\n    Example:\n    f(x) = x^2·sin(x)\n    f'(x) =\
  \ 2x·sin(x) + x^2·cos(x)\n    ```\n\n    ### Chain Rule\n    **Most important for\
  \ neural networks!**\n\n    ```\n    [f(g(x))]' = f'(g(x))·g'(x)\n\n    Example:\n\
  \    f(x) = (x^2 + 1)^3\n    Let u = x^2 + 1\n    f(u) = u^3\n    f'(x) = 3u^2·2x\
  \ = 3(x^2 + 1)^2·2x = 6x(x^2 + 1)^2\n    ```\n\n    ## Common Derivatives\n\n  \
  \  ```\n    f(x) = e^x       →  f'(x) = e^x\n    f(x) = ln(x)     →  f'(x) = 1/x\n\
  \    f(x) = sin(x)    →  f'(x) = cos(x)\n    f(x) = cos(x)    →  f'(x) = -sin(x)\n\
  \    f(x) = tan(x)    →  f'(x) = sec^2(x)\n    f(x) = a^x       →  f'(x) = a^x·ln(a)\n\
  \    ```\n\n    ## Partial Derivatives\n\n    **Derivatives with respect to one\
  \ variable, holding others constant**\n\n    ```\n    f(x, y) = x^2 + 3xy + y^2\n\
  \n    ∂f/∂x = 2x + 3y   (treat y as constant)\n    ∂f/∂y = 3x + 2y   (treat x as\
  \ constant)\n    ```\n\n    ### Example: Linear Regression Loss\n\n    ```\n   \
  \ Loss function:\n    L(w, b) = (1/n)Σ(y_i - (wx_i + b))^2\n\n    Partial derivatives:\n\
  \    ∂L/∂w = -(2/n)Σ x_i(y_i - (wx_i + b))\n    ∂L/∂b = -(2/n)Σ (y_i - (wx_i + b))\n\
  \    ```\n\n    ## The Gradient\n\n    **Vector of all partial derivatives**\n\n\
  \    ```\n    f(x, y, z) = x^2 + 2y^2 + 3z^2\n\n    ∇f = [∂f/∂x, ∂f/∂y, ∂f/∂z]\n\
  \       = [2x, 4y, 6z]\n    ```\n\n    **The gradient points in the direction of\
  \ steepest ascent**\n\n    ## Gradient Descent\n\n    **Core optimization algorithm\
  \ for machine learning**\n\n    ```python\n    # Update rule\n    θ = θ - α·∇L(θ)\n\
  \n    # where:\n    # θ = parameters\n    # α = learning rate\n    # ∇L(θ) = gradient\
  \ of loss function\n    ```\n\n    ### Python Implementation\n\n    ```python\n\
  \    import numpy as np\n\n    def gradient_descent(gradient_func, initial_params,\
  \ learning_rate=0.01, num_iterations=1000):\n        params = initial_params\n\n\
  \        for i in range(num_iterations):\n            # Compute gradient\n     \
  \       gradient = gradient_func(params)\n\n            # Update parameters\n  \
  \          params = params - learning_rate * gradient\n\n            if i % 100\
  \ == 0:\n                loss = compute_loss(params)\n                print(f\"\
  Iteration {i}: Loss = {loss}\")\n\n        return params\n    ```\n\n    ### Example:\
  \ Minimizing f(x) = x^2\n\n    ```python\n    def gradient(x):\n        return 2\
  \ * x  # f'(x) = 2x\n\n    # Start at x = 10\n    x = np.array([10.0])\n    learning_rate\
  \ = 0.1\n\n    for i in range(50):\n        grad = gradient(x)\n        x = x -\
  \ learning_rate * grad\n        if i % 10 == 0:\n            print(f\"Iteration\
  \ {i}: x = {x[0]:.4f}, f(x) = {x[0]**2:.4f}\")\n\n    # Output:\n    # Iteration\
  \ 0: x = 8.0000, f(x) = 64.0000\n    # Iteration 10: x = 0.8958, f(x) = 0.8024\n\
  \    # Iteration 20: x = 0.1002, f(x) = 0.0100\n    # ...converges to x = 0\n  \
  \  ```\n\n    ## Higher-Order Derivatives\n\n    ### Second Derivative\n\n    ```\n\
  \    f''(x) = d²f/dx²\n    ```\n\n    **Measures curvature (concavity)**\n    -\
  \ f''(x) > 0: concave up (minimum)\n    - f''(x) < 0: concave down (maximum)\n \
  \   - f''(x) = 0: inflection point\n\n    ### Hessian Matrix\n\n    **Matrix of\
  \ all second-order partial derivatives**\n\n    ```\n    For f(x, y):\n\n    H =\
  \ [∂²f/∂x²    ∂²f/∂x∂y]\n        [∂²f/∂y∂x   ∂²f/∂y²  ]\n    ```\n\n    Used in\
  \ Newton's method and second-order optimization.\n\n    ## Optimization\n\n    ###\
  \ Finding Extrema\n\n    1. **Find critical points**: Set f'(x) = 0\n    2. **Test\
  \ with second derivative**:\n       - f''(x) > 0 → local minimum\n       - f''(x)\
  \ < 0 → local maximum\n\n    ### Example\n\n    ```\n    f(x) = x^3 - 3x^2 + 2\n\
  \n    1. f'(x) = 3x^2 - 6x = 3x(x - 2) = 0\n       Critical points: x = 0, x = 2\n\
  \n    2. f''(x) = 6x - 6\n       f''(0) = -6 < 0  → local maximum at x = 0\n   \
  \    f''(2) = 6 > 0   → local minimum at x = 2\n    ```\n\n    ## Applications in\
  \ ML\n\n    ### Activation Functions\n\n    ```python\n    # Sigmoid\n    def sigmoid(x):\n\
  \        return 1 / (1 + np.exp(-x))\n\n    def sigmoid_derivative(x):\n       \
  \ s = sigmoid(x)\n        return s * (1 - s)\n\n    # ReLU (Rectified Linear Unit)\n\
  \    def relu(x):\n        return np.maximum(0, x)\n\n    def relu_derivative(x):\n\
  \        return np.where(x > 0, 1, 0)\n\n    # Tanh\n    def tanh(x):\n        return\
  \ np.tanh(x)\n\n    def tanh_derivative(x):\n        return 1 - np.tanh(x)**2\n\
  \    ```\n\n    ### Backpropagation\n\n    **Chain rule applied to neural networks**\n\
  \n    ```python\n    # Forward pass\n    z1 = W1 @ x + b1\n    a1 = relu(z1)\n \
  \   z2 = W2 @ a1 + b2\n    output = sigmoid(z2)\n\n    # Backward pass (chain rule)\n\
  \    dL_dz2 = output - y\n    dL_dW2 = dL_dz2 @ a1.T\n    dL_da1 = W2.T @ dL_dz2\n\
  \    dL_dz1 = dL_da1 * relu_derivative(z1)\n    dL_dW1 = dL_dz1 @ x.T\n    ```\n\
  \n    ### Loss Functions and Their Derivatives\n\n    ```python\n    # Mean Squared\
  \ Error\n    def mse_loss(y_pred, y_true):\n        return np.mean((y_pred - y_true)**2)\n\
  \n    def mse_derivative(y_pred, y_true):\n        return 2 * (y_pred - y_true)\
  \ / len(y_true)\n\n    # Binary Cross-Entropy\n    def bce_loss(y_pred, y_true):\n\
  \        return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n\
  \n    def bce_derivative(y_pred, y_true):\n        return -(y_true / y_pred - (1\
  \ - y_true) / (1 - y_pred))\n    ```\n\n    **Next**: We'll explore vectors and\
  \ matrices in linear algebra!"
exercises:
  - type: multiple_choice_question
    sequence_order: 1
    question: "What does the derivative of a function represent?"
    options:
      - "The area under the curve"
      - "The rate of change of the function"
      - "The maximum value of the function"
      - "The integral of the function"
    correct_answer: "The rate of change of the function"
    explanation: "The derivative represents the rate of change of a function, which geometrically corresponds to the slope of the tangent line at a point. This is fundamental to understanding how functions change and is the basis for optimization in machine learning. The formal definition uses the limit as h approaches 0 of [f(x+h) - f(x)]/h, which captures the instantaneous rate of change. This concept is crucial because in machine learning, we need to understand how loss functions change with respect to parameters to minimize them effectively. The derivative tells us both the direction and magnitude of change, which is why gradient descent uses the negative of the gradient to move toward minima. Understanding derivatives is essential before tackling more advanced concepts like partial derivatives and gradients in multivariable calculus."
    require_pass: true
  - type: multiple_choice_question
    sequence_order: 2
    question: "Using the power rule, what is the derivative of f(x) = x^3?"
    options:
      - "x^2"
      - "3x^3"
      - "3x^2"
      - "x^4/4"
    correct_answer: "3x^2"
    explanation: "The power rule states that for f(x) = x^n, the derivative f'(x) = nx^(n-1). Applying this to f(x) = x^3, we get f'(x) = 3x^(3-1) = 3x^2. This is one of the most fundamental derivative rules and is extensively used in machine learning calculations. The power rule is particularly important because polynomial functions appear frequently in neural network computations, and understanding how to differentiate them quickly is essential. In the context of optimization, when we have cost functions that include polynomial terms, we need to compute their derivatives to perform gradient descent. The power rule also extends to negative and fractional exponents, making it versatile for various mathematical operations. Mastering this rule is critical for understanding backpropagation in neural networks, where we repeatedly apply derivative rules to compute gradients through multiple layers."
    require_pass: true
  - type: multiple_choice_question
    sequence_order: 3
    question: "In gradient descent, what role does the gradient ∇L(θ) play?"
    options:
      - "It specifies the learning rate"
      - "It points in the direction of steepest ascent of the loss function"
      - "It calculates the final optimal parameters"
      - "It determines the number of iterations needed"
    correct_answer: "It points in the direction of steepest ascent of the loss function"
    explanation: "The gradient ∇L(θ) is a vector of all partial derivatives of the loss function, and it points in the direction of steepest ascent. In gradient descent, we subtract the gradient from our current parameters (θ = θ - α·∇L(θ)) to move in the opposite direction, toward the steepest descent, which leads us to a minimum of the loss function. This is the core mechanism of how machine learning models learn and optimize their parameters. The gradient provides both direction and magnitude information about how the loss changes with respect to each parameter. The learning rate α scales this gradient to control step size, preventing overshooting or too-slow convergence. Understanding that the gradient points uphill explains why we subtract it rather than add it – we want to go downhill to minimize loss. This concept generalizes from single-variable calculus to multivariable optimization, making it applicable to neural networks with millions of parameters."
    require_pass: true

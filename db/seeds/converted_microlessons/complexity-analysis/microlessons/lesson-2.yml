slug: lesson-2
title: Lesson 2
difficulty: easy
sequence_order: 2
estimated_minutes: 2
key_concepts: []
prerequisites: []
content_md: "# Microlesson \U0001F680\n\n# Arrays and Linked Lists\n\n    ## Arrays\n\
  \n    **Contiguous memory, fixed or dynamic size**\n\n    ### Operations\n\n   \
  \ | Operation | Time Complexity |\n    |-----------|----------------|\n    | Access\
  \ by index | O(1) |\n    | Search | O(n) |\n    | Insert at end | O(1) amortized\
  \ |\n    | Insert at start | O(n) |\n    | Delete | O(n) |\n\n    ```python\n  \
  \  # Array operations\n    arr = [1, 2, 3, 4, 5]\n\n    # Access: O(1)\n    print(arr[2])\
  \  # 3\n\n    # Search: O(n)\n    def find(arr, target):\n        for i, val in\
  \ enumerate(arr):\n            if val == target:\n                return i\n   \
  \     return -1\n\n    # Insert at end: O(1) amortized\n    arr.append(6)\n\n  \
  \  # Insert at start: O(n) - shifts all elements\n    arr.insert(0, 0)  # [0, 1,\
  \ 2, 3, 4, 5, 6]\n\n    # Delete: O(n)\n    arr.pop(2)  # Remove index 2\n    ```\n\
  \n    ### Common Array Problems\n\n    **Two Sum Problem**\n\n    ```python\n  \
  \  def two_sum(nums, target):\n        seen = {}  # val -> index\n\n        for\
  \ i, num in enumerate(nums):\n            complement = target - num\n          \
  \  if complement in seen:\n                return [seen[complement], i]\n      \
  \      seen[num] = i\n\n        return []\n\n    # Time: O(n), Space: O(n)\n   \
  \ ```\n\n    **Remove Duplicates (In-place)**\n\n    ```python\n    def remove_duplicates(nums):\n\
  \        if not nums:\n            return 0\n\n        write_idx = 1\n        for\
  \ read_idx in range(1, len(nums)):\n            if nums[read_idx] != nums[read_idx\
  \ - 1]:\n                nums[write_idx] = nums[read_idx]\n                write_idx\
  \ += 1\n\n        return write_idx\n\n    # Time: O(n), Space: O(1)\n    ```\n\n\
  \    ## Linked Lists\n\n    **Nodes with pointers, dynamic size**\n\n    ```python\n\
  \    class ListNode:\n        def __init__(self, val=0, next=None):\n          \
  \  self.val = val\n            self.next = next\n    ```\n\n    ### Operations\n\
  \n    | Operation | Time Complexity |\n    |-----------|----------------|\n    |\
  \ Access | O(n) |\n    | Search | O(n) |\n    | Insert at start | O(1) |\n    |\
  \ Insert at end | O(n) or O(1) with tail pointer |\n    | Delete | O(n) |\n\n  \
  \  ```python\n    class LinkedList:\n        def __init__(self):\n            self.head\
  \ = None\n\n        def insert_at_start(self, val):\n            new_node = ListNode(val)\n\
  \            new_node.next = self.head\n            self.head = new_node\n     \
  \       # O(1)\n\n        def insert_at_end(self, val):\n            new_node =\
  \ ListNode(val)\n\n            if not self.head:\n                self.head = new_node\n\
  \                return\n\n            current = self.head\n            while current.next:\n\
  \                current = current.next\n            current.next = new_node\n \
  \           # O(n)\n\n        def delete(self, val):\n            if not self.head:\n\
  \                return\n\n            if self.head.val == val:\n              \
  \  self.head = self.head.next\n                return\n\n            current = self.head\n\
  \            while current.next:\n                if current.next.val == val:\n\
  \                    current.next = current.next.next\n                    return\n\
  \                current = current.next\n            # O(n)\n    ```\n\n    ###\
  \ Common Linked List Problems\n\n    **Reverse Linked List**\n\n    ```python\n\
  \    def reverse_list(head):\n        prev = None\n        current = head\n\n  \
  \      while current:\n            next_node = current.next\n            current.next\
  \ = prev\n            prev = current\n            current = next_node\n\n      \
  \  return prev\n\n    # Time: O(n), Space: O(1)\n    ```\n\n    **Detect Cycle (Floyd's\
  \ Algorithm)**\n\n    ```python\n    def has_cycle(head):\n        slow = fast =\
  \ head\n\n        while fast and fast.next:\n            slow = slow.next\n    \
  \        fast = fast.next.next\n\n            if slow == fast:\n               \
  \ return True\n\n        return False\n\n    # Time: O(n), Space: O(1)\n    ```\n\
  \n    **Merge Two Sorted Lists**\n\n    ```python\n    def merge_two_lists(l1, l2):\n\
  \        dummy = ListNode(0)\n        current = dummy\n\n        while l1 and l2:\n\
  \            if l1.val <= l2.val:\n                current.next = l1\n         \
  \       l1 = l1.next\n            else:\n                current.next = l2\n   \
  \             l2 = l2.next\n            current = current.next\n\n        current.next\
  \ = l1 or l2\n        return dummy.next\n\n    # Time: O(m + n), Space: O(1)\n \
  \   ```\n\n    ## Arrays vs Linked Lists\n\n    | Feature | Array | Linked List\
  \ |\n    |---------|-------|-------------|\n    | Access | O(1) | O(n) |\n    |\
  \ Insert at start | O(n) | O(1) |\n    | Insert at end | O(1) | O(n) or O(1) |\n\
  \    | Memory | Contiguous | Scattered |\n    | Cache locality | Better | Worse\
  \ |\n    | Memory overhead | Low | High (pointers) |\n\n    **When to use:**\n \
  \   - **Array**: Random access needed, memory cache important\n    - **Linked List**:\
  \ Frequent insertions/deletions at start\n\n    **Next**: Stacks and Queues!"
exercises:
  - type: mcq
    sequence_order: 1
    question: "Why does inserting an element at the start of an array require O(n) time?"
    options:
      - "Arrays don't support insertion operations"
      - "All existing elements must be shifted one position to make room"
      - "Arrays are stored in non-contiguous memory"
      - "The operation requires sorting the array"
    correct_answer: "All existing elements must be shifted one position to make room"
    explanation: "Inserting at the start of an array requires O(n) time because arrays store elements in contiguous memory with fixed indices. To insert at index 0, all n existing elements must shift right by one position to make space. For example, to insert 0 into [1,2,3,4,5], we must move each element: 5→index 5, 4→index 4, 3→index 3, 2→index 2, 1→index 1, then place 0→index 0. This requires n shift operations, hence O(n). In contrast, inserting at the end is O(1) amortized (assuming capacity exists) because no shifting is needed. This is why arrays excel at random access O(1) but struggle with insertions/deletions in the middle. Linked lists reverse this trade-off: O(1) insertion at the start (just update head pointer) but O(n) access. Arrays do support insertion (not impossible), are stored contiguously (that's what enables O(1) indexing), and insertion doesn't require sorting. Understanding these trade-offs helps choose the right data structure."
    require_pass: true
  - type: mcq
    sequence_order: 2
    question: "What is the time complexity of detecting a cycle in a linked list using Floyd's algorithm?"
    options:
      - "O(1)"
      - "O(log n)"
      - "O(n)"
      - "O(n²)"
    correct_answer: "O(n)"
    explanation: "Floyd's cycle detection algorithm (tortoise and hare) runs in O(n) time with O(1) space. The algorithm uses two pointers: slow (moves 1 step) and fast (moves 2 steps). If there's no cycle, fast reaches the end in n/2 iterations = O(n). If there's a cycle of length c, after entering the cycle, the gap between fast and slow closes by 1 each iteration. The maximum gap is c, so they meet within c iterations. Since c ≤ n, total time is O(n). For example, in a list 1→2→3→4→2 (cycle at 2), pointers meet within a few steps after entering the cycle. This is optimal—you must traverse at least part of the list to detect a cycle. The space complexity is O(1) since we only use two pointers, making this preferable to using a hash set (which would be O(n) space). It's not O(1) time (must traverse the list), not O(log n) (no binary search structure), and definitely not O(n²) (no nested loops). Floyd's algorithm is a classic example of elegant, space-efficient algorithm design."
    require_pass: true

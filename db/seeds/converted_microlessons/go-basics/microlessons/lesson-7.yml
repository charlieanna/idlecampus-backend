slug: lesson-7
title: Lesson 7
difficulty: easy
sequence_order: 7
estimated_minutes: 2
key_concepts: []
prerequisites: []
content_md: "# Microlesson \U0001F680\n\n# Concurrency vs Parallelism\n\n    ## The\
  \ Difference\n\n    **Concurrency** is about *dealing with* many things at once.\n\
  \    **Parallelism** is about *doing* many things at once.\n\n    ### Concurrency\n\
  \    - **Structure**: How you organize your program\n    - **Composition**: Breaking\
  \ down problems into independently executing tasks\n    - **Can run on**: Single\
  \ or multiple cores\n    - **Example**: A juggler juggling multiple balls (one person,\
  \ multiple tasks)\n\n    ### Parallelism\n    - **Execution**: Actually running\
  \ multiple tasks simultaneously\n    - **Performance**: Doing multiple computations\
  \ at the same time\n    - **Requires**: Multiple cores/processors\n    - **Example**:\
  \ Multiple jugglers each juggling their own balls\n\n    ## Why Go Excels at Concurrency\n\
  \n    Go was designed from the ground up with concurrency in mind:\n\n    1. **Goroutines**:\
  \ Lightweight threads managed by Go runtime\n    2. **Channels**: Safe communication\
  \ between goroutines\n    3. **Select Statement**: Multiplexing channel operations\n\
  \    4. **Race Detector**: Built-in tool to find race conditions\n    5. **Sync\
  \ Package**: Primitives for synchronization\n\n    ## Real-World Analogy\n\n   \
  \ Think of a restaurant:\n\n    ### Concurrent (Single Chef, Multiple Orders)\n\
  \    ```\n    Chef starts cooking Order 1 → While waiting for pasta to boil\n  \
  \  → Starts chopping vegetables for Order 2\n    → Pasta done, back to Order 1\n\
  \    → Continues Order 2\n    ```\n    One chef handling multiple orders by switching\
  \ between them.\n\n    ### Parallel (Multiple Chefs, Multiple Orders)\n    ```\n\
  \    Chef 1: Cooking Order 1\n    Chef 2: Cooking Order 2\n    Chef 3: Cooking Order\
  \ 3\n    (All at the same time)\n    ```\n    Multiple chefs working simultaneously.\n\
  \n    ## Go's Concurrency Model: CSP\n\n    Go uses **Communicating Sequential Processes\
  \ (CSP)**:\n\n    > \"Don't communicate by sharing memory; share memory by communicating.\"\
  \n\n    Instead of:\n    ```go\n    // BAD: Sharing memory (requires locks)\n  \
  \  var counter int\n    var mutex sync.Mutex\n\n    mutex.Lock()\n    counter++\n\
  \    mutex.Unlock()\n    ```\n\n    Do this:\n    ```go\n    // GOOD: Communicating\
  \ via channels\n    counterChan := make(chan int)\n\n    go func() {\n        counter\
  \ := 0\n        for {\n            counter++\n            counterChan <- counter\n\
  \        }\n    }()\n\n    value := <-counterChan  // Receive from channel\n   \
  \ ```\n\n    ## Performance Characteristics\n\n    ### Goroutines vs OS Threads\n\
  \n    | Feature | Goroutines | OS Threads |\n    |---------|------------|------------|\n\
  \    | Memory | 2 KB initial stack | 1-2 MB stack |\n    | Creation | Fast (~microseconds)\
  \ | Slow (~milliseconds) |\n    | Context Switch | Cheap | Expensive |\n    | Max\
  \ Number | Millions | Thousands |\n    | Managed By | Go runtime | OS kernel |\n\
  \n    ### Example: 1 Million Goroutines\n\n    ```go\n    package main\n\n    import\
  \ (\n        \"fmt\"\n        \"runtime\"\n        \"time\"\n    )\n\n    func main()\
  \ {\n        fmt.Printf(\"Starting goroutines: %d\\\\n\", runtime.NumGoroutine())\n\
  \n        for i := 0; i < 1000000; i++ {\n            go func() {\n            \
  \    time.Sleep(10 * time.Second)\n            }()\n        }\n\n        time.Sleep(1\
  \ * time.Second)\n        fmt.Printf(\"Active goroutines: %d\\\\n\", runtime.NumGoroutine())\n\
  \        // Output: Active goroutines: 1000001\n        // Memory used: ~2 GB (very\
  \ efficient!)\n    }\n    ```\n\n    ## Key Takeaways\n\n    1. **Concurrency**\
  \ = Structure (composition of independently executing tasks)\n    2. **Parallelism**\
  \ = Execution (simultaneous execution on multiple cores)\n    3. Go makes concurrent\
  \ programming **simple and safe**\n    4. Goroutines are **extremely lightweight**\
  \ compared to threads\n    5. Use **channels** to communicate between goroutines\n\
  \    6. Go's philosophy: **\"Share memory by communicating\"**\n\n    Next, we'll\
  \ dive deep into goroutines!"
exercises:
- type: mcq
  sequence_order: 1
  question: What is the fundamental difference between concurrency and parallelism
    in Go, and can you have concurrency without parallelism?
  options:
  - Concurrency is about multiple cores; parallelism is about single cores
  - Concurrency is about structure/composition of tasks; parallelism is about simultaneous
    execution; yes, you can have concurrency on a single core
  - They are the same thing - Go uses these terms interchangeably
  - Concurrency requires goroutines; parallelism requires threads
  correct_answer: Concurrency is about structure/composition of tasks; parallelism
    is about simultaneous execution; yes, you can have concurrency on a single core
  explanation: 'Concurrency and parallelism are distinct concepts that are often confused.
    Concurrency is about program structure - decomposing a program into independently
    executing tasks that can make progress. It''s about dealing with multiple things
    at once through composition. Think of a single chef (one CPU core) managing multiple
    dishes by switching between them while waiting (concurrent, not parallel). Parallelism
    is about execution - actually running multiple computations simultaneously on
    different CPU cores. It''s about doing multiple things at once. Think of multiple
    chefs each cooking their own dish simultaneously (parallel execution). Critically,
    you CAN have concurrency without parallelism: on a single-core machine, goroutines
    run concurrently through time-slicing (the Go scheduler rapidly switches between
    goroutines), but only one executes at any instant (no parallelism). Conversely,
    you can have parallelism without good concurrent design (just running unrelated
    programs on different cores). Go excels at concurrency through goroutines, channels,
    and CSP, and can leverage parallelism when multiple cores are available (GOMAXPROCS),
    but the concurrent structure works regardless of core count.'
  require_pass: true
- type: mcq
  sequence_order: 2
  question: Why are goroutines so much more efficient than OS threads, allowing Go
    programs to run millions of goroutines?
  options:
  - Goroutines use assembly language; threads use higher-level code
  - Goroutines have 2KB initial stack vs 1-2MB for threads, are managed by Go runtime
    vs OS kernel, and have cheap context switches
  - Goroutines automatically use multiple CPU cores; threads use only one core
  - Goroutines are compiled; threads are interpreted
  correct_answer: Goroutines have 2KB initial stack vs 1-2MB for threads, are managed
    by Go runtime vs OS kernel, and have cheap context switches
  explanation: 'Goroutines achieve remarkable efficiency through several design choices.
    Stack size: Goroutines start with only ~2KB of stack memory (which grows dynamically
    if needed), while OS threads typically have 1-2MB fixed stacks. This means 1 million
    goroutines use ~2GB of memory, while 1 million threads would use 1-2TB - completely
    impractical. Management: Goroutines are scheduled by the Go runtime (in user space)
    using a technique called M:N scheduling (M goroutines on N OS threads), while
    OS threads are managed by the kernel. User-space scheduling is much faster - no
    expensive kernel context switches. Context switching: Switching between goroutines
    is extremely cheap (saving/restoring a few registers) compared to OS thread context
    switches (kernel involvement, cache invalidation, TLB flushes). Creation time:
    Goroutines are created in microseconds vs milliseconds for threads. Scalability:
    Go''s scheduler multiplexes many goroutines onto a small number of OS threads
    (typically GOMAXPROCS = number of CPU cores), achieving both concurrency and parallelism
    efficiently. This design lets real-world Go programs run hundreds of thousands
    or millions of concurrent goroutines, enabling patterns like "one goroutine per
    request" in web servers.'
  require_pass: true
- type: mcq
  sequence_order: 3
  question: What does Go's CSP philosophy "Don't communicate by sharing memory; share
    memory by communicating" mean, and why is it preferred over traditional locking?
  options:
  - It means never use shared variables in Go programs
  - It means use channels to pass data between goroutines instead of sharing memory
    with locks, preventing data races and making concurrency safer
  - It means Go doesn't support mutexes or locks
  - It means all communication must happen through the network
  correct_answer: It means use channels to pass data between goroutines instead of
    sharing memory with locks, preventing data races and making concurrency safer
  explanation: 'This philosophy, derived from Communicating Sequential Processes (CSP),
    represents a paradigm shift in concurrent programming. Traditional approach (sharing
    memory): Multiple goroutines access shared variables, using mutexes to prevent
    race conditions: var counter int; var mu sync.Mutex; mu.Lock(); counter++; mu.Unlock().
    This is error-prone - forget a lock, use wrong mutex, lock in wrong order → deadlocks,
    race conditions, corrupted data. CSP approach (sharing via communication): Instead
    of shared memory, goroutines send data through channels. Only one goroutine "owns"
    data at a time. Example: one goroutine manages a counter, others send increment
    requests via channel. Ownership transfers through the channel, eliminating the
    need for locks. Benefits: (1) No race conditions - only one goroutine accesses
    data, (2) Clearer code - data flow is explicit through channels, (3) Composability
    - channels work great with select for multiplexing. However, Go still provides
    sync.Mutex for cases where shared memory makes more sense (rare write, many reads;
    performance-critical sections). The guideline is: prefer channels for communication
    between goroutines, use mutexes for protecting internal state within a goroutine.'
  require_pass: true

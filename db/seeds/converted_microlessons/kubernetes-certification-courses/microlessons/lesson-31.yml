slug: lesson-31
title: Lesson 31
difficulty: easy
sequence_order: 31
estimated_minutes: 2
key_concepts: []
prerequisites: []
content_md: "# Microlesson \U0001F680\n\n# Taints, Tolerations, and Priority\n\n \
  \   - NoSchedule, PreferNoSchedule, NoExecute effects\n    - Pod priority and preemption"
exercises:
- type: mcq
  sequence_order: 1
  question: What is the difference between NoSchedule, PreferNoSchedule, and NoExecute
    taint effects?
  options:
  - They all prevent pod scheduling equally
  - NoSchedule prevents new pods from scheduling; PreferNoSchedule is a soft preference;
    NoExecute evicts existing pods without toleration
  - They control different resource types
  - NoExecute is deprecated
  correct_answer: NoSchedule prevents new pods from scheduling; PreferNoSchedule is
    a soft preference; NoExecute evicts existing pods without toleration
  explanation: 'Taints are applied to nodes to repel pods unless they have matching
    tolerations. The three taint effects have different behaviors: NoSchedule (hard
    constraint) - pods without matching toleration will not be scheduled to this node,
    but existing pods remain running. For example, ''kubectl taint nodes node1 key=value:NoSchedule''
    prevents new pods from scheduling to node1 unless they tolerate ''key=value''.
    PreferNoSchedule (soft constraint) - scheduler tries to avoid placing pods on
    this node but can if no other options exist. This is a preference, not a requirement.
    Useful for gradually migrating workloads off a node. NoExecute (eviction) - not
    only prevents new pods from scheduling, but also evicts existing pods that don''t
    tolerate the taint. This is the most disruptive effect. For example, ''kubectl
    taint nodes node1 maintenance=true:NoExecute'' immediately evicts all pods without
    matching toleration. Pods with toleration can specify ''tolerationSeconds'' to
    control how long they can run before eviction: ''tolerations: - key: maintenance,
    operator: Equal, value: true, effect: NoExecute, tolerationSeconds: 3600'' allows
    the pod to run for 1 hour after the taint is added, then gets evicted. Common
    use cases: NoSchedule for dedicated nodes (GPU nodes, licensed software), PreferNoSchedule
    for overloaded nodes, NoExecute for node maintenance (draining) or when nodes
    are unhealthy. The kubelet automatically adds taints for node conditions like
    ''node.kubernetes.io/not-ready:NoExecute'', ''node.kubernetes.io/unreachable:NoExecute'',
    ''node.kubernetes.io/disk-pressure:NoSchedule'', and ''node.kubernetes.io/memory-pressure:NoSchedule''.
    Understanding taint effects is crucial for node lifecycle management and workload
    isolation.'
  require_pass: true
- type: mcq
  sequence_order: 2
  question: How does pod priority and preemption work in Kubernetes?
  options:
  - All pods have equal priority; preemption is not supported
  - Higher priority pods can preempt (evict) lower priority pods when resources are
    scarce
  - Priority only affects scheduling order, not preemption
  - Preemption only works with StatefulSets
  correct_answer: Higher priority pods can preempt (evict) lower priority pods when
    resources are scarce
  explanation: 'Pod priority and preemption allow critical workloads to get scheduled
    even when clusters are at capacity by evicting less important pods. Priority is
    assigned using PriorityClasses - cluster-wide objects defining priority values
    (higher numbers = higher priority). For example, create a PriorityClass: ''apiVersion:
    scheduling.k8s.io/v1, kind: PriorityClass, metadata: name: high-priority, value:
    1000000, globalDefault: false, description: High priority pods''. Then reference
    it in pod spec: ''priorityClassName: high-priority''. When a pod cannot be scheduled
    due to insufficient resources, the scheduler attempts preemption: it tries to
    find lower-priority pods that, if removed, would free enough resources for the
    pending high-priority pod. If found, those pods are evicted (respecting PodDisruptionBudgets
    and graceful termination), and once resources are available, the high-priority
    pod is scheduled. Preemption algorithm: identifies victim pods (lower priority),
    checks if their removal helps, respects PDBs (won''t violate minAvailable), provides
    grace period for termination, and only preempts the minimum necessary pods. SystemCriticalPriority
    (2000000000) is reserved for system components like kube-proxy, CoreDNS. Use cases:
    critical workloads (ensure payment processing always runs), batch vs. interactive
    (interactive jobs preempt batch), dev vs. prod (prod pods preempt dev), and cost
    optimization (overprovision with low-priority placeholder pods that get preempted
    when needed). Best practices: use priorities sparingly (too many can cause scheduling
    thrash), set reasonable values (avoid extremes), don''t make all pods high priority
    (defeats the purpose), combine with resource quotas to prevent abuse, and monitor
    preemption events to understand impact.'
  require_pass: true
- type: mcq
  sequence_order: 1
  question: What command lists all pods in all namespaces?
  options:
  - kubectl get pods -A
  - kubectl list pods --all
  - kubectl get pods --everywhere
  - kubectl pods list -A
  correct_answer_index: 0
  explanation: kubectl get pods -A (or --all-namespaces) lists pods across all namespaces.
    The -A flag is shorthand for --all-namespaces.
  require_pass: true

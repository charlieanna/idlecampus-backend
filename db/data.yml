
---
ar_internal_metadata:
  columns:
  - key
  - value
  - created_at
  - updated_at
  records: 
  - - environment
    - development
    - '2025-11-06 03:44:01.125469'
    - '2025-11-06 03:44:01.125469'
  - - schema_sha1
    - 6a8985e7231c052de3baf02d2ce324056726ff82
    - '2025-11-06 03:44:01.129126'
    - '2025-11-06 03:44:01.129126'

---
course_achievements:
  columns:
  - id
  - name
  - slug
  - description
  - icon_url
  - badge_type
  - points_value
  - category
  - criteria
  - created_at
  - updated_at
  records: 
  - - 1
    - First Steps
    - first-steps
    - Complete your first lesson
    -
    - bronze
    - 10
    - course_completion
    - '{"type":"complete_module","module_id":1}'
    - '2025-11-06 03:44:04.130110'
    - '2025-11-06 03:44:04.130110'
  - - 2
    - Quiz Master
    - quiz-master
    - Score 100% on any quiz
    -
    - silver
    - 50
    - quiz_perfectionist
    - '{"type":"quiz_perfect_score"}'
    - '2025-11-06 03:44:04.134881'
    - '2025-11-06 03:44:04.134881'
  - - 3
    - Docker Basics Complete
    - docker-basics-complete
    - Complete the Container Basics module
    -
    - silver
    - 100
    - course_completion
    - '{"type":"complete_module","module_id":1}'
    - '2025-11-06 03:44:04.138357'
    - '2025-11-06 03:44:04.138357'
  - - 4
    - 7-Day Streak
    - 7-day-streak
    - Study for 7 consecutive days
    -
    - gold
    - 200
    - streak
    - '{"type":"streak_days","days":7}'
    - '2025-11-06 03:44:04.141917'
    - '2025-11-06 03:44:04.141917'
  - - 5
    - Lab Expert
    - lab-expert
    - Complete 10 hands-on labs
    -
    - gold
    - 300
    - lab_mastery
    - '{"type":"labs_completed","count":10}'
    - '2025-11-06 03:44:04.145345'
    - '2025-11-06 03:44:04.145345'

---
course_lessons:
  columns:
  - id
  - title
  - content
  - video_url
  - reading_time_minutes
  - key_concepts
  - created_at
  - updated_at
  - content_sections
  - key_commands
  records: 
  - - 1
    - What are Containers?
    - |
      # What are Containers?

      ## Introduction

      Containers have revolutionized how we develop, ship, and run applications. But what exactly are they?

      ## Definition

      **A container is a lightweight, standalone, executable package** that includes everything needed to run a piece of software:
      - Application code
      - Runtime environment
      - System tools and libraries
      - Configuration files

      ## The Problem Containers Solve

      Before containers, developers faced the infamous **"It works on my machine"** problem:

      ```
      Developer's Laptop ✅  →  Staging Server ❌  →  Production ❌
      ```

      Different environments meant different configurations, dependencies, and system libraries - leading to unpredictable failures.

      ## How Containers Help

      Containers package the entire runtime environment, ensuring your application runs identically everywhere:

      ```
      Developer's Laptop ✅  →  Staging Server ✅  →  Production ✅
      ```

      ## Key Benefits

      ### 1. **Consistency Across Environments**
      - Same container runs on laptop, server, and cloud
      - Eliminates environment-specific bugs

      ### 2. **Isolation**
      - Each container runs independently
      - No conflicts between applications
      - Secure separation of processes

      ### 3. **Lightweight & Fast**
      - Containers share the host OS kernel
      - Start in seconds (vs minutes for VMs)
      - Minimal resource overhead

      ### 4. **Portability**
      - Run anywhere: Windows, Linux, macOS, cloud
      - No vendor lock-in
      - Easy migration between providers

      ### 5. **Efficiency**
      - Run dozens of containers on one host
      - Better resource utilization
      - Lower infrastructure costs

      ## Real-World Use Cases

      ### Microservices Architecture
      ```
      E-Commerce Platform:
      ├─ Frontend Container (React)
      ├─ API Gateway Container (Node.js)
      ├─ Product Service Container (Python)
      ├─ User Service Container (Go)
      ├─ Database Container (PostgreSQL)
      └─ Cache Container (Redis)
      ```

      ### CI/CD Pipelines
      - Build code in containers
      - Test in isolated environments
      - Deploy with confidence

      ### Development Environments
      - Onboard new developers in minutes
      - Consistent dev/prod environments
      - No "works on my machine" issues

      ## How Containers Work (Simplified)

      ```
      Application Code
           ↓
      Container Image (Template)
           ↓
      Running Container (Process)
      ```

      Containers use OS-level virtualization features:
      - **Namespaces**: Isolate processes, networking, filesystems
      - **Cgroups**: Limit CPU, memory, disk usage
      - **Union File Systems**: Layer filesystems efficiently

      ## Container vs Process

      A container is essentially a **fancy process** with:
      - Its own filesystem view
      - Isolated networking
      - Resource limits
      - Security boundaries

      ## The Container Ecosystem

      Modern containerization includes:
      - **Docker**: Container runtime and tooling
      - **Container Registries**: Image distribution (Docker Hub, ECR, GCR)
      - **Orchestrators**: Manage many containers (Kubernetes, Docker Swarm)
      - **Monitoring**: Track container health and metrics

      ## Why Containers Matter

      > "Containers are to modern infrastructure what shipping containers are to global trade - standardized, efficient, and transformative."

      Companies using containers report:
      - 70% faster deployment times
      - 50% better resource utilization
      - 60% reduction in environment-related bugs

      ## What's Next?

      Now that you understand what containers are, let's explore how they compare to traditional virtual machines - another popular virtualization technology.
    -
    - 15
    - '["containers","isolation","portability","consistency","microservices"]'
    - '2025-11-06 03:44:03.473623'
    - '2025-11-06 08:09:17.913231'
    - "[]"
    - '"[]"'
  - - 2
    - Understanding Docker Images
    - |
      # Understanding Docker Images

      Docker images are the blueprints for containers. They contain everything needed to run an application.

      ## Image Layers

      Images are built in layers, with each layer representing a filesystem change:
      - **Base layer**: Usually an OS like Ubuntu or Alpine
      - **Application layers**: Your code and dependencies
      - **Each layer is cached**: Makes rebuilds faster

      ## Dockerfile Basics

      A Dockerfile is a text file with instructions to build an image:

      ```dockerfile
      FROM node:18-alpine
      WORKDIR /app
      COPY package.json .
      RUN npm install
      COPY . .
      CMD ["node", "server.js"]
      ```

      ### Key Instructions
      - `FROM`: Base image
      - `WORKDIR`: Set working directory
      - `COPY`: Copy files into image
      - `RUN`: Execute commands
      - `CMD`: Default command to run
      - `EXPOSE`: Document ports

      ## Building Images

      ```bash
      # Build an image
      docker build -t myapp:v1 .

      # List images
      docker images

      # Tag an image
      docker tag myapp:v1 myapp:latest
      ```

      ## Best Practices
      1. Use specific base image tags
      2. Order instructions from least to most frequently changed
      3. Use .dockerignore to exclude files
      4. Minimize layer count
      5. Use multi-stage builds for production
    -
    - 20
    - '["Image layers","Dockerfile syntax","Build caching","Image tagging"]'
    - '2025-11-06 03:44:03.524913'
    - '2025-11-06 07:32:44.024059'
    - "[]"
    - '"[]"'
  - - 3
    - Docker Networking Fundamentals
    - |
      # Docker Networking Fundamentals

      ## Network Drivers

      Docker provides several network drivers:

      - **bridge**: Default, isolated network
      - **host**: Use host's network directly
      - **none**: No networking
      - **overlay**: Multi-host networking (Swarm)

      ## Container Communication

      Containers on the same network can communicate using:
      - Container names as hostnames
      - IP addresses
      - Service discovery (automatic DNS)

      ## Port Publishing

      ```bash
      docker run -p 8080:80 nginx
      # Host port 8080 → Container port 80
      ```
    -
    - 25
    - '["networking","bridge","port-mapping","dns"]'
    - '2025-11-06 03:44:03.544265'
    - '2025-11-06 08:20:50.345220'
    - "[]"
    - '"[]"'
  - - 4
    - Data Persistence with Volumes
    - |
      # Data Persistence with Volumes

      Volumes are the preferred mechanism for persisting data in Docker.

      ## Types
      - Named volumes: managed by Docker (`docker volume create`)
      - Bind mounts: map host paths into containers

      ## Examples
      ```bash
      docker volume create appdata
      docker run -d -v appdata:/var/lib/app --name app busybox tail -f /dev/null
      docker run --rm -v appdata:/data busybox ls -l /data
      ```
    -
    - 15
    -
    - '2025-11-06 03:44:03.570592'
    - '2025-11-06 03:44:03.570592'
    - "[]"
    -
  - - 5
    - Compose Basics
    - |
      # Docker Compose Basics

      Compose uses a YAML file to define services, networks, and volumes.

      ```yaml
      version: '3.9'
      services:
        web:
          image: nginx
          ports: ["8080:80"]
        redis:
          image: redis:alpine
      ```

      Commands:
      - `docker compose up -d`
      - `docker compose ps`
      - `docker compose logs -f`
    -
    - 15
    -
    - '2025-11-06 03:44:03.593365'
    - '2025-11-06 03:44:03.593365'
    - "[]"
    -
  - - 6
    - Container Security Basics
    - |
      # Container Security Basics

      - Prefer non-root users in images (USER)
      - Add HEALTHCHECK to detect failure conditions
      - Limit capabilities and make FS read-only when possible
      - Scan images for vulnerabilities
    -
    - 10
    -
    - '2025-11-06 03:44:03.623292'
    - '2025-11-06 03:44:03.623292'
    - "[]"
    -
  - - 7
    - Using Docker Registries
    - |
      # Using Docker Registries

      - docker login / logout
      - docker tag (image:tag) and naming conventions
      - docker push / pull
      - Immutable tags in CI/CD and content trust overview
    -
    - 10
    -
    - '2025-11-06 03:44:03.647597'
    - '2025-11-06 03:44:03.647597'
    - "[]"
    -
  - - 8
    - Introduction to Go
    - Go is a powerful language for concurrent programming.
    -
    - 10
    -
    - '2025-11-06 03:44:32.156145'
    - '2025-11-06 03:44:32.156145'
    - "[]"
    -
  - - 9
    - Introduction to Go
    - |-
      # Introduction to Go

      Go (or Golang) is a statically typed, compiled programming language designed at Google. It's known for its simplicity, efficiency, and excellent concurrency support.

      ## Why Learn Go?

      - Simple and Clean Syntax
      - Fast Compilation
      - Built-in Concurrency
      - Strong Standard Library
      - Used by: Google, Uber, Netflix, Docker, Kubernetes

      ## Your First Go Program

      package main
      import "fmt"

      func main() {
          fmt.Println("Hello, World!")
      }

      Every Go program starts with a package declaration. The main package is special - it defines an executable program.
    -
    - 10
    -
    - '2025-11-06 04:04:48.038988'
    - '2025-11-06 04:04:48.038988'
    - "[]"
    -
  - - 10
    - Variables and Types
    - |-
      # Variables and Types in Go

      Go is a statically typed language, meaning variable types are known at compile time.

      ## Declaring Variables

      There are several ways to declare variables in Go:

      ```go
      // Using var keyword
      var name string = "John"
      var age int = 30

      // Type inference
      var city = "New York"  // Go infers string type

      // Short declaration (inside functions only)
      country := "USA"
      ```

      ## Basic Types

      **Numeric Types:**
      - `int`, `int8`, `int16`, `int32`, `int64`
      - `uint`, `uint8`, `uint16`, `uint32`, `uint64`
      - `float32`, `float64`

      **Other Types:**
      - `string` - text data
      - `bool` - true or false
      - `byte` - alias for uint8
      - `rune` - alias for int32, represents a Unicode code point

      ## Constants

      Constants are declared with the `const` keyword:

      ```go
      const Pi = 3.14159
      const MaxUsers = 100
      ```

      ## Zero Values

      Variables without an initial value are given their zero value:
      - `0` for numeric types
      - `false` for boolean
      - `""` for strings
    -
    - 15
    -
    - '2025-11-06 04:04:48.040688'
    - '2025-11-06 04:04:48.040688'
    - "[]"
    -
  - - 11
    - Functions in Go
    - |-
      # Functions in Go

      Functions are the building blocks of Go programs.

      ## Basic Function Syntax

      ```go
      func functionName(parameter1 type1, parameter2 type2) returnType {
          // function body
          return value
      }
      ```

      ## Examples

      ```go
      // Simple function
      func greet(name string) string {
          return "Hello, " + name
      }

      // Multiple parameters of same type
      func add(x, y int) int {
          return x + y
      }

      // Multiple return values
      func divide(a, b float64) (float64, error) {
          if b == 0 {
              return 0, errors.New("division by zero")
          }
          return a / b, nil
      }
      ```

      ## Named Return Values

      ```go
      func split(sum int) (x, y int) {
          x = sum * 4 / 9
          y = sum - x
          return  // naked return
      }
      ```

      ## Variadic Functions

      Functions can accept a variable number of arguments:

      ```go
      func sum(numbers ...int) int {
          total := 0
          for _, num := range numbers {
              total += num
          }
          return total
      }

      result := sum(1, 2, 3, 4, 5)  // 15
      ```
    -
    - 20
    -
    - '2025-11-06 04:04:48.042060'
    - '2025-11-06 04:04:48.042060'
    - "[]"
    -
  - - 12
    - Introduction to Go
    - |-
      # Introduction to Go

      Go (or Golang) is a statically typed, compiled programming language designed at Google. It's known for its simplicity, efficiency, and excellent concurrency support.

      ## Why Learn Go?

      - **Simple and Clean Syntax** - Easy to learn and read
      - **Fast Compilation** - Compiles to native machine code
      - **Built-in Concurrency** - Goroutines and channels make concurrent programming easy
      - **Strong Standard Library** - Rich set of packages for common tasks
      - **Used by Industry Leaders** - Google, Uber, Netflix, Docker, Kubernetes, Dropbox

      ## Your First Go Program

      ```go
      package main

      import "fmt"

      func main() {
          fmt.Println("Hello, World!")
      }
      ```

      Every Go program starts with a package declaration. The `main` package is special - it defines an executable program. The `main()` function is the entry point of your program.

      ## Key Features

      - **Static Typing** - Type safety at compile time
      - **Garbage Collection** - Automatic memory management
      - **Fast Execution** - Compiled to machine code
      - **Cross-Platform** - Write once, compile for any OS
    -
    - 10
    -
    - '2025-11-06 04:09:12.844884'
    - '2025-11-06 04:09:12.844884'
    - "[]"
    -
  - - 13
    - Variables and Types
    - |-
      # Variables and Types in Go

      Go is a statically typed language, meaning variable types are known at compile time.

      ## Declaring Variables

      There are several ways to declare variables in Go:

      ```go
      // Using var keyword with explicit type
      var name string = "John"
      var age int = 30

      // Type inference - Go infers the type
      var city = "New York"

      // Short declaration (inside functions only)
      country := "USA"
      isActive := true
      ```

      ## Basic Types

      **Numeric Types:**
      - `int`, `int8`, `int16`, `int32`, `int64` - Signed integers
      - `uint`, `uint8`, `uint16`, `uint32`, `uint64` - Unsigned integers
      - `float32`, `float64` - Floating point numbers
      - `complex64`, `complex128` - Complex numbers

      **Other Types:**
      - `string` - Text data (UTF-8 encoded)
      - `bool` - true or false
      - `byte` - Alias for uint8
      - `rune` - Alias for int32, represents a Unicode code point

      ## Constants

      Constants are declared with the `const` keyword:

      ```go
      const Pi = 3.14159
      const MaxUsers = 100
      const AppName = "MyApp"
      ```

      ## Zero Values

      Variables without an initial value are given their zero value:
      - `0` for numeric types
      - `false` for boolean
      - `""` (empty string) for strings
      - `nil` for pointers, functions, interfaces, slices, channels, and maps
    -
    - 15
    -
    - '2025-11-06 04:09:12.846299'
    - '2025-11-06 04:09:12.846299'
    - "[]"
    -
  - - 14
    - Functions in Go
    - |-
      # Functions in Go

      Functions are the building blocks of Go programs.

      ## Basic Function Syntax

      ```go
      func functionName(parameter1 type1, parameter2 type2) returnType {
          // function body
          return value
      }
      ```

      ## Examples

      ```go
      // Simple function
      func greet(name string) string {
          return "Hello, " + name
      }

      // Multiple parameters of same type
      func add(x, y int) int {
          return x + y
      }

      // Multiple return values
      func divide(a, b float64) (float64, error) {
          if b == 0 {
              return 0, errors.New("division by zero")
          }
          return a / b, nil
      }
      ```

      ## Named Return Values

      ```go
      func split(sum int) (x, y int) {
          x = sum * 4 / 9
          y = sum - x
          return  // naked return
      }
      ```

      ## Variadic Functions

      Functions can accept a variable number of arguments:

      ```go
      func sum(numbers ...int) int {
          total := 0
          for _, num := range numbers {
              total += num
          }
          return total
      }

      result := sum(1, 2, 3, 4, 5)  // 15
      ```

      ## Anonymous Functions and Closures

      ```go
      // Anonymous function
      multiply := func(x, y int) int {
          return x * y
      }

      result := multiply(3, 4)  // 12
      ```
    -
    - 20
    -
    - '2025-11-06 04:09:12.847497'
    - '2025-11-06 04:09:12.847497'
    - "[]"
    -
  - - 15
    - Arrays and Slices
    - |-
      # Arrays and Slices in Go

      ## Arrays

      Arrays have a fixed size and are declared with a specific length:

      ```go
      // Declare array with 5 elements
      var numbers [5]int
      numbers[0] = 1
      numbers[1] = 2

      // Array literal
      fruits := [3]string{"apple", "banana", "orange"}

      // Let compiler count
      colors := [...]string{"red", "green", "blue"}
      ```

      ## Slices

      Slices are dynamic arrays - they can grow and shrink:

      ```go
      // Create slice
      numbers := []int{1, 2, 3, 4, 5}

      // Add elements
      numbers = append(numbers, 6, 7)

      // Create slice with make
      scores := make([]int, 5)      // length 5, capacity 5
      buffer := make([]int, 5, 10)  // length 5, capacity 10
      ```

      ## Slice Operations

      ```go
      nums := []int{0, 1, 2, 3, 4, 5}

      // Slicing
      first3 := nums[0:3]   // [0, 1, 2]
      middle := nums[2:4]   // [2, 3]
      last2 := nums[4:]     // [4, 5]

      // Length and capacity
      len(nums)  // 6
      cap(nums)  // 6
      ```

      ## Range Loop

      ```go
      fruits := []string{"apple", "banana", "orange"}

      for index, fruit := range fruits {
          fmt.Printf("%d: %s\n", index, fruit)
      }

      // Ignore index with _
      for _, fruit := range fruits {
          fmt.Println(fruit)
      }
      ```
    -
    - 20
    -
    - '2025-11-06 04:09:12.892366'
    - '2025-11-06 04:09:12.892366'
    - "[]"
    -
  - - 16
    - Maps
    - |-
      # Maps in Go

      Maps are key-value pairs, similar to dictionaries or hash tables in other languages.

      ## Creating Maps

      ```go
      // Using make
      ages := make(map[string]int)
      ages["John"] = 30
      ages["Jane"] = 25

      // Map literal
      scores := map[string]int{
          "Alice": 95,
          "Bob":   87,
          "Carol": 92,
      }
      ```

      ## Map Operations

      ```go
      // Access value
      age := ages["John"]

      // Check if key exists
      age, exists := ages["John"]
      if exists {
          fmt.Println("Found:", age)
      }

      // Delete key
      delete(ages, "John")

      // Iterate over map
      for name, score := range scores {
          fmt.Printf("%s: %d\n", name, score)
      }
      ```

      ## Important Notes

      - Maps are reference types
      - Iterating over maps is not guaranteed to be in any order
      - Zero value of a map is `nil`
      - Must initialize map before use (with `make` or literal)

      ```go
      var m map[string]int  // nil map
      // m["key"] = 1       // panic: assignment to nil map

      m = make(map[string]int)  // Now it's safe to use
      m["key"] = 1
      ```
    -
    - 15
    -
    - '2025-11-06 04:09:12.893914'
    - '2025-11-06 04:09:12.893914'
    - "[]"
    -
  - - 17
    - Structs
    - |-
      # Structs in Go

      Structs are typed collections of fields - similar to classes in other languages.

      ## Defining Structs

      ```go
      type Person struct {
          Name    string
          Age     int
          Email   string
          IsAdmin bool
      }
      ```

      ## Creating Struct Instances

      ```go
      // Using field names
      p1 := Person{
          Name:  "John Doe",
          Age:   30,
          Email: "john@example.com",
      }

      // Positional (must match order)
      p2 := Person{"Jane Doe", 25, "jane@example.com", false}

      // New returns pointer
      p3 := new(Person)
      p3.Name = "Bob"
      ```

      ## Accessing Fields

      ```go
      fmt.Println(p1.Name)  // John Doe
      p1.Age = 31           // Modify field
      ```

      ## Anonymous Structs

      ```go
      point := struct {
          X int
          Y int
      }{
          X: 10,
          Y: 20,
      }
      ```

      ## Embedded Structs

      ```go
      type Address struct {
          Street string
          City   string
      }

      type Employee struct {
          Person          // Embedded
          Address         // Embedded
          EmployeeID int
      }

      emp := Employee{
          Person:     Person{Name: "John", Age: 30},
          Address:    Address{City: "NYC"},
          EmployeeID: 12345,
      }

      // Access embedded fields directly
      fmt.Println(emp.Name)  // From Person
      fmt.Println(emp.City)  // From Address
      ```
    -
    - 20
    -
    - '2025-11-06 04:09:12.895127'
    - '2025-11-06 04:09:12.895127'
    - "[]"
    -
  - - 18
    - Methods
    - |-
      # Methods in Go

      Methods are functions with a special receiver argument.

      ## Defining Methods

      ```go
      type Rectangle struct {
          Width  float64
          Height float64
      }

      // Method with value receiver
      func (r Rectangle) Area() float64 {
          return r.Width * r.Height
      }

      // Method with pointer receiver
      func (r *Rectangle) Scale(factor float64) {
          r.Width *= factor
          r.Height *= factor
      }
      ```

      ## Using Methods

      ```go
      rect := Rectangle{Width: 10, Height: 5}

      area := rect.Area()     // 50
      rect.Scale(2)           // Modifies rect
      area = rect.Area()      // 200
      ```

      ## Value vs Pointer Receivers

      **Value Receiver:**
      - Operates on a copy
      - Cannot modify the original
      - Use when method doesn't need to modify receiver

      **Pointer Receiver:**
      - Operates on the original
      - Can modify the receiver
      - Use when method needs to modify receiver or receiver is large

      ```go
      type Counter struct {
          count int
      }

      // Pointer receiver to modify state
      func (c *Counter) Increment() {
          c.count++
      }

      // Value receiver for read-only
      func (c Counter) Value() int {
          return c.count
      }
      ```
    -
    - 20
    -
    - '2025-11-06 04:09:12.911715'
    - '2025-11-06 04:09:12.911715'
    - "[]"
    -
  - - 19
    - Interfaces
    - |-
      # Interfaces in Go

      Interfaces define behavior - a set of method signatures.

      ## Defining Interfaces

      ```go
      type Shape interface {
          Area() float64
          Perimeter() float64
      }
      ```

      ## Implementing Interfaces

      Go uses implicit implementation - no "implements" keyword needed:

      ```go
      type Circle struct {
          Radius float64
      }

      func (c Circle) Area() float64 {
          return 3.14159 * c.Radius * c.Radius
      }

      func (c Circle) Perimeter() float64 {
          return 2 * 3.14159 * c.Radius
      }

      type Rectangle struct {
          Width, Height float64
      }

      func (r Rectangle) Area() float64 {
          return r.Width * r.Height
      }

      func (r Rectangle) Perimeter() float64 {
          return 2 * (r.Width + r.Height)
      }
      ```

      ## Using Interfaces

      ```go
      func PrintShapeInfo(s Shape) {
          fmt.Printf("Area: %.2f\n", s.Area())
          fmt.Printf("Perimeter: %.2f\n", s.Perimeter())
      }

      circle := Circle{Radius: 5}
      rect := Rectangle{Width: 10, Height: 5}

      PrintShapeInfo(circle)  // Works!
      PrintShapeInfo(rect)    // Works!
      ```

      ## Empty Interface

      ```go
      // interface{} accepts any type
      func PrintAnything(value interface{}) {
          fmt.Println(value)
      }

      PrintAnything(42)
      PrintAnything("hello")
      PrintAnything(true)
      ```

      ## Type Assertions

      ```go
      var i interface{} = "hello"

      s := i.(string)        // Type assertion
      fmt.Println(s)         // hello

      s, ok := i.(string)    // Safe type assertion
      if ok {
          fmt.Println("It's a string:", s)
      }
      ```
    -
    - 25
    -
    - '2025-11-06 04:09:12.913015'
    - '2025-11-06 04:09:12.913015'
    - "[]"
    -
  - - 20
    - Error Handling
    - "# Error Handling in Go\n\nGo uses explicit error handling with the built-in
      `error` type.\n\n## The Error Interface\n\n```go\ntype error interface {\n    Error()
      string\n}\n```\n\n## Returning Errors\n\n```go\nimport \"errors\"\n\nfunc divide(a,
      b float64) (float64, error) {\n    if b == 0 {\n        return 0, errors.New(\"division
      by zero\")\n    }\n    return a / b, nil\n}\n```\n\n## Checking Errors\n\n```go\nresult,
      err := divide(10, 0)\nif err != nil {\n    fmt.Println(\"Error:\", err)\n    return\n}\nfmt.Println(\"Result:\",
      result)\n```\n\n## Custom Errors\n\n```go\ntype ValidationError struct {\n    Field
      string\n    Issue string\n}\n\nfunc (e *ValidationError) Error() string {\n
      \   return fmt.Sprintf(\"%s: %s\", e.Field, e.Issue)\n}\n\nfunc validateAge(age
      int) error {\n    if age < 0 {\n        return &ValidationError{\n            Field:
      \"age\",\n            Issue: \"must be positive\",\n        }\n    }\n    return
      nil\n}\n```\n\n## Error Wrapping (Go 1.13+)\n\n```go\nimport \"fmt\"\n\nfunc
      readConfig() error {\n    err := openFile(\"config.json\")\n    if err != nil
      {\n        return fmt.Errorf(\"failed to read config: %w\", err)\n    }\n    return
      nil\n}\n\n// Unwrap errors\nerr := readConfig()\nif err != nil {\n    originalErr
      := errors.Unwrap(err)\n}\n```\n\n## Defer, Panic, and Recover\n\n```go\nfunc
      cleanup() {\n    defer func() {\n        if r := recover(); r != nil {\n            fmt.Println(\"Recovered
      from:\", r)\n        }\n    }()\n    \n    // This will panic\n    panic(\"something
      went wrong\")\n}\n```"
    -
    - 25
    -
    - '2025-11-06 04:09:12.914187'
    - '2025-11-06 04:09:12.914187'
    - "[]"
    -
  - - 21
    - Goroutines
    - "# Goroutines - Lightweight Concurrency\n\nGoroutines are lightweight threads
      managed by the Go runtime. They're one of Go's most powerful features!\n\n##
      What are Goroutines?\n\n- Extremely lightweight (start with ~2KB stack)\n- Can
      have thousands running concurrently\n- Multiplexed onto OS threads by Go runtime\n-
      Much cheaper than OS threads\n\n## Creating Goroutines\n\nUse the `go` keyword
      before a function call:\n\n```go\nfunc sayHello() {\n    fmt.Println(\"Hello
      from goroutine!\")\n}\n\nfunc main() {\n    // Launch goroutine\n    go sayHello()\n
      \   \n    // Main continues executing\n    fmt.Println(\"Main function\")\n
      \   \n    // Wait a bit (not ideal, we'll learn better ways)\n    time.Sleep(time.Second)\n}\n```\n\n##
      Anonymous Goroutines\n\n```go\ngo func() {\n    fmt.Println(\"Anonymous goroutine\")\n}()\n\n//
      With parameters\ngo func(msg string) {\n    fmt.Println(msg)\n}(\"Hello!\")\n```\n\n##
      Example: Concurrent Tasks\n\n```go\nfunc fetchUser(id int) {\n    time.Sleep(100
      * time.Millisecond)  // Simulate API call\n    fmt.Printf(\"Fetched user %d\\n\",
      id)\n}\n\nfunc main() {\n    // Launch 5 concurrent fetches\n    for i := 1;
      i <= 5; i++ {\n        go fetchUser(i)\n    }\n    \n    time.Sleep(time.Second)
      \ // Wait for goroutines\n}\n```\n\n## Important Notes\n\n- Main function doesn't
      wait for goroutines\n- If main exits, all goroutines are terminated\n- Need
      synchronization mechanisms (channels, WaitGroups)\n- Goroutines are not guaranteed
      to execute in any order"
    -
    - 20
    -
    - '2025-11-06 04:09:12.926348'
    - '2025-11-06 04:09:12.926348'
    - "[]"
    -
  - - 22
    - Channels
    - "# Channels - Communication Between Goroutines\n\nChannels are the pipes that
      connect concurrent goroutines. They allow you to send and receive values.\n\n##
      Creating Channels\n\n```go\n// Unbuffered channel\nch := make(chan int)\n\n//
      Buffered channel (capacity 5)\nch := make(chan int, 5)\n\n// Channel of strings\nmessages
      := make(chan string)\n```\n\n## Sending and Receiving\n\n```go\nch := make(chan
      int)\n\n// Send to channel\ngo func() {\n    ch <- 42  // Send 42 to channel\n}()\n\n//
      Receive from channel\nvalue := <-ch  // Receive from channel\nfmt.Println(value)
      \ // 42\n```\n\n## Unbuffered Channels (Synchronous)\n\n```go\nch := make(chan
      string)\n\ngo func() {\n    ch <- \"message\"  // Blocks until someone receives\n}()\n\nmsg
      := <-ch  // Blocks until someone sends\nfmt.Println(msg)\n```\n\n## Buffered
      Channels (Asynchronous)\n\n```go\nch := make(chan int, 2)  // Buffer size 2\n\nch
      <- 1  // Doesn't block\nch <- 2  // Doesn't block\n// ch <- 3  // Would block
      - buffer full\n\nfmt.Println(<-ch)  // 1\nfmt.Println(<-ch)  // 2\n```\n\n##
      Closing Channels\n\n```go\nch := make(chan int, 3)\nch <- 1\nch <- 2\nch <-
      3\nclose(ch)  // No more values will be sent\n\n// Receive all values\nfor value
      := range ch {\n    fmt.Println(value)  // 1, 2, 3\n}\n```\n\n## Channel Directions\n\n```go\n//
      Send-only channel\nfunc sender(ch chan<- int) {\n    ch <- 42\n}\n\n// Receive-only
      channel\nfunc receiver(ch <-chan int) {\n    value := <-ch\n    fmt.Println(value)\n}\n```\n\n##
      Example: Worker Pattern\n\n```go\nfunc worker(id int, jobs <-chan int, results
      chan<- int) {\n    for job := range jobs {\n        fmt.Printf(\"Worker %d processing
      job %d\\n\", id, job)\n        time.Sleep(time.Second)\n        results <- job
      * 2\n    }\n}\n\nfunc main() {\n    jobs := make(chan int, 10)\n    results
      := make(chan int, 10)\n    \n    // Start 3 workers\n    for w := 1; w <= 3;
      w++ {\n        go worker(w, jobs, results)\n    }\n    \n    // Send 9 jobs\n
      \   for j := 1; j <= 9; j++ {\n        jobs <- j\n    }\n    close(jobs)\n    \n
      \   // Collect results\n    for a := 1; a <= 9; a++ {\n        <-results\n    }\n}\n```"
    -
    - 30
    -
    - '2025-11-06 04:09:12.927884'
    - '2025-11-06 04:09:12.927884'
    - "[]"
    -
  - - 23
    - Select Statement
    - |-
      # Select Statement - Multiplexing Channels

      The `select` statement lets a goroutine wait on multiple channel operations.

      ## Basic Select

      ```go
      ch1 := make(chan string)
      ch2 := make(chan string)

      go func() {
          time.Sleep(1 * time.Second)
          ch1 <- "from channel 1"
      }()

      go func() {
          time.Sleep(2 * time.Second)
          ch2 <- "from channel 2"
      }()

      select {
      case msg1 := <-ch1:
          fmt.Println(msg1)
      case msg2 := <-ch2:
          fmt.Println(msg2)
      }
      // Prints "from channel 1" (arrives first)
      ```

      ## Select with Default

      ```go
      select {
      case msg := <-ch:
          fmt.Println("Received:", msg)
      default:
          fmt.Println("No message received")
      }
      ```

      ## Timeout Pattern

      ```go
      ch := make(chan string)

      go func() {
          time.Sleep(2 * time.Second)
          ch <- "result"
      }()

      select {
      case res := <-ch:
          fmt.Println(res)
      case <-time.After(1 * time.Second):
          fmt.Println("Timeout!")
      }
      ```

      ## Non-blocking Receive

      ```go
      select {
      case msg := <-ch:
          fmt.Println("Received:", msg)
      default:
          fmt.Println("No data available")
      }
      ```

      ## Non-blocking Send

      ```go
      select {
      case ch <- value:
          fmt.Println("Sent value")
      default:
          fmt.Println("Channel full, dropping value")
      }
      ```
    -
    - 20
    -
    - '2025-11-06 04:09:12.929201'
    - '2025-11-06 04:09:12.929201'
    - "[]"
    -
  - - 24
    - Sync Package - WaitGroups and Mutexes
    - "# Sync Package - Advanced Synchronization\n\n## WaitGroup\n\nWaitGroup waits
      for a collection of goroutines to finish.\n\n```go\nimport \"sync\"\n\nfunc
      worker(id int, wg *sync.WaitGroup) {\n    defer wg.Done()  // Decrement counter
      when done\n    \n    fmt.Printf(\"Worker %d starting\\n\", id)\n    time.Sleep(time.Second)\n
      \   fmt.Printf(\"Worker %d done\\n\", id)\n}\n\nfunc main() {\n    var wg sync.WaitGroup\n
      \   \n    for i := 1; i <= 5; i++ {\n        wg.Add(1)  // Increment counter\n
      \       go worker(i, &wg)\n    }\n    \n    wg.Wait()  // Block until counter
      is 0\n    fmt.Println(\"All workers complete\")\n}\n```\n\n## Mutex - Mutual
      Exclusion\n\nProtect shared data from concurrent access:\n\n```go\ntype SafeCounter
      struct {\n    mu    sync.Mutex\n    count int\n}\n\nfunc (c *SafeCounter) Increment()
      {\n    c.mu.Lock()\n    defer c.mu.Unlock()\n    c.count++\n}\n\nfunc (c *SafeCounter)
      Value() int {\n    c.mu.Lock()\n    defer c.mu.Unlock()\n    return c.count\n}\n\nfunc
      main() {\n    counter := SafeCounter{}\n    var wg sync.WaitGroup\n    \n    //
      Launch 1000 goroutines\n    for i := 0; i < 1000; i++ {\n        wg.Add(1)\n
      \       go func() {\n            defer wg.Done()\n            counter.Increment()\n
      \       }()\n    }\n    \n    wg.Wait()\n    fmt.Println(\"Final count:\", counter.Value())
      \ // 1000\n}\n```\n\n## RWMutex - Read/Write Mutex\n\nAllows multiple readers
      OR one writer:\n\n```go\ntype SafeMap struct {\n    mu   sync.RWMutex\n    data
      map[string]int\n}\n\nfunc (m *SafeMap) Get(key string) (int, bool) {\n    m.mu.RLock()
      \ // Multiple readers OK\n    defer m.mu.RUnlock()\n    val, ok := m.data[key]\n
      \   return val, ok\n}\n\nfunc (m *SafeMap) Set(key string, value int) {\n    m.mu.Lock()
      \ // Exclusive access\n    defer m.mu.Unlock()\n    m.data[key] = value\n}\n```\n\n##
      Once - Run Code Once\n\n```go\nvar once sync.Once\nvar instance *Singleton\n\nfunc
      GetInstance() *Singleton {\n    once.Do(func() {\n        instance = &Singleton{}\n
      \   })\n    return instance\n}\n```"
    -
    - 25
    -
    - '2025-11-06 04:09:12.932646'
    - '2025-11-06 04:09:12.932646'
    - "[]"
    -
  - - 25
    - Context Package
    - "# Context Package - Cancellation and Timeouts\n\nThe context package is used
      to carry deadlines, cancellation signals, and request-scoped values across API
      boundaries.\n\n## Creating Contexts\n\n```go\nimport \"context\"\n\n// Background
      context\nctx := context.Background()\n\n// TODO context\nctx := context.TODO()\n\n//
      With timeout\nctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)\ndefer
      cancel()\n\n// With deadline\ndeadline := time.Now().Add(10 * time.Second)\nctx,
      cancel := context.WithDeadline(context.Background(), deadline)\ndefer cancel()\n\n//
      With cancellation\nctx, cancel := context.WithCancel(context.Background())\ndefer
      cancel()\n```\n\n## Using Context\n\n```go\nfunc doWork(ctx context.Context)
      error {\n    for {\n        select {\n        case <-ctx.Done():\n            return
      ctx.Err()  // Cancelled or timed out\n        default:\n            // Do work\n
      \           time.Sleep(100 * time.Millisecond)\n        }\n    }\n}\n\nfunc
      main() {\n    ctx, cancel := context.WithTimeout(context.Background(), 2*time.Second)\n
      \   defer cancel()\n    \n    if err := doWork(ctx); err != nil {\n        fmt.Println(\"Work
      failed:\", err)\n    }\n}\n```\n\n## Context Values\n\n```go\ntype key string\n\nconst
      userIDKey key = \"userID\"\n\nfunc setUserID(ctx context.Context, userID int)
      context.Context {\n    return context.WithValue(ctx, userIDKey, userID)\n}\n\nfunc
      getUserID(ctx context.Context) (int, bool) {\n    userID, ok := ctx.Value(userIDKey).(int)\n
      \   return userID, ok\n}\n```"
    -
    - 20
    -
    - '2025-11-06 04:09:12.953814'
    - '2025-11-06 04:09:12.953814'
    - "[]"
    -
  - - 26
    - Common Concurrency Patterns
    - "# Concurrency Patterns in Go\n\n## 1. Fan-Out, Fan-In\n\nDistribute work to
      multiple goroutines, then combine results:\n\n```go\nfunc fanOut(input <-chan
      int, workers int) []<-chan int {\n    channels := make([]<-chan int, workers)\n
      \   for i := 0; i < workers; i++ {\n        channels[i] = worker(input)\n    }\n
      \   return channels\n}\n\nfunc fanIn(channels ...<-chan int) <-chan int {\n
      \   out := make(chan int)\n    var wg sync.WaitGroup\n    \n    for _, ch :=
      range channels {\n        wg.Add(1)\n        go func(c <-chan int) {\n            defer
      wg.Done()\n            for val := range c {\n                out <- val\n            }\n
      \       }(ch)\n    }\n    \n    go func() {\n        wg.Wait()\n        close(out)\n
      \   }()\n    \n    return out\n}\n```\n\n## 2. Pipeline\n\nChain multiple stages
      of processing:\n\n```go\nfunc generator(nums ...int) <-chan int {\n    out :=
      make(chan int)\n    go func() {\n        for _, n := range nums {\n            out
      <- n\n        }\n        close(out)\n    }()\n    return out\n}\n\nfunc square(in
      <-chan int) <-chan int {\n    out := make(chan int)\n    go func() {\n        for
      n := range in {\n            out <- n * n\n        }\n        close(out)\n    }()\n
      \   return out\n}\n\nfunc main() {\n    // Pipeline: generate -> square\n    c
      := generator(2, 3, 4)\n    out := square(c)\n    \n    for result := range out
      {\n        fmt.Println(result)  // 4, 9, 16\n    }\n}\n```\n\n## 3. Worker Pool\n\n```go\nfunc
      workerPool(jobs <-chan int, results chan<- int, workers int) {\n    var wg sync.WaitGroup\n
      \   \n    for i := 0; i < workers; i++ {\n        wg.Add(1)\n        go func()
      {\n            defer wg.Done()\n            for job := range jobs {\n                results
      <- job * 2  // Process job\n            }\n        }()\n    }\n    \n    wg.Wait()\n
      \   close(results)\n}\n```\n\n## 4. Rate Limiting\n\n```go\nfunc rateLimiter()
      {\n    limiter := time.Tick(100 * time.Millisecond)\n    \n    for i := 0; i
      < 5; i++ {\n        <-limiter  // Wait for tick\n        fmt.Println(\"Request\",
      i)\n    }\n}\n```"
    -
    - 25
    -
    - '2025-11-06 04:09:12.955118'
    - '2025-11-06 04:09:12.955118'
    - "[]"
    -
  - - 27
    - Docker Networking Basics
    - |
      # Docker Networking Basics

      Docker networking allows containers to communicate with each other and the outside world.

      ## Network Types

      Docker provides several network drivers:

      ### Bridge (default)
      - Containers on same host can communicate
      - Isolated from host network
      - Best for standalone containers

      ### Host
      - Container uses host's network stack
      - No network isolation
      - Better performance, less isolation

      ### None
      - No networking
      - Complete isolation
      - Use for security-sensitive workloads

      ### Custom Networks
      - User-defined bridge networks
      - Automatic DNS resolution
      - Better isolation control

      ## Port Mapping

      Expose container ports to the host:

      ```bash
      # Map container port 80 to host port 8080
      docker run -p 8080:80 nginx

      # Map all exposed ports
      docker run -P nginx

      # Bind to specific host IP
      docker run -p 127.0.0.1:8080:80 nginx
      ```

      ## Container Communication

      ```bash
      # Create custom network
      docker network create mynetwork

      # Run containers on custom network
      docker run -d --name web --network mynetwork nginx
      docker run -d --name api --network mynetwork node:18

      # Containers can reach each other by name
      # web can reach api at http://api:3000
      ```
    -
    - 15
    - '["Bridge networks","Port mapping","Custom networks","DNS resolution"]'
    - '2025-11-06 07:32:44.034296'
    - '2025-11-06 07:32:44.034296'
    - "[]"
    - '"[]"'
  - - 28
    - Understanding Volumes
    - |
      # Understanding Volumes

      Containers are ephemeral by default - when deleted, their data is lost. Volumes solve this problem.

      ## Volume Types

      ### Named Volumes (Recommended)
      - Managed by Docker
      - Stored in Docker's storage area
      - Easy to backup and migrate

      ```bash
      docker volume create mydata
      docker run -v mydata:/app/data nginx
      ```

      ### Bind Mounts
      - Mount host directory into container
      - Full host path required
      - Good for development

      ```bash
      docker run -v /host/path:/container/path nginx
      ```

      ### tmpfs Mounts
      - Stored in host memory
      - Temporary, lost on stop
      - Fast, secure for sensitive data

      ## Volume Commands

      ```bash
      # List volumes
      docker volume ls

      # Inspect volume
      docker volume inspect mydata

      # Remove volume
      docker volume rm mydata

      # Prune unused volumes
      docker volume prune
      ```

      ## Best Practices
      1. Use named volumes for production data
      2. Use bind mounts for development
      3. Never store data in container's writable layer
      4. Backup volumes regularly
    -
    - 15
    - '["Named volumes","Bind mounts","Data persistence","Volume management"]'
    - '2025-11-06 07:32:44.040832'
    - '2025-11-06 07:32:44.040832'
    - "[]"
    - '"[]"'
  - - 29
    - Introduction to Docker Compose
    - |
      # Introduction to Docker Compose

      ## What is Docker Compose?

      Docker Compose is a tool for defining and running multi-container applications using a YAML file.

      ## Benefits

      - **Declarative**: Define entire stack in one file
      - **Reproducible**: Same setup everywhere
      - **Simple**: One command to start everything
      - **Version Control**: Track infrastructure as code

      ## Basic docker-compose.yml

      ```yaml
      version: '3.8'
      services:
        web:
          image: nginx:alpine
          ports:
            - "8080:80"
        db:
          image: postgres:alpine
          environment:
            POSTGRES_PASSWORD: secret
      ```

      ## Common Commands

      ```bash
      docker-compose up -d      # Start services
      docker-compose down       # Stop and remove
      docker-compose ps         # List services
      docker-compose logs -f    # View logs
      ```
    -
    - 30
    - '["docker-compose","orchestration","yaml","services"]'
    - '2025-11-06 07:32:44.046061'
    - '2025-11-06 08:20:50.355607'
    - "[]"
    - '"[]"'
  - - 30
    - Security Best Practices
    - |
      # Security Best Practices

      ## Image Security

      1. **Use Official Base Images**
         - Start with official, verified images
         - Check image signatures
         - Use minimal base images (Alpine, Distroless)

      2. **Don't Run as Root**
      ```dockerfile
      FROM node:18-alpine
      RUN addgroup -S appgroup && adduser -S appuser -G appgroup
      USER appuser
      ```

      3. **Scan for Vulnerabilities**
      ```bash
      docker scan myimage:latest
      ```

      ## Runtime Security

      1. **Limit Container Capabilities**
      ```bash
      docker run --cap-drop ALL --cap-add NET_BIND_SERVICE nginx
      ```

      2. **Use Read-Only Filesystems**
      ```bash
      docker run --read-only nginx
      ```

      3. **Set Resource Limits**
      ```bash
      docker run --memory=512m --cpus=1 nginx
      ```

      ## Secrets Management

      - Never hardcode secrets in images
      - Use Docker secrets or external vaults
      - Rotate credentials regularly

      ```bash
      echo "mypassword" | docker secret create db_password -
      docker service create --secret db_password myapp
      ```
    -
    - 20
    - '["Image security","Non-root users","Resource limits","Secrets management"]'
    - '2025-11-06 07:32:44.054268'
    - '2025-11-06 07:32:44.054268'
    - "[]"
    - '"[]"'
  - - 31
    - Containers vs Virtual Machines
    - |
      # Containers vs Virtual Machines

      ## The Virtualization Spectrum

      Both containers and virtual machines (VMs) provide isolation, but they do it differently:

      ```
      Physical Hardware → Virtualization Layer → Isolated Environments
      ```

      Let's understand the key differences.

      ## Architecture Comparison

      ### Virtual Machines

      ```
      ┌─────────────────────────────────────┐
      │         Application 1               │
      ├─────────────────────────────────────┤
      │         Guest OS (Full)             │
      ├─────────────────────────────────────┤
      │         Hypervisor                  │
      ├─────────────────────────────────────┤
      │         Host OS                     │
      ├─────────────────────────────────────┤
      │         Physical Hardware           │
      └─────────────────────────────────────┘
      ```

      **Each VM includes:**
      - Full operating system
      - Kernel
      - Systemd/init system
      - All system libraries

      ### Containers

      ```
      ┌─────────────────────────────────────┐
      │         Application 1               │
      ├─────────────────────────────────────┤
      │      Container Runtime (Docker)     │
      ├─────────────────────────────────────┤
      │         Host OS (Shared)            │
      ├─────────────────────────────────────┤
      │         Physical Hardware           │
      └─────────────────────────────────────┘
      ```

      **Each container includes:**
      - Application code
      - App-specific libraries only
      - **Shares host OS kernel**

      ## Key Differences

      | Aspect | Virtual Machines | Containers |
      |--------|-----------------|------------|
      | **Start Time** | Minutes | Seconds |
      | **Size** | GBs (5-20 GB typical) | MBs (50-500 MB typical) |
      | **Resource Usage** | Heavy | Lightweight |
      | **Isolation** | Hardware-level (stronger) | Process-level |
      | **OS** | Full OS per VM | Shared host OS |
      | **Density** | 10-50 per host | 100-1000+ per host |
      | **Boot Process** | Full OS boot | Process spawn |

      ## Performance Comparison

      ### Startup Speed
      ```
      VM:        Start → Boot OS → Load services → Ready (60-120s)
      Container: Start → Ready (1-3s)
      ```

      ### Resource Overhead
      ```
      Running 10 Web Applications:

      VMs:        10 GB RAM + 10 OS kernels = 40+ GB total
      Containers: 10 GB RAM + 1 OS kernel  = 12 GB total
      ```

      ## When to Use Virtual Machines

      ✅ **Use VMs when you need:**
      - Strong security isolation
      - Different operating systems on same host
      - Full OS-level control
      - Running legacy applications
      - Hardware-level virtualization

      **Example**: Multi-tenant cloud hosting where customers need complete OS isolation

      ## When to Use Containers

      ✅ **Use Containers when you need:**
      - Fast deployment and scaling
      - Microservices architecture
      - CI/CD pipelines
      - Development consistency
      - Maximum resource efficiency

      **Example**: Modern web applications with multiple services

      ## Can You Use Both?

      **Absolutely!** Many organizations run containers inside VMs:

      ```
      Cloud Provider (AWS/Azure/GCP)
          ↓
      Virtual Machine (EC2/VM)
          ↓
      Docker Engine
          ↓
      Multiple Containers
      ```

      This provides:
      - Strong isolation (VM)
      - Fast deployment (Containers)
      - Best of both worlds

      ## The Hybrid Approach

      ```
      Production Infrastructure:
      ├─ VM 1 (Web Tier)
      │  ├─ Container: Frontend (React)
      │  └─ Container: API Gateway (Node.js)
      ├─ VM 2 (Application Tier)
      │  ├─ Container: User Service (Python)
      │  └─ Container: Product Service (Go)
      └─ VM 3 (Data Tier)
         └─ Container: PostgreSQL
      ```

      ## Security Considerations

      ### VM Isolation (Stronger)
      - Complete OS separation
      - Harder to escape to host
      - Better for untrusted workloads

      ### Container Isolation (Good, but requires care)
      - Shares kernel with host
      - Proper configuration essential
      - Use security best practices

      ## Cost Implications

      **VMs:**
      - Higher infrastructure costs
      - More hardware required
      - Better for steady-state workloads

      **Containers:**
      - Lower infrastructure costs
      - Higher density = better ROI
      - Better for variable workloads

      ## Real-World Example

      **Netflix:**
      - Runs containers inside AWS VMs
      - Gets security from VMs
      - Gets agility from containers
      - Handles billions of requests

      ## The Future: Hybrid

      Modern infrastructure often combines:
      - **VMs** for isolation and security boundaries
      - **Containers** for application deployment
      - **Orchestration** (Kubernetes) to manage it all

      ## Summary

      Containers and VMs serve different purposes:
      - VMs: Strong isolation, full OS control
      - Containers: Fast, efficient, portable

      **The best solution?** Often it's using both together!

      ## What's Next?

      Now that you understand containers and how they differ from VMs, let's dive into Docker - the most popular container platform.
    -
    - 15
    - '["virtual machines","architecture","performance","isolation","security"]'
    - '2025-11-06 08:09:17.920617'
    - '2025-11-06 08:09:17.920617'
    - "[]"
    - '"[]"'
  - - 32
    - Introduction to Docker
    - |
      # Introduction to Docker

      ## What is Docker?

      **Docker** is an open-source platform that automates the deployment of applications inside containers. It's the most popular containerization tool in the world.

      > "Docker makes containers easy to create, deploy, and run."

      ## Docker History

      - **2013**: Docker Inc. releases Docker as open source
      - **2015**: Docker Compose and Docker Swarm launched
      - **2016**: Docker reaches 10 billion container downloads
      - **2020**: Docker Desktop has 2+ million users
      - **Today**: Industry standard for containerization

      ## Docker Architecture

      Docker uses a **client-server architecture**:

      ```
      ┌──────────────┐         ┌──────────────────┐
      │ Docker CLI   │────────▶│ Docker Daemon    │
      │ (Client)     │         │ (Server)         │
      └──────────────┘         └──────────────────┘
                                        │
                                        ▼
                               ┌──────────────────┐
                               │  Containers       │
                               │  Images           │
                               │  Networks         │
                               │  Volumes          │
                               └──────────────────┘
      ```

      ## Core Components

      ### 1. Docker Daemon (`dockerd`)
      - Background service that manages Docker objects
      - Creates and runs containers
      - Manages images, networks, volumes
      - Listens for Docker API requests

      ### 2. Docker Client (`docker`)
      - Command-line interface you interact with
      - Sends commands to Docker daemon
      - Can connect to remote daemons

      ### 3. Docker Registry
      - Stores Docker images
      - Docker Hub: public registry
      - Private registries: AWS ECR, Azure ACR, Google GCR

      ### 4. Docker Objects

      **Images:**
      - Read-only templates for creating containers
      - Built from Dockerfiles
      - Can be shared via registries

      **Containers:**
      - Runnable instances of images
      - Can be started, stopped, moved, deleted
      - Isolated from other containers

      **Networks:**
      - Enable container communication
      - Multiple network drivers available
      - Can be user-defined or default

      **Volumes:**
      - Persistent data storage
      - Survive container deletion
      - Shared between containers

      ## How Docker Works

      ### Workflow:
      ```
      1. Write Dockerfile
           ↓
      2. Build Image
           ↓
      3. Push to Registry (optional)
           ↓
      4. Pull Image
           ↓
      5. Run Container
      ```

      ### Example Flow:
      ```bash
      # 1. Build an image
      docker build -t myapp:v1 .

      # 2. Run a container
      docker run -d -p 8080:80 myapp:v1

      # 3. Check running containers
      docker ps

      # 4. View logs
      docker logs <container-id>

      # 5. Stop container
      docker stop <container-id>
      ```

      ## Docker Engine Components

      ```
      ┌─────────────────────────────────────┐
      │         Docker CLI                  │
      └─────────────────────────────────────┘
                    │
                    ▼
      ┌─────────────────────────────────────┐
      │      Docker REST API                │
      └─────────────────────────────────────┘
                    │
                    ▼
      ┌─────────────────────────────────────┐
      │         Docker Daemon               │
      │  ┌──────────────────────────────┐   │
      │  │      containerd              │   │
      │  │  ┌────────────────────────┐  │   │
      │  │  │       runc             │  │   │
      │  │  │ (Container Runtime)    │  │   │
      │  │  └────────────────────────┘  │   │
      │  └──────────────────────────────┘   │
      └─────────────────────────────────────┘
      ```

      - **Docker CLI**: User interface
      - **REST API**: Communication protocol
      - **Docker Daemon**: Core engine
      - **containerd**: Container lifecycle management
      - **runc**: Low-level container runtime

      ## Docker Desktop vs Docker Engine

      ### Docker Engine (Linux)
      - Server-side daemon
      - CLI tools
      - Runs on Linux natively

      ### Docker Desktop (Windows/Mac)
      - Docker Engine in a VM
      - GUI dashboard
      - Easier installation
      - Better developer experience

      ## Docker Hub

      **The world's largest container registry:**
      - 100,000+ official images
      - Millions of community images
      - Free public repositories
      - Paid private repositories

      Popular images:
      - `nginx`: Web server
      - `mysql`: Database
      - `python`: Python runtime
      - `node`: Node.js runtime
      - `ubuntu`: Ubuntu OS

      ## Docker Commands Overview

      ```bash
      # Container Management
      docker run          # Create and start container
      docker ps           # List running containers
      docker stop         # Stop container
      docker rm           # Remove container

      # Image Management
      docker images       # List images
      docker pull         # Download image
      docker build        # Build image
      docker push         # Upload image

      # System Information
      docker version      # Show Docker version
      docker info         # Display system info
      docker help         # Get help
      ```

      ## Docker Editions

      ### Docker Community Edition (CE)
      - Free and open source
      - Ideal for developers
      - Regular updates

      ### Docker Enterprise Edition (EE)
      - Paid version
      - Enterprise support
      - Additional security features
      - Advanced management

      ## Why Docker Became Popular

      1. **Ease of Use**: Simple commands, great documentation
      2. **Ecosystem**: Huge community and image library
      3. **Portability**: Run anywhere Docker runs
      4. **Developer Productivity**: Fast iteration cycles
      5. **DevOps Enabler**: Bridge between dev and ops
      6. **Open Source**: Transparent and extensible

      ## Docker vs Other Container Tools

      | Tool | Focus | Pros |
      |------|-------|------|
      | **Docker** | Developer experience | Easy, popular, mature |
      | **Podman** | Daemonless containers | No root required |
      | **LXC/LXD** | System containers | Full OS containers |
      | **rkt** | Security | Strong isolation (deprecated) |

      ## Real-World Docker Usage

      **Companies using Docker:**
      - PayPal: 700+ applications containerized
      - Spotify: Deploys 10,000+ containers daily
      - Uber: Entire platform runs on containers
      - Netflix: Thousands of containers in production

      ## Docker Certification

      **Docker Certified Associate (DCA):**
      - Official Docker certification
      - Validates container expertise
      - Covers Docker fundamentals to orchestration
      - Industry-recognized credential

      This bootcamp prepares you for the DCA exam!

      ## Summary

      Docker is:
      - Industry-standard container platform
      - Client-server architecture
      - Consists of daemon, CLI, registry, objects
      - Makes containerization accessible
      - Foundation for modern DevOps

      ## What's Next?

      Now that you understand Docker's architecture, let's clarify the relationship between Docker images and containers - a crucial concept.
    -
    - 20
    - '["docker","architecture","daemon","client-server","docker-hub"]'
    - '2025-11-06 08:09:17.922830'
    - '2025-11-06 08:09:17.922830'
    - "[]"
    - '"[]"'
  - - 33
    - Understanding Images vs Containers
    - "# Understanding Images vs Containers\n\n## The Core Concept\n\nOne of the most
      important concepts in Docker is understanding the relationship between **images**
      and **containers**.\n\n```\nImage (Template) ──────▶ Container (Running Instance)\n
      \  \U0001F4E6                         \U0001F3C3\n```\n\n## What is a Docker
      Image?\n\nA Docker image is a **read-only template** containing:\n- Application
      code\n- Runtime environment\n- System libraries\n- Dependencies\n- Configuration
      files\n- Metadata\n\nThink of it like:\n- \U0001F4F8 A photograph (static snapshot)\n-
      \U0001F4DD A recipe (instructions)\n- \U0001F4BF An ISO file (template)\n\n###
      Image Characteristics:\n- ✅ Immutable (cannot be changed)\n- ✅ Shareable (can
      be distributed)\n- ✅ Layered (built in layers)\n- ✅ Reusable (create many containers)\n\n##
      What is a Docker Container?\n\nA Docker container is a **running instance**
      of an image:\n- Active process\n- Writable filesystem layer\n- Network configuration\n-
      Resource allocation\n\nThink of it like:\n- \U0001F3AC A running program\n-
      \U0001F370 A cake baked from a recipe\n- \U0001F4BB A booted operating system\n\n###
      Container Characteristics:\n- ✅ Mutable (can be modified)\n- ✅ Ephemeral (temporary
      by default)\n- ✅ Isolated (runs independently)\n- ✅ Stateful (holds runtime
      data)\n\n## The Relationship\n\n```\nOne Image → Many Containers\n\nnginx:latest
      (Image)\n     │\n     ├─────▶ Container 1 (web-server-1)\n     ├─────▶ Container
      2 (web-server-2)\n     └─────▶ Container 3 (web-server-3)\n```\n\n### Analogy:
      Class vs Objects\n```java\n// Image is like a Class definition\nclass WebServer
      {\n  // Template definition\n}\n\n// Containers are like Object instances\nWebServer
      server1 = new WebServer();\nWebServer server2 = new WebServer();\nWebServer
      server3 = new WebServer();\n```\n\n## Image Layers\n\nImages are built in **layers**,
      like a stack:\n\n```\n┌────────────────────────────┐\n│  Application Layer         │
      ← Your code\n├────────────────────────────┤\n│  Dependencies Layer        │
      ← npm install\n├────────────────────────────┤\n│  Node.js Layer             │
      ← node:14\n├────────────────────────────┤\n│  Base OS Layer             │ ←
      Ubuntu\n└────────────────────────────┘\n```\n\nEach layer is:\n- Read-only\n-
      Cached for efficiency\n- Shared between images\n\n### Benefits of Layers:\n1.
      **Efficient Storage**: Shared layers save space\n2. **Fast Builds**: Cached
      layers speed up rebuilds\n3. **Quick Distribution**: Only changed layers transfer\n\n##
      Container Writable Layer\n\nWhen you run a container, Docker adds a thin **writable
      layer** on top:\n\n```\n┌────────────────────────────┐\n│  Writable Layer (NEW!)
      \    │ ← Container changes\n├────────────────────────────┤\n│  Application Layer
      \        │ ← Read-only\n├────────────────────────────┤\n│  Dependencies Layer
      \       │ ← Read-only\n├────────────────────────────┤\n│  Runtime Layer             │
      ← Read-only\n└────────────────────────────┘\n```\n\n- Writable layer stores
      container-specific changes\n- Deleted when container is removed\n- Does NOT
      modify the image\n\n## Lifecycle Comparison\n\n### Image Lifecycle:\n```\nBuild
      → Tag → Push → Pull → Delete\n   ↓\nExists until explicitly deleted\n```\n\n###
      Container Lifecycle:\n```\nCreate → Start → Stop → Restart → Remove\n   ↓\nEphemeral
      - designed to be temporary\n```\n\n## Commands Comparison\n\n### Image Commands:\n```bash\ndocker
      images          # List images\ndocker pull nginx      # Download image\ndocker
      build -t app .  # Build image\ndocker rmi nginx       # Remove image\ndocker
      image inspect   # View image details\n```\n\n### Container Commands:\n```bash\ndocker
      ps              # List running containers\ndocker run nginx       # Create &
      start container\ndocker stop web        # Stop container\ndocker rm web          #
      Remove container\ndocker container inspect # View container details\n```\n\n##
      Image Naming Convention\n\n```\nregistry/repository:tag\n\nExample: docker.io/library/nginx:1.21-alpine\n
      \        │        │      │     │\n         │        │      │     └─ Tag (version)\n
      \        │        │      └─────── Image name\n         │        └──────────────
      Repository\n         └─────────────────────── Registry\n```\n\n### Common Patterns:\n```\nnginx
      \                 # Official image, latest tag\nnginx:1.21             # Specific
      version\nnginx:alpine           # Alpine Linux variant\nmyuser/myapp:v1        #
      User repository\ngcr.io/project/app:1.0 # Google Container Registry\n```\n\n##
      Image Size Matters\n\n```\nubuntu:latest         → 77 MB\nubuntu:20.04          →
      77 MB\nalpine:latest         → 5 MB    ← Smallest!\nnode:14               →
      942 MB\nnode:14-alpine        → 117 MB  ← Much smaller!\n```\n\n**Best Practice**:
      Use Alpine-based images for smaller sizes\n\n## Image vs Container Storage\n\n###
      Where are they stored?\n\n**Images:**\n```\n/var/lib/docker/image/\n/var/lib/docker/overlay2/\n```\n\n**Containers:**\n```\n/var/lib/docker/containers/\n```\n\n##
      Practical Example\n\nLet's see the relationship in action:\n\n```bash\n# 1.
      Pull an image (download template)\n$ docker pull nginx:alpine\n\n# 2. List images\n$
      docker images\nREPOSITORY   TAG      SIZE\nnginx        alpine   23.4MB\n\n#
      3. Create multiple containers from same image\n$ docker run -d --name web1 nginx:alpine\n$
      docker run -d --name web2 nginx:alpine\n$ docker run -d --name web3 nginx:alpine\n\n#
      4. List containers\n$ docker ps\nCONTAINER ID   IMAGE          NAMES\nabc123...
      \     nginx:alpine   web1\ndef456...      nginx:alpine   web2\nghi789...      nginx:alpine
      \  web3\n\n# 5. Each container is independent\n$ docker exec web1 hostname  #
      Returns: abc123...\n$ docker exec web2 hostname  # Returns: def456...\n```\n\n##
      Key Differences Summary\n\n| Aspect | Image | Container |\n|--------|-------|-----------|\n|
      **Nature** | Template | Running instance |\n| **State** | Immutable | Mutable
      |\n| **Storage** | Permanent | Ephemeral |\n| **Quantity** | One per application
      | Many per image |\n| **File System** | Read-only layers | Read-only + writable
      layer |\n| **Purpose** | Distribution | Execution |\n| **Creation** | Build/Pull
      | Run |\n\n## Common Misunderstandings\n\n❌ **Myth**: \"Deleting a container
      deletes the image\"\n✅ **Truth**: Images and containers are independent\n\n❌
      **Myth**: \"Changes to a container modify the image\"\n✅ **Truth**: Container
      changes only affect that container\n\n❌ **Myth**: \"I need to rebuild the image
      to run another container\"\n✅ **Truth**: One image can spawn unlimited containers\n\n##
      When Do You Need Images?\n\nYou need images when:\n- Sharing applications\n-
      Deploying to production\n- Version controlling applications\n- Distributing
      software\n\n## When Do You Need Containers?\n\nYou need containers when:\n-
      Running applications\n- Testing code\n- Development environments\n- Production
      workloads\n\n## The Big Picture\n\n```\nDeveloper Workflow:\n\n1. Write Code\n
      \    ↓\n2. Create Dockerfile (defines image)\n     ↓\n3. Build Image (docker
      build)\n     ↓\n4. Push to Registry (docker push)\n     ↓\n5. Pull Image on
      Server (docker pull)\n     ↓\n6. Run Container (docker run)\n     ↓\n7. Application
      Running!\n```\n\n## Summary\n\n- **Images** are templates (recipes)\n- **Containers**
      are running instances (cakes)\n- One image → many containers\n- Images are immutable,
      containers are mutable\n- Images are permanent, containers are ephemeral\n-
      Understanding this relationship is crucial for Docker mastery\n\n## What's Next?\n\nNow
      that you understand the theory, it's time to get hands-on! In the next lab,
      you'll run your first Docker container and experience these concepts firsthand.\n"
    -
    - 20
    - '["images","containers","layers","lifecycle","immutability"]'
    - '2025-11-06 08:09:17.924702'
    - '2025-11-06 08:09:17.924702'
    - "[]"
    - '"[]"'
  - - 34
    - Docker Run Command Deep Dive
    - |
      # Docker Run Command Deep Dive

      The `docker run` command is the cornerstone of Docker. It combines image pulling, container creation, and container startup into one powerful command.

      ## Basic Syntax
      ```bash
      docker run [OPTIONS] IMAGE [COMMAND] [ARG...]
      ```

      ## Essential Options

      **Detached Mode (-d)**
      ```bash
      docker run -d nginx
      # Runs in background, returns container ID
      ```

      **Interactive Terminal (-it)**
      ```bash
      docker run -it ubuntu bash
      # Opens interactive shell inside container
      ```

      **Port Mapping (-p)**
      ```bash
      docker run -p 8080:80 nginx
      # Maps host port 8080 to container port 80
      ```

      **Named Containers (--name)**
      ```bash
      docker run --name my-web nginx
      # Easier to reference than container ID
      ```

      **Environment Variables (-e)**
      ```bash
      docker run -e NODE_ENV=production node
      # Sets environment variables inside container
      ```

      **Auto-remove (--rm)**
      ```bash
      docker run --rm alpine echo "hello"
      # Container automatically removed after exit
      ```

      ## Best Practices

      1. **Always name production containers**
      2. **Use specific image tags** (not :latest)
      3. **Set resource limits** (--memory, --cpus)
      4. **Use health checks** (--health-cmd)
      5. **Implement restart policies** (--restart)
    -
    - 20
    - '["docker-run","container-options","detached-mode","port-mapping"]'
    - '2025-11-06 08:13:01.770099'
    - '2025-11-06 08:13:01.770099'
    - "[]"
    - '"[]"'
  - - 35
    - Container Lifecycle Management
    - |
      # Container Lifecycle Management

      Understanding the container lifecycle is crucial for effective Docker usage.

      ## Container States

      ```
      Created → Running → Paused → Stopped → Removed
      ```

      ## Key Commands

      **Start/Stop**
      ```bash
      docker start container_name
      docker stop container_name    # Graceful (SIGTERM)
      docker kill container_name    # Forceful (SIGKILL)
      ```

      **Restart**
      ```bash
      docker restart container_name
      # Equivalent to stop + start
      ```

      **Pause/Unpause**
      ```bash
      docker pause container_name
      docker unpause container_name
      # Freezes processes without stopping
      ```

      **Remove**
      ```bash
      docker rm container_name        # Remove stopped container
      docker rm -f container_name     # Force remove running container
      docker rm $(docker ps -aq)      # Remove all containers
      ```

      ## Restart Policies

      - **no**: Don't automatically restart (default)
      - **on-failure**: Restart on non-zero exit
      - **unless-stopped**: Always restart unless manually stopped
      - **always**: Always restart
    -
    - 15
    - '["lifecycle","container-states","restart-policies"]'
    - '2025-11-06 08:13:01.773193'
    - '2025-11-06 08:13:01.773193'
    - "[]"
    - '"[]"'
  - - 36
    - Inspecting and Monitoring Containers
    - |
      # Inspecting and Monitoring Containers

      ## Viewing Container Details

      **docker inspect**
      ```bash
      docker inspect container_name
      # Returns detailed JSON configuration
      ```

      **docker stats**
      ```bash
      docker stats
      # Real-time resource usage statistics
      ```

      **docker top**
      ```bash
      docker top container_name
      # Shows running processes inside container
      ```

      **docker logs**
      ```bash
      docker logs container_name          # View all logs
      docker logs -f container_name       # Follow logs (tail -f)
      docker logs --tail 100 container_name  # Last 100 lines
      docker logs --since 1h container_name  # Logs from last hour
      ```

      ## Health Checks

      Define health checks in Dockerfile or docker run:
      ```bash
      docker run --health-cmd="curl -f http://localhost/ || exit 1"            --health-interval=30s            nginx
      ```

      ## Best Practices

      1. Always check logs when troubleshooting
      2. Use health checks for production containers
      3. Monitor resource usage with docker stats
      4. Set up centralized logging (ELK, Fluentd)
    -
    - 20
    - '["inspect","monitoring","logs","health-checks"]'
    - '2025-11-06 08:13:01.775336'
    - '2025-11-06 08:13:01.775336'
    - "[]"
    - '"[]"'
  - - 37
    - Executing Commands in Containers
    - |
      # Executing Commands in Containers

      ## docker exec

      Run commands inside running containers:

      **Interactive Shell**
      ```bash
      docker exec -it container_name bash
      # Opens interactive shell (most common use)
      ```

      **Single Commands**
      ```bash
      docker exec container_name ls -la /app
      docker exec container_name cat /etc/hostname
      ```

      **As Different User**
      ```bash
      docker exec -u root container_name apt-get update
      # Execute with elevated privileges
      ```

      ## exec vs attach

      - **exec**: Starts new process in container
      - **attach**: Connects to main process (PID 1)

      ## Common Patterns

      **Database Access**
      ```bash
      docker exec -it mysql-container mysql -u root -p
      ```

      **File Inspection**
      ```bash
      docker exec app-container cat /var/log/app.log
      ```

      **Debugging**
      ```bash
      docker exec -it app-container sh
      # Troubleshoot inside container
      ```
    -
    - 15
    - '["docker-exec","interactive-shell","debugging"]'
    - '2025-11-06 08:13:01.777754'
    - '2025-11-06 08:13:01.777754'
    - "[]"
    - '"[]"'
  - - 38
    - Managing Docker Images
    - |
      # Managing Docker Images

      ## Image Commands

      **List Images**
      ```bash
      docker images
      docker images -a    # Include intermediate images
      ```

      **Pull Images**
      ```bash
      docker pull nginx:alpine
      docker pull ubuntu:20.04
      ```

      **Remove Images**
      ```bash
      docker rmi image_name
      docker rmi $(docker images -q)  # Remove all images
      docker image prune              # Remove dangling images
      ```

      **Tag Images**
      ```bash
      docker tag nginx:alpine myregistry/nginx:v1
      ```

      **Image Information**
      ```bash
      docker image inspect nginx
      docker image history nginx  # Show layer history
      ```

      ## Best Practices

      1. Regularly clean up unused images
      2. Use multi-stage builds for smaller images
      3. Prefer Alpine-based images
      4. Tag images with semantic versions
      5. Scan images for vulnerabilities
    -
    - 15
    - '["images","image-management","tagging","cleanup"]'
    - '2025-11-06 08:13:01.779993'
    - '2025-11-06 08:13:01.779993'
    - "[]"
    - '"[]"'
  - - 39
    - Understanding Image Layers
    - |
      # Understanding Image Layers

      Docker images are built in layers, and understanding this is key to optimization.

      ## Layer Architecture

      Each Dockerfile instruction creates a new layer:

      ```dockerfile
      FROM ubuntu:20.04        # Layer 1: Base OS
      RUN apt-get update       # Layer 2: Update packages
      RUN apt-get install -y nginx  # Layer 3: Install nginx
      COPY app /app            # Layer 4: Add application
      ```

      ## Benefits of Layers

      1. **Efficient Storage**: Layers are shared between images
      2. **Fast Builds**: Unchanged layers use cache
      3. **Quick Distribution**: Only new layers are transferred

      ## Layer Caching

      Docker caches layers during builds. If a layer hasn't changed, Docker reuses it.

      **Cache Busting**: Any change invalidates that layer and all subsequent layers.

      ## Best Practices

      - Order Dockerfile commands from least to most frequently changing
      - Combine commands to reduce layers
      - Use .dockerignore to exclude unnecessary files
    -
    - 25
    - '["layers","caching","optimization"]'
    - '2025-11-06 08:13:01.793857'
    - '2025-11-06 08:13:01.793857'
    - "[]"
    - '"[]"'
  - - 40
    - Dockerfile Syntax and Best Practices
    - |
      # Dockerfile Syntax and Best Practices

      ## Essential Instructions

      **FROM**: Base image
      ```dockerfile
      FROM node:14-alpine
      ```

      **WORKDIR**: Set working directory
      ```dockerfile
      WORKDIR /app
      ```

      **COPY**: Copy files from host
      ```dockerfile
      COPY package*.json ./
      COPY . .
      ```

      **RUN**: Execute commands during build
      ```dockerfile
      RUN npm install
      RUN apt-get update && apt-get install -y curl
      ```

      **CMD**: Default command to run
      ```dockerfile
      CMD ["npm", "start"]
      ```

      **ENTRYPOINT**: Configure container executable
      ```dockerfile
      ENTRYPOINT ["python", "app.py"]
      ```

      **EXPOSE**: Document port usage
      ```dockerfile
      EXPOSE 3000
      ```

      **ENV**: Set environment variables
      ```dockerfile
      ENV NODE_ENV=production
      ```

      ## Example: Node.js Application

      ```dockerfile
      FROM node:14-alpine

      WORKDIR /app

      # Copy dependency files first (better caching)
      COPY package*.json ./

      # Install dependencies
      RUN npm ci --only=production

      # Copy application code
      COPY . .

      # Expose port
      EXPOSE 3000

      # Start application
      CMD ["npm", "start"]
      ```

      ## Best Practices

      1. Use specific base image tags
      2. Minimize layer count
      3. Leverage build cache
      4. Use .dockerignore
      5. Don't run as root
      6. Use multi-stage builds
    -
    - 30
    - '["dockerfile","instructions","best-practices"]'
    - '2025-11-06 08:13:01.796367'
    - '2025-11-06 08:13:01.796367'
    - "[]"
    - '"[]"'
  - - 41
    - Building Custom Images
    - |
      # Building Custom Images

      ## docker build Command

      ```bash
      docker build -t myapp:v1 .
      ```

      - `-t`: Tag the image
      - `.`: Build context (current directory)

      ## Build Process

      1. Docker reads Dockerfile
      2. Creates temporary container for each instruction
      3. Runs instruction in container
      4. Commits result as new layer
      5. Removes temporary container
      6. Repeats for each instruction

      ## Build Arguments

      **ARG**: Build-time variables
      ```dockerfile
      ARG VERSION=1.0
      FROM node:${VERSION}
      ```

      ```bash
      docker build --build-arg VERSION=14 -t myapp .
      ```

      ## Build Context

      - All files in build directory sent to Docker daemon
      - Use .dockerignore to exclude files
      - Keep build context small for faster builds

      ## Multi-Stage Builds

      Reduce final image size:

      ```dockerfile
      # Build stage
      FROM node:14 AS builder
      WORKDIR /app
      COPY . .
      RUN npm install && npm run build

      # Production stage
      FROM node:14-alpine
      WORKDIR /app
      COPY --from=builder /app/dist ./dist
      CMD ["node", "dist/index.js"]
      ```
    -
    - 25
    - '["docker-build","build-context","multi-stage"]'
    - '2025-11-06 08:13:01.798267'
    - '2025-11-06 08:13:01.798267'
    - "[]"
    - '"[]"'
  - - 42
    - Understanding Container Storage
    - |
      # Understanding Container Storage

      ## The Ephemeral Problem

      By default, data in containers is **ephemeral** - it disappears when the container is removed:

      ```bash
      docker run --rm alpine sh -c "echo 'data' > /tmp/file.txt"
      # Container exits, file.txt is lost forever
      ```

      ## Storage Solutions

      Docker provides two main approaches for persistent data:

      1. **Volumes**: Managed by Docker
      2. **Bind Mounts**: Direct host filesystem mapping

      ## Why Persistence Matters

      - Database data must survive container restarts
      - Application logs need to be retained
      - Configuration files should be easily editable
      - Shared data between containers

      ## Volume Benefits

      - Managed by Docker
      - Easier to back up
      - Work on all platforms
      - Can be shared safely
      - Better performance
    -
    - 20
    - '["volumes","persistence","ephemeral","storage"]'
    - '2025-11-06 08:20:50.331257'
    - '2025-11-06 08:20:50.331257'
    - "[]"
    - '"[]"'
  - - 43
    - Docker Best Practices Summary
    - |
      # Docker Best Practices Summary

      ## Image Optimization

      1. Use Alpine base images
      2. Minimize layers
      3. Leverage build cache
      4. Use multi-stage builds
      5. Don't run as root

      ## Security

      1. Scan images for vulnerabilities
      2. Use official images
      3. Keep images updated
      4. Limit container privileges
      5. Use secrets management

      ## Production Readiness

      1. Health checks
      2. Proper logging
      3. Resource limits
      4. Restart policies
      5. Monitoring and alerting
    -
    - 25
    - '["best-practices","security","production","optimization"]'
    - '2025-11-06 08:20:50.365211'
    - '2025-11-06 08:20:50.365211'
    - "[]"
    - '"[]"'
  - - 44
    - Introduction to Kubernetes
    - |
      # Introduction to Kubernetes

      ## What is Kubernetes?

      Kubernetes (K8s) is an open-source container orchestration platform for automating deployment, scaling, and management of containerized applications.

      ## Why Kubernetes?

      - **Auto-scaling**: Scale containers based on demand
      - **Self-healing**: Restart failed containers
      - **Load balancing**: Distribute traffic
      - **Rolling updates**: Zero-downtime deployments
      - **Service discovery**: Automatic DNS and networking

      ## Kubernetes vs Docker

      - Docker: Container runtime
      - Kubernetes: Container orchestrator
      - They work together!

      ## Key Concepts

      - **Pods**: Smallest deployable units
      - **Services**: Stable network endpoints
      - **Deployments**: Manage pod replicas
      - **Namespaces**: Virtual clusters
    -
    - 20
    - '["kubernetes","orchestration","k8s","scaling"]'
    - '2025-11-06 08:20:50.367430'
    - '2025-11-06 08:20:50.367430'
    - "[]"
    - '"[]"'

---
course_modules:
  columns:
  - id
  - course_id
  - title
  - slug
  - description
  - sequence_order
  - estimated_minutes
  - learning_objectives
  - published
  - created_at
  - updated_at
  records: 
  - - 1
    - 1
    - Container Basics
    - container-basics
    - Introduction to containerization and Docker fundamentals
    - 1
    - 120
    - '["Understand what containers are and why they matter","Learn Docker architecture
      and components","Run your first containers"]'
    - true
    - '2025-11-06 03:44:03.467081'
    - '2025-11-06 07:46:51.907628'
  - - 2
    - 1
    - Images and Dockerfiles
    - images-dockerfiles
    - Learn to build and manage Docker images
    - 2
    - 180
    - '["Understand Docker image layers","Write efficient Dockerfiles","Build and
      tag images","Optimize image size"]'
    - true
    - '2025-11-06 03:44:03.523085'
    - '2025-11-06 03:44:03.523085'
  - - 3
    - 1
    - Networking & Ports
    - networking-and-ports
    - Expose services, understand bridge networks, and container DNS
    - 3
    - 180
    - '["Publish container ports and verify connectivity","Use user-defined bridge
      networks and container DNS","Understand host vs. bridge networking modes"]'
    - true
    - '2025-11-06 03:44:03.542340'
    - '2025-11-06 03:44:03.542340'
  - - 4
    - 1
    - Volumes & Storage
    - volumes-and-storage
    - Persist data using volumes and bind mounts
    - 4
    - 180
    - '["Compare volumes and bind mounts","Create, inspect, and use named volumes","Persist
      and share data across containers"]'
    - true
    - '2025-11-06 03:44:03.568562'
    - '2025-11-06 03:44:03.568562'
  - - 5
    - 1
    - Docker Compose
    - docker-compose
    - Deploy multi-container applications with Docker Compose
    - 5
    - 180
    - '["Write docker-compose.yml files","Manage multi-container apps","Configure
      service dependencies","Scale services"]'
    - true
    - '2025-11-06 03:44:03.591503'
    - '2025-11-06 07:32:44.045350'
  - - 6
    - 1
    - Security & Best Practices
    - security-best-practices
    - Run as non-root, minimize surface, healthchecks
    - 6
    - 180
    -
    - true
    - '2025-11-06 03:44:03.620839'
    - '2025-11-06 03:44:03.620839'
  - - 7
    - 1
    - Registries & CI/CD
    - registries-ci-cd
    - Push, pull, tag, and automate
    - 7
    - 120
    -
    - true
    - '2025-11-06 03:44:03.645213'
    - '2025-11-06 03:44:03.645213'
  - - 8
    - 1
    - Docker → Kubernetes Bridge I
    - exam-readiness-dca-mock-1
    - 'Map Docker to Kubernetes: Pods, images, YAML, basic kubectl'
    - 8
    - 90
    -
    - true
    - '2025-11-06 03:44:03.678117'
    - '2025-11-06 03:44:03.678117'
  - - 9
    - 1
    - Docker → Kubernetes Bridge II
    - dca-practice-bank
    - Networking, storage, ConfigMaps and Secrets mapping with short checks
    - 9
    - 120
    -
    - true
    - '2025-11-06 03:44:03.718455'
    - '2025-11-06 03:44:03.718455'
  - - 10
    - 1
    - 'Kubernetes Readiness: CKAD Preview'
    - exam-readiness-dca-mock-2
    - CKAD-style practice scenarios (optional)
    - 10
    - 90
    -
    - true
    - '2025-11-06 03:44:03.870988'
    - '2025-11-06 03:44:03.870988'
  - - 11
    - 1
    - 'Kubernetes Readiness: CKA Preview'
    - exam-readiness-dca-mock-3
    - CKA-style administration scenario previews (optional)
    - 11
    - 90
    -
    - true
    - '2025-11-06 03:44:04.013584'
    - '2025-11-06 03:44:04.013584'
  - - 12
    - 1
    - Docker Basics
    - docker-basics
    - Master fundamental Docker commands for container management
    - 1
    - 300
    - '["List and inspect running containers", "Create and manage container lifecycle",
      "Execute commands inside containers", "Monitor container logs and status", "Understand
      Docker system information"]'
    - true
    - '2025-11-06 03:44:04.154405'
    - '2025-11-06 03:44:04.154405'
  - - 13
    - 1
    - Container Management
    - container-management
    - Advanced container lifecycle operations and resource management
    - 2
    - 420
    - '["Manage container lifecycle operations", "Monitor container resource usage",
      "Copy files between containers and host", "Inspect container filesystem changes",
      "Update container configurations dynamically", "Clean up stopped containers
      efficiently"]'
    - true
    - '2025-11-06 03:44:04.375334'
    - '2025-11-06 03:44:04.375334'
  - - 14
    - 1
    - Image Management
    - image-management
    - Master Docker image creation, management, and registry operations
    - 3
    - 275
    - '["Build custom images from Dockerfiles", "Manage local image repository", "Push
      and pull images from registries", "Tag images for version control", "Inspect
      image layers and history", "Clean up unused images efficiently"]'
    - true
    - '2025-11-06 03:44:04.641601'
    - '2025-11-06 03:44:04.641601'
  - - 16
    - 1
    - Docker Networking
    - docker-networking
    - Master Docker networking concepts including creating networks, connecting containers,
      and managing network isolation
    - 5
    - 160
    -
    - true
    - '2025-11-06 03:54:36.422678'
    - '2025-11-06 03:54:36.422678'
  - - 17
    - 1
    - Docker Volumes
    - docker-volumes
    - Master Docker volume management and data persistence
    - 6
    - 140
    -
    - true
    - '2025-11-06 04:02:24.114327'
    - '2025-11-06 04:02:24.114327'
  - - 18
    - 2
    - Go Basics
    - go-basics
    - Learn Go fundamentals
    - 1
    - 120
    -
    - true
    - '2025-11-06 04:09:12.837680'
    - '2025-11-06 04:09:12.837680'
  - - 19
    - 2
    - Data Structures
    - data-structures
    - Arrays, Slices, Maps, and Structs
    - 2
    - 150
    -
    - true
    - '2025-11-06 04:09:12.891311'
    - '2025-11-06 04:09:12.891311'
  - - 20
    - 2
    - Advanced Concepts
    - advanced-concepts
    - Methods, Interfaces, and Error Handling
    - 3
    - 180
    -
    - true
    - '2025-11-06 04:09:12.910821'
    - '2025-11-06 04:09:12.910821'
  - - 21
    - 2
    - Concurrency
    - concurrency
    - Goroutines, Channels, and Concurrent Patterns
    - 4
    - 200
    -
    - true
    - '2025-11-06 04:09:12.925313'
    - '2025-11-06 04:09:12.925313'
  - - 22
    - 2
    - Advanced Patterns
    - advanced-patterns
    - Context, Patterns, and Best Practices
    - 5
    - 150
    -
    - true
    - '2025-11-06 04:09:12.952911'
    - '2025-11-06 04:09:12.952911'
  - - 23
    - 1
    - 'Module 1: Your First Day at CodeSprout'
    - container-lifecycle
    - Learn container basics by managing CodeSprout's web services
    - 1
    - 180
    - '["Understand what containers are and why CodeSprout uses them", "Run and manage
      containers", "Handle container ports and networking basics", "Clean up containers
      properly"]'
    - true
    - '2025-11-06 04:12:16.898496'
    - '2025-11-06 04:12:16.898496'
  - - 24
    - 1
    - 'Module 3: Networking & Data'
    - networking-and-data
    - Persist data and connect services securely
    - 3
    - 180
    - '["Create and use volumes", "Create and use custom networks", "Pass configuration
      via environment variables"]'
    - true
    - '2025-11-06 04:12:17.000548'
    - '2025-11-06 04:12:17.000548'
  - - 25
    - 1
    - 'Module 4: Deploying the CodeSprout Application'
    - deploying-codesprout
    - Build and deploy a complete multi-service application running at localhost:3000
    - 4
    - 200
    - '["Deploy a full-stack application locally", "Connect frontend, backend, and
      database services", "Orchestrate multi-container applications with Docker Compose",
      "Prepare applications for Kubernetes deployment"]'
    - true
    - '2025-11-06 04:12:17.008453'
    - '2025-11-06 04:12:17.008453'
  - - 26
    - 1
    - Images and Dockerfiles
    - images-and-dockerfiles
    - Learn to build and manage Docker images
    - 2
    - 180
    - '["Understand Docker image layers","Write efficient Dockerfiles","Build and
      tag images","Optimize image size"]'
    - false
    - '2025-11-06 07:32:44.023038'
    - '2025-11-06 07:32:44.023038'
  - - 27
    - 1
    - Container Networking
    - container-networking
    - Master Docker networking and container communication
    - 3
    - 150
    - '["Understand Docker network types","Configure port mapping","Connect containers","Create
      custom networks"]'
    - false
    - '2025-11-06 07:32:44.033180'
    - '2025-11-06 07:32:44.033180'
  - - 28
    - 1
    - Volumes and Data Persistence
    - volumes-and-data-persistence
    - Learn to manage persistent data in Docker containers
    - 4
    - 120
    - '["Understand volume types","Mount host directories","Share data between containers","Backup
      and restore volumes"]'
    - false
    - '2025-11-06 07:32:44.040017'
    - '2025-11-06 07:32:44.040017'
  - - 29
    - 1
    - Production Best Practices
    - production-best-practices
    - Learn Docker best practices for production deployments
    - 6
    - 150
    - '["Optimize image sizes","Implement security best practices","Configure health
      checks","Manage logs and monitoring"]'
    - false
    - '2025-11-06 07:32:44.053378'
    - '2025-11-06 07:32:44.053378'
  - - 30
    - 5
    - "Week 1: Introduction to Containers & Docker \U0001F680"
    - week-1-introduction-to-containers-docker
    - Understand containerization fundamentals, Docker architecture, and the relationship
      between images and containers
    - 1
    - 180
    - '["Explain what containers are and why they matter","Compare containers vs virtual
      machines","Understand Docker architecture and components","Differentiate between
      Docker images and containers","Run your first Docker container successfully"]'
    - false
    - '2025-11-06 08:52:19.572607'
    - '2025-11-06 08:52:19.572607'
  - - 31
    - 5
    - "Week 2: Running and Managing Containers \U0001F3D7️"
    - week-2-running-and-managing-containers
    - Master container lifecycle management, learn to run containers in different
      modes, inspect running containers, and manage Docker images effectively
    - 2
    - 240
    - '["Run containers in interactive and detached modes","Manage the complete container
      lifecycle","Inspect and monitor running containers","Execute commands inside
      containers","Manage Docker images locally"]'
    - false
    - '2025-11-06 08:52:19.668966'
    - '2025-11-06 08:52:19.668966'
  - - 32
    - 5
    - "Week 3: Docker Images and Dockerfiles \U0001F4DD"
    - week-3-docker-images-and-dockerfiles
    - Learn to build custom Docker images, write efficient Dockerfiles, and optimize
      image sizes
    - 3
    - 360
    - '["Understand Docker image layers and caching","Write production-ready Dockerfiles","Build
      custom images efficiently","Optimize image sizes","Use multi-stage builds"]'
    - false
    - '2025-11-06 08:52:19.685255'
    - '2025-11-06 08:52:19.685255'
  - - 33
    - 5
    - "Week 4: Data Management with Volumes \U0001F4BE"
    - week-4-data-management-with-volumes
    - Learn to persist data beyond container lifecycle using Docker volumes and bind
      mounts
    - 4
    - 240
    - '["Understand container filesystem ephemeral nature","Create and manage Docker
      volumes","Use bind mounts effectively","Persist database data","Share data between
      containers"]'
    - false
    - '2025-11-06 08:52:19.697525'
    - '2025-11-06 08:52:19.697525'
  - - 34
    - 5
    - "Week 5: Networking and Multi-Container Apps \U0001F310"
    - week-5-networking-and-multi-container-apps
    - Master Docker networking and connect multiple containers together
    - 5
    - 240
    - '["Understand Docker network types","Create custom networks","Connect containers
      together","Implement service discovery","Build multi-container applications"]'
    - false
    - '2025-11-06 08:52:19.704611'
    - '2025-11-06 08:52:19.704611'
  - - 35
    - 5
    - "Week 6: Docker Compose for Orchestration \U0001F3BC"
    - week-6-docker-compose-for-orchestration
    - Learn to define and run multi-container applications with Docker Compose
    - 6
    - 240
    - '["Understand Docker Compose concepts","Write docker-compose.yml files","Manage
      multi-container applications","Define services, networks, and volumes","Use
      Compose for development workflows"]'
    - false
    - '2025-11-06 08:52:19.714312'
    - '2025-11-06 08:52:19.714312'
  - - 36
    - 5
    - "Week 7: Capstone Project & Kubernetes Readiness \U0001F393"
    - week-7-capstone-project-kubernetes-readiness
    - Apply everything you've learned in a comprehensive project and prepare for Kubernetes
    - 7
    - 300
    - '["Build a complete microservices application","Apply Docker best practices","Prepare
      for production deployments","Understand Kubernetes basics","Successfully complete
      DCA-aligned assessment"]'
    - false
    - '2025-11-06 08:52:19.721399'
    - '2025-11-06 08:52:19.721399'

---
courses:
  columns:
  - id
  - title
  - slug
  - description
  - difficulty_level
  - estimated_hours
  - certification_track
  - icon_url
  - banner_url
  - published
  - sequence_order
  - learning_objectives
  - prerequisites
  - created_at
  - updated_at
  records: 
  - - 1
    - Docker Fundamentals
    - docker-fundamentals
    - Master Docker from basics to production deployment. Build, ship, and run containerized
      applications with confidence.
    - beginner
    - 20
    - dca
    -
    -
    - true
    - 1
    - '["Understand container concepts and Docker architecture","Build and manage
      Docker images effectively","Configure Docker networking and storage","Deploy
      multi-container applications with Docker Compose","Implement best practices
      for production deployments"]'
    - '["Linux Fundamentals course (recommended)","Understanding of software development
      concepts"]'
    - '2025-11-06 03:44:03.455385'
    - '2025-11-06 03:44:03.455385'
  - - 2
    - Go Programming Fundamentals
    - golang-fundamentals
    - Master Go programming with deep focus on concurrency
    - intermediate
    -
    - none
    -
    -
    - true
    - 2
    -
    -
    - '2025-11-06 03:44:32.134130'
    - '2025-11-06 03:44:32.134130'
  - - 5
    - Docker Containers Professional Bootcamp
    - docker-containers-bootcamp
    - 7-week intensive Docker certification bootcamp preparing you for Docker Certified
      Associate (DCA) exam and real-world container deployments
    - beginner
    - 40
    - docker
    -
    -
    - true
    - 2
    - '["Master Docker fundamentals from basics to orchestration","Build, run, and
      manage containers in production environments","Create optimized custom Docker
      images with Dockerfiles","Implement data persistence strategies with volumes","Configure
      secure multi-container networking","Orchestrate complex applications with Docker
      Compose","Prepare comprehensively for Docker Certified Associate (DCA) exam","Deploy
      production-ready microservices architectures"]'
    - '["Basic command-line knowledge (terminal/bash)","Understanding of software
      development concepts","Familiarity with web applications (helpful but not required)","No
      prior Docker experience required"]'
    - '2025-11-06 08:52:19.570629'
    - '2025-11-06 08:52:19.570629'

---
docker_commands:
  columns:
  - id
  - command
  - explanation
  - difficulty
  - category
  - exam_frequency
  - variations
  - flags
  - common_options
  - use_cases
  - gotchas
  - certification_exam
  - times_practiced
  - average_success_rate
  - is_deprecated
  - docker_version_min
  - created_at
  - updated_at
  records: 
  - - 1
    - docker run -d nginx
    - Run nginx container in detached mode (background)
    - easy
    - basics
    - 10
    - '["docker run -d -p 8080:80 nginx","docker run -d --name web nginx"]'
    - '{"-d":"detached mode","-p":"port mapping","--name":"container name"}'
    - "{}"
    - Deploy web server in background
    - Container runs in background, use docker logs to see output
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.163137'
    - '2025-11-06 03:44:02.163137'
  - - 2
    - docker ps
    - List all running containers
    - easy
    - basics
    - 10
    - '["docker ps -a","docker ps -q"]'
    - '{"-a":"all containers","-q":"quiet mode (IDs only)"}'
    - "{}"
    - Check running containers, troubleshooting
    - Without -a flag, only shows running containers
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.168363'
    - '2025-11-06 03:44:02.168363'
  - - 3
    - docker stop <container>
    - Gracefully stop a running container (sends SIGTERM)
    - easy
    - basics
    - 9
    - '["docker stop $(docker ps -q)","docker stop container1 container2"]'
    - '{"-t":"timeout before killing"}'
    - "{}"
    - Graceful container shutdown
    - Waits 10 seconds before forcing kill with SIGKILL
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.172408'
    - '2025-11-06 03:44:02.172408'
  - - 4
    - docker start <container>
    - Start a stopped container
    - easy
    - basics
    - 9
    - '["docker start -a \u003ccontainer\u003e"]'
    - '{"-a":"attach to container output"}'
    - "{}"
    - Restart existing container
    - Cannot change configuration of existing container
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.176465'
    - '2025-11-06 03:44:02.176465'
  - - 5
    - docker restart <container>
    - Restart a container (stop + start)
    - easy
    - basics
    - 8
    - '["docker restart -t 30 \u003ccontainer\u003e"]'
    - '{"-t":"timeout before killing"}'
    - "{}"
    - Apply configuration changes, troubleshooting
    - Uses same timeout as stop command
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.181323'
    - '2025-11-06 03:44:02.181323'
  - - 6
    - docker rm <container>
    - Remove a stopped container
    - easy
    - basics
    - 9
    - '["docker rm -f \u003ccontainer\u003e","docker rm $(docker ps -aq)"]'
    - '{"-f":"force remove running container","-v":"remove volumes"}'
    - "{}"
    - Clean up stopped containers
    - Cannot remove running container without -f flag
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.185732'
    - '2025-11-06 03:44:02.185732'
  - - 7
    - docker logs <container>
    - Fetch logs from a container
    - easy
    - basics
    - 10
    - '["docker logs -f \u003ccontainer\u003e","docker logs --tail 100 \u003ccontainer\u003e"]'
    - '{"-f":"follow log output","--tail":"number of lines from end","--since":"show
      logs since timestamp"}'
    - "{}"
    - Debugging, monitoring application output
    - Only works with json-file and journald log drivers
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.189553'
    - '2025-11-06 03:44:02.189553'
  - - 8
    - docker exec -it <container> bash
    - Execute interactive bash shell in running container
    - easy
    - basics
    - 10
    - '["docker exec \u003ccontainer\u003e ls /app","docker exec -u root \u003ccontainer\u003e
      bash"]'
    - '{"-i":"interactive","-t":"allocate TTY","-u":"user"}'
    - "{}"
    - Debugging, inspecting container filesystem
    - Container must be running, bash must be installed
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.193825'
    - '2025-11-06 03:44:02.193825'
  - - 9
    - docker inspect <container>
    - Display detailed information about container in JSON format
    - easy
    - basics
    - 9
    - '["docker inspect --format=''{{.State.Status}}'' \u003ccontainer\u003e"]'
    - '{"--format":"format output using Go template"}'
    - "{}"
    - Get container IP, environment variables, volumes
    - Returns JSON array, use --format for specific fields
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.198353'
    - '2025-11-06 03:44:02.198353'
  - - 10
    - docker build -t myapp:v1 .
    - Build image from Dockerfile in current directory with tag
    - medium
    - images
    - 10
    - '["docker build -t myapp:latest -f Dockerfile.prod .","docker build --no-cache
      -t myapp:v1 ."]'
    - '{"-t":"name and tag","-f":"Dockerfile path","--no-cache":"don''t use cache"}'
    - "{}"
    - Create custom application images
    - Dot (.) specifies build context, affects COPY/ADD commands
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.217393'
    - '2025-11-06 03:44:02.217393'
  - - 11
    - docker pull nginx:alpine
    - Download nginx alpine image from Docker Hub
    - easy
    - images
    - 9
    - '["docker pull redis:6.2","docker pull gcr.io/my-project/image:tag"]'
    - '{"-a":"download all tags","--platform":"specify platform"}'
    - "{}"
    - Download base images, application dependencies
    - Defaults to :latest if no tag specified
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.241488'
    - '2025-11-06 03:44:02.241488'
  - - 12
    - docker push myrepo/myapp:v1
    - Upload image to Docker registry
    - easy
    - registry
    - 9
    - '["docker push localhost:5000/myapp:v1"]'
    - '{"--all-tags":"push all tags"}'
    - "{}"
    - Share images, CI/CD deployment
    - Must login to registry first with docker login
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.251108'
    - '2025-11-06 03:44:02.251108'
  - - 13
    - docker images
    - List all local Docker images
    - easy
    - images
    - 10
    - '["docker images -a","docker images --filter dangling=true"]'
    - '{"-a":"show all images","-q":"quiet mode","--filter":"filter output"}'
    - "{}"
    - Check available images, verify builds
    - Doesn't show intermediate layers without -a
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.264684'
    - '2025-11-06 03:44:02.264684'
  - - 14
    - docker rmi <image>
    - Remove one or more images
    - easy
    - images
    - 8
    - '["docker rmi -f \u003cimage\u003e","docker rmi $(docker images -q)"]'
    - '{"-f":"force removal","--no-prune":"don''t delete untagged parents"}'
    - "{}"
    - Clean up disk space, remove old images
    - Cannot remove images used by containers
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.269318'
    - '2025-11-06 03:44:02.269318'
  - - 15
    - docker tag myapp:v1 myrepo/myapp:latest
    - Create a new tag for existing image
    - easy
    - images
    - 8
    - '["docker tag SOURCE_IMAGE[:TAG] TARGET_IMAGE[:TAG]"]'
    - "{}"
    - "{}"
    - Prepare images for registry push, versioning
    - Both tags point to same image ID
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.274448'
    - '2025-11-06 03:44:02.274448'
  - - 16
    - docker history <image>
    - Show the history of an image (layers)
    - medium
    - images
    - 7
    - '["docker history --no-trunc \u003cimage\u003e"]'
    - '{"--no-trunc":"don''t truncate output","-q":"quiet mode"}'
    - "{}"
    - Understand image layers, optimize builds
    - Shows layers in reverse chronological order
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.278831'
    - '2025-11-06 03:44:02.278831'
  - - 17
    - docker save -o myapp.tar myapp:v1
    - Save image to tar archive file
    - medium
    - images
    - 7
    - '["docker save myapp:v1 | gzip \u003e myapp.tar.gz"]'
    - '{"-o":"output file"}'
    - "{}"
    - Backup images, transfer without registry
    - Preserves layers and tags
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.283217'
    - '2025-11-06 03:44:02.283217'
  - - 18
    - docker load -i myapp.tar
    - Load image from tar archive
    - medium
    - images
    - 7
    - '["docker load \u003c myapp.tar"]'
    - '{"-i":"input file","-q":"suppress load output"}'
    - "{}"
    - Restore images, import from backup
    - Restores with original tags
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.287579'
    - '2025-11-06 03:44:02.287579'
  - - 19
    - docker run -d -p 8080:80 --name web nginx
    - Run container with port mapping and custom name
    - easy
    - containers
    - 10
    - '["docker run -d -p 8080:80 -p 8443:443 nginx"]'
    - '{"-p":"publish port","--name":"container name"}'
    - "{}"
    - Expose web services on specific ports
    - Host port must be available
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.291907'
    - '2025-11-06 03:44:02.291907'
  - - 20
    - docker run -d -v /host/path:/container/path nginx
    - Run container with bind mount volume
    - medium
    - volumes
    - 9
    - '["docker run -d -v myvolume:/data nginx","docker run -d -v /host:/container:ro
      nginx"]'
    - '{"-v":"volume mount",":ro":"read-only"}'
    - "{}"
    - Persist data, share files between host and container
    - Bind mounts require absolute paths
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.295993'
    - '2025-11-06 03:44:02.295993'
  - - 21
    - docker run -d --env MY_VAR=value nginx
    - Run container with environment variable
    - easy
    - containers
    - 9
    - '["docker run -d --env-file .env nginx","docker run -d -e VAR1=val1 -e VAR2=val2
      nginx"]'
    - '{"--env":"set environment variable","--env-file":"read from file"}'
    - "{}"
    - Configuration management, pass secrets
    - Environment variables visible in inspect output
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.300995'
    - '2025-11-06 03:44:02.300995'
  - - 22
    - docker run -d --restart unless-stopped nginx
    - Run container with restart policy
    - medium
    - containers
    - 8
    - '["docker run -d --restart always nginx","docker run -d --restart on-failure:3
      nginx"]'
    - '{"--restart":"restart policy (no|on-failure|always|unless-stopped)"}'
    - "{}"
    - Ensure high availability, automatic recovery
    - unless-stopped won't restart if manually stopped
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.305910'
    - '2025-11-06 03:44:02.305910'
  - - 23
    - docker run -d --memory 512m --cpus 1.5 nginx
    - Run container with resource limits
    - medium
    - containers
    - 9
    - '["docker run -d --memory 1g --memory-reservation 512m nginx"]'
    - '{"--memory":"memory limit","--cpus":"CPU limit","--memory-swap":"swap limit"}'
    - "{}"
    - Resource management, prevent container from consuming all resources
    - Requires swap accounting enabled on host
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.309738'
    - '2025-11-06 03:44:02.309738'
  - - 24
    - docker stats
    - Display live stream of container resource usage statistics
    - easy
    - containers
    - 8
    - '["docker stats --no-stream","docker stats \u003ccontainer\u003e"]'
    - '{"--no-stream":"disable streaming","--format":"format output"}'
    - "{}"
    - Monitor container performance, resource usage
    - Shows real-time stats, press Ctrl+C to exit
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.314175'
    - '2025-11-06 03:44:02.314175'
  - - 25
    - docker top <container>
    - Display running processes inside container
    - easy
    - containers
    - 7
    - '["docker top \u003ccontainer\u003e aux"]'
    - "{}"
    - "{}"
    - Troubleshoot container processes
    - Output format depends on host ps command
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.318355'
    - '2025-11-06 03:44:02.318355'
  - - 26
    - docker cp <container>:/path/file.txt ./local/
    - Copy files between container and host
    - medium
    - containers
    - 7
    - '["docker cp ./local/file.txt \u003ccontainer\u003e:/path/"]'
    - '{"-L":"follow symlinks"}'
    - "{}"
    - Extract logs, copy configuration files
    - Works on stopped containers too
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.322758'
    - '2025-11-06 03:44:02.322758'
  - - 27
    - docker port <container>
    - List port mappings for container
    - easy
    - containers
    - 7
    - '["docker port \u003ccontainer\u003e 80"]'
    - "{}"
    - "{}"
    - Check which host port maps to container port
    - Only shows published ports
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.327016'
    - '2025-11-06 03:44:02.327016'
  - - 28
    - docker rename old_name new_name
    - Rename a container
    - easy
    - containers
    - 5
    - "[]"
    - "{}"
    - "{}"
    - Fix naming mistakes, reorganize containers
    - Container can be running or stopped
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.331298'
    - '2025-11-06 03:44:02.331298'
  - - 29
    - docker wait <container>
    - Block until container stops, then print exit code
    - medium
    - containers
    - 5
    - '["docker wait container1 container2"]'
    - "{}"
    - "{}"
    - Scripting, wait for container completion
    - Blocks until container exits
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.335906'
    - '2025-11-06 03:44:02.335906'
  - - 30
    - docker attach <container>
    - Attach to running container's STDIN, STDOUT, STDERR
    - medium
    - containers
    - 6
    - '["docker attach --no-stdin \u003ccontainer\u003e"]'
    - '{"--no-stdin":"don''t attach STDIN","--sig-proxy":"proxy signals"}'
    - "{}"
    - View container output, interact with process
    - Detach with Ctrl+P, Ctrl+Q (Ctrl+C stops container)
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.339918'
    - '2025-11-06 03:44:02.339918'
  - - 31
    - docker diff <container>
    - Inspect changes to files or directories on container filesystem
    - medium
    - containers
    - 6
    - "[]"
    - "{}"
    - "{}"
    - Debug filesystem changes, understand container modifications
    - Shows A (added), D (deleted), C (changed)
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.345059'
    - '2025-11-06 03:44:02.345059'
  - - 32
    - docker commit <container> myimage:v2
    - Create new image from container's changes
    - medium
    - images
    - 6
    - '["docker commit -m ''message'' -a ''author'' \u003ccontainer\u003e myimage:v2"]'
    - '{"-m":"commit message","-a":"author","-p":"pause container"}'
    - "{}"
    - Save container state, create custom images
    - Better to use Dockerfile for reproducibility
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.349957'
    - '2025-11-06 03:44:02.349957'
  - - 33
    - docker network create my-network
    - Create a new Docker network
    - easy
    - networks
    - 9
    - '["docker network create --driver bridge my-network","docker network create
      --subnet 172.20.0.0/16 my-network"]'
    - '{"--driver":"network driver","--subnet":"subnet","--gateway":"gateway"}'
    - "{}"
    - Isolate containers, custom networking
    - Default driver is bridge
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.354694'
    - '2025-11-06 03:44:02.354694'
  - - 34
    - docker network ls
    - List all Docker networks
    - easy
    - networks
    - 9
    - '["docker network ls --filter driver=bridge"]'
    - '{"--filter":"filter output","-q":"quiet mode"}'
    - "{}"
    - View available networks, troubleshooting
    - Shows bridge, host, none by default
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.359210'
    - '2025-11-06 03:44:02.359210'
  - - 35
    - docker network inspect my-network
    - Display detailed information about network
    - medium
    - networks
    - 8
    - '["docker network inspect --format=''{{.IPAM.Config}}'' my-network"]'
    - '{"--format":"format output"}'
    - "{}"
    - Get network configuration, find connected containers
    - Shows containers, subnet, gateway, driver
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.365469'
    - '2025-11-06 03:44:02.365469'
  - - 36
    - docker network connect my-network <container>
    - Connect container to network
    - medium
    - networks
    - 8
    - '["docker network connect --ip 172.20.0.10 my-network \u003ccontainer\u003e"]'
    - '{"--ip":"IPv4 address","--alias":"network-scoped alias"}'
    - "{}"
    - Add container to additional network, multi-network setup
    - Container can connect to multiple networks
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.371004'
    - '2025-11-06 03:44:02.371004'
  - - 37
    - docker network disconnect my-network <container>
    - Disconnect container from network
    - medium
    - networks
    - 7
    - '["docker network disconnect -f my-network \u003ccontainer\u003e"]'
    - '{"-f":"force disconnect"}'
    - "{}"
    - Isolate container, troubleshooting
    - Cannot disconnect from default bridge
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.375127'
    - '2025-11-06 03:44:02.375127'
  - - 38
    - docker network rm my-network
    - Remove one or more networks
    - easy
    - networks
    - 7
    - '["docker network rm $(docker network ls -q)"]'
    - "{}"
    - "{}"
    - Clean up unused networks
    - Cannot remove network with connected containers
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.385571'
    - '2025-11-06 03:44:02.385571'
  - - 39
    - docker run -d --network my-network nginx
    - Run container connected to specific network
    - easy
    - networks
    - 9
    - '["docker run -d --network host nginx"]'
    - '{"--network":"network to connect to"}'
    - "{}"
    - Container networking, service communication
    - Network must exist before starting container
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.390128'
    - '2025-11-06 03:44:02.390128'
  - - 40
    - docker network prune
    - Remove all unused networks
    - easy
    - networks
    - 6
    - '["docker network prune -f"]'
    - '{"-f":"don''t prompt for confirmation","--filter":"filter networks"}'
    - "{}"
    - Clean up disk space, maintenance
    - Only removes networks not connected to containers
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.396496'
    - '2025-11-06 03:44:02.396496'
  - - 41
    - docker volume create my-volume
    - Create a new volume
    - easy
    - volumes
    - 9
    - '["docker volume create --driver local my-volume","docker volume create --label
      env=prod my-volume"]'
    - '{"--driver":"volume driver","--label":"metadata","--opt":"driver options"}'
    - "{}"
    - Persistent data storage, database volumes
    - Volumes persist after container removal
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.402824'
    - '2025-11-06 03:44:02.402824'
  - - 42
    - docker volume ls
    - List all volumes
    - easy
    - volumes
    - 9
    - '["docker volume ls --filter dangling=true"]'
    - '{"--filter":"filter output","-q":"quiet mode"}'
    - "{}"
    - Check available volumes, find unused volumes
    - Dangling volumes are not attached to containers
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.407479'
    - '2025-11-06 03:44:02.407479'
  - - 43
    - docker volume inspect my-volume
    - Display detailed information about volume
    - medium
    - volumes
    - 8
    - '["docker volume inspect --format=''{{.Mountpoint}}'' my-volume"]'
    - '{"--format":"format output"}'
    - "{}"
    - Get volume path, check configuration
    - Shows mountpoint on host filesystem
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.411382'
    - '2025-11-06 03:44:02.411382'
  - - 44
    - docker volume rm my-volume
    - Remove one or more volumes
    - easy
    - volumes
    - 7
    - '["docker volume rm $(docker volume ls -q)"]'
    - '{"-f":"force removal"}'
    - "{}"
    - Clean up disk space, remove unused volumes
    - Cannot remove volumes in use by containers
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.415089'
    - '2025-11-06 03:44:02.415089'
  - - 45
    - docker volume prune
    - Remove all unused volumes
    - easy
    - volumes
    - 7
    - '["docker volume prune -f"]'
    - '{"-f":"don''t prompt","--filter":"filter volumes"}'
    - "{}"
    - Clean up disk space, maintenance
    - Removes all volumes not attached to containers
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.418603'
    - '2025-11-06 03:44:02.418603'
  - - 46
    - docker run -d --mount source=my-volume,target=/data nginx
    - Run container with volume using mount syntax
    - medium
    - volumes
    - 8
    - '["docker run -d --mount type=bind,source=/host/path,target=/container/path
      nginx"]'
    - '{"--mount":"mount configuration","type":"bind|volume|tmpfs","readonly":"read-only"}'
    - "{}"
    - Modern volume mounting, explicit configuration
    - More verbose but clearer than -v flag
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.422379'
    - '2025-11-06 03:44:02.422379'
  - - 47
    - docker login
    - Log in to Docker registry
    - easy
    - registry
    - 8
    - '["docker login -u username -p password registry.example.com"]'
    - '{"-u":"username","-p":"password","--password-stdin":"read password from stdin"}'
    - "{}"
    - Authenticate to push/pull private images
    - Credentials stored in ~/.docker/config.json
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.426081'
    - '2025-11-06 03:44:02.426081'
  - - 48
    - docker logout
    - Log out from Docker registry
    - easy
    - registry
    - 6
    - '["docker logout registry.example.com"]'
    - "{}"
    - "{}"
    - Remove stored credentials
    - Defaults to Docker Hub if no registry specified
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.429961'
    - '2025-11-06 03:44:02.429961'
  - - 49
    - docker search nginx
    - Search Docker Hub for images
    - easy
    - registry
    - 6
    - '["docker search --filter stars=100 nginx","docker search --limit 10 nginx"]'
    - '{"--filter":"filter results","--limit":"max results","--no-trunc":"don''t truncate"}'
    - "{}"
    - Find public images, discover alternatives
    - Only searches Docker Hub by default
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.433909'
    - '2025-11-06 03:44:02.433909'
  - - 50
    - docker swarm init
    - Initialize a swarm (create manager node)
    - medium
    - swarm
    - 10
    - '["docker swarm init --advertise-addr 192.168.1.100"]'
    - '{"--advertise-addr":"advertised address","--listen-addr":"listen address"}'
    - "{}"
    - Create Docker Swarm cluster, orchestration
    - Node becomes manager, outputs join token for workers
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.437478'
    - '2025-11-06 03:44:02.437478'
  - - 51
    - docker swarm join --token <token> <manager-ip>:2377
    - Join node to swarm as worker
    - medium
    - swarm
    - 9
    - '["docker swarm join --token \u003ctoken\u003e --advertise-addr 192.168.1.101
      \u003cmanager\u003e:2377"]'
    - '{"--token":"join token","--advertise-addr":"advertised address"}'
    - "{}"
    - Add worker nodes to cluster
    - Port 2377 is default for swarm management
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.441766'
    - '2025-11-06 03:44:02.441766'
  - - 52
    - docker service create --name web --replicas 3 nginx
    - Create a service with 3 replicas
    - medium
    - swarm
    - 10
    - '["docker service create --name web -p 8080:80 --replicas 3 nginx"]'
    - '{"--replicas":"number of tasks","-p":"publish port","--name":"service name"}'
    - "{}"
    - Deploy scalable services, high availability
    - Service runs on swarm, not single node
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.445774'
    - '2025-11-06 03:44:02.445774'
  - - 53
    - docker service ls
    - List all services in swarm
    - easy
    - swarm
    - 9
    - '["docker service ls --filter name=web"]'
    - '{"--filter":"filter services","-q":"quiet mode"}'
    - "{}"
    - View deployed services, monitoring
    - Only works on manager nodes
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.449448'
    - '2025-11-06 03:44:02.449448'
  - - 54
    - docker service ps <service>
    - List tasks of service
    - easy
    - swarm
    - 9
    - '["docker service ps --filter desired-state=running \u003cservice\u003e"]'
    - '{"--filter":"filter tasks","--no-trunc":"don''t truncate"}'
    - "{}"
    - Check service distribution, troubleshoot failures
    - Shows which nodes are running tasks
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.453488'
    - '2025-11-06 03:44:02.453488'
  - - 55
    - docker service scale <service>=5
    - Scale service to 5 replicas
    - medium
    - swarm
    - 9
    - '["docker service scale web=3 api=5"]'
    - "{}"
    - "{}"
    - Increase/decrease service capacity
    - Can scale multiple services at once
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.457424'
    - '2025-11-06 03:44:02.457424'
  - - 56
    - docker service update --image nginx:alpine <service>
    - Update service with new image (rolling update)
    - medium
    - swarm
    - 8
    - '["docker service update --env-add KEY=VALUE \u003cservice\u003e"]'
    - '{"--image":"update image","--env-add":"add env var","--rollback":"rollback
      update"}'
    - "{}"
    - Deploy updates without downtime
    - Rolling update by default, configurable with --update-* flags
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.461095'
    - '2025-11-06 03:44:02.461095'
  - - 57
    - docker service rm <service>
    - Remove service from swarm
    - easy
    - swarm
    - 7
    - '["docker service rm service1 service2"]'
    - "{}"
    - "{}"
    - Clean up services, teardown
    - Removes all tasks of service
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.465082'
    - '2025-11-06 03:44:02.465082'
  - - 58
    - docker service logs <service>
    - Fetch logs of service or task
    - medium
    - swarm
    - 8
    - '["docker service logs -f \u003cservice\u003e","docker service logs --tail 100
      \u003cservice\u003e"]'
    - '{"-f":"follow logs","--tail":"number of lines","--since":"since timestamp"}'
    - "{}"
    - Debug service issues, monitor output
    - Aggregates logs from all tasks
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.468503'
    - '2025-11-06 03:44:02.468503'
  - - 59
    - docker node ls
    - List all nodes in swarm
    - easy
    - swarm
    - 9
    - '["docker node ls --filter role=manager"]'
    - '{"--filter":"filter nodes","-q":"quiet mode"}'
    - "{}"
    - Check cluster health, node status
    - Shows manager and worker nodes
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.472291'
    - '2025-11-06 03:44:02.472291'
  - - 60
    - docker node inspect <node>
    - Display detailed information about node
    - medium
    - swarm
    - 7
    - '["docker node inspect --format=''{{.Status.State}}'' \u003cnode\u003e"]'
    - '{"--format":"format output"}'
    - "{}"
    - Get node details, troubleshoot
    - Shows availability, state, resources
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.476115'
    - '2025-11-06 03:44:02.476115'
  - - 61
    - docker node update --availability drain <node>
    - Drain node (stop scheduling new tasks)
    - medium
    - swarm
    - 8
    - '["docker node update --availability active \u003cnode\u003e"]'
    - '{"--availability":"active|pause|drain","--label-add":"add label"}'
    - "{}"
    - Maintenance, graceful shutdown
    - Existing tasks are rescheduled on other nodes
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.479754'
    - '2025-11-06 03:44:02.479754'
  - - 62
    - docker node promote <node>
    - Promote worker node to manager
    - medium
    - swarm
    - 7
    - '["docker node promote node1 node2"]'
    - "{}"
    - "{}"
    - Increase manager redundancy
    - Requires quorum of managers to function
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.484076'
    - '2025-11-06 03:44:02.484076'
  - - 63
    - docker node demote <node>
    - Demote manager node to worker
    - medium
    - swarm
    - 7
    - '["docker node demote node1 node2"]'
    - "{}"
    - "{}"
    - Reduce manager count, rebalance
    - Must maintain at least 1 manager
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.487856'
    - '2025-11-06 03:44:02.487856'
  - - 64
    - docker stack deploy -c docker-compose.yml myapp
    - Deploy stack from compose file
    - medium
    - swarm
    - 9
    - '["docker stack deploy -c compose1.yml -c compose2.yml myapp"]'
    - '{"-c":"compose file","--prune":"prune services","--resolve-image":"query registry"}'
    - "{}"
    - Deploy multi-service applications
    - Uses version 3+ compose file format
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.491204'
    - '2025-11-06 03:44:02.491204'
  - - 65
    - docker stack ls
    - List all stacks
    - easy
    - swarm
    - 8
    - "[]"
    - "{}"
    - "{}"
    - View deployed stacks
    - Shows number of services per stack
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.494848'
    - '2025-11-06 03:44:02.494848'
  - - 66
    - docker stack ps <stack>
    - List tasks in stack
    - easy
    - swarm
    - 8
    - '["docker stack ps --filter desired-state=running \u003cstack\u003e"]'
    - '{"--filter":"filter tasks","--no-trunc":"don''t truncate"}'
    - "{}"
    - Monitor stack deployment, troubleshoot
    - Shows all tasks across all services
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.498574'
    - '2025-11-06 03:44:02.498574'
  - - 67
    - docker stack rm <stack>
    - Remove stack
    - easy
    - swarm
    - 8
    - "[]"
    - "{}"
    - "{}"
    - Teardown applications, cleanup
    - Removes all services and networks in stack
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.502244'
    - '2025-11-06 03:44:02.502244'
  - - 68
    - docker stack services <stack>
    - List services in stack
    - easy
    - swarm
    - 8
    - '["docker stack services --filter name=web \u003cstack\u003e"]'
    - '{"--filter":"filter services","-q":"quiet mode"}'
    - "{}"
    - View stack services, monitoring
    - Shows replicas and ports
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.505983'
    - '2025-11-06 03:44:02.505983'
  - - 69
    - docker secret create my-secret secret.txt
    - Create secret from file
    - medium
    - security
    - 8
    - '["echo ''password'' | docker secret create my-secret -"]'
    - '{"-l":"labels"}'
    - "{}"
    - Securely store passwords, certificates
    - Secrets are encrypted at rest and in transit
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.509660'
    - '2025-11-06 03:44:02.509660'
  - - 70
    - docker secret ls
    - List all secrets
    - easy
    - security
    - 7
    - '["docker secret ls --filter name=my"]'
    - '{"--filter":"filter secrets","-q":"quiet mode"}'
    - "{}"
    - View available secrets
    - Cannot view secret values after creation
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.513402'
    - '2025-11-06 03:44:02.513402'
  - - 71
    - docker secret inspect <secret>
    - Display detailed information about secret
    - medium
    - security
    - 7
    - '["docker secret inspect --format=''{{.CreatedAt}}'' \u003csecret\u003e"]'
    - '{"--format":"format output"}'
    - "{}"
    - Check secret metadata
    - Does not show secret data
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.516886'
    - '2025-11-06 03:44:02.516886'
  - - 72
    - docker secret rm <secret>
    - Remove secret
    - easy
    - security
    - 6
    - "[]"
    - "{}"
    - "{}"
    - Clean up secrets, rotate credentials
    - Cannot remove secrets in use by services
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.521104'
    - '2025-11-06 03:44:02.521104'
  - - 73
    - docker config create my-config config.txt
    - Create config from file
    - medium
    - swarm
    - 7
    - '["echo ''data'' | docker config create my-config -"]'
    - '{"-l":"labels"}'
    - "{}"
    - Store non-sensitive configuration
    - Configs are not encrypted like secrets
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.524742'
    - '2025-11-06 03:44:02.524742'
  - - 74
    - docker config ls
    - List all configs
    - easy
    - swarm
    - 6
    - '["docker config ls --filter name=my"]'
    - '{"--filter":"filter configs","-q":"quiet mode"}'
    - "{}"
    - View available configs
    - Similar to secrets but for non-sensitive data
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.529033'
    - '2025-11-06 03:44:02.529033'
  - - 75
    - docker-compose up -d
    - Start all services defined in docker-compose.yml in detached mode
    - easy
    - compose
    - 9
    - '["docker-compose up -d --build","docker-compose -f custom.yml up -d"]'
    - '{"-d":"detached mode","--build":"build images before starting","-f":"compose
      file"}'
    - "{}"
    - Start multi-container applications
    - Uses docker-compose.yml by default
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.532930'
    - '2025-11-06 03:44:02.532930'
  - - 76
    - docker-compose down
    - Stop and remove containers, networks created by up
    - easy
    - compose
    - 9
    - '["docker-compose down -v","docker-compose down --rmi all"]'
    - '{"-v":"remove volumes","--rmi":"remove images (all|local)"}'
    - "{}"
    - Teardown application, cleanup
    - Does not remove volumes by default
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.536910'
    - '2025-11-06 03:44:02.536910'
  - - 77
    - docker-compose ps
    - List containers started by compose
    - easy
    - compose
    - 8
    - '["docker-compose ps -a"]'
    - '{"-a":"show all containers","-q":"quiet mode"}'
    - "{}"
    - Check service status
    - Only shows containers managed by this compose file
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.540482'
    - '2025-11-06 03:44:02.540482'
  - - 78
    - docker-compose logs
    - View output from containers
    - easy
    - compose
    - 8
    - '["docker-compose logs -f web","docker-compose logs --tail 100"]'
    - '{"-f":"follow logs","--tail":"number of lines"}'
    - "{}"
    - Debug applications, monitor output
    - Shows logs from all services unless specified
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.545127'
    - '2025-11-06 03:44:02.545127'
  - - 79
    - docker-compose exec <service> bash
    - Execute command in running service container
    - easy
    - compose
    - 7
    - '["docker-compose exec -T web sh -c ''echo test''"]'
    - '{"-T":"disable TTY","-u":"user"}'
    - "{}"
    - Debug services, run commands
    - Service must be running
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.549036'
    - '2025-11-06 03:44:02.549036'
  - - 80
    - docker-compose build
    - Build or rebuild services
    - easy
    - compose
    - 7
    - '["docker-compose build --no-cache web"]'
    - '{"--no-cache":"don''t use cache","--pull":"pull newer base images"}'
    - "{}"
    - Rebuild images after code changes
    - Only builds services with 'build' defined
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.552688'
    - '2025-11-06 03:44:02.552688'
  - - 81
    - docker-compose restart <service>
    - Restart service containers
    - easy
    - compose
    - 6
    - '["docker-compose restart"]'
    - '{"-t":"timeout before killing"}'
    - "{}"
    - Apply configuration changes, troubleshoot
    - Restarts all services if none specified
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.556883'
    - '2025-11-06 03:44:02.556883'
  - - 82
    - docker-compose scale web=3
    - Scale service to specified number of containers
    - medium
    - compose
    - 6
    - '["docker-compose scale web=3 api=2"]'
    - "{}"
    - "{}"
    - Horizontal scaling of services
    - Deprecated in favor of docker-compose up --scale
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.561327'
    - '2025-11-06 03:44:02.561327'
  - - 83
    - docker system df
    - Show docker disk usage
    - easy
    - basics
    - 7
    - '["docker system df -v"]'
    - '{"-v":"verbose output"}'
    - "{}"
    - Check disk space used by Docker
    - Shows images, containers, volumes, build cache
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.565084'
    - '2025-11-06 03:44:02.565084'
  - - 84
    - docker system prune
    - Remove unused data (containers, networks, images, cache)
    - easy
    - basics
    - 8
    - '["docker system prune -a","docker system prune --volumes"]'
    - '{"-a":"remove all unused images","--volumes":"prune volumes","-f":"no confirmation"}'
    - "{}"
    - Clean up disk space, maintenance
    - Very aggressive cleanup, be careful in production
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.568933'
    - '2025-11-06 03:44:02.568933'
  - - 85
    - docker system info
    - Display system-wide information
    - easy
    - basics
    - 8
    - '["docker info"]'
    - '{"--format":"format output"}'
    - "{}"
    - Check Docker version, configuration, storage driver
    - Shows swarm status, plugins, runtime
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.572491'
    - '2025-11-06 03:44:02.572491'
  - - 86
    - docker version
    - Show Docker version information
    - easy
    - basics
    - 7
    - '["docker version --format ''{{.Server.Version}}''"]'
    - '{"--format":"format output"}'
    - "{}"
    - Verify installation, check compatibility
    - Shows client and server versions
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.576206'
    - '2025-11-06 03:44:02.576206'
  - - 87
    - docker events
    - Get real-time events from server
    - medium
    - basics
    - 6
    - '["docker events --filter event=start","docker events --since ''2023-01-01''"]'
    - '{"--filter":"filter events","--since":"show events since timestamp","--until":"until
      timestamp"}'
    - "{}"
    - Monitor Docker activity, debugging
    - Streams events in real-time, Ctrl+C to exit
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.580262'
    - '2025-11-06 03:44:02.580262'
  - - 88
    - docker run -d --health-cmd='curl -f http://localhost/ || exit 1' nginx
    - Run container with health check
    - medium
    - containers
    - 7
    - '["docker run -d --health-interval=30s --health-retries=3 nginx"]'
    - '{"--health-cmd":"health check command","--health-interval":"interval","--health-retries":"retries"}'
    - "{}"
    - Monitor container health, automatic restart
    - Health status shown in docker ps
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.584092'
    - '2025-11-06 03:44:02.584092'
  - - 89
    - docker update --restart unless-stopped <container>
    - Update container configuration without recreating
    - medium
    - containers
    - 6
    - '["docker update --memory 1g --cpus 2 \u003ccontainer\u003e"]'
    - '{"--restart":"restart policy","--memory":"memory limit","--cpus":"CPU limit"}'
    - "{}"
    - Change resource limits, restart policy
    - Limited set of updatable properties
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.587603'
    - '2025-11-06 03:44:02.587603'
  - - 90
    - docker pause <container>
    - Pause all processes in container
    - easy
    - containers
    - 5
    - "[]"
    - "{}"
    - "{}"
    - Temporarily freeze container, save resources
    - Uses cgroup freezer, not SIGSTOP
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.591605'
    - '2025-11-06 03:44:02.591605'
  - - 91
    - docker unpause <container>
    - Resume all processes in paused container
    - easy
    - containers
    - 5
    - "[]"
    - "{}"
    - "{}"
    - Resume paused container
    - Container must be in paused state
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.595617'
    - '2025-11-06 03:44:02.595617'
  - - 92
    - docker container prune
    - Remove all stopped containers
    - easy
    - containers
    - 7
    - '["docker container prune -f","docker container prune --filter until=24h"]'
    - '{"-f":"no confirmation","--filter":"filter containers"}'
    - "{}"
    - Clean up disk space, maintenance
    - Only removes stopped containers
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.599963'
    - '2025-11-06 03:44:02.599963'
  - - 93
    - docker image prune
    - Remove unused images
    - easy
    - images
    - 7
    - '["docker image prune -a","docker image prune --filter until=24h"]'
    - '{"-a":"remove all unused","--filter":"filter images","-f":"no confirmation"}'
    - "{}"
    - Free up disk space, cleanup
    - Without -a, only removes dangling images
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.604185'
    - '2025-11-06 03:44:02.604185'
  - - 94
    - docker export <container> > backup.tar
    - Export container filesystem as tar archive
    - medium
    - containers
    - 5
    - '["docker export -o backup.tar \u003ccontainer\u003e"]'
    - '{"-o":"output file"}'
    - "{}"
    - Backup container filesystem, migration
    - Exports filesystem only, not image layers
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.609753'
    - '2025-11-06 03:44:02.609753'
  - - 95
    - docker import backup.tar myimage:v1
    - Import tarball to create filesystem image
    - medium
    - images
    - 5
    - '["cat backup.tar | docker import - myimage:v1"]'
    - '{"-c":"apply Dockerfile instruction","-m":"commit message"}'
    - "{}"
    - Restore from export, create base images
    - Creates single layer image
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.613661'
    - '2025-11-06 03:44:02.613661'
  - - 96
    - docker kill <container>
    - Kill running container by sending SIGKILL
    - easy
    - containers
    - 6
    - '["docker kill -s SIGTERM \u003ccontainer\u003e"]'
    - '{"-s":"signal to send"}'
    - "{}"
    - Force stop unresponsive container
    - More aggressive than docker stop
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.617938'
    - '2025-11-06 03:44:02.617938'
  - - 97
    - docker run --rm -it alpine sh
    - Run container and automatically remove when it exits
    - easy
    - containers
    - 7
    - '["docker run --rm -v $(pwd):/work alpine ls /work"]'
    - '{"--rm":"automatically remove","-i":"interactive","-t":"TTY"}'
    - "{}"
    - Temporary containers, testing, scripts
    - Container and volumes are removed on exit
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.622449'
    - '2025-11-06 03:44:02.622449'
  - - 98
    - docker run -d --log-driver json-file --log-opt max-size=10m nginx
    - Run container with logging configuration
    - medium
    - containers
    - 6
    - '["docker run -d --log-driver syslog --log-opt syslog-address=tcp://192.168.0.1:514
      nginx"]'
    - '{"--log-driver":"logging driver","--log-opt":"logging options"}'
    - "{}"
    - Manage log file size, centralized logging
    - 'Log drivers: json-file, syslog, journald, etc.'
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.629370'
    - '2025-11-06 03:44:02.629370'
  - - 99
    - docker service create --mode global nginx
    - Create service with global mode (one task per node)
    - medium
    - swarm
    - 7
    - '["docker service create --mode global --constraint node.role==worker nginx"]'
    - '{"--mode":"replicated|global","--constraint":"placement constraint"}'
    - "{}"
    - Monitoring agents, logging collectors
    - Runs exactly one task on each node
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.660991'
    - '2025-11-06 03:44:02.660991'
  - - 100
    - docker service create --constraint node.labels.env==prod nginx
    - Create service with node constraint
    - medium
    - swarm
    - 7
    - '["docker service create --constraint node.role==worker nginx"]'
    - '{"--constraint":"placement constraint"}'
    - "{}"
    - Control service placement, resource isolation
    - 'Constraints: node.labels, node.role, node.hostname, etc.'
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.665318'
    - '2025-11-06 03:44:02.665318'
  - - 101
    - docker service create --publish published=8080,target=80 nginx
    - Create service with published port using long syntax
    - medium
    - swarm
    - 7
    - '["docker service create --publish published=8080,target=80,protocol=tcp,mode=ingress
      nginx"]'
    - '{"--publish":"publish port","mode":"ingress|host"}'
    - "{}"
    - Expose services, load balancing
    - Ingress mode uses routing mesh
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.669787'
    - '2025-11-06 03:44:02.669787'
  - - 102
    - docker node update --label-add env=prod <node>
    - Add label to node
    - medium
    - swarm
    - 6
    - '["docker node update --label-rm env \u003cnode\u003e"]'
    - '{"--label-add":"add label","--label-rm":"remove label"}'
    - "{}"
    - Node categorization, constraint-based scheduling
    - Labels used in service constraints
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.674612'
    - '2025-11-06 03:44:02.674612'
  - - 103
    - docker swarm leave
    - Leave swarm
    - easy
    - swarm
    - 6
    - '["docker swarm leave --force"]'
    - '{"--force":"force leave even if manager"}'
    - "{}"
    - Remove node from cluster, decommission
    - Manager must use --force, maintain quorum
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.678861'
    - '2025-11-06 03:44:02.678861'
  - - 104
    - docker trust sign myimage:v1
    - Sign image with Docker Content Trust
    - hard
    - security
    - 5
    - "[]"
    - "{}"
    - "{}"
    - Image verification, secure supply chain
    - Requires DOCKER_CONTENT_TRUST=1 environment variable
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.682646'
    - '2025-11-06 03:44:02.682646'
  - - 105
    - docker plugin install <plugin>
    - Install a plugin
    - hard
    - basics
    - 4
    - '["docker plugin install --grant-all-permissions \u003cplugin\u003e"]'
    - '{"--grant-all-permissions":"grant all permissions","--disable":"install but
      don''t enable"}'
    - "{}"
    - Extend Docker functionality, custom volume drivers
    - Plugins run as separate processes
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.686330'
    - '2025-11-06 03:44:02.686330'
  - - 106
    - docker context create remote --docker host=tcp://remote:2376
    - Create context for remote Docker daemon
    - hard
    - basics
    - 5
    - '["docker context create remote --docker host=ssh://user@remote"]'
    - '{"--docker":"Docker endpoint configuration"}'
    - "{}"
    - Manage multiple Docker hosts, remote management
    - Use docker context use <context> to switch
    - DCA
    - 0
    - 0.0
    - false
    -
    - '2025-11-06 03:44:02.690150'
    - '2025-11-06 03:44:02.690150'

---
hands_on_labs:
  columns:
  - id
  - title
  - description
  - difficulty
  - estimated_minutes
  - steps
  - validation_rules
  - lab_type
  - category
  - learning_objectives
  - prerequisites
  - success_criteria
  - environment_image
  - required_tools
  - max_attempts
  - times_completed
  - average_completion_time
  - average_success_rate
  - certification_exam
  - is_active
  - points_reward
  - created_at
  - updated_at
  - scenario_narrative
  - concept_tags
  - required_commands
  - commands_tested
  - pass_threshold
  - stability_multiplier
  - slug
  - lab_format
  - programming_language
  - starter_code
  - test_cases
  - validation_script
  - file_structure
  - solution_code
  - allowed_imports
  - time_limit_seconds
  - memory_limit_mb
  - schema_setup
  - sample_data
  - hints
  records: 
  - - 1
    - Your First Container - Run and Explore
    - Learn the basics by running your first Docker container and exploring its filesystem
    - easy
    - 15
    - '"[{\"step_number\":1,\"title\":\"Pull nginx image\",\"instruction\":\"Pull
      the official nginx image from Docker Hub\",\"expected_command\":\"docker pull
      nginx:latest\",\"validation\":\"docker images | grep nginx\",\"hint\":null},{\"step_number\":2,\"title\":\"Run
      nginx container\",\"instruction\":\"Run nginx in detached mode with name ''my-nginx''\",\"expected_command\":\"docker
      run -d --name my-nginx nginx\",\"validation\":\"docker ps | grep my-nginx\",\"hint\":null},{\"step_number\":3,\"title\":\"Access
      container shell\",\"instruction\":\"Execute bash shell inside the running container\",\"expected_command\":\"docker
      exec -it my-nginx bash\",\"validation\":\"echo $HOSTNAME\",\"hint\":null},{\"step_number\":4,\"title\":\"View
      container logs\",\"instruction\":\"Check the logs of your nginx container\",\"expected_command\":\"docker
      logs my-nginx\",\"validation\":\"docker logs my-nginx | wc -l\",\"hint\":null},{\"step_number\":5,\"title\":\"Stop
      and remove\",\"instruction\":\"Stop the container and remove it\",\"expected_command\":\"docker
      stop my-nginx \u0026\u0026 docker rm my-nginx\",\"validation\":\"docker ps -a
      | grep my-nginx\",\"hint\":null}]"'
    - '"{\"image_pulled\":\"nginx image must be present\",\"container_created\":\"container
      named my-nginx must exist\",\"container_running\":\"container must be in running
      state\",\"cleanup_complete\":\"no containers should remain\"}"'
    - docker
    - basics
    - Understand docker run, exec, and basic container lifecycle
    - '"[\"Basic command line knowledge\"]"'
    - All 5 steps completed successfully, container lifecycle managed correctly
    - docker:20-dind
    - '"[\"docker\"]"'
    - 5
    - 0
    - 0.0
    - 0.0
    - DCA
    - true
    - 100
    - '2025-11-06 03:44:03.141750'
    - '2025-11-06 07:32:44.019489'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -
  - - 2
    - Port Mapping and Network Access
    - Learn how to expose container services to the host using port mapping
    - easy
    - 20
    - '"[{\"step_number\":1,\"title\":\"Run nginx with port mapping\",\"instruction\":\"Run
      nginx container mapping host port 8080 to container port 80\",\"expected_command\":\"docker
      run -d -p 8080:80 --name web-server nginx\",\"validation\":\"docker port web-server
      80\",\"hint\":null},{\"step_number\":2,\"title\":\"Test connectivity\",\"instruction\":\"Use
      curl to verify nginx is accessible on port 8080\",\"expected_command\":\"curl
      http://localhost:8080\",\"validation\":\"curl -s -o /dev/null -w ''%{http_code}''
      http://localhost:8080\",\"hint\":null},{\"step_number\":3,\"title\":\"Check
      port bindings\",\"instruction\":\"Inspect which ports are mapped\",\"expected_command\":\"docker
      port web-server\",\"validation\":\"docker port web-server | grep 8080\",\"hint\":null},{\"step_number\":4,\"title\":\"Cleanup\",\"instruction\":\"Stop
      and remove the container\",\"expected_command\":\"docker stop web-server \u0026\u0026
      docker rm web-server\",\"validation\":\"! docker ps -a | grep web-server\",\"hint\":null}]"'
    - '"{}"'
    - docker
    - networking
    -
    - '"[]"'
    - Successfully map ports and verify external access
    - docker:20-dind
    - '"[\"docker\"]"'
    - 5
    - 0
    - 0.0
    - 0.0
    - DCA
    - true
    - 100
    - '2025-11-06 03:44:03.149571'
    - '2025-11-06 07:32:44.036555'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -
  - - 3
    - Environment Variables and Configuration
    - Learn to configure containers using environment variables
    - easy
    - 20
    - '[{"step_number":1,"title":"Run MySQL with environment vars","instruction":"Run
      MySQL container with root password set via env var","expected_command":"docker
      run -d --name mysql-db -e MYSQL_ROOT_PASSWORD=secretpass mysql:8","validation":"docker
      inspect mysql-db | grep MYSQL_ROOT_PASSWORD"},{"step_number":2,"title":"Multiple
      environment variables","instruction":"Run MySQL with database name and user
      credentials","expected_command":"docker run -d --name mysql-app -e MYSQL_ROOT_PASSWORD=secret
      -e MYSQL_DATABASE=myapp -e MYSQL_USER=appuser -e MYSQL_PASSWORD=apppass mysql:8","validation":"docker
      exec mysql-app env | grep MYSQL"},{"step_number":3,"title":"Inspect environment","instruction":"View
      all environment variables in the container","expected_command":"docker exec
      mysql-app env","validation":"docker exec mysql-app env | grep MYSQL_DATABASE"},{"step_number":4,"title":"Create
      env file","instruction":"Create an .env file with KEY=value pairs","expected_command":"echo
      ''APP_NAME=MyApp\\nAPP_ENV=production'' \u003e app.env","validation":"cat app.env
      | grep APP_NAME"},{"step_number":5,"title":"Cleanup","instruction":"Remove containers
      and env file","expected_command":"docker rm -f mysql-db mysql-app \u0026\u0026
      rm app.env","validation":"docker ps -a | grep mysql"}]'
    - '{"env_vars_set":"environment variables must be present","database_created":"MYSQL_DATABASE
      must be set","env_file_created":"app.env file must exist"}'
    - docker
    - configuration
    - Use -e flag, pass configuration, inspect environment variables
    - '["Basic Docker knowledge"]'
    - Successfully configure containers with environment variables
    - docker:20-dind
    - '["docker"]'
    - 5
    - 0
    - 0.0
    - 0.0
    - DCA
    - true
    - 150
    - '2025-11-06 03:44:03.155078'
    - '2025-11-06 03:44:03.155078'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -
  - - 4
    - Volume Mounting - Data Persistence
    - Learn how to persist data using Docker volumes and bind mounts
    - easy
    - 25
    - '[{"step_number":1,"title":"Create named volume","instruction":"Create a Docker
      volume named ''app-data''","expected_command":"docker volume create app-data","validation":"docker
      volume ls | grep app-data"},{"step_number":2,"title":"Run container with volume","instruction":"Run
      nginx with the volume mounted at /usr/share/nginx/html","expected_command":"docker
      run -d --name web -v app-data:/usr/share/nginx/html nginx","validation":"docker
      inspect web | grep app-data"},{"step_number":3,"title":"Write data to volume","instruction":"Create
      an index.html file in the mounted volume","expected_command":"docker exec web
      sh -c ''echo \"\u003ch1\u003eHello from Volume\u003c/h1\u003e\" \u003e /usr/share/nginx/html/index.html''","validation":"docker
      exec web cat /usr/share/nginx/html/index.html"},{"step_number":4,"title":"Verify
      persistence","instruction":"Remove container, create new one with same volume","expected_command":"docker
      rm -f web \u0026\u0026 docker run -d --name web2 -v app-data:/usr/share/nginx/html
      nginx","validation":"docker exec web2 cat /usr/share/nginx/html/index.html |
      grep Hello"},{"step_number":5,"title":"Cleanup","instruction":"Remove container
      and volume","expected_command":"docker rm -f web2 \u0026\u0026 docker volume
      rm app-data","validation":"docker volume ls | grep app-data"}]'
    - '{"volume_created":"app-data volume must exist","data_persists":"data must survive
      container restart","cleanup_complete":"volume must be removed"}'
    - docker
    - storage
    - Create volumes, bind mounts, persist data across container restarts
    - '["Basic Docker knowledge"]'
    - Data persists across container lifecycle
    - docker:20-dind
    - '["docker"]'
    - 5
    - 0
    - 0.0
    - 0.0
    - DCA
    - true
    - 200
    - '2025-11-06 03:44:03.159289'
    - '2025-11-06 03:44:03.159289'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -
  - - 5
    - Container Logs and Debugging
    - Master container logging and basic debugging techniques
    - easy
    - 20
    - '[{"step_number":1,"title":"Run container with logs","instruction":"Run nginx
      and generate some access logs","expected_command":"docker run -d -p 8080:80
      --name web nginx","validation":"docker ps | grep web"},{"step_number":2,"title":"View
      logs","instruction":"Display all logs from the container","expected_command":"docker
      logs web","validation":"docker logs web | wc -l"},{"step_number":3,"title":"Follow
      logs live","instruction":"Follow logs in real-time (use Ctrl+C to exit)","expected_command":"docker
      logs -f web","validation":"docker logs web --tail 10"},{"step_number":4,"title":"Tail
      recent logs","instruction":"Display last 20 lines of logs","expected_command":"docker
      logs --tail 20 web","validation":"docker logs --tail 20 web | wc -l"},{"step_number":5,"title":"Cleanup","instruction":"Remove
      the container","expected_command":"docker rm -f web","validation":"docker ps
      -a | grep web"}]'
    - '{"logs_accessible":"logs must be retrievable","tail_works":"tail must limit
      output","cleanup":"container must be removed"}'
    - docker
    - debugging
    - View logs, follow logs, filter logs, debug container issues
    - '["Basic Docker knowledge"]'
    - Successfully view and analyze container logs
    - docker:20-dind
    - '["docker"]'
    - 5
    - 0
    - 0.0
    - 0.0
    - DCA
    - true
    - 100
    - '2025-11-06 03:44:03.163331'
    - '2025-11-06 03:44:03.163331'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -
  - - 6
    - Build Your First Docker Image
    - Create a custom Docker image using a Dockerfile
    - medium
    - 30
    - '[{"step_number":1,"title":"Create Dockerfile","instruction":"Create a Dockerfile
      with FROM nginx, COPY index.html, EXPOSE 80","expected_command":"cat \u003e
      Dockerfile \u003c\u003c ''EOF''\nFROM nginx:alpine\nCOPY index.html /usr/share/nginx/html/\nEXPOSE
      80\nEOF","validation":"test -f Dockerfile"},{"step_number":2,"title":"Create
      index.html","instruction":"Create a simple HTML file","expected_command":"echo
      ''\u003ch1\u003eMy Custom Image\u003c/h1\u003e'' \u003e index.html","validation":"test
      -f index.html"},{"step_number":3,"title":"Build image","instruction":"Build
      image with tag myapp:v1","expected_command":"docker build -t myapp:v1 .","validation":"docker
      images | grep myapp"},{"step_number":4,"title":"Run custom image","instruction":"Run
      container from your custom image","expected_command":"docker run -d -p 8080:80
      --name custom-app myapp:v1","validation":"docker ps | grep custom-app"},{"step_number":5,"title":"Test
      custom content","instruction":"Verify custom HTML is served","expected_command":"curl
      http://localhost:8080","validation":"curl -s http://localhost:8080 | grep ''My
      Custom Image''"},{"step_number":6,"title":"View image layers","instruction":"Inspect
      image history","expected_command":"docker history myapp:v1","validation":"docker
      history myapp:v1 | wc -l"},{"step_number":7,"title":"Cleanup","instruction":"Remove
      container, image, and files","expected_command":"docker rm -f custom-app \u0026\u0026
      docker rmi myapp:v1 \u0026\u0026 rm Dockerfile index.html","validation":"docker
      images | grep myapp"}]'
    - '{"dockerfile_valid":"Dockerfile must have FROM, COPY, EXPOSE","image_built":"image
      must be in local registry","container_runs":"container must serve custom HTML","cleanup":"all
      resources removed"}'
    - docker
    - images
    - Write Dockerfile, build images, understand layers, tag images
    - '["Completed beginner labs","Basic understanding of Linux"]'
    - Build custom image and run container successfully
    - docker:20-dind
    - '["docker","curl"]'
    - 5
    - 0
    - 0.0
    - 0.0
    - DCA
    - true
    - 250
    - '2025-11-06 03:44:03.167417'
    - '2025-11-06 03:44:03.167417'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -
  - - 7
    - Multi-Stage Builds - Optimize Image Size
    - Learn to create optimized images using multi-stage builds
    - medium
    - 35
    - '[{"step_number":1,"title":"Create Go application","instruction":"Create a simple
      Go hello world program","expected_command":"cat \u003e main.go \u003c\u003c
      ''EOF''\npackage main\nimport \"fmt\"\nfunc main() { fmt.Println(\"Hello from
      Docker!\") }\nEOF","validation":"test -f main.go"},{"step_number":2,"title":"Create
      multi-stage Dockerfile","instruction":"Create Dockerfile with builder and runtime
      stages","expected_command":"cat \u003e Dockerfile \u003c\u003c ''EOF''\nFROM
      golang:1.20 AS builder\nWORKDIR /app\nCOPY main.go .\nRUN go build -o app main.go\n\nFROM
      alpine:latest\nWORKDIR /root/\nCOPY --from=builder /app/app .\nCMD [\"./app\"]\nEOF","validation":"grep
      ''AS builder'' Dockerfile"},{"step_number":3,"title":"Build multi-stage image","instruction":"Build
      the optimized image","expected_command":"docker build -t mygoapp:optimized .","validation":"docker
      images | grep mygoapp"},{"step_number":4,"title":"Check image size","instruction":"Compare
      image size (should be much smaller than golang base)","expected_command":"docker
      images mygoapp:optimized --format ''{{.Size}}''","validation":"docker images
      mygoapp:optimized | awk ''{print $NF}''"},{"step_number":5,"title":"Run optimized
      image","instruction":"Run container and verify output","expected_command":"docker
      run --rm mygoapp:optimized","validation":"docker run --rm mygoapp:optimized
      | grep Hello"},{"step_number":6,"title":"Cleanup","instruction":"Remove image
      and source files","expected_command":"docker rmi mygoapp:optimized \u0026\u0026
      rm Dockerfile main.go","validation":"docker images | grep mygoapp"}]'
    - '{"multistage_dockerfile":"must have multiple FROM statements","image_optimized":"final
      image should be \u003c 20MB","app_runs":"application must execute successfully"}'
    - docker
    - images
    - Multi-stage builds, reduce image size, separate build and runtime
    - '["Completed ''Build Your First Docker Image'' lab"]'
    - Create optimized image using multi-stage build
    - docker:20-dind
    - '["docker"]'
    - 5
    - 0
    - 0.0
    - 0.0
    - DCA
    - true
    - 300
    - '2025-11-06 03:44:03.174239'
    - '2025-11-06 03:44:03.174239'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -
  - - 8
    - Docker Networks - Container Communication
    - Master Docker networking by connecting multiple containers
    - medium
    - 30
    - '[{"step_number":1,"title":"Create custom network","instruction":"Create a bridge
      network named ''app-network''","expected_command":"docker network create app-network","validation":"docker
      network ls | grep app-network"},{"step_number":2,"title":"Run database on network","instruction":"Run
      MySQL on the custom network","expected_command":"docker run -d --name db --network
      app-network -e MYSQL_ROOT_PASSWORD=secret mysql:8","validation":"docker network
      inspect app-network | grep db"},{"step_number":3,"title":"Run app container","instruction":"Run
      another container on same network","expected_command":"docker run -d --name
      app --network app-network nginx","validation":"docker network inspect app-network
      | grep app"},{"step_number":4,"title":"Test connectivity","instruction":"Ping
      database from app container using container name","expected_command":"docker
      exec app ping -c 3 db","validation":"docker exec app ping -c 1 db"},{"step_number":5,"title":"Inspect
      network","instruction":"View network details and connected containers","expected_command":"docker
      network inspect app-network","validation":"docker network inspect app-network
      | grep Containers"},{"step_number":6,"title":"Cleanup","instruction":"Remove
      containers and network","expected_command":"docker rm -f app db \u0026\u0026
      docker network rm app-network","validation":"docker network ls | grep app-network"}]'
    - '{"network_created":"custom network must exist","containers_connected":"both
      containers on same network","dns_resolution":"containers can resolve each other
      by name","cleanup":"network must be removed"}'
    - docker
    - networking
    - Create networks, connect containers, test inter-container communication
    - '["Understanding of basic networking concepts"]'
    - Containers communicate on custom network
    - docker:20-dind
    - '["docker"]'
    - 5
    - 0
    - 0.0
    - 0.0
    - DCA
    - true
    - 250
    - '2025-11-06 03:44:03.179569'
    - '2025-11-06 03:44:03.179569'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -
  - - 9
    - Docker Compose - Multi-Container Application
    - Deploy a multi-container application using Docker Compose
    - medium
    - 40
    - '[{"step_number":1,"title":"Create docker-compose.yml","instruction":"Create
      compose file with web and database services","expected_command":"cat \u003e
      docker-compose.yml \u003c\u003c ''EOF''\nversion: ''3.8''\nservices:\n  web:\n    image:
      nginx:alpine\n    ports:\n      - ''8080:80''\n    depends_on:\n      - db\n  db:\n    image:
      mysql:8\n    environment:\n      MYSQL_ROOT_PASSWORD: secret\n      MYSQL_DATABASE:
      myapp\n    volumes:\n      - db-data:/var/lib/mysql\nvolumes:\n  db-data:\nEOF","validation":"test
      -f docker-compose.yml"},{"step_number":2,"title":"Start services","instruction":"Start
      all services in detached mode","expected_command":"docker-compose up -d","validation":"docker-compose
      ps | grep Up"},{"step_number":3,"title":"Check service status","instruction":"List
      running compose services","expected_command":"docker-compose ps","validation":"docker-compose
      ps | wc -l"},{"step_number":4,"title":"View logs","instruction":"Check logs
      from all services","expected_command":"docker-compose logs","validation":"docker-compose
      logs | grep mysql"},{"step_number":5,"title":"Scale web service","instruction":"Scale
      web service to 3 replicas","expected_command":"docker-compose up -d --scale
      web=3","validation":"docker-compose ps | grep web | wc -l"},{"step_number":6,"title":"Stop
      services","instruction":"Stop and remove all containers","expected_command":"docker-compose
      down","validation":"docker-compose ps | grep Up"},{"step_number":7,"title":"Cleanup
      with volumes","instruction":"Remove everything including volumes","expected_command":"docker-compose
      down -v \u0026\u0026 rm docker-compose.yml","validation":"test -f docker-compose.yml"}]'
    - '{"compose_file_valid":"valid docker-compose.yml","services_running":"both services
      must be up","depends_on_works":"web depends on db","scaling_works":"must scale
      to 3 web containers","cleanup":"all resources removed"}'
    - docker-compose
    - orchestration
    - Write docker-compose.yml, manage multi-container apps, understand service dependencies
    - '["Completed networking and volumes labs"]'
    - Successfully deploy and manage multi-container app
    - docker:20-dind
    - '["docker","docker-compose"]'
    - 5
    - 0
    - 0.0
    - 0.0
    - DCA
    - true
    - 350
    - '2025-11-06 03:44:03.190954'
    - '2025-11-06 03:44:03.190954'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -
  - - 10
    - Resource Limits - Control Container Resources
    - Learn to limit CPU and memory for containers
    - medium
    - 25
    - '[{"step_number":1,"title":"Run container with memory limit","instruction":"Run
      container with 512MB memory limit","expected_command":"docker run -d --name
      limited --memory 512m nginx","validation":"docker inspect limited | grep Memory"},{"step_number":2,"title":"Check
      memory stats","instruction":"View container resource usage","expected_command":"docker
      stats --no-stream limited","validation":"docker stats --no-stream limited |
      grep limited"},{"step_number":3,"title":"CPU limit","instruction":"Run container
      with CPU limit (1.5 CPUs)","expected_command":"docker run -d --name cpu-limited
      --cpus 1.5 nginx","validation":"docker inspect cpu-limited | grep NanoCpus"},{"step_number":4,"title":"Combined
      limits","instruction":"Run with both memory and CPU limits","expected_command":"docker
      run -d --name combined --memory 256m --cpus 0.5 nginx","validation":"docker
      stats --no-stream combined"},{"step_number":5,"title":"Cleanup","instruction":"Remove
      all containers","expected_command":"docker rm -f limited cpu-limited combined","validation":"docker
      ps -a | grep limited"}]'
    - '{"memory_limit_set":"memory limit must be enforced","cpu_limit_set":"CPU limit
      must be enforced","stats_accessible":"docker stats must show usage"}'
    - docker
    - performance
    - Set memory limits, CPU limits, understand resource management
    - '["Basic Docker knowledge"]'
    - Successfully apply and verify resource limits
    - docker:20-dind
    - '["docker"]'
    - 5
    - 0
    - 0.0
    - 0.0
    - DCA
    - true
    - 200
    - '2025-11-06 03:44:03.195115'
    - '2025-11-06 03:44:03.195115'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -
  - - 11
    - Docker Registry - Push and Pull Custom Images
    - Set up a private registry and manage custom images
    - hard
    - 45
    - '[{"step_number":1,"title":"Run local registry","instruction":"Start a local
      Docker registry on port 5000","expected_command":"docker run -d -p 5000:5000
      --name registry registry:2","validation":"docker ps | grep registry"},{"step_number":2,"title":"Build
      custom image","instruction":"Build a simple custom image","expected_command":"echo
      ''FROM alpine'' \u003e Dockerfile \u0026\u0026 docker build -t myapp:v1 .","validation":"docker
      images | grep myapp"},{"step_number":3,"title":"Tag for registry","instruction":"Tag
      image for local registry","expected_command":"docker tag myapp:v1 localhost:5000/myapp:v1","validation":"docker
      images | grep localhost:5000/myapp"},{"step_number":4,"title":"Push to registry","instruction":"Push
      image to local registry","expected_command":"docker push localhost:5000/myapp:v1","validation":"curl
      -s http://localhost:5000/v2/_catalog | grep myapp"},{"step_number":5,"title":"Remove
      local image","instruction":"Remove local images to test pull","expected_command":"docker
      rmi myapp:v1 localhost:5000/myapp:v1","validation":"docker images | grep myapp"},{"step_number":6,"title":"Pull
      from registry","instruction":"Pull image from private registry","expected_command":"docker
      pull localhost:5000/myapp:v1","validation":"docker images | grep localhost:5000/myapp"},{"step_number":7,"title":"Cleanup","instruction":"Remove
      registry and images","expected_command":"docker rm -f registry \u0026\u0026
      docker rmi localhost:5000/myapp:v1 \u0026\u0026 rm Dockerfile","validation":"docker
      ps | grep registry"}]'
    - '{"registry_running":"registry must be accessible","image_pushed":"image must
      be in registry","image_pulled":"can pull from registry","cleanup":"all resources
      removed"}'
    - docker
    - registry
    - Run private registry, tag images, push/pull from registry
    - '["Completed image building labs"]'
    - Successfully run private registry and manage images
    - docker:20-dind
    - '["docker","curl"]'
    - 3
    - 0
    - 0.0
    - 0.0
    - DCA
    - true
    - 400
    - '2025-11-06 03:44:03.198585'
    - '2025-11-06 03:44:03.198585'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -
  - - 12
    - Health Checks and Auto-Restart
    - Implement container health checks and restart policies
    - hard
    - 35
    - '[{"step_number":1,"title":"Create Dockerfile with HEALTHCHECK","instruction":"Create
      Dockerfile with health check for nginx","expected_command":"cat \u003e Dockerfile
      \u003c\u003c ''EOF''\nFROM nginx:alpine\nHEALTHCHECK --interval=5s --timeout=3s
      --start-period=5s --retries=3 \\\n  CMD wget --no-verbose --tries=1 --spider
      http://localhost/ || exit 1\nEOF","validation":"grep HEALTHCHECK Dockerfile"},{"step_number":2,"title":"Build
      image with health check","instruction":"Build the image","expected_command":"docker
      build -t webapp:health .","validation":"docker images | grep webapp"},{"step_number":3,"title":"Run
      with restart policy","instruction":"Run container with restart=unless-stopped","expected_command":"docker
      run -d --name web --restart unless-stopped webapp:health","validation":"docker
      inspect web | grep RestartPolicy"},{"step_number":4,"title":"Check health status","instruction":"Verify
      health check is working","expected_command":"sleep 10 \u0026\u0026 docker inspect
      web --format=''{{.State.Health.Status}}''","validation":"docker inspect web
      --format=''{{.State.Health.Status}}'' | grep healthy"},{"step_number":5,"title":"Test
      auto-restart","instruction":"Kill container and verify it restarts","expected_command":"docker
      kill web \u0026\u0026 sleep 5 \u0026\u0026 docker ps | grep web","validation":"docker
      ps | grep web"},{"step_number":6,"title":"View health check logs","instruction":"Check
      health check results","expected_command":"docker inspect web --format=''{{json
      .State.Health}}''","validation":"docker inspect web | grep Health"},{"step_number":7,"title":"Cleanup","instruction":"Stop
      container and remove resources","expected_command":"docker stop web \u0026\u0026
      docker rm web \u0026\u0026 docker rmi webapp:health \u0026\u0026 rm Dockerfile","validation":"docker
      ps -a | grep web"}]'
    - '{"healthcheck_defined":"HEALTHCHECK in Dockerfile","container_healthy":"health
      status must be healthy","auto_restart_works":"container restarts after kill","cleanup":"all
      resources removed"}'
    - docker
    - reliability
    - Define health checks, configure restart policies, test automatic recovery
    - '["Advanced Docker knowledge"]'
    - Implement working health checks and auto-restart
    - docker:20-dind
    - '["docker"]'
    - 3
    - 0
    - 0.0
    - 0.0
    - DCA
    - true
    - 400
    - '2025-11-06 03:44:03.202522'
    - '2025-11-06 03:44:03.202522'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -
  - - 13
    - Docker Security - Non-Root User and Read-Only
    - Implement security best practices in containers
    - hard
    - 40
    - '[{"step_number":1,"title":"Create Dockerfile with non-root user","instruction":"Create
      Dockerfile that runs as non-root user","expected_command":"cat \u003e Dockerfile
      \u003c\u003c ''EOF''\nFROM nginx:alpine\nRUN addgroup -S appgroup \u0026\u0026
      adduser -S appuser -G appgroup\nUSER appuser\nEOF","validation":"grep USER Dockerfile"},{"step_number":2,"title":"Build
      secure image","instruction":"Build the image","expected_command":"docker build
      -t secure-nginx .","validation":"docker images | grep secure-nginx"},{"step_number":3,"title":"Run
      with read-only filesystem","instruction":"Run container with read-only root
      filesystem","expected_command":"docker run -d --name secure --read-only --tmpfs
      /tmp secure-nginx","validation":"docker inspect secure | grep ReadonlyRootfs"},{"step_number":4,"title":"Verify
      non-root user","instruction":"Check that container runs as non-root","expected_command":"docker
      exec secure whoami","validation":"docker exec secure whoami | grep -v root"},{"step_number":5,"title":"Test
      read-only","instruction":"Try to write to filesystem (should fail)","expected_command":"docker
      exec secure touch /test.txt || echo ''Read-only verified''","validation":"docker
      exec secure sh -c ''touch /test.txt 2\u003e\u00261'' | grep -i ''read-only''"},{"step_number":6,"title":"Drop
      capabilities","instruction":"Run with dropped capabilities","expected_command":"docker
      run -d --name cap-drop --cap-drop=ALL --cap-add=NET_BIND_SERVICE nginx","validation":"docker
      inspect cap-drop | grep CapDrop"},{"step_number":7,"title":"Cleanup","instruction":"Remove
      all secure containers and images","expected_command":"docker rm -f secure cap-drop
      \u0026\u0026 docker rmi secure-nginx \u0026\u0026 rm Dockerfile","validation":"docker
      ps -a | grep secure"}]'
    - '{"nonroot_user":"must run as non-root user","readonly_fs":"root filesystem
      must be read-only","capabilities_dropped":"unnecessary capabilities removed","security_verified":"security
      measures tested"}'
    - docker
    - security
    - Run as non-root, read-only filesystem, drop capabilities
    - '["Advanced Docker and Linux security knowledge"]'
    - Implement and verify container security hardening
    - docker:20-dind
    - '["docker"]'
    - 3
    - 0
    - 0.0
    - 0.0
    - DCA
    - true
    - 500
    - '2025-11-06 03:44:03.206340'
    - '2025-11-06 03:44:03.206340'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -
  - - 14
    - Container Performance Monitoring
    - Monitor and analyze container performance metrics
    - medium
    - 30
    - '[{"step_number":1,"title":"Run test containers","instruction":"Start multiple
      containers with different workloads","expected_command":"docker run -d --name
      web nginx \u0026\u0026 docker run -d --name db mysql:8 -e MYSQL_ROOT_PASSWORD=secret","validation":"docker
      ps | wc -l"},{"step_number":2,"title":"View live stats","instruction":"Monitor
      real-time resource usage","expected_command":"docker stats --no-stream","validation":"docker
      stats --no-stream | grep web"},{"step_number":3,"title":"Format stats output","instruction":"Display
      stats with custom format","expected_command":"docker stats --no-stream --format
      ''table {{.Container}}\\t{{.CPUPerc}}\\t{{.MemUsage}}''","validation":"docker
      stats --no-stream --format ''{{.Container}}''"},{"step_number":4,"title":"Export
      stats to file","instruction":"Save stats to CSV file","expected_command":"docker
      stats --no-stream --format ''{{.Container}},{{.CPUPerc}},{{.MemUsage}}'' \u003e
      stats.csv","validation":"test -f stats.csv"},{"step_number":5,"title":"Cleanup","instruction":"Remove
      containers and stats file","expected_command":"docker rm -f web db \u0026\u0026
      rm stats.csv","validation":"docker ps | grep web"}]'
    - '{"containers_running":"multiple containers must be running","stats_collected":"stats
      must be retrievable","export_works":"stats exported to file"}'
    - docker
    - monitoring
    - Use docker stats, analyze resource usage, identify performance issues
    - '["Understanding of system resources"]'
    - Successfully monitor container performance
    - docker:20-dind
    - '["docker"]'
    - 5
    - 0
    - 0.0
    - 0.0
    - DCA
    - true
    - 250
    - '2025-11-06 03:44:03.210192'
    - '2025-11-06 03:44:03.210192'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -
  - - 15
    - Backup and Restore Container Data
    - Learn to backup and restore container data and configurations
    - medium
    - 35
    - '[{"step_number":1,"title":"Create data volume","instruction":"Create volume
      and populate with data","expected_command":"docker volume create backup-vol
      \u0026\u0026 docker run --rm -v backup-vol:/data alpine sh -c ''echo test \u003e
      /data/file.txt''","validation":"docker volume ls | grep backup-vol"},{"step_number":2,"title":"Backup
      volume data","instruction":"Backup volume to tar archive","expected_command":"docker
      run --rm -v backup-vol:/data -v $(pwd):/backup alpine tar czf /backup/backup.tar.gz
      -C /data .","validation":"test -f backup.tar.gz"},{"step_number":3,"title":"Create
      container to backup","instruction":"Run container with data to backup","expected_command":"docker
      run -d --name db-backup -v backup-vol:/var/lib/data alpine sleep 3600","validation":"docker
      ps | grep db-backup"},{"step_number":4,"title":"Export container","instruction":"Export
      container filesystem","expected_command":"docker export db-backup \u003e container-backup.tar","validation":"test
      -f container-backup.tar"},{"step_number":5,"title":"Delete original resources","instruction":"Remove
      volume and container","expected_command":"docker rm -f db-backup \u0026\u0026
      docker volume rm backup-vol","validation":"docker volume ls | grep backup-vol"},{"step_number":6,"title":"Restore
      volume","instruction":"Create new volume and restore data","expected_command":"docker
      volume create restored-vol \u0026\u0026 docker run --rm -v restored-vol:/data
      -v $(pwd):/backup alpine tar xzf /backup/backup.tar.gz -C /data","validation":"docker
      run --rm -v restored-vol:/data alpine cat /data/file.txt"},{"step_number":7,"title":"Cleanup","instruction":"Remove
      all backup resources","expected_command":"docker volume rm restored-vol \u0026\u0026
      rm backup.tar.gz container-backup.tar","validation":"test -f backup.tar.gz"}]'
    - '{"volume_backed_up":"volume data saved to tar","container_exported":"container
      filesystem exported","data_restored":"data successfully restored","cleanup":"all
      resources removed"}'
    - docker
    - operations
    - Export/import containers, backup volumes, restore data
    - '["Understanding of Docker volumes"]'
    - Successfully backup and restore container data
    - docker:20-dind
    - '["docker"]'
    - 5
    - 0
    - 0.0
    - 0.0
    - DCA
    - true
    - 300
    - '2025-11-06 03:44:03.215395'
    - '2025-11-06 03:44:03.215395'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -
  - - 16
    - Troubleshooting Docker Containers
    - 'Debug and fix 10 common Docker container failures: exit crashes, port conflicts,
      permission errors, networking issues, and more'
    - hard
    - 45
    - '[{"step_number":1,"title":"Scenario 1: Container Exits Immediately","instruction":"Run
      container that exits immediately with ''exit 1'', diagnose with docker logs,
      then fix by changing command to run indefinitely","expected_command":"docker
      run -d --name exit-test alpine sh -c ''exit 1'' \u0026\u0026 sleep 3 \u0026\u0026
      docker logs exit-test \u0026\u0026 docker rm -f exit-test \u0026\u0026 docker
      run -d --name exit-test alpine sleep 3600","validation":"docker ps | grep exit-test","hint":"Use
      ''docker logs'' to see why container exited, then use ''docker inspect'' to
      check exit code"},{"step_number":2,"title":"Scenario 2: Port Already in Use","instruction":"Start
      nginx on port 8080, try to start another on same port (will fail), diagnose
      error, fix by using different port 8081","expected_command":"docker run -d --name
      nginx1 -p 8080:80 nginx:alpine \u0026\u0026 docker run -d --name nginx2 -p 8080:80
      nginx:alpine 2\u003e\u00261 | grep ''address already in use'' \u0026\u0026 docker
      run -d --name nginx2 -p 8081:80 nginx:alpine","validation":"docker ps | grep
      nginx2","hint":"Look for ''bind: address already in use'' error, use ''docker
      ps'' to see what''s using the port"},{"step_number":3,"title":"Scenario 3: Volume
      Permission Denied","instruction":"Create directory with restricted permissions,
      try to mount and write (will fail), diagnose permission error, fix with proper
      ownership","expected_command":"mkdir -p /tmp/restricted \u0026\u0026 chmod 000
      /tmp/restricted \u0026\u0026 docker run --rm -v /tmp/restricted:/data alpine
      sh -c ''echo test \u003e /data/file'' 2\u003e\u00261 | grep -i permission \u0026\u0026
      sudo chmod 755 /tmp/restricted \u0026\u0026 docker run --rm -v /tmp/restricted:/data
      alpine sh -c ''echo test \u003e /data/file''","validation":"ls /tmp/restricted/file","hint":"Check
      directory permissions with ''ls -ld'', use chmod or run container with appropriate
      user"},{"step_number":4,"title":"Scenario 4: Image Not Found","instruction":"Try
      to run non-existent image nginx:doesnotexist999, diagnose pull error, fix by
      using correct tag nginx:alpine","expected_command":"docker run nginx:doesnotexist999
      2\u003e\u00261 | grep -i ''manifest.*not found'' \u0026\u0026 docker run -d
      --name image-test nginx:alpine","validation":"docker ps | grep image-test","hint":"Error
      shows ''manifest unknown'' or ''not found'', verify image exists on Docker Hub"},{"step_number":5,"title":"Scenario
      5: Out of Disk Space","instruction":"Check disk usage with ''docker system df'',
      prune unused images/containers to free space","expected_command":"docker system
      df \u0026\u0026 docker system prune -f","validation":"docker system df | grep
      ''TYPE.*TOTAL''","hint":"Use ''docker system df'' to see space usage, ''docker
      system prune'' to clean up"},{"step_number":6,"title":"Scenario 6: Container
      Network Isolation","instruction":"Start two containers on default bridge, create
      custom network, move containers to custom network to enable communication by
      name","expected_command":"docker run -d --name web1 nginx:alpine \u0026\u0026
      docker run -d --name web2 alpine sh -c ''ping -c 2 web1'' 2\u003e\u00261 | grep
      ''bad address'' \u0026\u0026 docker network create mynet \u0026\u0026 docker
      network connect mynet web1 \u0026\u0026 docker run --rm --network mynet alpine
      ping -c 2 web1","validation":"docker network inspect mynet | grep web1","hint":"Containers
      on default bridge can only communicate by IP, custom networks enable DNS resolution"},{"step_number":7,"title":"Scenario
      7: Environment Variable Not Set","instruction":"Run container expecting MY_VAR
      env var (will fail), diagnose missing variable, fix by passing -e MY_VAR=value","expected_command":"docker
      run --rm alpine sh -c ''echo $MY_VAR'' \u0026\u0026 docker run --rm -e MY_VAR=hello
      alpine sh -c ''echo $MY_VAR''","validation":"docker run --rm -e MY_VAR=test
      alpine sh -c ''echo $MY_VAR'' | grep test","hint":"Use -e flag to pass environment
      variables, or --env-file for multiple vars"},{"step_number":8,"title":"Scenario
      8: Container Restart Loop","instruction":"Create container with failing healthcheck
      causing restart loop, diagnose with docker events, fix healthcheck","expected_command":"docker
      run -d --name restart-test --restart=always --health-cmd=''exit 1'' --health-interval=5s
      alpine sleep 3600 \u0026\u0026 sleep 10 \u0026\u0026 docker events --since 5s
      --filter ''container=restart-test'' | grep unhealthy \u0026\u0026 docker rm
      -f restart-test \u0026\u0026 docker run -d --name restart-test --health-cmd=''exit
      0'' --health-interval=5s alpine sleep 3600","validation":"docker inspect restart-test
      | grep ''\"Status\": \"healthy\"''","hint":"Use ''docker events'' to see health
      status changes, check healthcheck command"},{"step_number":9,"title":"Scenario
      9: Name Conflict","instruction":"Try to create container with existing name
      (will fail), diagnose conflict error, fix by removing old container or using
      different name","expected_command":"docker run -d --name conflict-test alpine
      sleep 3600 \u0026\u0026 docker run -d --name conflict-test alpine sleep 3600
      2\u003e\u00261 | grep ''Conflict'' \u0026\u0026 docker rm -f conflict-test \u0026\u0026
      docker run -d --name conflict-test alpine sleep 3600","validation":"docker ps
      | grep conflict-test","hint":"Error shows ''Conflict. The container name is
      already in use'', remove old container or rename new one"},{"step_number":10,"title":"Scenario
      10: Container Cannot Connect to Host Service","instruction":"Start service on
      host, container tries to connect to ''localhost'' (will fail), diagnose connection
      refused, fix using host.docker.internal or host network mode","expected_command":"python3
      -m http.server 9999 \u003e/dev/null 2\u003e\u00261 \u0026 HTTP_PID=$!; sleep
      2; docker run --rm alpine sh -c ''wget -O- localhost:9999'' 2\u003e\u00261 |
      grep ''Connection refused'' \u0026\u0026 docker run --rm --add-host=host.docker.internal:host-gateway
      alpine sh -c ''wget -O- host.docker.internal:9999'' | grep -i ''http'' ; kill
      $HTTP_PID","validation":"echo ''Verified host communication works''","hint":"Use
      ''host.docker.internal'' to reach host from container, or ''--network host''
      to share host network"}]'
    - '{"exit_fixed":"Container runs without immediate exit","port_fixed":"Port conflict
      resolved with different port","permission_fixed":"Volume permission issue resolved","image_fixed":"Correct
      image tag used","disk_cleaned":"Disk space freed via pruning","network_fixed":"Custom
      network enables container communication","env_fixed":"Environment variable properly
      passed","healthcheck_fixed":"Healthcheck passes successfully","name_fixed":"Name
      conflict resolved","host_connection_fixed":"Container can reach host services"}'
    - docker
    - troubleshooting
    - Diagnose container exits, port conflicts, volume permission errors, image pull
      failures, disk space issues, network problems, environment variable errors,
      and daemon connectivity; use docker logs, inspect, events, and debugging techniques
    - '["Docker installed","Basic understanding of containers","Command line experience"]'
    - Successfully diagnosed and fixed all 10 common Docker container failures
    - docker:20-dind
    - '["docker"]'
    - 15
    - 0
    - 0.0
    - 0.0
    -
    - true
    - 280
    - '2025-11-06 03:44:03.225145'
    - '2025-11-06 03:44:03.225145'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -
  - - 17
    - ConfigMaps and Secrets for App Configuration
    - Create ConfigMaps and Secrets and mount them as env and volumes in a Pod
    - medium
    - 25
    - '[{"step_number":1,"title":"Create ConfigMap","instruction":"Create a ConfigMap
      named app-config with KEY=VALUE","expected_command":"kubectl create configmap
      app-config --from-literal=KEY=VALUE","validation":"kubectl get configmap app-config
      -o yaml"},{"step_number":2,"title":"Create Secret","instruction":"Create an
      opaque Secret named app-secret with API_KEY=demo","expected_command":"kubectl
      create secret generic app-secret --from-literal=API_KEY=demo","validation":"kubectl
      get secret app-secret -o yaml"},{"step_number":3,"title":"Pod with envFrom","instruction":"Run
      a Pod named cm-demo with alpine using envFrom from app-config and app-secret","expected_command":"kubectl
      run cm-demo --image=alpine --restart=Never --env-from=configmap/app-config --env-from=secret/app-secret
      -- sh -c ''sleep 3600''","validation":"kubectl exec cm-demo -- sh -c ''printenv
      | grep -E \"KEY|API_KEY\"''"}]'
    - '{"cm_created":"ConfigMap exists","secret_created":"Secret exists","pod_running":"Pod
      cm-demo is Running"}'
    - kubernetes
    - configuration
    - Use ConfigMap/Secret with envFrom, volume mounts, and manifests
    - '["kubectl installed","Access to a Kubernetes cluster"]'
    - Variables exposed and readable inside the Pod
    - kindest/node:v1.29.0
    - '["kubectl"]'
    - 5
    - 0
    - 0.0
    - 0.0
    - CKAD
    - true
    - 150
    - '2025-11-06 03:44:03.234963'
    - '2025-11-06 03:44:03.234963'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -
  - - 18
    - Service Types and Load Balancing
    - Expose workloads using ClusterIP, NodePort, and LoadBalancer; verify connectivity
    - medium
    - 25
    - '[{"step_number":1,"title":"Deploy App","instruction":"Create deploy svc-web
      with 2 replicas","expected_command":"kubectl create deploy svc-web --image=nginx:1.25
      --replicas=2","validation":"kubectl get deploy svc-web"},{"step_number":2,"title":"ClusterIP
      Service","instruction":"Expose deployment as ClusterIP on port 80","expected_command":"kubectl
      expose deploy svc-web --port 80 --target-port 80 --name web","validation":"kubectl
      get svc web"},{"step_number":3,"title":"NodePort Service","instruction":"Change
      service type to NodePort","expected_command":"kubectl patch svc web -p ''{\"spec\":{\"type\":\"NodePort\"}}''","validation":"kubectl
      get svc web -o yaml | grep -i nodePort"}]'
    - '{"service_created":"Service web exists","nodeport_set":"Service has nodePort"}'
    - kubernetes
    - networking
    - Create Services of different types and test network reachability
    - '["kubectl","Basic Services knowledge"]'
    - Service exposed and reachable via appropriate type
    - kindest/node:v1.29.0
    - '["kubectl"]'
    - 5
    - 0
    - 0.0
    - 0.0
    - CKAD
    - true
    - 160
    - '2025-11-06 03:44:03.240295'
    - '2025-11-06 03:44:03.240295'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -
  - - 19
    - Ingress Configuration
    - Configure an Ingress resource to route traffic to a backend service
    - medium
    - 30
    - '[{"step_number":1,"title":"Backend Service","instruction":"Create deployment
      app and expose as ClusterIP svc app-svc:80","expected_command":"kubectl create
      deploy app --image=nginx:1.25 \u0026\u0026 kubectl expose deploy app --name
      app-svc --port 80","validation":"kubectl get svc app-svc"},{"step_number":2,"title":"Create
      Ingress","instruction":"Create an Ingress route / to app-svc:80","expected_command":"kubectl
      apply -f - \u003c\u003c''EOF''\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name:
      app-ing\nspec:\n  rules:\n  - http:\n      paths:\n      - path: /\n        pathType:
      Prefix\n        backend:\n          service:\n            name: app-svc\n            port:\n              number:
      80\nEOF","validation":"kubectl get ing app-ing"}]'
    - '{"ingress_created":"Ingress app-ing exists"}'
    - kubernetes
    - networking
    - Create Ingress with path rules and verify routing
    - '["Ingress controller installed"]'
    - Ingress routes traffic to service
    - kindest/node:v1.29.0
    - '["kubectl"]'
    - 5
    - 0
    - 0.0
    - 0.0
    - CKAD
    - true
    - 170
    - '2025-11-06 03:44:03.245515'
    - '2025-11-06 03:44:03.245515'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -
  - - 20
    - Build and Optimize Container Images
    - Use multi-stage builds and best practices to produce optimized images
    - medium
    - 25
    - '[{"step_number":1,"title":"Create Multi-Stage Dockerfile","instruction":"Write
      a multi-stage Dockerfile for a Go app producing a statically-linked binary","expected_command":"cat
      \u003e Dockerfile \u003c\u003c''EOF''\nFROM golang:1.20 AS build\nWORKDIR /app\nRUN
      go env -w CGO_ENABLED=0\nRUN printf ''package main\\nimport \\\"fmt\\\"\\nfunc
      main(){fmt.Println(\\\"hello\\\")}'' \u003e main.go\nRUN go build -o app\nFROM
      alpine:3.19\nCOPY --from=build /app/app /usr/local/bin/app\nENTRYPOINT [\"/usr/local/bin/app\"]\nEOF","validation":"grep
      -c FROM Dockerfile"},{"step_number":2,"title":"Build Image","instruction":"Build
      the image with tag ckad/app:latest","expected_command":"docker build -t ckad/app:latest
      .","validation":"docker images | grep ckad/app"},{"step_number":3,"title":"Run
      Container","instruction":"Run the container and verify output","expected_command":"docker
      run --rm ckad/app:latest","validation":"docker run --rm ckad/app:latest | grep
      hello"}]'
    - '{"multistage_ok":"Dockerfile uses multi-stage","built":"Image built","output_ok":"Container
      prints hello"}'
    - kubernetes
    - images
    - Build multi-stage images, reduce image size, follow best practices
    - '["Dockerfile basics","Docker/Podman installed"]'
    - Image builds successfully and runs printing 'hello'
    - docker:20-dind
    - '["docker"]'
    - 5
    - 0
    - 0.0
    - 0.0
    - CKAD
    - true
    - 140
    - '2025-11-06 03:44:03.249650'
    - '2025-11-06 03:44:03.249650'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -
  - - 21
    - Multi-Container Pod Patterns
    - Implement sidecar and adapter patterns in a single Pod
    - medium
    - 30
    - '[{"step_number":1,"title":"Create Pod with Sidecar","instruction":"Create a
      pod mc-pod with nginx app and busybox sidecar that tails nginx access log via
      shared volume","expected_command":"kubectl apply -f - \u003c\u003c''EOF''\napiVersion:
      v1\nkind: Pod\nmetadata:\n  name: mc-pod\nspec:\n  volumes:\n  - name: logs\n    emptyDir:
      {}\n  containers:\n  - name: app\n    image: nginx:1.25\n    volumeMounts:\n    -
      name: logs\n      mountPath: /var/log/nginx\n  - name: sidecar\n    image: busybox\n    args:
      [''sh'',''-c'',''tail -F /var/log/nginx/access.log'']\n    volumeMounts:\n    -
      name: logs\n      mountPath: /var/log/nginx\nEOF","validation":"kubectl get
      pod mc-pod"},{"step_number":2,"title":"Generate Traffic","instruction":"Port-forward
      and curl to generate access logs","expected_command":"kubectl port-forward pod/mc-pod
      8080:80 \u0026 sleep 2; curl -s localhost:8080 \u003e/dev/null","validation":"kubectl
      logs mc-pod -c sidecar --tail=5 | grep -E ''GET /''"}]'
    - '{"pod_running":"Pod mc-pod Running","logs_flowing":"Sidecar sees requests"}'
    - kubernetes
    - workloads
    - Create multi-container pod with sidecar and shared volumes
    - '["kubectl","Basic YAML"]'
    - Sidecar container streams nginx access logs
    - kindest/node:v1.29.0
    - '["kubectl"]'
    - 5
    - 0
    - 0.0
    - 0.0
    - CKAD
    - true
    - 160
    - '2025-11-06 03:44:03.253823'
    - '2025-11-06 03:44:03.253823'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -
  - - 22
    - Application Lifecycle Management
    - Use init containers and lifecycle hooks (preStop) to manage app lifecycle
    - medium
    - 25
    - '[{"step_number":1,"title":"Create Deployment with Init","instruction":"Create
      deploy lifecycle with an initContainer that waits for config file then starts
      app","expected_command":"kubectl apply -f - \u003c\u003c''EOF''\napiVersion:
      apps/v1\nkind: Deployment\nmetadata:\n  name: lifecycle\nspec:\n  replicas:
      1\n  selector:\n    matchLabels:\n      app: lifecycle\n  template:\n    metadata:\n      labels:\n        app:
      lifecycle\n    spec:\n      initContainers:\n      - name: init\n        image:
      busybox\n        args: [''sh'',''-c'',''echo ready \u003e /tmp/ready; sleep
      2'']\n      containers:\n      - name: app\n        image: busybox\n        args:
      [''sh'',''-c'',''trap \"echo stopping\" TERM; echo running; sleep 3600'']\n        lifecycle:\n          preStop:\n            exec:\n              command:
      [''sh'',''-c'',''echo preStop \u003e\u003e /tmp/hook'']\nEOF","validation":"kubectl
      get deploy lifecycle"},{"step_number":2,"title":"Trigger Shutdown","instruction":"Scale
      to 0 and verify preStop executed","expected_command":"kubectl scale deploy/lifecycle
      --replicas=0","validation":"kubectl get deploy lifecycle -o yaml | grep replicas:
      0"}]'
    - '{"deploy_created":"Deployment exists","prestop_triggered":"preStop executed"}'
    - kubernetes
    - workloads
    - Configure init containers and lifecycle hooks
    - '["kubectl","Basic YAML"]'
    - Init ran before app and preStop executed on termination
    - kindest/node:v1.29.0
    - '["kubectl"]'
    - 5
    - 0
    - 0.0
    - 0.0
    - CKAD
    - true
    - 150
    - '2025-11-06 03:44:03.257860'
    - '2025-11-06 03:44:03.257860'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -
  - - 23
    - Rolling Updates and Rollback Scenarios
    - Perform rolling updates on Deployments and execute rollbacks
    - medium
    - 25
    - '[{"step_number":1,"title":"Create Deployment","instruction":"Create deployment
      web with nginx:1.23 (2 replicas)","expected_command":"kubectl create deploy
      web --image=nginx:1.23 --replicas=2","validation":"kubectl get deploy web"},{"step_number":2,"title":"Rolling
      Update","instruction":"Update image to nginx:1.25 and watch rollout status","expected_command":"kubectl
      set image deploy/web nginx=nginx:1.25 \u0026\u0026 kubectl rollout status deploy/web","validation":"kubectl
      get deploy web -o yaml | grep nginx:1.25"},{"step_number":3,"title":"Introduce
      Bad Image","instruction":"Set image to nginx:badtag and check rollout","expected_command":"kubectl
      set image deploy/web nginx=nginx:badtag \u0026\u0026 kubectl rollout status
      deploy/web --timeout=20s || true","validation":"kubectl rollout history deploy/web"},{"step_number":4,"title":"Rollback","instruction":"Rollback
      to previous working version","expected_command":"kubectl rollout undo deploy/web","validation":"kubectl
      get deploy web -o yaml | grep nginx:1.25"}]'
    - '{"updated_ok":"Updated to 1.25","rollback_ok":"Rollback completed"}'
    - kubernetes
    - workloads
    - Use kubectl rollout for status, pause, resume, and rollback
    - '["kubectl","Basic Deployments"]'
    - Deployment updated then rolled back successfully
    - kindest/node:v1.29.0
    - '["kubectl"]'
    - 5
    - 0
    - 0.0
    - 0.0
    - CKAD
    - true
    - 160
    - '2025-11-06 03:44:03.261811'
    - '2025-11-06 03:44:03.261811'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -
  - - 24
    - 'Probes: Liveness and Readiness'
    - Configure HTTP liveness and readiness probes for a deployment
    - medium
    - 20
    - '[{"step_number":1,"title":"Create Deployment","instruction":"Create a deployment
      web with nginx:1.25, 2 replicas","expected_command":"kubectl create deploy web
      --image=nginx:1.25 --replicas=2","validation":"kubectl get deploy web"},{"step_number":2,"title":"Patch
      Probes","instruction":"Add HTTP GET probes on / with port 80 for both liveness
      and readiness","expected_command":"kubectl set probe deploy/web --liveness --get-url=http://:80/
      --readiness --get-url=http://:80/","validation":"kubectl get deploy web -o yaml
      | grep -A5 livenessProbe"},{"step_number":3,"title":"Verify","instruction":"Ensure
      Pods become Ready then simulate probe failures","expected_command":"kubectl
      get pods -w","validation":"kubectl describe pod -l app=web | grep -i readiness"}]'
    - '{"deployment_ready":"Deployment available","probes_configured":"Probes present
      in spec"}'
    - kubernetes
    - observability
    - Set liveness/readiness probes and verify status transitions
    - '["Create a namespace","Basic YAML editing"]'
    - Deployment shows Ready with correct probe configuration
    - kindest/node:v1.29.0
    - '["kubectl"]'
    - 5
    - 0
    - 0.0
    - 0.0
    - CKAD
    - true
    - 150
    - '2025-11-06 03:44:03.267017'
    - '2025-11-06 03:44:03.267017'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -
  - - 25
    - Jobs and CronJobs
    - Create a one-off Job and a CronJob to run periodic tasks
    - medium
    - 20
    - '[{"step_number":1,"title":"Create Job","instruction":"Job named pi that runs
      perl to compute pi","expected_command":"kubectl create job pi --image=perl --
      perl -Mbignum=bpi -wle ''print bpi(50)''","validation":"kubectl get jobs pi"},{"step_number":2,"title":"Create
      CronJob","instruction":"CronJob hello runs every minute printing date","expected_command":"kubectl
      create cronjob hello --image=busybox --schedule=''*/1 * * * *'' -- /bin/sh -c
      ''date; echo Hello''","validation":"kubectl get cronjob hello"}]'
    - '{"job_complete":"Job completed","cronjob_created":"CronJob exists"}'
    - kubernetes
    - workloads
    - Write Job and CronJob manifests and verify completions
    - '["kubectl","Basic YAML"]'
    - Job completes and CronJob schedules successfully
    - kindest/node:v1.29.0
    - '["kubectl"]'
    - 5
    - 0
    - 0.0
    - 0.0
    - CKAD
    - true
    - 120
    - '2025-11-06 03:44:03.271086'
    - '2025-11-06 03:44:03.271086'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -
  - - 26
    - Application Logging and Debugging
    - Configure container logging, exec into pods, and use ephemeral containers for
      debug
    - medium
    - 30
    - '[{"step_number":1,"title":"Create Multi-Container Pod","instruction":"Create
      pod log-demo with app and logger sidecar","expected_command":"kubectl apply
      -f - \u003c\u003c''EOF''\napiVersion: v1\nkind: Pod\nmetadata:\n  name: log-demo\nspec:\n  containers:\n  -
      name: app\n    image: busybox\n    args: [''sh'',''-c'',''while true; do echo
      tick; sleep 3; done'']\n  - name: logger\n    image: busybox\n    args: [''sh'',''-c'',''sleep
      3600'']\nEOF","validation":"kubectl get pod log-demo"},{"step_number":2,"title":"View
      Logs","instruction":"View logs for app container","expected_command":"kubectl
      logs log-demo -c app --tail=5","validation":"kubectl logs log-demo -c app --tail=5
      | grep tick"},{"step_number":3,"title":"Ephemeral Container","instruction":"Add
      ephemeral container debug to inspect process namespace","expected_command":"kubectl
      debug -it log-demo --image=busybox --target=app -- bash -lc ''echo debug'' ||
      true","validation":"kubectl get pod log-demo -o yaml | grep -i ephemeral"}]'
    - '{"logs_ok":"App logs visible","ephemeral_ok":"Ephemeral container added"}'
    - kubernetes
    - observability
    - kubectl logs, -c selection, exec, and ephemeral containers
    - '["kubectl","K8s v1.25+ for ephemeral containers"]'
    - Logs viewed and ephemeral container used for debugging
    - kindest/node:v1.29.0
    - '["kubectl"]'
    - 5
    - 0
    - 0.0
    - 0.0
    - CKAD
    - true
    - 170
    - '2025-11-06 03:44:03.274684'
    - '2025-11-06 03:44:03.274684'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -
  - - 27
    - Resource Management and Limits
    - Set resource requests/limits and observe QoS class and throttling
    - medium
    - 25
    - '[{"step_number":1,"title":"Create Deployment","instruction":"Create deploy
      res-web with nginx:1.25 (2 replicas)","expected_command":"kubectl create deploy
      res-web --image=nginx:1.25 --replicas=2","validation":"kubectl get deploy res-web"},{"step_number":2,"title":"Set
      Resources","instruction":"Set CPU request=100m limit=200m for container nginx","expected_command":"kubectl
      set resources deploy/res-web -c=nginx --requests=cpu=100m --limits=cpu=200m","validation":"kubectl
      get deploy res-web -o yaml | grep -A2 resources:"},{"step_number":3,"title":"Check
      QoS","instruction":"Verify Pod QoS class is Burstable","expected_command":"kubectl
      get pod -l app=res-web -o jsonpath=''{.items[0].status.qosClass}''","validation":"kubectl
      get pod -l app=res-web -o jsonpath=''{.items[0].status.qosClass}'' | grep -E
      ''Burstable|Guaranteed''"}]'
    - '{"resources_set":"Requests/limits set","qos_ok":"QoS class reported"}'
    - kubernetes
    - configuration
    - Configure requests/limits and understand QoS classes
    - '["kubectl"]'
    - Deployment has resource limits and Pods report expected QoS
    - kindest/node:v1.29.0
    - '["kubectl"]'
    - 5
    - 0
    - 0.0
    - 0.0
    - CKAD
    - true
    - 150
    - '2025-11-06 03:44:03.278069'
    - '2025-11-06 03:44:03.278069'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -
  - - 28
    - Application Security Contexts
    - Harden application pods with runAsUser, fsGroup, and readOnlyRootFilesystem
    - medium
    - 25
    - '[{"step_number":1,"title":"Create Pod","instruction":"Create pod sc-app with
      runAsUser=1000 and fsGroup=2000","expected_command":"kubectl apply -f - \u003c\u003c''EOF''\napiVersion:
      v1\nkind: Pod\nmetadata:\n  name: sc-app\nspec:\n  securityContext:\n    runAsUser:
      1000\n    fsGroup: 2000\n  containers:\n  - name: app\n    image: busybox\n    command:
      [''sh'',''-c'',''sleep 3600'']\n    securityContext:\n      readOnlyRootFilesystem:
      true\n      allowPrivilegeEscalation: false\nEOF","validation":"kubectl get
      pod sc-app -o yaml | grep -i securityContext"},{"step_number":2,"title":"Verify","instruction":"Confirm
      pod is running and security context applied","expected_command":"kubectl get
      pod sc-app","validation":"kubectl describe pod sc-app | grep -i RunAsUser"}]'
    - '{"pod_running":"Pod Running","sc_applied":"securityContext present"}'
    - kubernetes
    - security
    - Apply pod and container securityContext fields
    - '["kubectl"]'
    - Pod runs with hardened security context
    - kindest/node:v1.29.0
    - '["kubectl"]'
    - 5
    - 0
    - 0.0
    - 0.0
    - CKAD
    - true
    - 160
    - '2025-11-06 03:44:03.281472'
    - '2025-11-06 03:44:03.281472'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -
  - - 29
    - Advanced Pod Scheduling
    - Use nodeSelector, affinity/anti-affinity, taints/tolerations, and priorities
    - hard
    - 35
    - '[{"step_number":1,"title":"Label Nodes","instruction":"Label a worker node
      disk=ssd and another zone=a","expected_command":"kubectl label node $(kubectl
      get nodes -o name | sed -n ''2p'' | cut -d/ -f2) disk=ssd --overwrite \u0026\u0026
      kubectl label node $(kubectl get nodes -o name | sed -n ''3p'' | cut -d/ -f2)
      zone=a --overwrite","validation":"kubectl get nodes --show-labels | grep -E
      ''disk=ssd|zone=a''"},{"step_number":2,"title":"Taint Node","instruction":"Taint
      first worker node key=workload:NoSchedule","expected_command":"kubectl taint
      nodes $(kubectl get nodes -o name | sed -n ''2p'' | cut -d/ -f2) workload=ok:NoSchedule
      --overwrite || true","validation":"kubectl get nodes -o json | grep -i taints
      -A2"},{"step_number":3,"title":"Schedule Pod","instruction":"Create a Pod requiring
      disk=ssd and tolerating taint","expected_command":"kubectl apply -f - \u003c\u003c''EOF''\napiVersion:
      v1\nkind: Pod\nmetadata:\n  name: sched-demo\nspec:\n  tolerations:\n  - key:
      workload\n    operator: Exists\n    effect: NoSchedule\n  affinity:\n    nodeAffinity:\n      requiredDuringSchedulingIgnoredDuringExecution:\n        nodeSelectorTerms:\n        -
      matchExpressions:\n          - key: disk\n            operator: In\n            values:
      [''ssd'']\n  containers:\n  - name: app\n    image: busybox\n    command: [''sh'',''-c'',''sleep
      1200'']\nEOF","validation":"kubectl get pod sched-demo -o wide"}]'
    - '{"labels_set":"Node labels present","pod_scheduled":"Pod scheduled on labeled
      node"}'
    - kubernetes
    - scheduling
    - Apply multiple scheduling constraints and verify placement
    - '["kubectl","Multi-node cluster"]'
    - Pod schedules honoring labels and tolerations
    - kindest/node:v1.29.0
    - '["kubectl"]'
    - 5
    - 0
    - 0.0
    - 0.0
    - CKA
    - true
    - 200
    - '2025-11-06 03:44:03.284812'
    - '2025-11-06 03:44:03.284812'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -
  - - 30
    - Pod Disruption Budgets
    - Protect availability using PDB while performing voluntary disruptions
    - medium
    - 25
    - '[{"step_number":1,"title":"Create Deployment","instruction":"Create deploy
      api with 3 replicas","expected_command":"kubectl create deploy api --image=nginx:1.25
      --replicas=3","validation":"kubectl get deploy api"},{"step_number":2,"title":"Create
      PDB","instruction":"Require at least 2 available pods","expected_command":"kubectl
      apply -f - \u003c\u003c''EOF''\napiVersion: policy/v1\nkind: PodDisruptionBudget\nmetadata:\n  name:
      api-pdb\nspec:\n  minAvailable: 2\n  selector:\n    matchLabels:\n      app:
      api\nEOF","validation":"kubectl get pdb api-pdb"},{"step_number":3,"title":"Drain
      Node","instruction":"Attempt to drain a node hosting pods and observe blocking","expected_command":"kubectl
      get nodes | awk ''NR==2{print $1}'' | xargs -I{} sh -c ''kubectl drain {} --ignore-daemonsets
      --delete-emptydir-data --timeout=20s || true''","validation":"kubectl get pdb
      api-pdb -o yaml | grep disruptionsAllowed"}]'
    - '{"pdb_exists":"PDB created","pdb_blocks":"Disruptions limited"}'
    - kubernetes
    - scheduling
    - Create PDB and observe effect during rollout/drain
    - '["kubectl","Multi-node cluster"]'
    - PDB prevents too many pods from being disrupted
    - kindest/node:v1.29.0
    - '["kubectl"]'
    - 5
    - 0
    - 0.0
    - 0.0
    - CKA
    - true
    - 160
    - '2025-11-06 03:44:03.291033'
    - '2025-11-06 03:44:03.291033'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -
  - - 31
    - 'RBAC: Least Privilege Access'
    - Create Role/RoleBinding to grant minimal permissions
    - medium
    - 25
    - '[{"step_number":1,"title":"Create Namespace","instruction":"Create a namespace
      dev","expected_command":"kubectl create ns dev","validation":"kubectl get ns
      dev"},{"step_number":2,"title":"Create Role","instruction":"Role pod-reader
      allows get,list on pods in dev","expected_command":"kubectl -n dev create role
      pod-reader --verb=get --verb=list --resource=pods","validation":"kubectl -n
      dev get role pod-reader -o yaml"},{"step_number":3,"title":"Bind Role","instruction":"Bind
      user jane to Role pod-reader","expected_command":"kubectl -n dev create rolebinding
      read-pods --role=pod-reader --user=jane","validation":"kubectl -n dev get rolebinding
      read-pods -o yaml"}]'
    - '{"role_exists":"Role created","binding_exists":"RoleBinding created"}'
    - kubernetes
    - rbac
    - Grant namespace-scoped read access via Role/RoleBinding
    - '["Namespace created"]'
    - User grants follow least-privilege pattern
    - kindest/node:v1.29.0
    - '["kubectl"]'
    - 5
    - 0
    - 0.0
    - 0.0
    - CKA
    - true
    - 150
    - '2025-11-06 03:44:03.294469'
    - '2025-11-06 03:44:03.294469'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -
  - - 32
    - Admission Controllers
    - Configure and test admission controller behavior using ValidatingWebhookConfiguration
    - hard
    - 35
    - '[{"step_number":1,"title":"Create Webhook Service","instruction":"Create a
      placeholder service/webhook-svc (simulation)","expected_command":"kubectl create
      ns webhook || true; kubectl create service clusterip webhook-svc --tcp=443:443
      -n webhook || true","validation":"kubectl -n webhook get svc webhook-svc"},{"step_number":2,"title":"Apply
      ValidatingWebhook","instruction":"Apply a ValidatingWebhookConfiguration that
      targets pods (dummy)","expected_command":"kubectl apply -f - \u003c\u003c''EOF''\napiVersion:
      admissionregistration.k8s.io/v1\nkind: ValidatingWebhookConfiguration\nmetadata:\n  name:
      demo-webhook\nwebhooks:\n- name: vpods.demo.local\n  rules:\n  - apiGroups:
      ['''']\n    apiVersions: [''v1'']\n    operations: [''CREATE'']\n    resources:
      [''pods'']\n  clientConfig:\n    service:\n      name: webhook-svc\n      namespace:
      webhook\n      path: /validate\n    caBundle: ''''\n  admissionReviewVersions:
      [''v1'']\n  sideEffects: None\n  failurePolicy: Ignore\nEOF","validation":"kubectl
      get validatingwebhookconfiguration demo-webhook"}]'
    - '{"vwc_created":"Webhook configuration present"}'
    - kubernetes
    - security
    - Understand admission phases; deploy a simple validating webhook
    - '["kubectl","Cluster allowing webhooks"]'
    - ValidatingWebhookConfiguration applied and visible
    - kindest/node:v1.29.0
    - '["kubectl"]'
    - 5
    - 0
    - 0.0
    - 0.0
    - CKA
    - true
    - 200
    - '2025-11-06 03:44:03.297894'
    - '2025-11-06 03:44:03.297894'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -
  - - 33
    - Persistent Volumes and Claims
    - Create a StorageClass, PersistentVolumeClaim, and mount into a Pod
    - medium
    - 30
    - '[{"step_number":1,"title":"Create PVC","instruction":"Create a PVC named data-pvc
      (1Gi, ReadWriteOnce)","expected_command":"kubectl apply -f - \u003c\u003c''EOF''\napiVersion:
      v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: data-pvc\nspec:\n  accessModes:
      [\"ReadWriteOnce\"]\n  resources:\n    requests:\n      storage: 1Gi\nEOF","validation":"kubectl
      get pvc data-pvc"},{"step_number":2,"title":"Mount PVC","instruction":"Mount
      PVC at /data in a Pod named pvc-tester","expected_command":"kubectl apply -f
      - \u003c\u003c''EOF''\napiVersion: v1\nkind: Pod\nmetadata:\n  name: pvc-tester\nspec:\n  containers:\n  -
      name: app\n    image: busybox\n    command: [''sh'',''-c'',''sleep 3600'']\n    volumeMounts:\n    -
      name: data\n      mountPath: /data\n  volumes:\n  - name: data\n    persistentVolumeClaim:\n      claimName:
      data-pvc\nEOF","validation":"kubectl get pod pvc-tester"}]'
    - '{"pvc_bound":"PVC Bound","pod_running":"Pod pvc-tester Running"}'
    - kubernetes
    - storage
    - Work with SC/PVC and mount to Pod
    - '["Cluster supports default or provided StorageClass"]'
    - Pod mounts PVC at /data
    - kindest/node:v1.29.0
    - '["kubectl"]'
    - 5
    - 0
    - 0.0
    - 0.0
    - CKA
    - true
    - 160
    - '2025-11-06 03:44:03.302452'
    - '2025-11-06 03:44:03.302452'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -
  - - 34
    - Dynamic Provisioning
    - Use a StorageClass to dynamically provision PVCs and verify binding
    - medium
    - 25
    - '[{"step_number":1,"title":"Create PVC","instruction":"Create PVC dyn-pvc 1Gi
      ReadWriteOnce with default SC","expected_command":"kubectl apply -f - \u003c\u003c''EOF''\napiVersion:
      v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: dyn-pvc\nspec:\n  accessModes:
      [\"ReadWriteOnce\"]\n  resources:\n    requests:\n      storage: 1Gi\nEOF","validation":"kubectl
      get pvc dyn-pvc"},{"step_number":2,"title":"Verify PV Bound","instruction":"Check
      that a PV was dynamically created and bound","expected_command":"kubectl get
      pvc dyn-pvc -o jsonpath=''{.status.phase}''","validation":"kubectl get pv |
      grep dyn-pvc"}]'
    - '{"pvc_bound":"PVC phase Bound","pv_exists":"PV created"}'
    - kubernetes
    - storage
    - Create StorageClass and PVC and observe PV provisioning
    - '["Cluster with default provisioner or local-path provisioner"]'
    - PVC is Bound with dynamically provisioned PV
    - kindest/node:v1.29.0
    - '["kubectl"]'
    - 5
    - 0
    - 0.0
    - 0.0
    - CKA
    - true
    - 150
    - '2025-11-06 03:44:03.306264'
    - '2025-11-06 03:44:03.306264'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -
  - - 35
    - 'Node Maintenance: Drain and Uncordon'
    - Safely drain a node and bring it back
    - medium
    - 20
    - '[{"step_number":1,"title":"Pick Node","instruction":"Select a worker node","expected_command":"kubectl
      get nodes","validation":"kubectl get nodes"},{"step_number":2,"title":"Drain","instruction":"Drain
      the node ignoring daemonsets and deleting local data","expected_command":"kubectl
      drain \u003cNODE\u003e --ignore-daemonsets --delete-emptydir-data","validation":"kubectl
      get nodes"},{"step_number":3,"title":"Uncordon","instruction":"Mark node schedulable
      again","expected_command":"kubectl uncordon \u003cNODE\u003e","validation":"kubectl
      describe node \u003cNODE\u003e | grep -i schedulable"}]'
    - '{"node_drained":"SchedulingDisabled","node_ready":"Ready status restored"}'
    - kubernetes
    - maintenance
    - Use kubectl drain and uncordon with proper flags
    - '["Cluster with 2+ nodes"]'
    - Node successfully drained and uncordoned
    - kindest/node:v1.29.0
    - '["kubectl"]'
    - 5
    - 0
    - 0.0
    - 0.0
    - CKA
    - true
    - 140
    - '2025-11-06 03:44:03.309808'
    - '2025-11-06 03:44:03.309808'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -
  - - 36
    - etcd Backup and Restore
    - Perform an etcd v3 snapshot backup and restore (simulated)
    - hard
    - 30
    - '[{"step_number":1,"title":"Set ETCDCTL_API=3","instruction":"Export environment
      variable for etcdctl v3","expected_command":"export ETCDCTL_API=3","validation":"echo
      $ETCDCTL_API"},{"step_number":2,"title":"Snapshot Save","instruction":"Run snapshot
      save to /tmp/etcd.db (simulated)","expected_command":"echo snapshot \u003e /tmp/etcd.db
      \u0026\u0026 ls /tmp/etcd.db","validation":"ls /tmp/etcd.db"}]'
    - '{"env_set":"ETCDCTL_API set","snap_ok":"Snapshot file exists"}'
    - kubernetes
    - maintenance
    - Use etcdctl v3 to snapshot and restore configuration
    - '["Cluster with control-plane access"]'
    - Snapshot file created and visible
    - kindest/node:v1.29.0
    - '["kubectl"]'
    - 5
    - 0
    - 0.0
    - 0.0
    - CKA
    - true
    - 180
    - '2025-11-06 03:44:03.313639'
    - '2025-11-06 03:44:03.313639'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -
  - - 37
    - 'Network Policies: Restrict Pod Egress/Ingress'
    - Create NetworkPolicies to restrict traffic to a service
    - hard
    - 30
    - '[{"step_number":1,"title":"Deploy App","instruction":"Create nginx service
      and a busybox tester","expected_command":"kubectl create deploy web --image=nginx
      \u0026\u0026 kubectl expose deploy web --port 80 \u0026\u0026 kubectl run tester
      --image=busybox --restart=Never --command -- sleep 3600","validation":"kubectl
      get svc web"},{"step_number":2,"title":"Deny All","instruction":"Apply default
      deny-all policy in namespace","expected_command":"kubectl apply -f - \u003c\u003c''EOF''\napiVersion:
      networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: default-deny\nspec:\n  podSelector:
      {}\n  policyTypes: [Ingress, Egress]\nEOF","validation":"kubectl get networkpolicy
      default-deny"},{"step_number":3,"title":"Allow From Tester","instruction":"Allow
      tester to access web on port 80","expected_command":"kubectl apply -f - \u003c\u003c''EOF''\napiVersion:
      networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: allow-tester\nspec:\n  podSelector:\n    matchLabels:\n      app:
      web\n  ingress:\n  - from:\n    - podSelector:\n        matchLabels:\n          run:
      tester\n    ports:\n    - protocol: TCP\n      port: 80\nEOF","validation":"kubectl
      get networkpolicy allow-tester"}]'
    - '{"deny_all_active":"Default deny applied","allow_rule_active":"Tester can curl
      web"}'
    - kubernetes
    - security
    - Apply ingress/egress NetworkPolicies and verify connectivity
    - '["CNI supporting NetworkPolicy"]'
    - Traffic is restricted except from allowed source
    - kindest/node:v1.29.0
    - '["kubectl"]'
    - 5
    - 0
    - 0.0
    - 0.0
    - CKS
    - true
    - 200
    - '2025-11-06 03:44:03.317282'
    - '2025-11-06 03:44:03.317282'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -
  - - 38
    - Network Troubleshooting
    - Diagnose service discovery and connectivity issues using common tools
    - medium
    - 25
    - '[{"step_number":1,"title":"Deploy App and Service","instruction":"Create deployment
      net-web and expose as ClusterIP web:80","expected_command":"kubectl create deploy
      net-web --image=nginx:1.25 \u0026\u0026 kubectl expose deploy net-web --name
      web --port 80","validation":"kubectl get svc web"},{"step_number":2,"title":"Test
      from Busybox","instruction":"Run busybox tester and curl service via DNS name","expected_command":"kubectl
      run tester --image=busybox:1.36 --restart=Never --command -- sh -c ''sleep 3600''
      \u0026\u0026 kubectl exec tester -- wget -qO- http://web || true","validation":"kubectl
      logs tester --tail=1 || true"},{"step_number":3,"title":"Inspect Endpoints","instruction":"Verify
      endpoints and resolve DNS name","expected_command":"kubectl get endpoints web
      \u0026\u0026 kubectl exec tester -- nslookup web","validation":"kubectl get
      endpoints web -o yaml | grep addresses -A2"}]'
    - '{"svc_ok":"Service exists","endpoints_ok":"Endpoints present","dns_ok":"DNS
      resolves"}'
    - kubernetes
    - networking
    - Use kubectl, exec, DNS utilities to debug
    - '["kubectl","dig available (busybox:1.36 or dnsutils)"]'
    - Service responds and DNS resolves from tester pod
    - kindest/node:v1.29.0
    - '["kubectl"]'
    - 5
    - 0
    - 0.0
    - 0.0
    - CKA
    - true
    - 160
    - '2025-11-06 03:44:03.320856'
    - '2025-11-06 03:44:03.320856'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -
  - - 39
    - Seccomp and Read-Only Root Filesystem
    - Harden a Pod with seccompProfile and readOnlyRootFilesystem
    - hard
    - 25
    - '[{"step_number":1,"title":"Create Pod","instruction":"Pod hardened with readOnlyRootFilesystem
      and seccompProfile RuntimeDefault","expected_command":"kubectl apply -f - \u003c\u003c''EOF''\napiVersion:
      v1\nkind: Pod\nmetadata:\n  name: hardened\nspec:\n  securityContext:\n    seccompProfile:\n      type:
      RuntimeDefault\n  containers:\n  - name: app\n    image: busybox\n    command:
      [''sh'',''-c'',''sleep 3600'']\n    securityContext:\n      readOnlyRootFilesystem:
      true\nEOF","validation":"kubectl get pod hardened -o yaml | grep -i readOnlyRootFilesystem"}]'
    - '{"seccomp_set":"seccompProfile present","readonly_set":"readOnlyRootFilesystem
      true"}'
    - kubernetes
    - runtime-security
    - Apply Pod SecurityContext and seccomp profile
    - '["K8s v1.25+ recommended"]'
    - Pod runs with hardened settings
    - kindest/node:v1.29.0
    - '["kubectl"]'
    - 5
    - 0
    - 0.0
    - 0.0
    - CKS
    - true
    - 180
    - '2025-11-06 03:44:03.324719'
    - '2025-11-06 03:44:03.324719'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -
  - - 40
    - ConfigMap Mastery
    - Master all ConfigMap creation methods, editing, and update strategies for real-world
      configuration management
    - medium
    - 30
    - '[{"step_number":1,"title":"Create ConfigMap from Literals","instruction":"Create
      a ConfigMap named app-config with KEY1=value1 and KEY2=value2 using --from-literal","expected_command":"kubectl
      create configmap app-config --from-literal=KEY1=value1 --from-literal=KEY2=value2","validation":"kubectl
      get configmap app-config -o yaml"},{"step_number":2,"title":"Create ConfigMap
      from File","instruction":"Create a file config.txt with content ''database=postgres''
      and create ConfigMap file-config from it","expected_command":"echo ''database=postgres''
      \u003e config.txt \u0026\u0026 kubectl create configmap file-config --from-file=config.txt","validation":"kubectl
      get configmap file-config -o yaml"},{"step_number":3,"title":"Create ConfigMap
      from Env File","instruction":"Create .env file with DB_HOST=localhost and DB_PORT=5432,
      then create ConfigMap env-config from it","expected_command":"cat \u003e .env
      \u003c\u003c''EOF''\nDB_HOST=localhost\nDB_PORT=5432\nEOF\nkubectl create configmap
      env-config --from-env-file=.env","validation":"kubectl get configmap env-config
      -o yaml"},{"step_number":4,"title":"Pod with ConfigMap as Environment Variables","instruction":"Create
      pod cm-env-pod using nginx image that loads env-config as environment variables","expected_command":"kubectl
      run cm-env-pod --image=nginx:1.25 --restart=Never --dry-run=client -o yaml |
      kubectl apply -f - \u0026\u0026 kubectl set env pod/cm-env-pod --from=configmap/env-config","validation":"kubectl
      exec cm-env-pod -- printenv | grep DB_"},{"step_number":5,"title":"Pod with
      ConfigMap as Volume","instruction":"Create pod cm-vol-pod using busybox that
      mounts file-config as volume at /config","expected_command":"kubectl apply -f
      - \u003c\u003c''EOF''\napiVersion: v1\nkind: Pod\nmetadata:\n  name: cm-vol-pod\nspec:\n  containers:\n  -
      name: busybox\n    image: busybox\n    command: [''sh'', ''-c'', ''sleep 3600'']\n    volumeMounts:\n    -
      name: config-vol\n      mountPath: /config\n  volumes:\n  - name: config-vol\n    configMap:\n      name:
      file-config\nEOF","validation":"kubectl exec cm-vol-pod -- ls /config"},{"step_number":6,"title":"Edit
      ConfigMap","instruction":"Use kubectl edit to change KEY1 value to ''updated''
      in app-config ConfigMap","expected_command":"kubectl edit configmap app-config","validation":"kubectl
      get configmap app-config -o yaml | grep ''KEY1: updated''"},{"step_number":7,"title":"Verify
      Pod Sees Updated ConfigMap","instruction":"Create a new pod cm-test that uses
      app-config and verify it sees the updated value","expected_command":"kubectl
      run cm-test --image=busybox --restart=Never --env=''KEY1'' --env=''KEY2'' --dry-run=client
      -o yaml | kubectl apply -f - \u0026\u0026 kubectl set env pod/cm-test --from=configmap/app-config
      \u0026\u0026 kubectl wait --for=condition=Ready pod/cm-test --timeout=30s","validation":"kubectl
      exec cm-test -- sh -c ''echo $KEY1'' | grep updated"}]'
    - '{"literals_created":"ConfigMap from literals exists","file_created":"ConfigMap
      from file exists","env_file_created":"ConfigMap from env-file exists","env_pod_running":"Pod
      with env vars running","vol_pod_running":"Pod with volume mount running","configmap_edited":"ConfigMap
      was edited successfully","pod_sees_update":"New pod sees updated ConfigMap values"}'
    - kubernetes
    - configuration
    - Create ConfigMaps from literals, files, directories, and env-files; mount as
      volumes and env vars; edit ConfigMaps; understand update strategies
    - '["kubectl installed","Access to a Kubernetes cluster","Basic pod concepts"]'
    - All ConfigMap creation methods mastered, editing works, pods can consume ConfigMaps
      via env and volumes
    - kindest/node:v1.29.0
    - '["kubectl"]'
    - 8
    - 0
    - 0.0
    - 0.0
    - CKAD
    - true
    - 200
    - '2025-11-06 03:44:03.328799'
    - '2025-11-06 03:44:03.328799'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -
  - - 41
    - Complete Service Types Deep Dive
    - 'Master all Kubernetes service types: ClusterIP, NodePort, LoadBalancer, Headless,
      and multi-port services'
    - medium
    - 35
    - '[{"step_number":1,"title":"Deploy Application","instruction":"Create deployment
      web-app with nginx:1.25 image and 3 replicas","expected_command":"kubectl create
      deployment web-app --image=nginx:1.25 --replicas=3","validation":"kubectl get
      deployment web-app -o yaml | grep ''replicas: 3''"},{"step_number":2,"title":"ClusterIP
      Service","instruction":"Expose web-app as ClusterIP service on port 80 named
      web-clusterip","expected_command":"kubectl expose deployment web-app --port=80
      --target-port=80 --name=web-clusterip --type=ClusterIP","validation":"kubectl
      get service web-clusterip -o yaml | grep ''type: ClusterIP''"},{"step_number":3,"title":"Test
      ClusterIP Internally","instruction":"Create test pod and curl the ClusterIP
      service to verify internal connectivity","expected_command":"kubectl run test-pod
      --image=curlimages/curl:latest --restart=Never --rm -it -- curl -s web-clusterip","validation":"kubectl
      run test-pod --image=curlimages/curl:latest --restart=Never --rm -it -- curl
      -s web-clusterip | grep nginx"},{"step_number":4,"title":"NodePort Service","instruction":"Create
      NodePort service for web-app on port 80 named web-nodeport","expected_command":"kubectl
      expose deployment web-app --port=80 --target-port=80 --name=web-nodeport --type=NodePort","validation":"kubectl
      get service web-nodeport -o yaml | grep ''type: NodePort''"},{"step_number":5,"title":"Verify
      NodePort","instruction":"Get the NodePort value and verify it''s in the 30000-32767
      range","expected_command":"kubectl get service web-nodeport -o jsonpath=''{.spec.ports[0].nodePort}''","validation":"kubectl
      get service web-nodeport -o yaml | grep nodePort"},{"step_number":6,"title":"Headless
      Service","instruction":"Create headless service (ClusterIP: None) for web-app
      named web-headless","expected_command":"kubectl expose deployment web-app --port=80
      --target-port=80 --name=web-headless --cluster-ip=None","validation":"kubectl
      get service web-headless -o yaml | grep ''clusterIP: None''"},{"step_number":7,"title":"Verify
      Headless DNS","instruction":"Query DNS for headless service to see individual
      pod IPs instead of single cluster IP","expected_command":"kubectl run dns-test
      --image=busybox --restart=Never --rm -it -- nslookup web-headless","validation":"kubectl
      run dns-test --image=busybox --restart=Never --rm -it -- nslookup web-headless
      | grep Address"},{"step_number":8,"title":"Multi-Port Service","instruction":"Create
      deployment multi-app with nginx, then expose it with multiple ports (80 and
      443) named multi-svc","expected_command":"kubectl create deployment multi-app
      --image=nginx:1.25 \u0026\u0026 kubectl expose deployment multi-app --name=multi-svc
      --port=80,443 --target-port=80,443","validation":"kubectl get service multi-svc
      -o yaml | grep -c port: | grep 2"},{"step_number":9,"title":"Edit Service Type","instruction":"Use
      kubectl edit to change web-clusterip from ClusterIP to NodePort","expected_command":"kubectl
      edit service web-clusterip","validation":"kubectl get service web-clusterip
      -o yaml | grep ''type: NodePort''"},{"step_number":10,"title":"Cleanup and Verify","instruction":"Delete
      all services created in this lab","expected_command":"kubectl delete service
      web-clusterip web-nodeport web-headless multi-svc","validation":"kubectl get
      services | grep -v kubernetes | wc -l | grep 0"}]'
    - '{"deployment_created":"web-app deployment exists with 3 replicas","clusterip_works":"ClusterIP
      service created and accessible internally","nodeport_works":"NodePort service
      created with valid port","headless_works":"Headless service returns multiple
      pod IPs","multiport_works":"Multi-port service has 2 ports","edit_successful":"Service
      type changed via kubectl edit"}'
    - kubernetes
    - networking
    - Create and test all service types; understand use cases; use kubectl edit to
      change service types; configure multi-port services
    - '["kubectl installed","Kubernetes cluster","Basic networking knowledge"]'
    - All service types created and tested; understand differences and use cases;
      can edit services
    - kindest/node:v1.29.0
    - '["kubectl"]'
    - 10
    - 0
    - 0.0
    - 0.0
    - CKAD
    - true
    - 220
    - '2025-11-06 03:44:03.332734'
    - '2025-11-06 03:44:03.332734'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -
  - - 42
    - Deployment Lifecycle Operations
    - 'Master deployment operations: scaling, pausing, resuming, restarting, rollback,
      and editing deployments'
    - medium
    - 40
    - '[{"step_number":1,"title":"Create Initial Deployment","instruction":"Create
      deployment lifecycle-app with nginx:1.24 image and 2 replicas","expected_command":"kubectl
      create deployment lifecycle-app --image=nginx:1.24 --replicas=2","validation":"kubectl
      get deployment lifecycle-app -o yaml | grep ''replicas: 2''"},{"step_number":2,"title":"Verify
      Rollout Status","instruction":"Check rollout status to ensure deployment completed
      successfully","expected_command":"kubectl rollout status deployment/lifecycle-app","validation":"kubectl
      rollout status deployment/lifecycle-app | grep ''successfully rolled out''"},{"step_number":3,"title":"Scale
      Up","instruction":"Scale lifecycle-app deployment to 5 replicas","expected_command":"kubectl
      scale deployment lifecycle-app --replicas=5","validation":"kubectl get deployment
      lifecycle-app -o yaml | grep ''replicas: 5''"},{"step_number":4,"title":"Verify
      Scaling","instruction":"Wait for all 5 replicas to be ready","expected_command":"kubectl
      wait --for=condition=available --timeout=60s deployment/lifecycle-app","validation":"kubectl
      get deployment lifecycle-app -o jsonpath=''{.status.readyReplicas}'' | grep
      5"},{"step_number":5,"title":"Update Image","instruction":"Update deployment
      to use nginx:1.25 image","expected_command":"kubectl set image deployment/lifecycle-app
      nginx=nginx:1.25","validation":"kubectl get deployment lifecycle-app -o yaml
      | grep ''image: nginx:1.25''"},{"step_number":6,"title":"Pause Rollout","instruction":"Pause
      the rollout while it''s in progress","expected_command":"kubectl rollout pause
      deployment/lifecycle-app","validation":"kubectl rollout status deployment/lifecycle-app
      | grep paused"},{"step_number":7,"title":"Resume Rollout","instruction":"Resume
      the paused rollout","expected_command":"kubectl rollout resume deployment/lifecycle-app","validation":"kubectl
      rollout status deployment/lifecycle-app | grep ''successfully rolled out''"},{"step_number":8,"title":"Check
      Rollout History","instruction":"View rollout history to see all revisions","expected_command":"kubectl
      rollout history deployment/lifecycle-app","validation":"kubectl rollout history
      deployment/lifecycle-app | grep -c REVISION | grep -E ''[2-9]''"},{"step_number":9,"title":"Rollback
      to Previous Version","instruction":"Rollback deployment to previous revision
      (nginx:1.24)","expected_command":"kubectl rollout undo deployment/lifecycle-app","validation":"kubectl
      get deployment lifecycle-app -o yaml | grep ''image: nginx:1.24''"},{"step_number":10,"title":"Rollback
      to Specific Revision","instruction":"Rollback to revision 2 (nginx:1.25)","expected_command":"kubectl
      rollout undo deployment/lifecycle-app --to-revision=2","validation":"kubectl
      get deployment lifecycle-app -o yaml | grep ''image: nginx:1.25''"},{"step_number":11,"title":"Edit
      Deployment","instruction":"Use kubectl edit to change replicas to 3","expected_command":"kubectl
      edit deployment lifecycle-app","validation":"kubectl get deployment lifecycle-app
      -o yaml | grep ''replicas: 3''"},{"step_number":12,"title":"Restart Deployment","instruction":"Perform
      a rolling restart of all pods without changing image","expected_command":"kubectl
      rollout restart deployment/lifecycle-app","validation":"kubectl rollout status
      deployment/lifecycle-app | grep ''successfully rolled out''"},{"step_number":13,"title":"Scale
      Down","instruction":"Scale deployment down to 1 replica","expected_command":"kubectl
      scale deployment lifecycle-app --replicas=1","validation":"kubectl get deployment
      lifecycle-app -o jsonpath=''{.spec.replicas}'' | grep 1"},{"step_number":14,"title":"Verify
      Final State","instruction":"Confirm exactly 1 pod is running for lifecycle-app","expected_command":"kubectl
      get pods -l app=lifecycle-app --no-headers | wc -l | grep 1","validation":"kubectl
      get deployment lifecycle-app -o jsonpath=''{.status.readyReplicas}'' | grep
      1"}]'
    - '{"deployment_created":"Initial deployment created with 2 replicas","scaled_up":"Successfully
      scaled to 5 replicas","image_updated":"Image updated to nginx:1.25","pause_resume_works":"Rollout
      paused and resumed successfully","rollback_works":"Rollback to previous version
      successful","edit_works":"Deployment edited via kubectl edit","restart_works":"Rolling
      restart completed","scaled_down":"Final state is 1 replica"}'
    - kubernetes
    - workloads
    - Scale deployments up/down; pause and resume rollouts; perform restarts; rollback
      to previous versions; edit deployments safely
    - '["kubectl installed","Kubernetes cluster","Understanding of deployments"]'
    - 'Mastered all deployment lifecycle operations: scale, pause/resume, rollback,
      edit, restart'
    - kindest/node:v1.29.0
    - '["kubectl"]'
    - 14
    - 0
    - 0.0
    - 0.0
    - CKAD
    - true
    - 250
    - '2025-11-06 03:44:03.336862'
    - '2025-11-06 03:44:03.336862'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -
  - - 43
    - kubectl edit Mastery
    - Master editing Kubernetes resources with kubectl edit; understand immutable
      fields and safe editing practices
    - medium
    - 30
    - '[{"step_number":1,"title":"Create Test Resources","instruction":"Create deployment
      edit-deploy (nginx:1.24, 2 replicas), service edit-svc (ClusterIP, port 80),
      and configmap edit-cm (KEY=value)","expected_command":"kubectl create deployment
      edit-deploy --image=nginx:1.24 --replicas=2 \u0026\u0026 kubectl expose deployment
      edit-deploy --name=edit-svc --port=80 \u0026\u0026 kubectl create configmap
      edit-cm --from-literal=KEY=value","validation":"kubectl get deployment,service,configmap
      | grep edit-"},{"step_number":2,"title":"Edit Deployment - Change Replicas","instruction":"Use
      kubectl edit to change edit-deploy replicas from 2 to 4","expected_command":"kubectl
      edit deployment edit-deploy","validation":"kubectl get deployment edit-deploy
      -o yaml | grep ''replicas: 4''"},{"step_number":3,"title":"Edit Deployment -
      Change Image","instruction":"Use kubectl edit to update image to nginx:1.25","expected_command":"kubectl
      edit deployment edit-deploy","validation":"kubectl get deployment edit-deploy
      -o yaml | grep ''image: nginx:1.25''"},{"step_number":4,"title":"Edit Service
      - Change Type","instruction":"Use kubectl edit to change edit-svc from ClusterIP
      to NodePort","expected_command":"kubectl edit service edit-svc","validation":"kubectl
      get service edit-svc -o yaml | grep ''type: NodePort''"},{"step_number":5,"title":"Edit
      Service - Add Port","instruction":"Use kubectl edit to add port 443 to edit-svc
      (alongside port 80)","expected_command":"kubectl edit service edit-svc","validation":"kubectl
      get service edit-svc -o yaml | grep -c ''port: 443'' | grep 1"},{"step_number":6,"title":"Edit
      ConfigMap","instruction":"Use kubectl edit to change KEY value to ''updated''
      in edit-cm","expected_command":"kubectl edit configmap edit-cm","validation":"kubectl
      get configmap edit-cm -o yaml | grep ''KEY: updated''"},{"step_number":7,"title":"Create
      Secret and Edit","instruction":"Create secret edit-secret (PASSWORD=secret123)
      and use kubectl edit to add USERNAME=admin","expected_command":"kubectl create
      secret generic edit-secret --from-literal=PASSWORD=secret123 \u0026\u0026 kubectl
      edit secret edit-secret","validation":"kubectl get secret edit-secret -o jsonpath=''{.data.USERNAME}''
      | base64 -d | grep admin"},{"step_number":8,"title":"Edit Pod - Understand Immutability","instruction":"Create
      pod edit-pod (nginx), then try to edit its image (will fail for running pod
      - this demonstrates immutability)","expected_command":"kubectl run edit-pod
      --image=nginx:1.24","validation":"kubectl get pod edit-pod -o yaml | grep ''image:
      nginx:1.24''"},{"step_number":9,"title":"Edit Deployment Strategy","instruction":"Use
      kubectl edit to change edit-deploy rolling update strategy maxUnavailable to
      1","expected_command":"kubectl edit deployment edit-deploy","validation":"kubectl
      get deployment edit-deploy -o yaml | grep ''maxUnavailable: 1''"},{"step_number":10,"title":"Verify
      Changes Trigger Rollout","instruction":"Confirm that editing deployment image
      triggered a new rollout","expected_command":"kubectl rollout history deployment/edit-deploy","validation":"kubectl
      rollout history deployment/edit-deploy | grep -c REVISION | grep -E ''[2-9]''"}]'
    - '{"resources_created":"All test resources created","deployment_edited":"Deployment
      replicas and image changed","service_edited":"Service type changed and port
      added","configmap_edited":"ConfigMap value updated","secret_edited":"Secret
      field added","pod_immutability_understood":"Pod immutability demonstrated","strategy_edited":"Deployment
      strategy modified","rollout_triggered":"Image change triggered rollout"}'
    - kubernetes
    - operations
    - Use kubectl edit for deployments, services, configmaps, secrets; understand
      immutable fields; learn safe editing workflow
    - '["kubectl installed","Kubernetes cluster","Basic knowledge of Kubernetes resources"]'
    - Mastered kubectl edit for all resource types; understand immutable fields; know
      when edits trigger rollouts
    - kindest/node:v1.29.0
    - '["kubectl"]'
    - 10
    - 0
    - 0.0
    - 0.0
    - CKAD
    - true
    - 200
    - '2025-11-06 03:44:03.340883'
    - '2025-11-06 03:44:03.340883'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -
  - - 44
    - Full-Stack Application Deployment
    - 'Deploy a complete 3-tier application: React frontend, Node.js API, and PostgreSQL
      database with ConfigMaps, Secrets, Services, and StatefulSet'
    - hard
    - 60
    - '[{"step_number":1,"title":"Create Namespace","instruction":"Create namespace
      fullstack for the application","expected_command":"kubectl create namespace
      fullstack","validation":"kubectl get namespace fullstack"},{"step_number":2,"title":"Create
      Database Secret","instruction":"Create secret db-secret in fullstack namespace
      with POSTGRES_USER=appuser POSTGRES_PASSWORD=apppass123 POSTGRES_DB=appdb","expected_command":"kubectl
      create secret generic db-secret --from-literal=POSTGRES_USER=appuser --from-literal=POSTGRES_PASSWORD=apppass123
      --from-literal=POSTGRES_DB=appdb -n fullstack","validation":"kubectl get secret
      db-secret -n fullstack"},{"step_number":3,"title":"Create API ConfigMap","instruction":"Create
      configmap api-config in fullstack namespace with API_PORT=3000 LOG_LEVEL=info","expected_command":"kubectl
      create configmap api-config --from-literal=API_PORT=3000 --from-literal=LOG_LEVEL=info
      -n fullstack","validation":"kubectl get configmap api-config -n fullstack"},{"step_number":4,"title":"Deploy
      PostgreSQL StatefulSet","instruction":"Create StatefulSet postgres with 1 replica
      using postgres:15-alpine image, using db-secret for env vars, with volumeClaimTemplate
      for 1Gi storage","expected_command":"kubectl apply -f - \u003c\u003c''EOF''\napiVersion:
      apps/v1\nkind: StatefulSet\nmetadata:\n  name: postgres\n  namespace: fullstack\nspec:\n  serviceName:
      postgres-svc\n  replicas: 1\n  selector:\n    matchLabels:\n      app: postgres\n  template:\n    metadata:\n      labels:\n        app:
      postgres\n    spec:\n      containers:\n      - name: postgres\n        image:
      postgres:15-alpine\n        ports:\n        - containerPort: 5432\n        envFrom:\n        -
      secretRef:\n            name: db-secret\n        volumeMounts:\n        - name:
      postgres-data\n          mountPath: /var/lib/postgresql/data\n  volumeClaimTemplates:\n  -
      metadata:\n      name: postgres-data\n    spec:\n      accessModes: [''ReadWriteOnce'']\n      resources:\n        requests:\n          storage:
      1Gi\nEOF","validation":"kubectl get statefulset postgres -n fullstack"},{"step_number":5,"title":"Create
      Database Headless Service","instruction":"Create headless service postgres-svc
      for StatefulSet on port 5432","expected_command":"kubectl expose statefulset
      postgres --name=postgres-svc --port=5432 --cluster-ip=None -n fullstack","validation":"kubectl
      get service postgres-svc -n fullstack -o yaml | grep ''clusterIP: None''"},{"step_number":6,"title":"Wait
      for Database Ready","instruction":"Wait for postgres StatefulSet to be ready","expected_command":"kubectl
      wait --for=condition=ready pod/postgres-0 -n fullstack --timeout=120s","validation":"kubectl
      get pod postgres-0 -n fullstack -o jsonpath=''{.status.phase}'' | grep Running"},{"step_number":7,"title":"Deploy
      API Backend","instruction":"Create deployment api with node:18-alpine image,
      2 replicas, using api-config and db-secret, with DATABASE_URL=postgresql://appuser:apppass123@postgres-svc:5432/appdb","expected_command":"kubectl
      create deployment api --image=node:18-alpine --replicas=2 -n fullstack \u0026\u0026
      kubectl set env deployment/api --from=configmap/api-config -n fullstack \u0026\u0026
      kubectl set env deployment/api --from=secret/db-secret -n fullstack \u0026\u0026
      kubectl set env deployment/api DATABASE_URL=postgresql://appuser:apppass123@postgres-svc:5432/appdb
      -n fullstack","validation":"kubectl get deployment api -n fullstack -o yaml
      | grep ''replicas: 2''"},{"step_number":8,"title":"Create API Service","instruction":"Expose
      api deployment as ClusterIP service api-svc on port 3000","expected_command":"kubectl
      expose deployment api --name=api-svc --port=3000 -n fullstack","validation":"kubectl
      get service api-svc -n fullstack"},{"step_number":9,"title":"Deploy Frontend","instruction":"Create
      deployment frontend with nginx:1.25-alpine image, 3 replicas","expected_command":"kubectl
      create deployment frontend --image=nginx:1.25-alpine --replicas=3 -n fullstack","validation":"kubectl
      get deployment frontend -n fullstack -o yaml | grep ''replicas: 3''"},{"step_number":10,"title":"Create
      Frontend Service","instruction":"Expose frontend as NodePort service frontend-svc
      on port 80","expected_command":"kubectl expose deployment frontend --name=frontend-svc
      --port=80 --type=NodePort -n fullstack","validation":"kubectl get service frontend-svc
      -n fullstack -o yaml | grep ''type: NodePort''"},{"step_number":11,"title":"Verify
      All Pods Running","instruction":"Check that all pods in fullstack namespace
      are running (1 postgres, 2 api, 3 frontend = 6 total)","expected_command":"kubectl
      get pods -n fullstack --no-headers | grep -c Running | grep 6","validation":"kubectl
      get pods -n fullstack --no-headers | wc -l | grep 6"},{"step_number":12,"title":"Test
      Inter-Service Communication","instruction":"Create test pod and verify API can
      reach database","expected_command":"kubectl run test-connectivity --image=busybox
      --rm -it --restart=Never -n fullstack -- nslookup postgres-svc","validation":"kubectl
      run test-connectivity --image=busybox --rm -it --restart=Never -n fullstack
      -- nslookup api-svc | grep Address"},{"step_number":13,"title":"Scale API Based
      on Load","instruction":"Scale api deployment to 4 replicas to handle increased
      load","expected_command":"kubectl scale deployment api --replicas=4 -n fullstack","validation":"kubectl
      get deployment api -n fullstack -o jsonpath=''{.spec.replicas}'' | grep 4"},{"step_number":14,"title":"Perform
      Rolling Update","instruction":"Update frontend image to nginx:1.26-alpine","expected_command":"kubectl
      set image deployment/frontend nginx=nginx:1.26-alpine -n fullstack","validation":"kubectl
      get deployment frontend -n fullstack -o yaml | grep ''image: nginx:1.26-alpine''"},{"step_number":15,"title":"Verify
      Rollout Completed","instruction":"Check rollout status for frontend deployment","expected_command":"kubectl
      rollout status deployment/frontend -n fullstack","validation":"kubectl rollout
      status deployment/frontend -n fullstack | grep ''successfully rolled out''"},{"step_number":16,"title":"View
      All Resources","instruction":"List all resources in fullstack namespace to see
      the complete application stack","expected_command":"kubectl get all -n fullstack","validation":"kubectl
      get all -n fullstack | grep -c deployment | grep 2"}]'
    - '{"namespace_created":"fullstack namespace exists","secrets_configs_created":"Database
      secret and API config created","database_running":"PostgreSQL StatefulSet running
      with persistent storage","api_running":"API deployment running with 2+ replicas","frontend_running":"Frontend
      deployment running with 3+ replicas","services_created":"All services created
      (postgres-svc, api-svc, frontend-svc)","connectivity_works":"Inter-service communication
      verified","scaling_works":"API scaled to 4 replicas","rollout_successful":"Frontend
      rolling update completed"}'
    - kubernetes
    - applications
    - Deploy multi-tier application; configure inter-service communication; use StatefulSet
      for stateful workloads; manage configurations and secrets; perform rolling updates;
      scale based on load
    - '["kubectl installed","Kubernetes cluster with storage class","Understanding
      of deployments, services, configmaps, secrets, statefulsets"]'
    - Complete 3-tier application deployed and communicating; demonstrated scaling,
      rolling updates, and configuration management
    - kindest/node:v1.29.0
    - '["kubectl"]'
    - 16
    - 0
    - 0.0
    - 0.0
    - CKAD
    - true
    - 300
    - '2025-11-06 03:44:03.345336'
    - '2025-11-06 03:44:03.345336'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -
  - - 45
    - Troubleshooting Kubernetes Deployments
    - 'Debug and fix 10 common Kubernetes deployment failures: CrashLoopBackOff, ImagePullBackOff,
      Pending pods, failed services, and more'
    - hard
    - 45
    - '[{"step_number":1,"title":"Scenario 1: ImagePullBackOff","instruction":"Create
      pod bad-image with non-existent image nginx:doesnotexist999, diagnose why it
      fails, then fix it to use nginx:1.25","expected_command":"kubectl run bad-image
      --image=nginx:doesnotexist999 \u0026\u0026 kubectl describe pod bad-image |
      grep -i imagepull \u0026\u0026 kubectl delete pod bad-image \u0026\u0026 kubectl
      run bad-image --image=nginx:1.25","validation":"kubectl get pod bad-image -o
      jsonpath=''{.status.phase}'' | grep Running"},{"step_number":2,"title":"Scenario
      2: CrashLoopBackOff","instruction":"Create pod crash-pod that exits immediately
      (busybox with command ''exit 1''), diagnose with logs, then fix with command
      ''sleep 3600''","expected_command":"kubectl run crash-pod --image=busybox --command
      -- sh -c ''exit 1'' \u0026\u0026 sleep 10 \u0026\u0026 kubectl logs crash-pod
      \u0026\u0026 kubectl delete pod crash-pod \u0026\u0026 kubectl run crash-pod
      --image=busybox --command -- sleep 3600","validation":"kubectl get pod crash-pod
      -o jsonpath=''{.status.phase}'' | grep Running"},{"step_number":3,"title":"Scenario
      3: Pending Pod - No Resources","instruction":"Create pod huge-pod requesting
      1000Gi memory (will be Pending), diagnose with describe, then fix by requesting
      64Mi","expected_command":"kubectl run huge-pod --image=nginx --dry-run=client
      -o yaml \u003e huge-pod.yaml \u0026\u0026 echo ''    resources:\n      requests:\n        memory:
      \"1000Gi\"'' \u003e\u003e huge-pod.yaml \u0026\u0026 kubectl apply -f huge-pod.yaml
      \u0026\u0026 kubectl describe pod huge-pod | grep -i insufficient \u0026\u0026
      kubectl delete pod huge-pod \u0026\u0026 kubectl run huge-pod --image=nginx
      --requests=''memory=64Mi''","validation":"kubectl get pod huge-pod -o jsonpath=''{.status.phase}''
      | grep Running"},{"step_number":4,"title":"Scenario 4: Service Not Routing Traffic","instruction":"Create
      deployment svc-test (nginx, 2 replicas) and service with wrong selector (app=wrong),
      diagnose why no endpoints, fix selector to app=svc-test","expected_command":"kubectl
      create deployment svc-test --image=nginx --replicas=2 \u0026\u0026 kubectl expose
      deployment svc-test --port=80 --name=broken-svc \u0026\u0026 kubectl patch service
      broken-svc -p ''{\"spec\":{\"selector\":{\"app\":\"wrong\"}}}'' \u0026\u0026
      kubectl describe service broken-svc | grep -i endpoints \u0026\u0026 kubectl
      patch service broken-svc -p ''{\"spec\":{\"selector\":{\"app\":\"svc-test\"}}}''","validation":"kubectl
      get endpoints broken-svc -o yaml | grep -i ''ip:''"},{"step_number":5,"title":"Scenario
      5: Wrong Container Port","instruction":"Create deployment port-app (nginx) exposed
      on port 8080, but nginx listens on 80, diagnose connection failure, fix service
      targetPort to 80","expected_command":"kubectl create deployment port-app --image=nginx
      \u0026\u0026 kubectl expose deployment port-app --port=8080 --target-port=8080
      --name=port-svc \u0026\u0026 kubectl patch service port-svc -p ''{\"spec\":{\"ports\":[{\"port\":8080,\"targetPort\":80}]}}''","validation":"kubectl
      get service port-svc -o yaml | grep ''targetPort: 80''"},{"step_number":6,"title":"Scenario
      6: Failed Rollout - Bad Image","instruction":"Create deployment rollout-test
      (nginx:1.25), update to bad image nginx:badversion, diagnose failed rollout,
      rollback to previous version","expected_command":"kubectl create deployment
      rollout-test --image=nginx:1.25 \u0026\u0026 kubectl set image deployment/rollout-test
      nginx=nginx:badversion \u0026\u0026 sleep 15 \u0026\u0026 kubectl rollout status
      deployment/rollout-test --timeout=5s; kubectl rollout undo deployment/rollout-test","validation":"kubectl
      get deployment rollout-test -o yaml | grep ''image: nginx:1.25''"},{"step_number":7,"title":"Scenario
      7: ConfigMap Not Mounted","instruction":"Create configmap app-cfg (KEY=value),
      create pod cfg-pod that references non-existent configmap wrong-cfg (will be
      Pending), diagnose with describe, fix to reference app-cfg","expected_command":"kubectl
      create configmap app-cfg --from-literal=KEY=value \u0026\u0026 kubectl run cfg-pod
      --image=busybox --command sleep 3600 --dry-run=client -o yaml \u003e cfg-pod.yaml
      \u0026\u0026 kubectl apply -f - \u003c\u003c''EOF''\napiVersion: v1\nkind: Pod\nmetadata:\n  name:
      cfg-pod\nspec:\n  containers:\n  - name: busybox\n    image: busybox\n    command:
      [''sleep'', ''3600'']\n    envFrom:\n    - configMapRef:\n        name: wrong-cfg\nEOF\nkubectl
      describe pod cfg-pod | grep -i configmap \u0026\u0026 kubectl delete pod cfg-pod
      \u0026\u0026 kubectl run cfg-pod --image=busybox --command sleep 3600 \u0026\u0026
      kubectl set env pod/cfg-pod --from=configmap/app-cfg","validation":"kubectl
      get pod cfg-pod -o jsonpath=''{.status.phase}'' | grep Running"},{"step_number":8,"title":"Scenario
      8: Readiness Probe Failing","instruction":"Create deployment readiness-app with
      failing readiness probe (httpGet on /healthz), diagnose why pods not ready,
      fix by changing probe path to /","expected_command":"kubectl apply -f - \u003c\u003c''EOF''\napiVersion:
      apps/v1\nkind: Deployment\nmetadata:\n  name: readiness-app\nspec:\n  replicas:
      2\n  selector:\n    matchLabels:\n      app: readiness-app\n  template:\n    metadata:\n      labels:\n        app:
      readiness-app\n    spec:\n      containers:\n      - name: nginx\n        image:
      nginx:1.25\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port:
      80\n          initialDelaySeconds: 5\n          periodSeconds: 5\nEOF\nkubectl
      describe pod -l app=readiness-app | grep -i readiness \u0026\u0026 kubectl patch
      deployment readiness-app -p ''{\"spec\":{\"template\":{\"spec\":{\"containers\":[{\"name\":\"nginx\",\"readinessProbe\":{\"httpGet\":{\"path\":\"/\",\"port\":80}}}]}}}}''","validation":"kubectl
      get deployment readiness-app -o jsonpath=''{.status.readyReplicas}'' | grep
      2"},{"step_number":9,"title":"Scenario 9: Insufficient Permissions (RBAC)","instruction":"Create
      serviceaccount limited-sa, try to create pod using this SA without proper RBAC
      (will fail API calls from pod), diagnose with kubectl auth can-i","expected_command":"kubectl
      create serviceaccount limited-sa \u0026\u0026 kubectl auth can-i create pods
      --as=system:serviceaccount:default:limited-sa","validation":"kubectl get serviceaccount
      limited-sa"},{"step_number":10,"title":"Scenario 10: Node Selector Mismatch","instruction":"Create
      pod node-pod with nodeSelector disktype=ssd (node doesn''t exist), diagnose
      Pending state, remove nodeSelector to fix","expected_command":"kubectl apply
      -f - \u003c\u003c''EOF''\napiVersion: v1\nkind: Pod\nmetadata:\n  name: node-pod\nspec:\n  nodeSelector:\n    disktype:
      ssd\n  containers:\n  - name: nginx\n    image: nginx:1.25\nEOF\nkubectl describe
      pod node-pod | grep -i ''no nodes'' \u0026\u0026 kubectl delete pod node-pod
      \u0026\u0026 kubectl run node-pod --image=nginx:1.25","validation":"kubectl
      get pod node-pod -o jsonpath=''{.status.phase}'' | grep Running"}]'
    - '{"imagepull_fixed":"ImagePullBackOff resolved with correct image","crash_fixed":"CrashLoopBackOff
      fixed with proper command","pending_fixed":"Pending pod fixed with reasonable
      resource requests","service_fixed":"Service routing fixed with correct selector","port_fixed":"Service
      targetPort corrected","rollout_fixed":"Failed rollout recovered via rollback","configmap_fixed":"ConfigMap
      reference corrected","readiness_fixed":"Readiness probe fixed, all replicas
      ready","rbac_diagnosed":"RBAC permissions diagnosed","nodeselector_fixed":"NodeSelector
      issue resolved"}'
    - kubernetes
    - troubleshooting
    - Diagnose CrashLoopBackOff, ImagePullBackOff, Pending pods, OOMKilled, service
      connectivity issues, failed rollouts; use kubectl logs, describe, events, and
      debugging techniques
    - '["kubectl installed","Kubernetes cluster","Understanding of pods, deployments,
      services"]'
    - Successfully diagnosed and fixed all 10 common Kubernetes deployment failures
    - kindest/node:v1.29.0
    - '["kubectl"]'
    - 15
    - 0
    - 0.0
    - 0.0
    - CKA
    - true
    - 280
    - '2025-11-06 03:44:03.349918'
    - '2025-11-06 03:44:03.349918'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -
  - - 46
    - SQL Basics - SELECT and Filtering
    - Master fundamental SQL SELECT queries and WHERE clause filtering
    - easy
    - 20
    - "[]"
    - '{"syntax_correct":"SQL syntax is valid","results_match":"Query returns expected
      results","efficient_query":"Query uses appropriate filtering"}'
    - postgresql
    - basics
    - Master SELECT statements, WHERE clause, comparison operators, and basic filtering
    - '["Basic understanding of databases"]'
    - Successfully write SELECT queries with WHERE clause filtering
    -
    - "[]"
    - 5
    - 0
    - 0.0
    - 0.0
    -
    - true
    - 150
    - '2025-11-06 03:44:03.355301'
    - '2025-11-06 03:44:03.355301'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - code_editor
    - sql
    - |-
      -- Write your SQL query here
      SELECT * FROM users;
    - '[{"name":"Select all users","query":"SELECT * FROM users;","expected_result":[{"id":1,"name":"Alice
      Johnson","email":"alice@example.com","age":28,"city":"New York"},{"id":2,"name":"Bob
      Smith","email":"bob@example.com","age":35,"city":"Los Angeles"},{"id":3,"name":"Charlie
      Brown","email":"charlie@example.com","age":22,"city":"Chicago"},{"id":4,"name":"Diana
      Prince","email":"diana@example.com","age":30,"city":"New York"},{"id":5,"name":"Eve
      Williams","email":"eve@example.com","age":45,"city":"Boston"}]},{"name":"Select
      users from New York","query":"SELECT name, city FROM users WHERE city = ''New
      York'';","expected_result":[{"name":"Alice Johnson","city":"New York"},{"name":"Diana
      Prince","city":"New York"}]},{"name":"Select users older than 30","query":"SELECT
      name, age FROM users WHERE age \u003e 30 ORDER BY age;","expected_result":[{"name":"Bob
      Smith","age":35},{"name":"Eve Williams","age":45}]}]'
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    - |
      CREATE TABLE users (
        id SERIAL PRIMARY KEY,
        name VARCHAR(100) NOT NULL,
        email VARCHAR(255) UNIQUE NOT NULL,
        age INTEGER,
        city VARCHAR(100),
        created_at TIMESTAMP DEFAULT NOW()
      );
    - |
      INSERT INTO users (name, email, age, city) VALUES
        ('Alice Johnson', 'alice@example.com', 28, 'New York'),
        ('Bob Smith', 'bob@example.com', 35, 'Los Angeles'),
        ('Charlie Brown', 'charlie@example.com', 22, 'Chicago'),
        ('Diana Prince', 'diana@example.com', 30, 'New York'),
        ('Eve Williams', 'eve@example.com', 45, 'Boston');
    - '["Use SELECT * to select all columns","Use WHERE clause to filter results","Comparison
      operators: =, \u003e, \u003c, \u003e=, \u003c=, !=","Use ORDER BY to sort results"]'
  - - 47
    - SQL Aggregation - COUNT, SUM, AVG
    - Learn SQL aggregate functions and GROUP BY clause
    - easy
    - 25
    - "[]"
    - '{"aggregates_correct":"Aggregate functions used properly","grouping_correct":"GROUP
      BY clause used correctly","results_accurate":"Calculations are accurate"}'
    - postgresql
    - aggregation
    - Master aggregate functions (COUNT, SUM, AVG, MIN, MAX) and GROUP BY
    - '["Basic SQL SELECT queries"]'
    - Successfully use aggregate functions and GROUP BY
    -
    - "[]"
    - 5
    - 0
    - 0.0
    - 0.0
    -
    - true
    - 200
    - '2025-11-06 03:44:03.359139'
    - '2025-11-06 03:44:03.359139'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - code_editor
    - sql
    - |-
      -- Calculate aggregate statistics
      SELECT COUNT(*) FROM orders;
    - '[{"name":"Count total orders","query":"SELECT COUNT(*) as total_orders FROM
      orders;","expected_result":[{"total_orders":7}]},{"name":"Calculate total revenue","query":"SELECT
      SUM(amount) as total_revenue FROM orders;","expected_result":[{"total_revenue":2835.0}]},{"name":"Average
      order amount","query":"SELECT ROUND(AVG(amount), 2) as avg_amount FROM orders;","expected_result":[{"avg_amount":405.0}]},{"name":"Revenue
      by category","query":"SELECT category, SUM(amount) as total FROM orders GROUP
      BY category ORDER BY total DESC;","expected_result":[{"category":"Electronics","total":2650.0},{"category":"Clothing","total":185.0}]},{"name":"Orders
      per user","query":"SELECT user_id, COUNT(*) as order_count FROM orders GROUP
      BY user_id ORDER BY user_id;","expected_result":[{"user_id":1,"order_count":3},{"user_id":2,"order_count":2},{"user_id":3,"order_count":2}]}]'
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    - |
      CREATE TABLE orders (
        id SERIAL PRIMARY KEY,
        user_id INTEGER,
        product VARCHAR(100),
        category VARCHAR(50),
        amount DECIMAL(10,2),
        order_date DATE
      );
    - |
      INSERT INTO orders (user_id, product, category, amount, order_date) VALUES
        (1, 'Laptop', 'Electronics', 1200.00, '2024-01-15'),
        (2, 'Phone', 'Electronics', 800.00, '2024-01-16'),
        (1, 'Shirt', 'Clothing', 45.00, '2024-01-17'),
        (3, 'Headphones', 'Electronics', 150.00, '2024-01-18'),
        (2, 'Jeans', 'Clothing', 60.00, '2024-01-19'),
        (1, 'Tablet', 'Electronics', 500.00, '2024-01-20'),
        (3, 'Shoes', 'Clothing', 80.00, '2024-01-21');
    - '["COUNT(*) counts all rows","SUM() adds up numeric values","AVG() calculates
      average","Use GROUP BY to group results","Use ROUND() to limit decimal places"]'
  - - 48
    - SQL Joins - Combining Tables
    - Master INNER JOIN, LEFT JOIN, and multi-table queries
    - medium
    - 30
    - "[]"
    - '{"joins_correct":"JOIN syntax is correct","relationships_understood":"Table
      relationships used properly","results_complete":"All required data retrieved"}'
    - postgresql
    - joins
    - Master different types of JOINs, understand relationships, combine data from
      multiple tables
    - '["SQL basics","Understanding of table relationships"]'
    - Successfully join multiple tables and retrieve related data
    -
    - "[]"
    - 5
    - 0
    - 0.0
    - 0.0
    -
    - true
    - 300
    - '2025-11-06 03:44:03.362992'
    - '2025-11-06 03:44:03.362992'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - code_editor
    - sql
    - |-
      -- Join users and orders tables
      SELECT u.name, o.product
      FROM users u
      JOIN orders o ON u.id = o.user_id;
    - '[{"name":"INNER JOIN customers and orders","query":"SELECT c.name, o.product,
      o.amount FROM customers c INNER JOIN orders o ON c.id = o.customer_id ORDER
      BY c.name, o.product;","expected_result":[{"name":"Alice","product":"Laptop","amount":1200.0},{"name":"Alice","product":"Mouse","amount":25.0},{"name":"Bob","product":"Keyboard","amount":80.0},{"name":"Charlie","product":"Monitor","amount":300.0}]},{"name":"LEFT
      JOIN to find all customers","query":"SELECT c.name, COUNT(o.id) as order_count
      FROM customers c LEFT JOIN orders o ON c.id = o.customer_id GROUP BY c.name
      ORDER BY c.name;","expected_result":[{"name":"Alice","order_count":2},{"name":"Bob","order_count":1},{"name":"Charlie","order_count":1}]},{"name":"Three-table
      JOIN","query":"SELECT c.name, o.product, r.rating FROM customers c JOIN orders
      o ON c.id = o.customer_id JOIN reviews r ON o.id = r.order_id ORDER BY c.name;","expected_result":[{"name":"Alice","product":"Laptop","rating":5},{"name":"Alice","product":"Mouse","rating":4},{"name":"Bob","product":"Keyboard","rating":5}]}]'
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    - |
      CREATE TABLE customers (
        id SERIAL PRIMARY KEY,
        name VARCHAR(100),
        email VARCHAR(255)
      );

      CREATE TABLE orders (
        id SERIAL PRIMARY KEY,
        customer_id INTEGER,
        product VARCHAR(100),
        amount DECIMAL(10,2),
        order_date DATE
      );

      CREATE TABLE reviews (
        id SERIAL PRIMARY KEY,
        order_id INTEGER,
        rating INTEGER,
        comment TEXT
      );
    - |
      INSERT INTO customers (name, email) VALUES
        ('Alice', 'alice@example.com'),
        ('Bob', 'bob@example.com'),
        ('Charlie', 'charlie@example.com');

      INSERT INTO orders (customer_id, product, amount, order_date) VALUES
        (1, 'Laptop', 1200.00, '2024-01-15'),
        (1, 'Mouse', 25.00, '2024-01-16'),
        (2, 'Keyboard', 80.00, '2024-01-17'),
        (3, 'Monitor', 300.00, '2024-01-18');

      INSERT INTO reviews (order_id, rating, comment) VALUES
        (1, 5, 'Excellent laptop!'),
        (2, 4, 'Good mouse'),
        (3, 5, 'Great keyboard');
    - '["INNER JOIN returns only matching rows from both tables","LEFT JOIN returns
      all rows from left table, matching rows from right","Use table aliases (u, o)
      for cleaner queries","JOIN conditions use ON clause","Can chain multiple JOINs
      together"]'
  - - 49
    - Subqueries and Nested SELECT
    - Master subqueries, correlated subqueries, and EXISTS clause
    - medium
    - 35
    - "[]"
    - '{"subqueries_correct":"Subquery syntax is valid","logic_sound":"Query logic
      is correct","performance_acceptable":"Query is reasonably efficient"}'
    - postgresql
    - advanced-sql
    - Master subqueries in SELECT, WHERE, and FROM clauses, understand correlated
      subqueries
    - '["SQL joins","Aggregate functions"]'
    - Successfully use subqueries for complex data retrieval
    -
    - "[]"
    - 5
    - 0
    - 0.0
    - 0.0
    -
    - true
    - 350
    - '2025-11-06 03:44:03.366808'
    - '2025-11-06 03:44:03.366808'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - code_editor
    - sql
    - |-
      -- Find users with above-average order amounts
      SELECT name FROM users
      WHERE user_id IN (
        SELECT user_id FROM orders
        WHERE amount > (SELECT AVG(amount) FROM orders)
      );
    - '[{"name":"Find employees earning above average","query":"SELECT name, salary
      FROM employees WHERE salary \u003e (SELECT AVG(salary) FROM employees) ORDER
      BY salary DESC;","expected_result":[{"name":"Alice","salary":120000.0},{"name":"Bob","salary":95000.0},{"name":"Diana","salary":90000.0}]},{"name":"Find
      departments with average salary \u003e 80000","query":"SELECT department, AVG(salary)
      as avg_salary FROM employees GROUP BY department HAVING AVG(salary) \u003e 80000
      ORDER BY avg_salary DESC;","expected_result":[{"department":"Engineering","avg_salary":100000.0},{"department":"Sales","avg_salary":82500.0}]},{"name":"Correlated
      subquery - find managers","query":"SELECT name, department FROM employees e
      WHERE EXISTS (SELECT 1 FROM employees WHERE manager_id = e.id) ORDER BY name;","expected_result":[{"name":"Alice","department":"Engineering"},{"name":"Diana","department":"Sales"}]}]'
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    - |
      CREATE TABLE employees (
        id SERIAL PRIMARY KEY,
        name VARCHAR(100),
        department VARCHAR(50),
        salary DECIMAL(10,2),
        manager_id INTEGER
      );
    - |
      INSERT INTO employees (name, department, salary, manager_id) VALUES
        ('Alice', 'Engineering', 120000, NULL),
        ('Bob', 'Engineering', 95000, 1),
        ('Charlie', 'Engineering', 85000, 1),
        ('Diana', 'Sales', 90000, NULL),
        ('Eve', 'Sales', 75000, 4),
        ('Frank', 'Marketing', 70000, NULL);
    - '["Subqueries can be used in WHERE, SELECT, and FROM clauses","Use IN for matching
      multiple values","EXISTS checks if subquery returns any rows","Correlated subqueries
      reference outer query","HAVING filters groups after GROUP BY"]'
  - - 50
    - Window Functions - Advanced Analytics
    - 'Master window functions: ROW_NUMBER, RANK, LAG, LEAD'
    - hard
    - 40
    - "[]"
    - '{"window_syntax_correct":"Window function syntax valid","partitioning_correct":"PARTITION
      BY used properly","results_accurate":"Calculations are correct"}'
    - postgresql
    - advanced-analytics
    - Master window functions, understand PARTITION BY and ORDER BY, calculate running
      totals
    - '["Advanced SQL","Understanding of aggregates"]'
    - Master window functions for advanced analytical queries
    -
    - "[]"
    - 3
    - 0
    - 0.0
    - 0.0
    -
    - true
    - 500
    - '2025-11-06 03:44:03.370547'
    - '2025-11-06 03:44:03.370547'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - code_editor
    - sql
    - "-- Calculate running total using window function\nSELECT \n  order_date,\n
      \ amount,\n  SUM(amount) OVER (ORDER BY order_date) as running_total\nFROM orders;"
    - '[{"name":"ROW_NUMBER - rank sales by date","query":"SELECT sale_date, amount,
      ROW_NUMBER() OVER (ORDER BY sale_date) as row_num FROM sales ORDER BY sale_date;","expected_result":[{"sale_date":"2024-01-01","amount":100.0,"row_num":1},{"sale_date":"2024-01-02","amount":150.0,"row_num":2},{"sale_date":"2024-01-03","amount":120.0,"row_num":3},{"sale_date":"2024-01-04","amount":180.0,"row_num":4},{"sale_date":"2024-01-05","amount":110.0,"row_num":5},{"sale_date":"2024-01-06","amount":160.0,"row_num":6}]},{"name":"Running
      total by region","query":"SELECT region, sale_date, amount, SUM(amount) OVER
      (PARTITION BY region ORDER BY sale_date) as running_total FROM sales ORDER BY
      region, sale_date;","expected_result":[{"region":"North","sale_date":"2024-01-01","amount":100.0,"running_total":100.0},{"region":"North","sale_date":"2024-01-02","amount":150.0,"running_total":250.0},{"region":"North","sale_date":"2024-01-05","amount":110.0,"running_total":360.0},{"region":"North","sale_date":"2024-01-06","amount":160.0,"running_total":520.0},{"region":"South","sale_date":"2024-01-03","amount":120.0,"running_total":120.0},{"region":"South","sale_date":"2024-01-04","amount":180.0,"running_total":300.0}]},{"name":"LAG
      function - compare with previous day","query":"SELECT sale_date, amount, LAG(amount)
      OVER (ORDER BY sale_date) as prev_amount FROM sales ORDER BY sale_date;","expected_result":[{"sale_date":"2024-01-01","amount":100.0,"prev_amount":null},{"sale_date":"2024-01-02","amount":150.0,"prev_amount":100.0},{"sale_date":"2024-01-03","amount":120.0,"prev_amount":150.0},{"sale_date":"2024-01-04","amount":180.0,"prev_amount":120.0},{"sale_date":"2024-01-05","amount":110.0,"prev_amount":180.0},{"sale_date":"2024-01-06","amount":160.0,"prev_amount":110.0}]}]'
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    - |
      CREATE TABLE sales (
        id SERIAL PRIMARY KEY,
        sale_date DATE,
        product VARCHAR(100),
        region VARCHAR(50),
        amount DECIMAL(10,2)
      );
    - |
      INSERT INTO sales (sale_date, product, region, amount) VALUES
        ('2024-01-01', 'Widget', 'North', 100.00),
        ('2024-01-02', 'Gadget', 'North', 150.00),
        ('2024-01-03', 'Widget', 'South', 120.00),
        ('2024-01-04', 'Gadget', 'South', 180.00),
        ('2024-01-05', 'Widget', 'North', 110.00),
        ('2024-01-06', 'Gadget', 'North', 160.00);
    - '["Window functions use OVER clause","PARTITION BY creates separate windows
      per group","ORDER BY within OVER determines calculation order","ROW_NUMBER assigns
      unique sequential numbers","LAG/LEAD access previous/next row values","Running
      totals use SUM() OVER (ORDER BY...)"]'
  - - 51
    - TCP/IP Basics - Analyze Network Packets
    - Learn TCP/IP fundamentals by capturing and analyzing network packets
    - easy
    - 25
    - '[{"step_number":1,"title":"Start network testing container","instruction":"Run
      container with networking tools","expected_command":"docker run -d --name netlab
      --cap-add=NET_ADMIN nicolaka/netshoot sleep 3600","validation":"docker ps |
      grep netlab"},{"step_number":2,"title":"Capture HTTP traffic","instruction":"Use
      tcpdump to capture packets","expected_command":"docker exec netlab timeout 2
      tcpdump -i any -c 10 -w /tmp/capture.pcap ''tcp port 80'' \u0026","validation":"docker
      exec netlab sh -c ''sleep 1 \u0026\u0026 curl -s http://httpbin.org/get \u003e
      /dev/null'' \u0026\u0026 echo ''Traffic captured''"},{"step_number":3,"title":"Analyze
      captured packets","instruction":"Read and analyze the packet capture","expected_command":"docker
      exec netlab tcpdump -r /tmp/capture.pcap -n || echo ''Packets analyzed''","validation":"docker
      exec netlab test -f /tmp/capture.pcap || echo ''Capture exists''"},{"step_number":4,"title":"View
      TCP flags","instruction":"Filter for TCP SYN packets","expected_command":"docker
      exec netlab tcpdump -r /tmp/capture.pcap -n ''tcp[tcpflags] \u0026 tcp-syn !=
      0'' 2\u003e/dev/null || echo ''SYN packets filtered''","validation":"docker
      exec netlab echo ''TCP flags checked''"},{"step_number":5,"title":"Test ping
      and ICMP","instruction":"Send ping and observe ICMP packets","expected_command":"docker
      exec netlab ping -c 3 8.8.8.8","validation":"docker exec netlab ping -c 1 8.8.8.8
      | grep ''1 packets transmitted''"},{"step_number":6,"title":"Check routing table","instruction":"View
      container''s routing table","expected_command":"docker exec netlab ip route
      show","validation":"docker exec netlab ip route show | grep default"},{"step_number":7,"title":"Cleanup","instruction":"Remove
      container","expected_command":"docker rm -f netlab","validation":"docker ps
      | grep netlab"}]'
    - '{"packets_captured":"tcpdump successfully captured traffic","protocols_analyzed":"TCP/IP
      headers examined","routing_understood":"routing table interpreted"}'
    - networking
    - protocols
    - Understand TCP/IP stack, analyze packet headers, use tcpdump
    - '["Basic networking concepts"]'
    - Successfully capture and analyze network packets
    - docker:20-dind
    - '["docker"]'
    - 5
    - 0
    - 0.0
    - 0.0
    -
    - true
    - 200
    - '2025-11-06 03:44:03.376205'
    - '2025-11-06 03:44:03.376205'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -
  - - 52
    - DNS Resolution and Name Servers
    - Understand DNS hierarchy and resolution process
    - easy
    - 20
    - '[{"step_number":1,"title":"Start network tools container","instruction":"Launch
      container with DNS tools","expected_command":"docker run -d --name dnslab nicolaka/netshoot
      sleep 3600","validation":"docker ps | grep dnslab"},{"step_number":2,"title":"Query
      A record","instruction":"Look up IPv4 address for google.com","expected_command":"docker
      exec dnslab nslookup google.com","validation":"docker exec dnslab nslookup google.com
      | grep ''Address:''"},{"step_number":3,"title":"Use dig for detailed query","instruction":"Query
      with dig to see full DNS response","expected_command":"docker exec dnslab dig
      google.com","validation":"docker exec dnslab dig google.com | grep ''ANSWER
      SECTION''"},{"step_number":4,"title":"Query MX records","instruction":"Find
      mail servers for gmail.com","expected_command":"docker exec dnslab dig gmail.com
      MX +short","validation":"docker exec dnslab dig gmail.com MX | grep ''ANSWER''"},{"step_number":5,"title":"Query
      TXT records","instruction":"Look up SPF records","expected_command":"docker
      exec dnslab dig google.com TXT +short","validation":"docker exec dnslab dig
      google.com TXT | grep ''TXT''"},{"step_number":6,"title":"Trace DNS resolution","instruction":"Use
      dig +trace to see full resolution path","expected_command":"docker exec dnslab
      dig +trace google.com | head -20","validation":"docker exec dnslab dig google.com
      +short | grep -E ''[0-9]+\\.[0-9]+''"},{"step_number":7,"title":"Check DNS server","instruction":"View
      configured DNS servers","expected_command":"docker exec dnslab cat /etc/resolv.conf","validation":"docker
      exec dnslab cat /etc/resolv.conf | grep nameserver"},{"step_number":8,"title":"Cleanup","instruction":"Remove
      container","expected_command":"docker rm -f dnslab","validation":"docker ps
      | grep dnslab"}]'
    - '{"dns_queries_work":"successful DNS lookups","record_types_understood":"A,
      MX, TXT records queried","resolution_traced":"DNS hierarchy explored"}'
    - networking
    - dns
    - Master DNS concepts, use dig and nslookup, understand DNS records
    - '["Basic understanding of DNS"]'
    - Successfully query and understand DNS resolution
    - docker:20-dind
    - '["docker"]'
    - 5
    - 0
    - 0.0
    - 0.0
    -
    - true
    - 150
    - '2025-11-06 03:44:03.380040'
    - '2025-11-06 03:44:03.380040'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -
  - - 53
    - Network Namespaces and Isolation
    - Explore Linux network namespaces and container networking
    - medium
    - 35
    - '[{"step_number":1,"title":"Create network namespace","instruction":"Create
      isolated network namespace","expected_command":"docker run -d --name nslab --privileged
      nicolaka/netshoot sleep 3600","validation":"docker ps | grep nslab"},{"step_number":2,"title":"List
      network interfaces","instruction":"View default interfaces in container","expected_command":"docker
      exec nslab ip link show","validation":"docker exec nslab ip link show | grep
      ''eth0\\|lo''"},{"step_number":3,"title":"Create veth pair","instruction":"Create
      virtual ethernet pair","expected_command":"docker exec nslab ip link add veth0
      type veth peer name veth1","validation":"docker exec nslab ip link show | grep
      veth"},{"step_number":4,"title":"Assign IP addresses","instruction":"Configure
      IPs on veth interfaces","expected_command":"docker exec nslab sh -c ''ip addr
      add 10.0.0.1/24 dev veth0 \u0026\u0026 ip addr add 10.0.0.2/24 dev veth1''","validation":"docker
      exec nslab ip addr show veth0 | grep ''10.0.0.1''"},{"step_number":5,"title":"Bring
      interfaces up","instruction":"Activate the veth interfaces","expected_command":"docker
      exec nslab sh -c ''ip link set veth0 up \u0026\u0026 ip link set veth1 up''","validation":"docker
      exec nslab ip link show veth0 | grep ''UP''"},{"step_number":6,"title":"Test
      connectivity","instruction":"Ping between veth interfaces","expected_command":"docker
      exec nslab ping -c 3 -I veth0 10.0.0.2","validation":"docker exec nslab ping
      -c 1 -I veth0 10.0.0.2 | grep ''1 packets transmitted'' || echo ''Connectivity
      tested''"},{"step_number":7,"title":"View routing","instruction":"Check routes
      added for veth interfaces","expected_command":"docker exec nslab ip route show","validation":"docker
      exec nslab ip route show | grep ''10.0.0''"},{"step_number":8,"title":"Cleanup","instruction":"Remove
      container","expected_command":"docker rm -f nslab","validation":"docker ps |
      grep nslab"}]'
    - '{"namespace_created":"network isolation working","veth_pair_configured":"virtual
      interfaces created","connectivity_established":"inter-namespace communication"}'
    - networking
    - linux-networking
    - Understand network namespaces, configure virtual interfaces, master veth pairs
    - '["Linux networking knowledge","Understanding of containers"]'
    - Successfully configure network namespaces and virtual interfaces
    - docker:20-dind
    - '["docker"]'
    - 5
    - 0
    - 0.0
    - 0.0
    -
    - true
    - 350
    - '2025-11-06 03:44:03.384861'
    - '2025-11-06 03:44:03.384861'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -
  - - 54
    - Network Traffic Shaping and QoS
    - Implement bandwidth limiting and Quality of Service controls
    - medium
    - 30
    - '[{"step_number":1,"title":"Start traffic control lab","instruction":"Launch
      container with tc tools","expected_command":"docker run -d --name tclab --privileged
      nicolaka/netshoot sleep 3600","validation":"docker ps | grep tclab"},{"step_number":2,"title":"Measure
      baseline speed","instruction":"Test download speed without limits","expected_command":"docker
      exec tclab sh -c ''wget -O /dev/null http://speedtest.tele2.net/1MB.zip 2\u003e\u00261
      | tail -2'' || echo ''Baseline measured''","validation":"docker exec tclab echo
      ''Baseline test complete''"},{"step_number":3,"title":"Add rate limiting","instruction":"Limit
      bandwidth to 1 Mbit/s using tc","expected_command":"docker exec tclab tc qdisc
      add dev eth0 root tbf rate 1mbit burst 32kbit latency 400ms","validation":"docker
      exec tclab tc qdisc show dev eth0 | grep tbf || echo ''Rate limit added''"},{"step_number":4,"title":"Test
      limited speed","instruction":"Download with rate limit applied","expected_command":"docker
      exec tclab sh -c ''wget -O /dev/null http://speedtest.tele2.net/1MB.zip 2\u003e\u00261
      | tail -2'' || echo ''Limited speed tested''","validation":"docker exec tclab
      echo ''Limited test complete''"},{"step_number":5,"title":"View qdisc statistics","instruction":"Check
      traffic control statistics","expected_command":"docker exec tclab tc -s qdisc
      show dev eth0","validation":"docker exec tclab tc qdisc show dev eth0 | grep
      -E ''qdisc|Sent'' || echo ''Stats viewed''"},{"step_number":6,"title":"Add packet
      delay","instruction":"Remove rate limit and add 100ms delay","expected_command":"docker
      exec tclab sh -c ''tc qdisc del dev eth0 root; tc qdisc add dev eth0 root netem
      delay 100ms''","validation":"docker exec tclab tc qdisc show dev eth0 | grep
      netem || echo ''Delay added''"},{"step_number":7,"title":"Test latency","instruction":"Measure
      ping latency with delay","expected_command":"docker exec tclab ping -c 3 8.8.8.8
      || echo ''Latency tested''","validation":"docker exec tclab echo ''Latency test
      complete''"},{"step_number":8,"title":"Cleanup","instruction":"Remove container","expected_command":"docker
      rm -f tclab","validation":"docker ps | grep tclab"}]'
    - '{"rate_limiting_works":"bandwidth successfully limited","latency_added":"packet
      delay configured","qos_understood":"traffic shaping concepts mastered"}'
    - networking
    - traffic-control
    - Master tc (traffic control), implement rate limiting, understand QoS
    - '["Advanced networking knowledge"]'
    - Successfully implement network traffic shaping
    - docker:20-dind
    - '["docker"]'
    - 5
    - 0
    - 0.0
    - 0.0
    -
    - true
    - 300
    - '2025-11-06 03:44:03.388774'
    - '2025-11-06 03:44:03.388774'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -
  - - 55
    - BGP and Advanced Routing with Bird
    - Learn Border Gateway Protocol and advanced routing concepts
    - hard
    - 50
    - '[{"step_number":1,"title":"Design BGP topology","instruction":"Document 3-AS
      BGP network","expected_command":"cat \u003e bgp-topology.md \u003c\u003c ''EOF''\n#
      BGP Lab Topology\n\n## Autonomous Systems\n- AS65001: ISP1 (10.1.0.0/16)\n-
      AS65002: ISP2 (10.2.0.0/16)\n- AS65003: Customer (10.3.0.0/16)\n\n## BGP Peering\n-
      AS65001 \u003c-\u003e AS65003 (eBGP)\n- AS65002 \u003c-\u003e AS65003 (eBGP)\n-
      AS65001 \u003c-\u003e AS65002 (eBGP)\n\n## Routing Policy\n- Customer (AS65003)
      prefers AS65001 for outbound\n- AS65001 and AS65002 load balance\nEOF","validation":"test
      -f bgp-topology.md \u0026\u0026 grep ''AS65001'' bgp-topology.md"},{"step_number":2,"title":"Create
      Bird configuration","instruction":"Configure BGP router for AS65003","expected_command":"cat
      \u003e bird.conf \u003c\u003c ''EOF''\nrouter id 10.3.0.1;\n\nprotocol kernel
      {\n  ipv4 {\n    export all;\n  };\n}\n\nprotocol device {\n}\n\nprotocol bgp
      isp1 {\n  local as 65003;\n  neighbor 10.1.0.1 as 65001;\n  ipv4 {\n    import
      all;\n    export all;\n  };\n}\n\nprotocol bgp isp2 {\n  local as 65003;\n  neighbor
      10.2.0.1 as 65002;\n  ipv4 {\n    import all;\n    export all;\n  };\n}\nEOF","validation":"test
      -f bird.conf \u0026\u0026 grep ''protocol bgp'' bird.conf"},{"step_number":3,"title":"Document
      BGP attributes","instruction":"Explain BGP path selection criteria","expected_command":"cat
      \u003e bgp-attributes.md \u003c\u003c ''EOF''\n# BGP Path Selection Criteria
      (in order)\n\n1. **Highest Weight** (Cisco proprietary)\n2. **Highest Local
      Preference**\n3. **Locally Originated Routes**\n4. **Shortest AS Path**\n5.
      **Lowest Origin Type** (IGP \u003c EGP \u003c Incomplete)\n6. **Lowest MED**
      (Multi-Exit Discriminator)\n7. **eBGP over iBGP**\n8. **Lowest IGP Cost to Next
      Hop**\n9. **Lowest Router ID**\n\n## Common Attributes\n- AS_PATH: List of ASes
      the route traversed\n- NEXT_HOP: Next hop IP address\n- LOCAL_PREF: Preference
      for outbound traffic\n- MED: Preference for inbound traffic\nEOF","validation":"test
      -f bgp-attributes.md \u0026\u0026 grep ''AS_PATH'' bgp-attributes.md"},{"step_number":4,"title":"Calculate
      AS path length","instruction":"Compare paths for route selection","expected_command":"cat
      \u003e path-calc.py \u003c\u003c ''EOF''\npaths = {\n    ''Path1'': [''AS65003'',
      ''AS65001'', ''AS65000''],\n    ''Path2'': [''AS65003'', ''AS65002'', ''AS65004'',
      ''AS65000'']\n}\n\nfor name, path in paths.items():\n    print(f\"{name}: Length
      = {len(path)-1} hops - {'' -\u003e ''.join(path)}\")\n\nprint(f\"\\nPath1 preferred
      (shorter AS path)\")\nEOF","validation":"test -f path-calc.py \u0026\u0026 python3
      path-calc.py | grep ''Path1''"},{"step_number":5,"title":"Simulate BGP decision
      process","instruction":"Document multi-path selection","expected_command":"cat
      \u003e bgp-decision.md \u003c\u003c ''EOF''\n# BGP Route Selection Example\n\n##
      Scenario: Customer AS65003 receives same prefix from 2 ISPs\n\n### Route 1 (via
      AS65001)\n- AS_PATH: 65001 65000\n- LOCAL_PREF: 200\n- MED: 0\n\n### Route 2
      (via AS65002)\n- AS_PATH: 65002 65004 65000\n- LOCAL_PREF: 100\n- MED: 0\n\n###
      Decision: Route 1 wins\n**Reason**: Higher LOCAL_PREF (200 \u003e 100)\nAS_PATH
      length not even compared (earlier criterion)\nEOF","validation":"test -f bgp-decision.md
      \u0026\u0026 grep ''LOCAL_PREF'' bgp-decision.md"},{"step_number":6,"title":"Cleanup","instruction":"Remove
      configuration files","expected_command":"rm bgp-topology.md bird.conf bgp-attributes.md
      path-calc.py bgp-decision.md","validation":"test ! -f bgp-topology.md"}]'
    - '{"bgp_understood":"BGP concepts mastered","path_selection_clear":"AS path selection
      logic understood","routing_policy_designed":"multi-AS routing configured"}'
    - networking
    - routing
    - Understand BGP protocol, configure routing daemons, master AS path selection
    - '["Expert networking knowledge","Understanding of BGP"]'
    - Master BGP protocol and advanced routing concepts
    - python:3.11-alpine
    - '["python3"]'
    - 3
    - 0
    - 0.0
    - 0.0
    -
    - true
    - 500
    - '2025-11-06 03:44:03.393010'
    - '2025-11-06 03:44:03.393010'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -
  - - 56
    - 'Lab 4.1: Deploy CodeSprout Frontend'
    - Build and deploy the CodeSprout React frontend, making it accessible at localhost:3000
    - easy
    - 20
    - '[{"step_number":1,"title":"Build the frontend image","instruction":"Navigate
      to the frontend directory and build the CodeSprout frontend image tagged as
      codesprout/frontend:1.0","expected_command":"docker build -t codesprout/frontend:1.0
      ./frontend","validation":"docker images | grep codesprout/frontend","hints":["Use
      ''docker build -t'' to tag the image","The path should be ./frontend","Tag format:
      name:version"]},{"step_number":2,"title":"Run the frontend container","instruction":"Run
      the frontend container in detached mode, map port 3000, and name it ''codesprout-web''","expected_command":"docker
      run -d -p 3000:3000 --name codesprout-web codesprout/frontend:1.0","validation":"docker
      ps | grep codesprout-web","hints":["Use -d for detached mode","Map port 3000:3000
      with -p","Name it with --name codesprout-web"]},{"step_number":3,"title":"Verify
      frontend is accessible","instruction":"Test that the frontend is serving content
      at localhost:3000","expected_command":"curl http://localhost:3000","validation":"curl
      -s http://localhost:3000 | grep -q ''CodeSprout'' \u0026\u0026 echo ''SUCCESS''","hints":["Use
      curl to fetch the page","The response should contain ''CodeSprout''","If it''s
      not working, check ''docker logs codesprout-web''"]},{"step_number":4,"title":"Add
      API configuration","instruction":"Stop and remove the current container, then
      run it again with the API_URL environment variable set to http://localhost:8080","expected_command":"docker
      stop codesprout-web \u0026\u0026 docker rm codesprout-web \u0026\u0026 docker
      run -d -p 3000:3000 -e API_URL=http://localhost:8080 --name codesprout-web codesprout/frontend:1.0","validation":"docker
      inspect codesprout-web | grep API_URL","hints":["Stop with ''docker stop codesprout-web''","Remove
      with ''docker rm codesprout-web''","Add -e API_URL=http://localhost:8080"]},{"step_number":5,"title":"View
      frontend logs","instruction":"Check the logs to confirm the frontend started
      successfully","expected_command":"docker logs codesprout-web","validation":"docker
      logs codesprout-web | grep -q ''Serving'' \u0026\u0026 echo ''SUCCESS''","hints":["Use
      ''docker logs'' followed by container name","Look for startup messages"]}]'
    - '{"required_containers":["codesprout-web"],"required_images":["codesprout/frontend:1.0"],"required_ports":["3000"],"max_time_minutes":20}'
    - docker
    - deployment
    - '["Build a frontend image from a Dockerfile", "Run a web server container with
      port mapping", "Configure containers with environment variables"]'
    - '["Build","Run containers","Port mapping"]'
    - Frontend accessible at localhost:3000 with API_URL configured
    -
    - '["docker","curl"]'
    - 3
    - 0
    - 0.0
    - 0.0
    - DCA
    - true
    - 200
    - '2025-11-06 03:44:03.398466'
    - '2025-11-06 03:44:03.398466'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    - codesprout-frontend-deployment
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -
  - - 57
    - 'Lab 4.2: Connect Frontend to Backend API'
    - Deploy the backend API and connect it to the frontend using a Docker network
    - medium
    - 25
    - '[{"step_number":1,"title":"Create a custom network","instruction":"Create a
      Docker bridge network named ''codesprout-net'' for all services to communicate","expected_command":"docker
      network create codesprout-net","validation":"docker network ls | grep codesprout-net","hints":["Use
      ''docker network create''","Name it ''codesprout-net''"]},{"step_number":2,"title":"Build
      the backend image","instruction":"Build the backend API image tagged as codesprout/backend:1.0","expected_command":"docker
      build -t codesprout/backend:1.0 ./backend","validation":"docker images | grep
      codesprout/backend","hints":["Use ''docker build -t''","Path is ./backend","Tag
      as codesprout/backend:1.0"]},{"step_number":3,"title":"Run backend on the network","instruction":"Run
      the backend container on port 8080, connected to codesprout-net, named ''codesprout-api''","expected_command":"docker
      run -d -p 8080:8080 --name codesprout-api --network codesprout-net codesprout/backend:1.0","validation":"docker
      ps | grep codesprout-api","hints":["Use --network codesprout-net","Name it ''codesprout-api''","Map
      port 8080:8080"]},{"step_number":4,"title":"Connect frontend to the network","instruction":"Stop
      the frontend, then restart it connected to codesprout-net with API_URL pointing
      to http://codesprout-api:8080","expected_command":"docker stop codesprout-web
      \u0026\u0026 docker rm codesprout-web \u0026\u0026 docker run -d -p 3000:3000
      --name codesprout-web --network codesprout-net -e API_URL=http://codesprout-api:8080
      codesprout/frontend:1.0","validation":"docker inspect codesprout-web | grep
      codesprout-net","hints":["Connect to --network codesprout-net","Set API_URL
      to http://codesprout-api:8080 (using container name)","Both containers must
      be on the same network"]},{"step_number":5,"title":"Test service communication","instruction":"Verify
      the frontend can reach the backend API","expected_command":"curl http://localhost:3000/api/health","validation":"curl
      -s http://localhost:8080/health | grep -q ''ok'' \u0026\u0026 echo ''SUCCESS''","hints":["Test
      the backend directly: curl http://localhost:8080/health","The frontend should
      be able to make API calls","Check logs with ''docker logs codesprout-web'' if
      issues"]}]'
    - '{"required_containers":["codesprout-web","codesprout-api"],"required_networks":["codesprout-net"],"max_time_minutes":25}'
    - docker
    - networking
    - '["Build and run backend API containers", "Create custom Docker networks", "Enable
      service-to-service communication using DNS"]'
    - '["Docker networks","Multi-container applications"]'
    - Frontend and backend communicating on custom network
    -
    - '["docker","curl"]'
    - 3
    - 0
    - 0.0
    - 0.0
    - DCA
    - true
    - 250
    - '2025-11-06 03:44:03.402255'
    - '2025-11-06 03:44:03.402255'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    - codesprout-backend-connection
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -
  - - 58
    - 'Lab 4.3: Deploy Full Stack with Database'
    - Add PostgreSQL database with persistent storage and connect the backend to it
    - medium
    - 30
    - '[{"step_number":1,"title":"Create a volume for database data","instruction":"Create
      a named volume called ''codesprout-data'' to persist PostgreSQL data","expected_command":"docker
      volume create codesprout-data","validation":"docker volume ls | grep codesprout-data","hints":["Use
      ''docker volume create''","Name it ''codesprout-data''"]},{"step_number":2,"title":"Run
      PostgreSQL container","instruction":"Run PostgreSQL 15 on the codesprout-net
      network, named ''codesprout-db'', with the volume mounted and password set to
      ''secret123''","expected_command":"docker run -d --name codesprout-db --network
      codesprout-net -v codesprout-data:/var/lib/postgresql/data -e POSTGRES_PASSWORD=secret123
      -e POSTGRES_DB=codesprout postgres:15","validation":"docker ps | grep codesprout-db","hints":["Use
      postgres:15 image","Mount volume: -v codesprout-data:/var/lib/postgresql/data","Set
      POSTGRES_PASSWORD and POSTGRES_DB"]},{"step_number":3,"title":"Verify database
      is running","instruction":"Check the PostgreSQL logs to confirm it started successfully","expected_command":"docker
      logs codesprout-db","validation":"docker logs codesprout-db | grep -q ''database
      system is ready'' \u0026\u0026 echo ''SUCCESS''","hints":["Use ''docker logs
      codesprout-db''","Look for ''database system is ready to accept connections''"]},{"step_number":4,"title":"Configure
      backend with database credentials","instruction":"Stop and restart the backend
      with database connection environment variables (DB_HOST=codesprout-db, DB_PORT=5432,
      DB_NAME=codesprout, DB_USER=postgres, DB_PASSWORD=secret123)","expected_command":"docker
      stop codesprout-api \u0026\u0026 docker rm codesprout-api \u0026\u0026 docker
      run -d -p 8080:8080 --name codesprout-api --network codesprout-net -e DB_HOST=codesprout-db
      -e DB_PORT=5432 -e DB_NAME=codesprout -e DB_USER=postgres -e DB_PASSWORD=secret123
      codesprout/backend:1.0","validation":"docker inspect codesprout-api | grep DB_HOST","hints":["Pass
      5 environment variables: DB_HOST, DB_PORT, DB_NAME, DB_USER, DB_PASSWORD","DB_HOST
      should be ''codesprout-db'' (container name)","Keep it on codesprout-net network"]},{"step_number":5,"title":"Test
      database connectivity","instruction":"Verify the backend can connect to the
      database by checking the API health endpoint","expected_command":"curl http://localhost:8080/health","validation":"curl
      -s http://localhost:8080/health | grep -q ''database.*connected'' \u0026\u0026
      echo ''SUCCESS''","hints":["The health endpoint should report database status","Check
      backend logs if connection fails: docker logs codesprout-api"]},{"step_number":6,"title":"Verify
      data persistence","instruction":"Restart the database container and confirm
      data persists","expected_command":"docker restart codesprout-db","validation":"docker
      ps | grep codesprout-db","hints":["Use ''docker restart''","The volume preserves
      data across restarts"]}]'
    - '{"required_containers":["codesprout-web","codesprout-api","codesprout-db"],"required_volumes":["codesprout-data"],"max_time_minutes":30}'
    - docker
    - data
    - '["Run database containers with persistent volumes", "Configure database credentials
      securely", "Connect backend services to databases"]'
    - '["Docker volumes","Environment variables","Networking"]'
    - Complete 3-tier application (frontend, backend, database) running with persistent
      data
    -
    - '["docker"]'
    - 3
    - 0
    - 0.0
    - 0.0
    - DCA
    - true
    - 300
    - '2025-11-06 03:44:03.405770'
    - '2025-11-06 03:44:03.405770'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    - codesprout-database-integration
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -
  - - 59
    - 'Lab 4.4: Deploy with Docker Compose'
    - Use Docker Compose to orchestrate the entire CodeSprout stack with a single
      command
    - medium
    - 35
    - '[{"step_number":1,"title":"Stop all running containers","instruction":"Clean
      up existing containers to start fresh with Docker Compose","expected_command":"docker
      stop codesprout-web codesprout-api codesprout-db \u0026\u0026 docker rm codesprout-web
      codesprout-api codesprout-db","validation":"! docker ps -a | grep codesprout","hints":["Stop
      all three containers","Then remove them","Use: docker stop [containers] \u0026\u0026
      docker rm [containers]"]},{"step_number":2,"title":"Create docker-compose.yml","instruction":"Create
      a docker-compose.yml file in the project root that defines all three services
      (frontend, backend, database)","expected_command":"cat docker-compose.yml","validation":"test
      -f docker-compose.yml \u0026\u0026 grep -q ''services:'' docker-compose.yml","hints":["File
      should define: services, networks, volumes","Include: frontend (port 3000),
      backend (port 8080), database (postgres:15)","Use the provided template or create
      your own"]},{"step_number":3,"title":"Start the stack with Compose","instruction":"Use
      docker-compose to start all services in detached mode","expected_command":"docker-compose
      up -d","validation":"docker-compose ps | grep Up","hints":["Use ''docker-compose
      up -d''","This builds images and starts all services","Wait for all containers
      to be ''Up''"]},{"step_number":4,"title":"Verify all services are running","instruction":"Check
      the status of all Compose services","expected_command":"docker-compose ps","validation":"docker-compose
      ps | grep -c Up | grep -q 3","hints":["All 3 services should show ''Up''","Use
      ''docker-compose ps'' to check status"]},{"step_number":5,"title":"Test the
      full application","instruction":"Verify the frontend is accessible and can communicate
      with the backend and database","expected_command":"curl http://localhost:3000
      \u0026\u0026 curl http://localhost:8080/health","validation":"curl -s http://localhost:8080/health
      | grep -q ''database.*connected''","hints":["Frontend: http://localhost:3000","Backend
      health: http://localhost:8080/health","Both should respond successfully"]},{"step_number":6,"title":"View
      logs from all services","instruction":"Use Docker Compose to view logs from
      all services","expected_command":"docker-compose logs","validation":"docker-compose
      logs 2\u003e\u00261 | grep -q ''codesprout''","hints":["Use ''docker-compose
      logs''","Add -f to follow logs in real-time","Add service name to see specific
      logs"]},{"step_number":7,"title":"Stop the stack","instruction":"Stop and remove
      all containers using Docker Compose (but preserve volumes)","expected_command":"docker-compose
      down","validation":"! docker-compose ps | grep Up","hints":["Use ''docker-compose
      down''","This removes containers and networks","Volumes are preserved"]}]'
    - '{"required_files":["docker-compose.yml"],"max_time_minutes":35}'
    - docker-compose
    - orchestration
    - '["Write docker-compose.yml for multi-container applications", "Define service
      dependencies and startup order", "Manage entire application stacks with single
      commands"]'
    - '["Docker Compose basics","Multi-container networking"]'
    - Complete CodeSprout stack managed with Docker Compose
    -
    - '["docker","docker-compose"]'
    - 3
    - 0
    - 0.0
    - 0.0
    - DCA
    - true
    - 350
    - '2025-11-06 03:44:03.410059'
    - '2025-11-06 03:44:03.410059'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    - codesprout-compose-deployment
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -
  - - 60
    - 'Lab 4.5: Manage and Scale CodeSprout'
    - Update services, check logs, and scale the backend to handle more traffic
    - medium
    - 25
    - '[{"step_number":1,"title":"Start the CodeSprout stack","instruction":"Bring
      up the entire stack using Docker Compose","expected_command":"docker-compose
      up -d","validation":"docker-compose ps | grep -c Up | grep -q 3","hints":["Use
      ''docker-compose up -d''","All services should start"]},{"step_number":2,"title":"View
      backend logs","instruction":"Check the backend logs to see API requests","expected_command":"docker-compose
      logs backend","validation":"docker-compose logs backend | grep -q ''codesprout''","hints":["Use
      ''docker-compose logs backend''","Add -f to follow logs in real-time"]},{"step_number":3,"title":"Update
      backend code","instruction":"Rebuild and update the backend service with code
      changes","expected_command":"docker-compose up -d --build backend","validation":"docker-compose
      ps backend | grep Up","hints":["Use --build to rebuild the image","Only update
      the backend service","Other services keep running"]},{"step_number":4,"title":"Scale
      the backend","instruction":"Scale the backend to 3 instances to handle more
      traffic","expected_command":"docker-compose up -d --scale backend=3","validation":"docker-compose
      ps | grep backend | wc -l | grep -q 3","hints":["Use --scale backend=3","This
      creates 3 backend containers","Note: You may need to remove explicit port mapping
      for scaling to work"]},{"step_number":5,"title":"Verify scaling","instruction":"Check
      that all 3 backend instances are running","expected_command":"docker-compose
      ps","validation":"docker-compose ps | grep backend | grep -c Up | grep -q 3","hints":["Use
      ''docker-compose ps''","You should see 3 backend containers","All should be
      in ''Up'' state"]},{"step_number":6,"title":"View aggregated logs","instruction":"View
      logs from all backend instances simultaneously","expected_command":"docker-compose
      logs backend","validation":"docker-compose logs backend 2\u003e\u00261 | grep
      -q backend","hints":["Logs from all 3 instances are combined","Each log line
      shows which instance it came from"]},{"step_number":7,"title":"Clean shutdown","instruction":"Stop
      and remove all containers gracefully","expected_command":"docker-compose down","validation":"!
      docker-compose ps | grep Up","hints":["Use ''docker-compose down''","This stops
      all services cleanly","Data in volumes is preserved"]}]'
    - '{"max_time_minutes":25}'
    - docker-compose
    - operations
    - '["Update and restart services without downtime", "Debug applications using
      logs", "Scale services horizontally to handle load"]'
    - '["Docker Compose","Multi-container operations"]'
    - Successfully scaled and managed CodeSprout services
    -
    - '["docker","docker-compose"]'
    - 3
    - 0
    - 0.0
    - 0.0
    - DCA
    - true
    - 300
    - '2025-11-06 03:44:03.413523'
    - '2025-11-06 03:44:03.413523'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    - codesprout-management-scaling
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -
  - - 61
    - Hello World in Go
    - Write your first Go program
    - easy
    - 10
    - "[]"
    - "{}"
    - golang
    - fundamentals
    - '["Learn basic Go syntax"]'
    - "[]"
    -
    -
    - "[]"
    - 3
    - 0
    - 0.0
    - 0.0
    -
    - true
    - 100
    - '2025-11-06 03:44:32.191831'
    - '2025-11-06 03:44:32.191831'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - code_editor
    - golang
    - package main\n\nimport "fmt"\n\nfunc main() {\n    // Your code here\n}
    - '[{"name":"Test 1","input":"","expected_output":"Hello, World!","hidden":false}]'
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    - '["Use fmt.Println()"]'
  - - 62
    - 'Lab: Hello World in Go'
    - Write your first Go program that prints "Hello, World!" to the console.
    - easy
    - 10
    - "[]"
    - "{}"
    - golang
    - fundamentals
    - '["Understand basic Go program structure", "Use the fmt package for output"]'
    - "[]"
    -
    -
    - "[]"
    - 3
    - 0
    - 0.0
    - 0.0
    -
    - true
    - 100
    - '2025-11-06 04:04:48.068331'
    - '2025-11-06 04:04:48.068331'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - code_editor
    - golang
    - |-
      package main

      import "fmt"

      func main() {
          // TODO: Print "Hello, World!" to the console
      }
    - '[{"name":"Test Hello World","input":"","expected_output":"Hello, World!","hidden":false,"description":"Should
      print Hello, World!"}]'
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    - '["Use fmt.Println() to print to the console","The exact text should be: Hello,
      World!"]'
  - - 63
    - 'Lab: Working with Variables'
    - Practice declaring and using variables in Go.
    - easy
    - 15
    - "[]"
    - "{}"
    - golang
    - fundamentals
    - '["Declare variables", "Use different data types", "Format output"]'
    - "[]"
    -
    -
    - "[]"
    - 3
    - 0
    - 0.0
    - 0.0
    -
    - true
    - 150
    - '2025-11-06 04:04:48.070208'
    - '2025-11-06 04:04:48.070208'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - code_editor
    - golang
    - |-
      package main

      import "fmt"

      func main() {
          // TODO: Declare variables for name (string), age (int), and height (float64)
          // Set name to "Alice", age to 25, height to 5.6
          // Print them in the format: "Name: Alice, Age: 25, Height: 5.60"
      }
    - '[{"name":"Test variable output","input":"","expected_output":"Name: Alice,
      Age: 25, Height: 5.60","hidden":false,"description":"Should correctly declare
      and print variables"}]'
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    - '["Use := for short variable declaration","Use fmt.Printf with format specifiers:
      %s for string, %d for int, %.2f for float"]'
  - - 64
    - 'Lab: Create a Calculator Function'
    - Write a function that adds two numbers and returns the result.
    - easy
    - 15
    - "[]"
    - "{}"
    - golang
    - fundamentals
    - '["Write functions", "Work with parameters and return values"]'
    - "[]"
    -
    -
    - "[]"
    - 3
    - 0
    - 0.0
    - 0.0
    -
    - true
    - 150
    - '2025-11-06 04:04:48.071729'
    - '2025-11-06 04:04:48.071729'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - code_editor
    - golang
    - |-
      package main

      import "fmt"

      // TODO: Create a function called add that takes two integers and returns their sum
      func add(a, b int) int {
          // Your code here
      }

      func main() {
          result := add(5, 3)
          fmt.Println(result)
      }
    - '[{"name":"Test addition","input":"","expected_output":"8","hidden":false,"description":"Should
      correctly add 5 + 3"}]'
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    - '["The function signature is already provided","Simply return a + b"]'
  - - 65
    - 'Lab: Hello World in Go'
    - Write your first Go program that prints "Hello, World!" to the console.
    - easy
    - 10
    - "[]"
    - "{}"
    - golang
    - fundamentals
    - '["Understand basic Go program structure", "Use the fmt package for output"]'
    - "[]"
    -
    -
    - "[]"
    - 3
    - 0
    - 0.0
    - 0.0
    -
    - true
    - 100
    - '2025-11-06 04:09:12.877959'
    - '2025-11-06 04:09:12.877959'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - code_editor
    - golang
    - |-
      package main

      import "fmt"

      func main() {
          // TODO: Print "Hello, World!" to the console
      }
    - '[{"name":"Test Hello World","input":"","expected_output":"Hello, World!","hidden":false,"description":"Should
      print Hello, World!"}]'
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    - '["Use fmt.Println() to print to the console","The exact text should be: Hello,
      World!"]'
  - - 66
    - 'Lab: Working with Variables'
    - Practice declaring and using variables in Go.
    - easy
    - 15
    - "[]"
    - "{}"
    - golang
    - fundamentals
    - '["Declare variables", "Use different data types", "Format output"]'
    - "[]"
    -
    -
    - "[]"
    - 3
    - 0
    - 0.0
    - 0.0
    -
    - true
    - 150
    - '2025-11-06 04:09:12.880549'
    - '2025-11-06 04:09:12.880549'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - code_editor
    - golang
    - |-
      package main

      import "fmt"

      func main() {
          // TODO: Declare variables for name (string), age (int), and height (float64)
          // Set name to "Alice", age to 25, height to 5.6
          // Print them in the format: "Name: Alice, Age: 25, Height: 5.60"
      }
    - '[{"name":"Test variable output","input":"","expected_output":"Name: Alice,
      Age: 25, Height: 5.60","hidden":false,"description":"Should correctly declare
      and print variables"}]'
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    - '["Use := for short variable declaration","Use fmt.Printf with format specifiers:
      %s for string, %d for int, %.2f for float"]'
  - - 67
    - 'Lab: Calculator Function'
    - Write a function that adds two numbers and returns the result.
    - easy
    - 15
    - "[]"
    - "{}"
    - golang
    - fundamentals
    - '["Write functions", "Work with parameters and return values"]'
    - "[]"
    -
    -
    - "[]"
    - 3
    - 0
    - 0.0
    - 0.0
    -
    - true
    - 150
    - '2025-11-06 04:09:12.882368'
    - '2025-11-06 04:09:12.882368'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - code_editor
    - golang
    - |-
      package main

      import "fmt"

      // TODO: Create a function called add that takes two integers and returns their sum
      func add(a, b int) int {
          // Your code here
      }

      func main() {
          result := add(5, 3)
          fmt.Println(result)
      }
    - '[{"name":"Test addition","input":"","expected_output":"8","hidden":false,"description":"Should
      correctly add 5 + 3"}]'
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    - '["The function signature is already provided","Simply return a + b"]'
  - - 68
    - 'Lab: Working with Slices'
    - Create and manipulate slices in Go.
    - medium
    - 20
    - "[]"
    - "{}"
    - golang
    - data_structures
    - '["Create slices", "Use append function", "Get slice length"]'
    - "[]"
    -
    -
    - "[]"
    - 3
    - 0
    - 0.0
    - 0.0
    -
    - true
    - 200
    - '2025-11-06 04:09:12.902025'
    - '2025-11-06 04:09:12.902025'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - code_editor
    - golang
    - |-
      package main

      import "fmt"

      func main() {
          // TODO: Create a slice with numbers 1-5
          // TODO: Append 6, 7, 8 to the slice
          // TODO: Print the length of the slice
          // Expected output: 8
      }
    - '[{"name":"Test slice length","input":"","expected_output":"8","hidden":false}]'
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    - '["Use []int{} to create a slice","Use append() to add elements","Use len()
      to get length"]'
  - - 69
    - 'Lab: Working with Maps'
    - Create a map and perform operations on it.
    - medium
    - 20
    - "[]"
    - "{}"
    - golang
    - data_structures
    - '["Create maps", "Add key-value pairs", "Access map values"]'
    - "[]"
    -
    -
    - "[]"
    - 3
    - 0
    - 0.0
    - 0.0
    -
    - true
    - 200
    - '2025-11-06 04:09:12.903895'
    - '2025-11-06 04:09:12.903895'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - code_editor
    - golang
    - |-
      package main

      import "fmt"

      func main() {
          // TODO: Create a map with string keys and int values
          // TODO: Add "apple": 5, "banana": 3, "orange": 7
          // TODO: Print the value for "banana"
          // Expected output: 3
      }
    - '[{"name":"Test map value","input":"","expected_output":"3","hidden":false}]'
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    - '["Use make(map[string]int)","Access values with map[key]"]'
  - - 70
    - 'Lab: Implement Methods'
    - Create a struct with methods.
    - medium
    - 25
    - "[]"
    - "{}"
    - golang
    - advanced
    - '["Define methods", "Use receiver arguments", "Access struct fields in methods"]'
    - "[]"
    -
    -
    - "[]"
    - 3
    - 0
    - 0.0
    - 0.0
    -
    - true
    - 250
    - '2025-11-06 04:09:12.920898'
    - '2025-11-06 04:09:12.920898'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - code_editor
    - golang
    - |-
      package main

      import "fmt"

      type Circle struct {
          Radius float64
      }

      // TODO: Implement Area method that returns radius * radius * 3.14
      func (c Circle) Area() float64 {
          // Your code here
      }

      func main() {
          circle := Circle{Radius: 5}
          fmt.Printf("%.2f", circle.Area())
      }
    - '[{"name":"Test circle area","input":"","expected_output":"78.50","hidden":false}]'
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    - '["Use c.Radius to access the radius","Return Radius * Radius * 3.14"]'
  - - 71
    - 'Lab: Your First Goroutine'
    - Launch a goroutine that prints a message.
    - medium
    - 20
    - "[]"
    - "{}"
    - golang
    - concurrency
    - '["Launch goroutines", "Understand concurrent execution"]'
    - "[]"
    -
    -
    - "[]"
    - 3
    - 0
    - 0.0
    - 0.0
    -
    - true
    - 300
    - '2025-11-06 04:09:12.944178'
    - '2025-11-06 04:09:12.944178'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - code_editor
    - golang
    - |-
      package main

      import (
          "fmt"
          "time"
      )

      // TODO: Create a function called printMessage that prints "Hello from goroutine!"
      // TODO: In main, launch it as a goroutine and wait 100ms
      func main() {
          // Your code here
          time.Sleep(100 * time.Millisecond)
      }
    - '[{"name":"Test goroutine","input":"","expected_output":"Hello from goroutine!","hidden":false}]'
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    - '["Use go keyword before function call","Define printMessage function first"]'
  - - 72
    - 'Lab: Send and Receive with Channels'
    - Use a channel to send a message between goroutines.
    - medium
    - 25
    - "[]"
    - "{}"
    - golang
    - concurrency
    - '["Create channels", "Send and receive data", "Coordinate goroutines"]'
    - "[]"
    -
    -
    - "[]"
    - 3
    - 0
    - 0.0
    - 0.0
    -
    - true
    - 350
    - '2025-11-06 04:09:12.946127'
    - '2025-11-06 04:09:12.946127'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - code_editor
    - golang
    - |-
      package main

      import "fmt"

      func main() {
          // TODO: Create a channel of strings
          // TODO: Launch a goroutine that sends "Hello Channel!" to the channel
          // TODO: Receive from the channel and print it
      }
    - '[{"name":"Test channel","input":"","expected_output":"Hello Channel!","hidden":false}]'
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    - '["Use make(chan string)","Send with ch \u003c- value","Receive with value :=
      \u003c-ch"]'
  - - 73
    - CodeSprout Web Server Management
    - Deploy and manage the CodeSprout web server in a real scenario
    - easy
    - 15
    - '[{"title":"Deploy the web server","instruction":"Run an nginx:alpine container
      named \"codesprout-main\" on port 3000","command":"docker run -d --name codesprout-main
      -p 3000:80 nginx:alpine","hint":"Use docker run with -d, -p and --name flags"},{"title":"Verify
      the server is running","instruction":"List running containers and ensure codesprout-main
      is present","command":"docker ps","hint":"Use docker ps and look for the container
      name"},{"title":"Stop the server","instruction":"Stop the running web server
      container","command":"docker stop codesprout-main","hint":"Use docker stop \u003ccontainer\u003e"},{"title":"Clean
      up the container","instruction":"Remove the stopped container to keep things
      tidy","command":"docker rm codesprout-main","hint":"Use docker rm \u003ccontainer\u003e"}]'
    - "{}"
    - docker
    - containers
    - '["Deploy a container with custom configuration", "Monitor running containers",
      "Manage container lifecycle"]'
    - "[]"
    -
    -
    - "[]"
    - 3
    - 0
    - 0.0
    - 0.0
    -
    - true
    - 100
    - '2025-11-06 04:12:16.943121'
    - '2025-11-06 04:12:16.943121'
    - |
      **Mission Brief from Sarah:**

      "Great work so far! Now I need you to handle our main web server. Here's what needs to happen:
      1. Deploy our web server with proper port mapping
      2. Verify it's running correctly
      3. Stop it when I give the signal
      4. Clean up the stopped container

      This is a typical day-to-day task for our DevOps team. Ready?"
    - '["docker-run","docker-ps","docker-stop","docker-rm","port-mapping"]'
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -
  - - 74
    - CodeSprout App Image Build
    - Write a multi-stage Dockerfile and build a lean app image
    - medium
    - 20
    - '[{"title":"Create Dockerfile","instruction":"Create a multi-stage Dockerfile
      (builder + final). Use alpine base.","command":"cat Dockerfile","hint":"First
      stage builds, second stage copies artifact"},{"title":"Build the image","instruction":"Build
      the image and tag it codesprout/app:1.0","command":"docker build -t codesprout/app:1.0
      .","hint":"Use docker build -t \u003cname\u003e ."},{"title":"Run the container","instruction":"Run
      the image and verify output","command":"docker run --rm codesprout/app:1.0","hint":"Run
      and check the program output"}]'
    - "{}"
    - docker
    - images
    - '["Write Dockerfiles", "Build and run images"]'
    - "[]"
    -
    -
    - "[]"
    - 3
    - 0
    - 0.0
    - 0.0
    -
    - true
    - 120
    - '2025-11-06 04:12:16.988660'
    - '2025-11-06 04:12:16.988660'
    - "**Mission:** Create an optimized production image for CodeSprout's app."
    - '["dockerfile","docker-build","multi-stage"]'
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -
  - - 75
    - CodeSprout Persistent Database
    - Run MySQL with a named volume and a custom network
    - medium
    - 25
    - '[{"title":"Create a volume","instruction":"Create a named volume called codesprout-db","command":"docker
      volume create codesprout-db","hint":"Use docker volume create \u003cname\u003e"},{"title":"Create
      a network","instruction":"Create a user-defined bridge network codesprout-net","command":"docker
      network create codesprout-net","hint":"Use docker network create \u003cname\u003e"},{"title":"Run
      MySQL","instruction":"Run mysql:8 with root password and mount the volume on
      /var/lib/mysql","command":"docker run -d --name codesprout-db --network codesprout-net
      -e MYSQL_ROOT_PASSWORD=secret -v codesprout-db:/var/lib/mysql mysql:8","hint":"Use
      -e for env vars, -v for volumes, --network to attach"}]'
    - "{}"
    - docker
    - data
    - '["Create volumes", "Create networks", "Run configured services"]'
    - "[]"
    -
    -
    - "[]"
    - 3
    - 0
    - 0.0
    - 0.0
    -
    - true
    - 150
    - '2025-11-06 04:12:17.002024'
    - '2025-11-06 04:12:17.002024'
    - "**Mission:** Deploy a MySQL database with persistent data on a custom network."
    - '["volumes","networking","env-vars"]'
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -
  - - 76
    - Building Your First Docker Image
    - Create a Dockerfile and build your first custom image
    - medium
    - 30
    - '"[{\"step_number\":1,\"title\":\"Create Dockerfile\",\"instruction\":\"Create
      a simple Dockerfile using Alpine base image\",\"expected_command\":\"echo -e
      ''FROM alpine:latest\\\\nRUN apk add --no-cache curl\\\\nCMD [\\\"curl\\\",
      \\\"--version\\\"]'' \u003e Dockerfile\",\"validation\":\"test -f Dockerfile\",\"hint\":null},{\"step_number\":2,\"title\":\"Build
      the image\",\"instruction\":\"Build the image with tag ''mycurl:v1''\",\"expected_command\":\"docker
      build -t mycurl:v1 .\",\"validation\":\"docker images | grep mycurl\",\"hint\":null},{\"step_number\":3,\"title\":\"Run
      container from custom image\",\"instruction\":\"Run a container from your newly
      built image\",\"expected_command\":\"docker run mycurl:v1\",\"validation\":\"docker
      run mycurl:v1 | grep curl\",\"hint\":null}]"'
    - '"{\"dockerfile_exists\":\"Dockerfile must exist\",\"image_built\":\"Image must
      be built successfully\"}"'
    - docker
    - images
    -
    - '"[]"'
    -
    - docker:20-dind
    - '"[\"docker\"]"'
    - 5
    - 0
    - 0.0
    - 0.0
    -
    - true
    - 100
    - '2025-11-06 07:32:44.030082'
    - '2025-11-06 07:32:44.030082'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -
  - - 77
    - Working with Volumes
    - 'Practice creating volumes, mounting them in containers, and persisting data.

      '
    - medium
    - 40
    - '"[{\"step_number\":1,\"title\":\"Create a Named Volume\",\"instruction\":\"Create
      a Docker volume called mydata\",\"expected_command\":\"docker volume create
      mydata\",\"validation\":null,\"hint\":null},{\"step_number\":2,\"title\":\"List
      Volumes\",\"instruction\":\"View all Docker volumes\",\"expected_command\":\"docker
      volume ls\",\"validation\":null,\"hint\":null},{\"step_number\":3,\"title\":\"Use
      Volume in Container\",\"instruction\":\"Run a container that mounts the volume\",\"expected_command\":\"docker
      run -d --name db -v mydata:/data postgres:alpine\",\"validation\":null,\"hint\":null}]"'
    - '"{}"'
    - docker
    - volumes
    -
    - '"[]"'
    -
    - docker:20-dind
    - '"[\"docker\"]"'
    - 5
    - 0
    - 0.0
    - 0.0
    -
    - true
    - 100
    - '2025-11-06 07:32:44.042849'
    - '2025-11-06 08:20:50.337739'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -
  - - 78
    - Hello Container!
    - |
      Welcome to your first hands-on Docker lab! In this exercise, you'll:

      1. Verify Docker is installed and running
      2. Pull and run the classic "hello-world" container
      3. Explore running and stopped containers
      4. Understand the container lifecycle

      This lab introduces you to basic Docker commands you'll use throughout the bootcamp.
    - easy
    - 30
    - '"[{\"step_number\":1,\"title\":\"Verify Docker Installation\",\"instruction\":\"Check
      that Docker is installed and the daemon is running\",\"expected_command\":\"docker
      version\",\"validation\":null,\"hint\":\"This command shows both client and
      server (daemon) versions\"},{\"step_number\":2,\"title\":\"Check Docker System
      Information\",\"instruction\":\"View detailed information about your Docker
      installation\",\"expected_command\":\"docker info\",\"validation\":null,\"hint\":\"Look
      for the number of containers and images\"},{\"step_number\":3,\"title\":\"Run
      Hello World Container\",\"instruction\":\"Pull and run the official Docker hello-world
      image\",\"expected_command\":\"docker run hello-world\",\"validation\":null,\"hint\":\"Docker
      will automatically pull the image if it doesn''t exist locally\"},{\"step_number\":4,\"title\":\"List
      Running Containers\",\"instruction\":\"Check which containers are currently
      running\",\"expected_command\":\"docker ps\",\"validation\":null,\"hint\":\"The
      hello-world container exits immediately, so it won''t appear here\"},{\"step_number\":5,\"title\":\"List
      All Containers\",\"instruction\":\"View all containers, including stopped ones\",\"expected_command\":\"docker
      ps -a\",\"validation\":null,\"hint\":\"The -a flag shows containers in all states\"},{\"step_number\":6,\"title\":\"List
      Downloaded Images\",\"instruction\":\"See what images are now stored locally\",\"expected_command\":\"docker
      images\",\"validation\":null,\"hint\":\"You should see the hello-world image\"},{\"step_number\":7,\"title\":\"Run
      Nginx Web Server\",\"instruction\":\"Start a more substantial container - an
      nginx web server\",\"expected_command\":\"docker run -d --name my-nginx -p 8080:80
      nginx:alpine\",\"validation\":null,\"hint\":\"-d runs in detached mode, -p maps
      ports, --name gives it a memorable name\"},{\"step_number\":8,\"title\":\"Verify
      Nginx is Running\",\"instruction\":\"Check that the nginx container is actively
      running\",\"expected_command\":\"docker ps\",\"validation\":null,\"hint\":\"You
      should now see my-nginx in the list\"},{\"step_number\":9,\"title\":\"View Nginx
      Logs\",\"instruction\":\"Check the logs from the nginx container\",\"expected_command\":\"docker
      logs my-nginx\",\"validation\":null,\"hint\":\"Logs show stdout/stderr from
      the container\"},{\"step_number\":10,\"title\":\"Stop the Nginx Container\",\"instruction\":\"Gracefully
      stop the running nginx container\",\"expected_command\":\"docker stop my-nginx\",\"validation\":null,\"hint\":\"This
      sends SIGTERM signal to stop the container\"},{\"step_number\":11,\"title\":\"Verify
      Container Stopped\",\"instruction\":\"Confirm the container is no longer running\",\"expected_command\":\"docker
      ps\",\"validation\":null,\"hint\":\"my-nginx should not appear in running containers\"},{\"step_number\":12,\"title\":\"Check
      All Containers Again\",\"instruction\":\"View both running and stopped containers\",\"expected_command\":\"docker
      ps -a\",\"validation\":null,\"hint\":\"my-nginx should now show as Exited\"}]"'
    - '"{}"'
    - docker
    - basics
    - '["Verify Docker installation", "Run your first Docker container", "List containers
      and images", "Understand container lifecycle"]'
    - '"[]"'
    -
    - docker:20-dind
    - '"[\"docker\"]"'
    - 5
    - 0
    - 0.0
    - 0.0
    -
    - true
    - 100
    - '2025-11-06 08:09:17.943326'
    - '2025-11-06 08:09:17.943326'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -
  - - 79
    - Deploy and Manage Web Server
    - 'In this lab, you''ll deploy an Nginx web server and practice essential container
      management skills including starting, stopping, inspecting, and monitoring containers.

      '
    - easy
    - 40
    - '"[{\"step_number\":1,\"title\":\"Run Nginx in Detached Mode\",\"instruction\":\"Start
      an nginx web server in the background with port mapping\",\"expected_command\":\"docker
      run -d --name web-server -p 8080:80 nginx:alpine\",\"validation\":null,\"hint\":\"-d
      runs detached, -p maps ports, --name assigns a friendly name\"},{\"step_number\":2,\"title\":\"Verify
      Container is Running\",\"instruction\":\"List running containers to confirm
      web-server is active\",\"expected_command\":\"docker ps\",\"validation\":null,\"hint\":null},{\"step_number\":3,\"title\":\"Inspect
      Container Details\",\"instruction\":\"View detailed configuration of the web-server
      container\",\"expected_command\":\"docker inspect web-server\",\"validation\":null,\"hint\":\"Look
      for IPAddress, ports, and environment variables in the JSON output\"},{\"step_number\":4,\"title\":\"Check
      Container Logs\",\"instruction\":\"View the logs from the nginx container\",\"expected_command\":\"docker
      logs web-server\",\"validation\":null,\"hint\":null},{\"step_number\":5,\"title\":\"Execute
      Command Inside Container\",\"instruction\":\"Run a command inside the container
      to see nginx version\",\"expected_command\":\"docker exec web-server nginx -v\",\"validation\":null,\"hint\":null},{\"step_number\":6,\"title\":\"Open
      Interactive Shell\",\"instruction\":\"Access the container''s shell interactively\",\"expected_command\":\"docker
      exec -it web-server sh\",\"validation\":null,\"hint\":\"Alpine Linux uses ''sh''
      instead of ''bash''\"},{\"step_number\":7,\"title\":\"View Container Resource
      Usage\",\"instruction\":\"Check CPU and memory usage of the container\",\"expected_command\":\"docker
      stats web-server --no-stream\",\"validation\":null,\"hint\":\"--no-stream shows
      stats once instead of continuously\"},{\"step_number\":8,\"title\":\"Stop the
      Container Gracefully\",\"instruction\":\"Stop the nginx container with graceful
      shutdown\",\"expected_command\":\"docker stop web-server\",\"validation\":null,\"hint\":null},{\"step_number\":9,\"title\":\"Restart
      the Container\",\"instruction\":\"Start the stopped container again\",\"expected_command\":\"docker
      start web-server\",\"validation\":null,\"hint\":null},{\"step_number\":10,\"title\":\"Follow
      Logs in Real-time\",\"instruction\":\"Watch logs as they happen (Ctrl+C to exit)\",\"expected_command\":\"docker
      logs -f web-server\",\"validation\":null,\"hint\":\"Try accessing http://localhost:8080
      in another terminal to generate logs\"},{\"step_number\":11,\"title\":\"Stop
      and Remove Container\",\"instruction\":\"Stop the container and remove it\",\"expected_command\":\"docker
      stop web-server \u0026\u0026 docker rm web-server\",\"validation\":null,\"hint\":null},{\"step_number\":12,\"title\":\"Cleanup
      Images\",\"instruction\":\"List images and optionally clean up\",\"expected_command\":\"docker
      images\",\"validation\":null,\"hint\":null}]"'
    - '"{}"'
    - docker
    - container-management
    - '["Run containers in detached mode", "Manage container lifecycle", "Inspect
      running containers", "View and follow container logs"]'
    - '"[]"'
    -
    - docker:20-dind
    - '"[\"docker\"]"'
    - 5
    - 0
    - 0.0
    - 0.0
    -
    - true
    - 100
    - '2025-11-06 08:13:01.782252'
    - '2025-11-06 08:13:01.782252'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -
  - - 80
    - Build Custom Web Application
    - 'Build a custom Docker image for a Node.js web application using best practices.

      '
    - medium
    - 45
    - '"[{\"step_number\":1,\"title\":\"Create Project Directory\",\"instruction\":\"Create
      a directory for the Node.js application\",\"expected_command\":\"mkdir -p ~/myapp
      \u0026\u0026 cd ~/myapp\",\"validation\":null,\"hint\":null},{\"step_number\":2,\"title\":\"Create
      Simple Node App\",\"instruction\":\"Create a basic package.json file\",\"expected_command\":\"echo
      ''{\\\"name\\\":\\\"myapp\\\",\\\"version\\\":\\\"1.0.0\\\",\\\"scripts\\\":{\\\"start\\\":\\\"node
      server.js\\\"}}'' \u003e package.json\",\"validation\":null,\"hint\":null},{\"step_number\":3,\"title\":\"Create
      Basic Dockerfile\",\"instruction\":\"Write a Dockerfile for the Node.js app\",\"expected_command\":\"echo
      ''FROM node:14-alpine\\nWORKDIR /app\\nCOPY package*.json ./\\nRUN npm install\\nCOPY
      . .\\nEXPOSE 3000\\nCMD [\\\"npm\\\",\\\"start\\\"]'' \u003e Dockerfile\",\"validation\":null,\"hint\":null},{\"step_number\":4,\"title\":\"Build
      the Image\",\"instruction\":\"Build the Docker image with a tag\",\"expected_command\":\"docker
      build -t myapp:v1 .\",\"validation\":null,\"hint\":\"The . specifies the build
      context (current directory)\"},{\"step_number\":5,\"title\":\"Verify Image Was
      Created\",\"instruction\":\"List images to confirm myapp:v1 exists\",\"expected_command\":\"docker
      images | grep myapp\",\"validation\":null,\"hint\":null}]"'
    - '"{}"'
    - docker
    - dockerfile
    - '["Write a production-ready Dockerfile", "Build a custom image", "Optimize image
      size", "Use multi-stage builds"]'
    - '"[]"'
    -
    - docker:20-dind
    - '"[\"docker\"]"'
    - 5
    - 0
    - 0.0
    - 0.0
    -
    - true
    - 100
    - '2025-11-06 08:20:50.322536'
    - '2025-11-06 08:20:50.322536'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -
  - - 81
    - Multi-Container Application
    - 'Deploy a web application with a separate database container, connected via
      a custom network.

      '
    - medium
    - 45
    - '"[{\"step_number\":1,\"title\":\"Create Custom Network\",\"instruction\":\"Create
      a bridge network for the application\",\"expected_command\":\"docker network
      create myapp-network\",\"validation\":null,\"hint\":null},{\"step_number\":2,\"title\":\"Run
      Database Container\",\"instruction\":\"Start a PostgreSQL database on the custom
      network\",\"expected_command\":\"docker run -d --name db --network myapp-network
      postgres:alpine\",\"validation\":null,\"hint\":null},{\"step_number\":3,\"title\":\"Run
      Web Application\",\"instruction\":\"Start a web app that connects to the database\",\"expected_command\":\"docker
      run -d --name web --network myapp-network -p 8080:80 nginx:alpine\",\"validation\":null,\"hint\":null}]"'
    - '"{}"'
    - docker
    - networking
    -
    - '"[]"'
    -
    - docker:20-dind
    - '"[\"docker\"]"'
    - 5
    - 0
    - 0.0
    - 0.0
    -
    - true
    - 100
    - '2025-11-06 08:20:50.347680'
    - '2025-11-06 08:20:50.347680'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -
  - - 82
    - Deploy with Docker Compose
    - 'Create a complete application stack using Docker Compose.

      '
    - medium
    - 45
    - '"[{\"step_number\":1,\"title\":\"Create Compose File\",\"instruction\":\"Create
      a docker-compose.yml file\",\"expected_command\":\"mkdir -p ~/compose-app \u0026\u0026
      cd ~/compose-app \u0026\u0026 echo ''version: \\\"3.8\\\"\\nservices:\\n  web:\\n    image:
      nginx:alpine\\n    ports:\\n      - \\\"8080:80\\\"'' \u003e docker-compose.yml\",\"validation\":null,\"hint\":null},{\"step_number\":2,\"title\":\"Start
      Services\",\"instruction\":\"Launch all services with Docker Compose\",\"expected_command\":\"docker-compose
      up -d\",\"validation\":null,\"hint\":null},{\"step_number\":3,\"title\":\"List
      Running Services\",\"instruction\":\"Check the status of Compose services\",\"expected_command\":\"docker-compose
      ps\",\"validation\":null,\"hint\":null}]"'
    - '"{}"'
    - docker
    - compose
    -
    - '"[]"'
    -
    - docker:20-dind
    - '"[\"docker\"]"'
    - 5
    - 0
    - 0.0
    - 0.0
    -
    - true
    - 100
    - '2025-11-06 08:20:50.358411'
    - '2025-11-06 08:20:50.358411'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -
  - - 83
    - 'Capstone: Full-Stack Application'
    - 'Build a complete microservices application with frontend, backend, database,
      and reverse proxy - all orchestrated with Docker Compose.

      '
    - hard
    - 90
    - '"[{\"step_number\":1,\"title\":\"Create Project Structure\",\"instruction\":\"Set
      up the capstone project directory\",\"expected_command\":\"mkdir -p ~/capstone/{frontend,backend,nginx}
      \u0026\u0026 cd ~/capstone\",\"validation\":null,\"hint\":null},{\"step_number\":2,\"title\":\"Create
      Backend Dockerfile\",\"instruction\":\"Create a Dockerfile for a Node.js API\",\"expected_command\":\"cd
      backend \u0026\u0026 echo ''FROM node:14-alpine\\nWORKDIR /app\\nCOPY package*.json
      ./\\nRUN npm install\\nCOPY . .\\nEXPOSE 3000\\nCMD [\\\"npm\\\",\\\"start\\\"]''
      \u003e Dockerfile \u0026\u0026 cd ..\",\"validation\":null,\"hint\":null},{\"step_number\":3,\"title\":\"Create
      Docker Compose Configuration\",\"instruction\":\"Define the complete application
      stack\",\"expected_command\":\"echo ''version: \\\"3.8\\\"\\nservices:\\n  frontend:\\n    image:
      nginx:alpine\\n    ports:\\n      - \\\"80:80\\\"\\n  backend:\\n    build:
      ./backend\\n    ports:\\n      - \\\"3000:3000\\\"\\n  db:\\n    image: postgres:alpine\\n    environment:\\n      POSTGRES_PASSWORD:
      secret'' \u003e docker-compose.yml\",\"validation\":null,\"hint\":null},{\"step_number\":4,\"title\":\"Build
      and Launch Application\",\"instruction\":\"Start the entire application stack\",\"expected_command\":\"docker-compose
      up -d --build\",\"validation\":null,\"hint\":null},{\"step_number\":5,\"title\":\"Verify
      All Services Running\",\"instruction\":\"Check that all services are healthy\",\"expected_command\":\"docker-compose
      ps\",\"validation\":null,\"hint\":null},{\"step_number\":6,\"title\":\"View
      Application Logs\",\"instruction\":\"Monitor logs from all services\",\"expected_command\":\"docker-compose
      logs\",\"validation\":null,\"hint\":null},{\"step_number\":7,\"title\":\"Scale
      Backend Service\",\"instruction\":\"Scale the backend to 3 instances\",\"expected_command\":\"docker-compose
      up -d --scale backend=3\",\"validation\":null,\"hint\":null},{\"step_number\":8,\"title\":\"Cleanup\",\"instruction\":\"Stop
      and remove all containers\",\"expected_command\":\"docker-compose down\",\"validation\":null,\"hint\":null}]"'
    - '"{}"'
    - docker
    - capstone
    -
    - '"[]"'
    -
    - docker:20-dind
    - '"[\"docker\"]"'
    - 5
    - 0
    - 0.0
    - 0.0
    -
    - true
    - 100
    - '2025-11-06 08:20:50.369565'
    - '2025-11-06 08:20:50.369565'
    -
    - "[]"
    - "[]"
    - "[]"
    - 70
    - 1.5
    -
    - terminal
    -
    -
    - "[]"
    -
    - "{}"
    -
    - "[]"
    - 5
    - 128
    -
    -
    -

---
interactive_learning_units:
  columns:
  - id
  - title
  - slug
  - concept_explanation
  - command_to_learn
  - command_variations
  - practice_hints
  - scenario_description
  - scenario_steps
  - difficulty_level
  - estimated_minutes
  - sequence_order
  - category
  - published
  - quiz_question_text
  - quiz_question_type
  - quiz_options
  - quiz_correct_answer
  - quiz_explanation
  - visual_aid_url
  - code_examples
  - learning_objectives
  - prerequisites
  - created_at
  - updated_at
  - scenario_narrative
  - problem_statement
  - concept_tags
  - required_commands
  records: 
  - - 1
    - 'Docker PS: Listing Running Containers'
    - docker-basics-ps-command
    - |
      # Understanding docker ps: Your Container Dashboard

      ## What is docker ps?
      The `docker ps` command is your primary tool for viewing running containers. Think of it as the "process list" for Docker containers - similar to how `ps` shows running processes in Linux, `docker ps` shows your active containers.

      ## Why It's Important
      - **Monitoring**: See which containers are currently running
      - **Troubleshooting**: Check container status, ports, and names
      - **Resource Management**: Identify containers consuming resources
      - **Quick Reference**: Get container IDs for other Docker commands

      ## Common Use Cases

      ### 1. Check Running Containers
      ```bash
      docker ps
      ```
      Shows only currently running containers with essential information.

      ### 2. See All Containers (Including Stopped)
      ```bash
      docker ps -a
      ```
      The `-a` flag shows all containers, regardless of their state.

      ### 3. Filter by Status
      ```bash
      docker ps -a --filter "status=exited"
      ```
      Find all stopped containers for cleanup.

      ### 4. Show Only Container IDs
      ```bash
      docker ps -q
      ```
      Useful for scripting and piping to other commands.

      ## Output Columns Explained

      ```
      CONTAINER ID   IMAGE         COMMAND                  CREATED        STATUS        PORTS                  NAMES
      abc123def456   nginx:alpine  "nginx -g 'daemon of…"   2 hours ago    Up 2 hours    0.0.0.0:8080->80/tcp   web-server
      ```

      - **CONTAINER ID**: Unique identifier (short form)
      - **IMAGE**: Docker image used to create the container
      - **COMMAND**: Command running inside the container
      - **CREATED**: When the container was created
      - **STATUS**: Current state (Up/Exited/Paused)
      - **PORTS**: Port mappings between host and container
      - **NAMES**: Human-friendly name (auto-generated or custom)

      ## Visual Example

      ```
      Your Terminal
           │
           ├─ docker ps
           │
           └─> Shows Running Containers
                ├─ web-server (nginx)
                ├─ database (mysql)
                └─ cache (redis)
      ```

      ## Common Mistakes to Avoid

      1. **Forgetting -a**: Running `docker ps` only shows running containers. Use `-a` to see stopped ones.
      2. **Confusing Names and IDs**: You can use either the container name or ID in commands.
      3. **Not Using Filters**: For large environments, use filters to narrow results.
      4. **Ignoring Status**: Always check the STATUS column - "Up" doesn't mean "healthy".

      ## Pro Tips

      - Use `--format` for custom output: `docker ps --format "{{.Names}}: {{.Status}}"`
      - Combine with `grep`: `docker ps | grep nginx`
      - Use `-n 5` to show only the last 5 containers
      - Set aliases: `alias dps='docker ps --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}"'`

      ## When to Use docker ps

      - Before starting a new container (check for port conflicts)
      - After deploying services (verify they're running)
      - During troubleshooting (check container status)
      - Before cleanup operations (identify containers to remove)
    - docker ps
    - '["docker ps -a","docker ps --all","docker ps -q","docker ps --filter \"status=running\"","docker
      ps -n 5"]'
    - '["Start with basic \"docker ps\" to see running containers","Add -a flag to
      see all containers including stopped ones","Use -q to get just container IDs
      (useful for scripting)","Try filtering: docker ps --filter \"status=exited\"","Format
      output with --format for better readability"]'
    -
    - "[]"
    - easy
    - 10
    - 1
    - docker-basics
    - true
    - What flag should you add to "docker ps" to see stopped containers?
    - mcq
    - '[{"text":"-a or --all","correct":true},{"text":"-s or --stopped","correct":false},{"text":"-e
      or --exited","correct":false},{"text":"--show-stopped","correct":false}]'
    - "-a or --all"
    - The -a (or --all) flag shows all containers, both running and stopped. Without
      it, only running containers are displayed.
    -
    - '[{"title":"Basic container listing","code":"docker ps","explanation":"Shows
      all currently running containers with their status, ports, and names"},{"title":"Show
      all containers including stopped","code":"docker ps -a","explanation":"Displays
      every container on the system regardless of state - useful for cleanup and troubleshooting"},{"title":"Get
      only container IDs","code":"docker ps -q","explanation":"Returns just the container
      IDs, perfect for piping to other commands like docker stop $(docker ps -q)"},{"title":"Filter
      by status","code":"docker ps --filter \"status=exited\"","explanation":"Shows
      only containers that have stopped running - helpful for identifying containers
      to remove"}]'
    - "[]"
    - "[]"
    - '2025-11-06 03:44:04.172215'
    - '2025-11-06 03:44:04.176646'
    - |
      **Your First Day as DevOps Engineer**

      Your team lead Maria greets you: "Welcome! Before we start, you need to understand what's running on our servers. We have several containers deployed, but I'm not sure which ones are active. Can you check what's currently running and give me a status report?"

      You need to list all containers, identify which are running, and understand their configuration.
    - List all running Docker containers on the system and identify their key information
      (names, images, ports)
    - '["containers","cli","monitoring","docker-ps","inspection"]'
    - "[]"
  - - 2
    - 'Docker Run: Creating and Starting Containers'
    - docker-basics-run-command
    - |
      # Mastering docker run: From Image to Running Container

      ## What is docker run?
      `docker run` is the most fundamental Docker command - it creates a new container from an image and starts it immediately. This single command combines container creation and startup in one operation.

      ## Why It's Critical
      - **Instant Deployment**: Launch applications in seconds
      - **Isolation**: Each container runs in its own isolated environment
      - **Reproducibility**: Same command works across all systems
      - **Flexibility**: Customize containers with numerous options

      ## Basic Syntax
      ```bash
      docker run [OPTIONS] IMAGE [COMMAND] [ARG...]
      ```

      ## Common Use Cases

      ### 1. Run a Simple Container
      ```bash
      docker run nginx
      ```
      Downloads nginx image (if needed) and starts a container in foreground mode.

      ### 2. Run in Detached Mode
      ```bash
      docker run -d nginx
      ```
      The `-d` flag runs the container in the background, freeing your terminal.

      ### 3. Assign a Name
      ```bash
      docker run --name my-nginx nginx
      ```
      Give your container a memorable name instead of random auto-generated one.

      ### 4. Map Ports
      ```bash
      docker run -p 8080:80 nginx
      ```
      Maps container port 80 to host port 8080. Access via http://localhost:8080

      ### 5. Complete Example
      ```bash
      docker run -d --name web-server -p 8080:80 nginx:alpine
      ```
      Runs nginx Alpine in background, names it "web-server", accessible on port 8080.

      ## Essential Options

      | Option | Description | Example |
      |--------|-------------|---------|
      | `-d` | Detached mode (background) | `docker run -d nginx` |
      | `--name` | Assign container name | `docker run --name web nginx` |
      | `-p` | Publish port (host:container) | `docker run -p 80:80 nginx` |
      | `-e` | Set environment variable | `docker run -e NODE_ENV=production node` |
      | `-v` | Mount volume | `docker run -v /data:/app/data mysql` |
      | `--rm` | Remove container when stopped | `docker run --rm alpine echo "hi"` |
      | `-it` | Interactive terminal | `docker run -it ubuntu bash` |

      ## How docker run Works Internally

      ```
      1. Check if image exists locally
         ↓ (if not found)
      2. Pull image from Docker Hub
         ↓
      3. Create container from image
         ↓
      4. Allocate filesystem layer
         ↓
      5. Set up networking
         ↓
      6. Start the container process
         ↓
      7. Execute the default command (or your override)
      ```

      ## Common Patterns

      ### Interactive Debugging
      ```bash
      docker run -it --rm ubuntu bash
      ```
      Opens interactive shell, automatically removes container on exit.

      ### One-off Tasks
      ```bash
      docker run --rm node:14 node --version
      ```
      Runs command and cleans up immediately.

      ### Environment Configuration
      ```bash
      docker run -d -e MYSQL_ROOT_PASSWORD=secret -p 3306:3306 mysql
      ```
      Sets up MySQL with environment variables and port mapping.

      ## Common Mistakes to Avoid

      1. **Forgetting -d**: Container runs in foreground, blocking terminal
      2. **Port Already in Use**: Check with `docker ps` before mapping ports
      3. **Not Using --rm for Testing**: Leaves many stopped containers
      4. **Wrong Port Order**: Format is `-p HOST:CONTAINER`, not the reverse
      5. **Missing Environment Variables**: Some images require specific env vars to work

      ## Interactive vs Detached Mode

      **Foreground (Default)**
      - Attaches to container output
      - Blocks terminal
      - Good for: debugging, one-off commands
      - Exit with: Ctrl+C (stops container)

      **Background (-d)**
      - Returns container ID immediately
      - Frees terminal
      - Good for: services, long-running processes
      - View logs with: `docker logs <container>`

      ## Pro Tips

      1. **Always name production containers**: Makes management easier
      2. **Use specific image tags**: `nginx:1.21` instead of `nginx:latest`
      3. **Set restart policies**: `--restart unless-stopped` for services
      4. **Limit resources**: `--memory="512m" --cpus="1.0"`
      5. **Use .env files**: `--env-file .env` for multiple variables
    - docker run -d -p 8080:80 --name my-nginx nginx:alpine
    - '["docker run nginx","docker run -d nginx","docker run -d --name web nginx","docker
      run -p 8080:80 nginx","docker run -d --name web -p 8080:80 nginx:alpine"]'
    - '["Basic run: docker run nginx (foreground mode)","Add -d for background: docker
      run -d nginx","Name it: docker run -d --name my-web nginx","Map ports: docker
      run -d -p 8080:80 nginx","Complete: docker run -d --name web -p 8080:80 nginx:alpine"]'
    -
    - "[]"
    - easy
    - 10
    - 2
    - docker-basics
    - true
    - In "docker run -p 8080:80 nginx", which port is on the host machine?
    - mcq
    - '[{"text":"8080","correct":true},{"text":"80","correct":false},{"text":"Both
      are host ports","correct":false},{"text":"Neither, both are container ports","correct":false}]'
    - '8080'
    - Port mapping format is -p HOST:CONTAINER. So 8080 is the host port, and 80 is
      the container port. Traffic to localhost:8080 routes to container port 80.
    -
    - '[{"title":"Simple foreground run","code":"docker run nginx","explanation":"Starts
      nginx in foreground - output appears in terminal, Ctrl+C stops it"},{"title":"Background
      with detached mode","code":"docker run -d nginx","explanation":"Runs nginx in
      background and returns container ID - terminal stays free"},{"title":"Named
      container with port mapping","code":"docker run -d --name web -p 8080:80 nginx","explanation":"Creates
      named container accessible at http://localhost:8080"},{"title":"Auto-remove
      after exit","code":"docker run --rm alpine echo \"Hello Docker\"","explanation":"Runs
      command and automatically removes container when finished - great for testing"}]'
    - "[]"
    - "[]"
    - '2025-11-06 03:44:04.198974'
    - '2025-11-06 03:44:04.207751'
    - |
      **Deploying Your First Service**

      Maria hands you a deployment ticket: "We need to spin up a new nginx web server. It should run in the background, be named 'production-web', and be accessible on port 8080. Use the nginx:alpine image for smaller footprint. Can you deploy it?"
    - Deploy an nginx:alpine container in detached mode, name it "production-web",
      and map port 8080 to container port 80
    - '["containers","docker-run","deployment","port-mapping","detached-mode"]'
    - "[]"
  - - 3
    - 'Docker Stop: Gracefully Stopping Containers'
    - docker-basics-stop-command
    - |
      # Understanding docker stop: Graceful Container Shutdown

      ## What is docker stop?
      `docker stop` gracefully stops one or more running containers by sending signals to the main process. This is the proper way to stop containers, allowing them to clean up resources before shutting down.

      ## Why Graceful Shutdown Matters
      - **Data Integrity**: Allows databases to flush buffers to disk
      - **Connection Cleanup**: Lets web servers close client connections properly
      - **State Preservation**: Enables applications to save state before exit
      - **Resource Release**: Properly releases locks, file handles, and network ports

      ## Basic Syntax
      ```bash
      docker stop [OPTIONS] CONTAINER [CONTAINER...]
      ```

      ## How It Works: The Signal Dance

      ```
      docker stop container_name
           │
           ├─ Sends SIGTERM signal
           │  (polite request to shut down)
           │
           ├─ Waits up to 10 seconds
           │  (default grace period)
           │
           └─ If still running: sends SIGKILL
              (forceful termination)
      ```

      ## Common Use Cases

      ### 1. Stop a Single Container
      ```bash
      docker stop web-server
      ```
      Gracefully stops the container named "web-server".

      ### 2. Stop Multiple Containers
      ```bash
      docker stop web-server database cache
      ```
      Stops all three containers in sequence.

      ### 3. Custom Timeout
      ```bash
      docker stop -t 30 database
      ```
      Waits 30 seconds before force-killing (useful for databases).

      ### 4. Stop All Running Containers
      ```bash
      docker stop $(docker ps -q)
      ```
      Stops every running container on the system.

      ## SIGTERM vs SIGKILL

      **SIGTERM (Signal 15)**
      - Polite request to terminate
      - Application can catch and handle it
      - Allows cleanup operations
      - Default first signal sent

      **SIGKILL (Signal 9)**
      - Immediate, forceful termination
      - Cannot be caught or ignored
      - No cleanup possible
      - Used as last resort

      ## Timing Considerations

      ```
      Start: docker stop database
           │
           ├─ 0s: SIGTERM sent → app starts shutdown
           ├─ 2s: closing connections...
           ├─ 5s: flushing data to disk...
           ├─ 8s: cleanup complete, exits gracefully ✓
           │
           └─ If took > 10s: SIGKILL sent ✗
      ```

      ## Stop vs Kill

      | Command | Signal | Graceful | Use Case |
      |---------|--------|----------|----------|
      | `docker stop` | SIGTERM → SIGKILL | Yes | Normal operations |
      | `docker kill` | SIGKILL immediately | No | Hung containers |

      ## Common Patterns

      ### Stop and Remove
      ```bash
      docker stop my-app && docker rm my-app
      ```
      Stops container then removes it.

      ### Stop with Specific Timeout
      ```bash
      docker stop -t 60 production-db
      ```
      Gives database 60 seconds to shut down cleanly.

      ### Emergency Stop All
      ```bash
      docker stop $(docker ps -q) -t 1
      ```
      Quickly stops all containers (1 second timeout).

      ## Common Mistakes to Avoid

      1. **Using docker kill first**: Always try `docker stop` before `docker kill`
      2. **Too short timeout**: Some apps need more than 10 seconds to shut down
      3. **Not checking status**: Verify container actually stopped with `docker ps`
      4. **Force-stopping databases**: Always use longer timeout for data services
      5. **Stopping without checking dependencies**: Stop dependent services first

      ## Container States After Stop

      ```
      Running → Stopping → Stopped (Exited)
                  │
                  ├─ Container remains on disk
                  ├─ Can be restarted with docker start
                  └─ Remove with docker rm
      ```

      ## Pro Tips

      1. **Check logs before stopping**: `docker logs container_name`
      2. **Use health checks**: Ensure graceful shutdown is working
      3. **Set appropriate timeouts**: Match to application needs
      4. **Script cleanup**: Create stop scripts for dependent services
      5. **Monitor shutdown**: Watch logs during stop to catch issues

      ## Restart vs Stop/Start

      ```bash
      # These are different:
      docker stop web && docker start web  # Keeps same container
      docker restart web                   # Equivalent to above
      docker stop web && docker run web    # Creates NEW container
      ```

      ## When to Use docker stop

      - Deploying new version (stop old, start new)
      - Maintenance windows (controlled shutdown)
      - Resource cleanup (free ports/memory)
      - Before system reboot (clean shutdown)
      - Troubleshooting (restart services)
    - docker stop my-container
    - '["docker stop container_name","docker stop -t 30 container_name","docker stop
      $(docker ps -q)","docker stop container1 container2 container3"]'
    - '["Basic stop: docker stop \u003ccontainer-name\u003e","Stop by ID: docker stop
      abc123","Custom timeout: docker stop -t 30 database","Stop multiple: docker
      stop web db cache","Stop all running: docker stop $(docker ps -q)"]'
    -
    - "[]"
    - easy
    - 10
    - 3
    - docker-basics
    - true
    - What signal does docker stop send first to a container?
    - mcq
    - '[{"text":"SIGTERM","correct":true},{"text":"SIGKILL","correct":false},{"text":"SIGINT","correct":false},{"text":"SIGHUP","correct":false}]'
    - SIGTERM
    - docker stop first sends SIGTERM (signal 15), which allows graceful shutdown.
      If the container doesn't stop within the timeout (default 10 seconds), it sends
      SIGKILL as a last resort.
    -
    - '[{"title":"Stop a single container","code":"docker stop web-server","explanation":"Gracefully
      stops the web-server container with default 10-second timeout"},{"title":"Stop
      with custom timeout","code":"docker stop -t 60 database","explanation":"Gives
      database 60 seconds to shut down cleanly - important for data integrity"},{"title":"Stop
      multiple containers","code":"docker stop web-server api-server background-worker","explanation":"Stops
      three containers in sequence - useful for microservices shutdown"},{"title":"Stop
      all running containers","code":"docker stop $(docker ps -q)","explanation":"Emergency
      stop for all running containers - docker ps -q returns just IDs"}]'
    - "[]"
    - "[]"
    - '2025-11-06 03:44:04.218231'
    - '2025-11-06 03:44:04.224214'
    - |
      **Scheduled Maintenance Window**

      Maria sends you a message: "We have a maintenance window in 5 minutes. We need to stop the 'api-server' container gracefully. It's a critical service that handles user sessions, so make sure it has enough time to close connections cleanly - give it at least 30 seconds. Can you handle this?"
    - Stop the api-server container gracefully with a 30-second timeout to allow proper
      connection cleanup
    - '["containers","lifecycle","docker-stop","signals","graceful-shutdown"]'
    - "[]"
  - - 4
    - 'Docker RM: Removing Containers'
    - docker-basics-rm-command
    - |
      # Mastering docker rm: Container Cleanup and Removal

      ## What is docker rm?
      `docker rm` permanently deletes one or more stopped containers from your system. This command frees up disk space and keeps your Docker environment clean and organized.

      ## Why Container Removal Matters
      - **Disk Space**: Each container consumes disk space even when stopped
      - **Organization**: Prevents clutter from old experiments and tests
      - **Name Conflicts**: Frees up container names for reuse
      - **System Health**: Reduces metadata overhead on Docker daemon

      ## Basic Syntax
      ```bash
      docker rm [OPTIONS] CONTAINER [CONTAINER...]
      ```

      ## Important Constraint
      **You CANNOT remove a running container without -f flag**
      ```bash
      docker rm running-container
      # Error: You cannot remove a running container

      docker stop running-container
      docker rm running-container
      # Success!
      ```

      ## Common Use Cases

      ### 1. Remove a Stopped Container
      ```bash
      docker rm old-container
      ```
      Removes a single stopped container.

      ### 2. Force Remove Running Container
      ```bash
      docker rm -f web-server
      ```
      Stops AND removes the container (not recommended for production).

      ### 3. Remove Multiple Containers
      ```bash
      docker rm container1 container2 container3
      ```
      Removes multiple containers in one command.

      ### 4. Remove All Stopped Containers
      ```bash
      docker rm $(docker ps -a -q -f status=exited)
      ```
      Cleans up all exited containers.

      ## Container Lifecycle: Remove in Context

      ```
      Created → Running → Stopped → Removed
                ↓          ↓         ↓
             (start)   (stop)     (rm)
                                   ↓
                             Gone forever!
                        (image still exists)
      ```

      ## Remove Options

      | Option | Description | Example |
      |--------|-------------|---------|
      | `-f` | Force remove (stops if running) | `docker rm -f web` |
      | `-v` | Remove associated volumes | `docker rm -v database` |
      | `-l` | Remove specified link | `docker rm -l my-link` |

      ## Volumes and Removal

      **Default Behavior (volumes persist)**
      ```bash
      docker rm database
      # Container removed, but volumes remain!
      ```

      **Remove Container AND Volumes**
      ```bash
      docker rm -v database
      # Container AND its anonymous volumes removed
      ```

      ## Common Cleanup Patterns

      ### 1. Stop and Remove
      ```bash
      docker stop my-app && docker rm my-app
      ```
      Proper two-step removal process.

      ### 2. Force Remove (shortcut)
      ```bash
      docker rm -f my-app
      ```
      Combines stop and remove (use with caution).

      ### 3. Clean All Stopped Containers
      ```bash
      docker container prune
      ```
      Modern way to remove all stopped containers.

      ### 4. Remove Containers Matching Pattern
      ```bash
      docker rm $(docker ps -a -q -f name=test-)
      ```
      Removes all containers with names starting with "test-".

      ## Common Mistakes to Avoid

      1. **Trying to remove running containers**: Always stop first (or use -f)
      2. **Forgetting about volumes**: Use -v if you want to remove volumes too
      3. **Removing production containers**: Double-check before removing!
      4. **Not using --rm flag on docker run**: For temporary containers
      5. **Manual cleanup when automated works**: Use `docker run --rm` for tests

      ## What Gets Removed?

      **Removed:**
      - Container filesystem layer
      - Container metadata
      - Network connections (unless connected to user-defined networks)
      - Anonymous volumes (if -v flag used)

      **NOT Removed:**
      - The underlying image
      - Named volumes
      - User-defined networks
      - Container logs (in some configurations)

      ## Preventing Accidental Removal

      ```bash
      # Use descriptive names
      docker run --name production-api-server nginx

      # Add labels for organization
      docker run --label env=production nginx

      # Use docker run --rm for temporary work
      docker run --rm alpine echo "test"
      ```

      ## Bulk Cleanup Strategies

      ### Remove All Stopped Containers
      ```bash
      docker container prune
      # or
      docker rm $(docker ps -a -q -f status=exited)
      ```

      ### Remove Containers Older Than 24h
      ```bash
      docker container prune --filter "until=24h"
      ```

      ### Remove Everything (nuclear option)
      ```bash
      docker rm -f $(docker ps -a -q)
      # WARNING: Removes ALL containers!
      ```

      ## Automation and Best Practices

      ### 1. Self-Cleaning Test Containers
      ```bash
      docker run --rm -it alpine sh
      # Automatically removed on exit
      ```

      ### 2. Cron Job for Cleanup
      ```bash
      # Daily cleanup of exited containers
      0 2 * * * docker container prune -f
      ```

      ### 3. Pre-Deployment Cleanup
      ```bash
      #!/bin/bash
      docker stop old-version
      docker rm old-version
      docker run -d --name new-version app:latest
      ```

      ## When to Use docker rm

      - After testing/development work
      - Before redeploying with same name
      - During regular maintenance
      - When freeing disk space
      - After failed deployments

      ## Recovery After Accidental Removal

      **Important**: Once removed, a container cannot be recovered!

      However, you can:
      1. Recreate from the same image
      2. Restore from volume backups (if volumes still exist)
      3. Check Docker logs (if log driver persists logs)

      ## Pro Tips

      1. **Use --rm for temporary work**: `docker run --rm alpine echo "test"`
      2. **Label your containers**: `--label purpose=testing`
      3. **Regular cleanup**: Schedule `docker container prune`
      4. **Check before removing**: `docker inspect` to verify it's safe
      5. **Backup important data**: Always backup before removing data containers
    - docker rm my-container
    - '["docker rm container_name","docker rm -f running_container","docker rm -v
      container_with_volumes","docker rm $(docker ps -a -q -f status=exited)"]'
    - '["Remove stopped container: docker rm \u003cname\u003e","Force remove running:
      docker rm -f \u003cname\u003e","Remove with volumes: docker rm -v \u003cname\u003e","Remove
      multiple: docker rm container1 container2","Clean all stopped: docker container
      prune"]'
    -
    - "[]"
    - easy
    - 10
    - 4
    - docker-basics
    - true
    - Can you remove a running container with just "docker rm container_name"?
    - mcq
    - '[{"text":"No, you must stop it first or use -f flag","correct":true},{"text":"Yes,
      it will stop automatically","correct":false},{"text":"Yes, but only if you use
      sudo","correct":false},{"text":"No, running containers cannot be removed","correct":false}]'
    - No, you must stop it first or use -f flag
    - Docker will not remove a running container with just docker rm. You must either
      stop it first with docker stop, or use the -f flag to force removal (which stops
      and removes in one step).
    -
    - '[{"title":"Remove a stopped container","code":"docker rm old-test-container","explanation":"Removes
      a container that has already been stopped - frees up disk space and the name"},{"title":"Force
      remove running container","code":"docker rm -f web-server","explanation":"Stops
      and removes in one command - use with caution in production"},{"title":"Remove
      container and its volumes","code":"docker rm -v database-test","explanation":"Removes
      container along with its anonymous volumes - important for complete cleanup"},{"title":"Clean
      all stopped containers","code":"docker container prune -f","explanation":"Modern
      cleanup command that removes all stopped containers without confirmation"}]'
    - "[]"
    - "[]"
    - '2025-11-06 03:44:04.233725'
    - '2025-11-06 03:44:04.239477'
    - |
      **Cleanup After Testing**

      Maria sends you a cleanup task: "We ran a bunch of tests last week and there are many stopped containers cluttering the system. Can you remove all containers with names starting with 'test-'? Make sure they're stopped first, and clean up their volumes too since they're just test data."
    - Remove all stopped containers that start with "test-" including their volumes
    - '["containers","lifecycle","docker-rm","cleanup","maintenance"]'
    - "[]"
  - - 5
    - 'Docker Exec: Running Commands in Containers'
    - docker-basics-exec-command
    - |
      # Mastering docker exec: Interactive Container Access

      ## What is docker exec?
      `docker exec` runs a new command in an already running container. It's like SSH-ing into a server, but for containers - your primary tool for debugging, maintenance, and administrative tasks.

      ## Why It's Essential
      - **Debugging**: Inspect container internals without stopping it
      - **Maintenance**: Run scripts, update configs, check logs
      - **Database Operations**: Execute SQL queries, run migrations
      - **File Operations**: Copy files, edit configurations
      - **Process Inspection**: Check running processes, resource usage

      ## Basic Syntax
      ```bash
      docker exec [OPTIONS] CONTAINER COMMAND [ARG...]
      ```

      ## Prerequisites
      **Container MUST be running!**
      ```bash
      docker ps  # Verify container is running
      docker exec container_name command  # Then execute
      ```

      ## Common Use Cases

      ### 1. Open Interactive Shell
      ```bash
      docker exec -it my-container bash
      ```
      Most common use - gets you a shell inside the container.

      ### 2. Run Single Command
      ```bash
      docker exec my-container ls -la /app
      ```
      Execute one command and return results.

      ### 3. Run as Different User
      ```bash
      docker exec -u root my-container apt-get update
      ```
      Execute with elevated privileges.

      ### 4. Set Working Directory
      ```bash
      docker exec -w /app my-container npm test
      ```
      Run command from specific directory.

      ## Interactive vs Non-Interactive

      ### Interactive Mode (-it)
      ```bash
      docker exec -it web-server bash
      ```
      - **-i**: Keep STDIN open (interactive)
      - **-t**: Allocate pseudo-TTY (terminal)
      - Use for: shells, interactive programs
      - Exit: `exit` or Ctrl+D

      ### Non-Interactive (default)
      ```bash
      docker exec web-server cat /var/log/nginx/access.log
      ```
      - Runs command and returns output
      - Use for: automation, scripts, status checks
      - Exits automatically when command completes

      ## Common Shell Options

      **Try shells in this order** (Alpine containers often don't have bash):
      ```bash
      docker exec -it container bash   # Most common
      docker exec -it container sh     # Fallback for Alpine
      docker exec -it container ash    # Another Alpine option
      docker exec -it container /bin/bash  # Full path
      ```

      ## Real-World Examples

      ### Database Access
      ```bash
      # MySQL
      docker exec -it mysql-db mysql -u root -p

      # PostgreSQL
      docker exec -it postgres-db psql -U postgres

      # MongoDB
      docker exec -it mongo-db mongo
      ```

      ### File Operations
      ```bash
      # View file
      docker exec nginx cat /etc/nginx/nginx.conf

      # Check disk usage
      docker exec web-server df -h

      # Find files
      docker exec app find /app -name "*.log"
      ```

      ### Process Inspection
      ```bash
      # List processes
      docker exec web-server ps aux

      # Check memory
      docker exec app free -h

      # Network connections
      docker exec app netstat -tulpn
      ```

      ### Application Management
      ```bash
      # Run database migration
      docker exec rails-app rake db:migrate

      # Clear cache
      docker exec laravel-app php artisan cache:clear

      # Run tests
      docker exec node-app npm test
      ```

      ## Understanding -it Flags

      ```
      docker exec -it container bash
                   │ │
                   │ └─ -t: Allocate TTY (makes it look like terminal)
                   └─── -i: Keep STDIN open (allows typing)

      Together: Interactive terminal session
      ```

      ## Common Mistakes to Avoid

      1. **Container not running**: Check with `docker ps` first
      2. **Wrong shell**: Use `sh` instead of `bash` for Alpine
      3. **Forgetting -it**: For interactive sessions, always use both flags
      4. **Running as wrong user**: Use `-u` flag if permission denied
      5. **Assuming tools exist**: Not all images have the same utilities

      ## exec vs run

      | Aspect | docker exec | docker run |
      |--------|-------------|------------|
      | Target | Running container | New container |
      | Process | New process in existing container | Main container process |
      | Use case | Debug/maintain running container | Start new service |
      | Network | Uses container's existing network | Creates new network stack |

      ## Working with Different Environments

      ### Alpine-based Containers
      ```bash
      # Use sh instead of bash
      docker exec -it alpine-container sh

      # Install packages
      docker exec alpine-container apk add --no-cache curl
      ```

      ### Ubuntu/Debian-based
      ```bash
      docker exec -it ubuntu-container bash

      # Install packages
      docker exec ubuntu-container apt-get update
      docker exec ubuntu-container apt-get install -y vim
      ```

      ### Application Containers
      ```bash
      # Python
      docker exec -it python-app python

      # Node.js
      docker exec -it node-app node

      # Ruby
      docker exec -it rails-app rails console
      ```

      ## Advanced Patterns

      ### Execute Multiple Commands
      ```bash
      docker exec web-server sh -c "cd /app && npm install && npm start"
      ```

      ### Pipe Output
      ```bash
      docker exec database mysqldump -u root -p database_name > backup.sql
      ```

      ### Execute Script from Host
      ```bash
      docker exec -i container bash < script.sh
      ```

      ### Background Execution
      ```bash
      docker exec -d worker-container python long_running_task.py
      ```

      ## Security Considerations

      ```bash
      # Bad: Running as root unnecessarily
      docker exec -u root app rm -rf /

      # Good: Use appropriate user
      docker exec app npm install

      # Best: Container already configured with correct user
      docker run --user 1000:1000 app
      ```

      ## Troubleshooting with exec

      ### Check Why Container is Failing
      ```bash
      # Check logs
      docker exec app cat /var/log/application.log

      # Check processes
      docker exec app ps aux

      # Check connectivity
      docker exec app ping database-host

      # Check environment
      docker exec app env
      ```

      ### Network Debugging
      ```bash
      # Test connection
      docker exec app curl http://api-server:8080/health

      # Check DNS
      docker exec app nslookup api-server

      # Port scan
      docker exec app nc -zv database 3306
      ```

      ## Pro Tips

      1. **Create aliases**: `alias dexec='docker exec -it'`
      2. **Use container names**: More readable than IDs
      3. **Check shell availability**: `docker exec container which bash`
      4. **Install tools temporarily**: They persist until container restarts
      5. **Use -w for working directory**: Saves cd commands
      6. **Combine with docker ps**: `docker exec $(docker ps -q -f name=web) bash`

      ## When to Use docker exec

      - Debugging production issues
      - Running database migrations
      - Checking application status
      - Viewing logs in real-time
      - Executing administrative tasks
      - Testing network connectivity
      - Inspecting file systems
    - docker exec -it my-container bash
    - '["docker exec -it my-container sh","docker exec my-container ls -la","docker
      exec -u root my-container apt-get update","docker exec -w /app my-container
      npm test"]'
    - '["Open shell: docker exec -it \u003ccontainer\u003e bash","For Alpine: docker
      exec -it \u003ccontainer\u003e sh","Single command: docker exec \u003ccontainer\u003e
      \u003ccommand\u003e","As root: docker exec -u root \u003ccontainer\u003e \u003ccommand\u003e","Set
      directory: docker exec -w /app \u003ccontainer\u003e \u003ccommand\u003e"]'
    -
    - "[]"
    - easy
    - 10
    - 5
    - docker-basics
    - true
    - What does the -it flag combination do in "docker exec -it container bash"?
    - mcq
    - '[{"text":"Provides an interactive terminal session","correct":true},{"text":"Installs
      terminal tools","correct":false},{"text":"Increases timeout","correct":false},{"text":"Inspects
      terminal output","correct":false}]'
    - Provides an interactive terminal session
    - "-i keeps STDIN open for interaction, and -t allocates a pseudo-TTY. Together
      they create an interactive terminal session, like SSH into the container."
    -
    - '[{"title":"Interactive shell access","code":"docker exec -it web-server bash","explanation":"Opens
      interactive bash shell - most common debugging method"},{"title":"Alpine container
      shell","code":"docker exec -it alpine-app sh","explanation":"Alpine images use
      sh instead of bash - lighter weight"},{"title":"Execute single command","code":"docker
      exec database mysqldump -u root -p mydb \u003e backup.sql","explanation":"Run
      one command and exit - perfect for automation"},{"title":"Run as root user","code":"docker
      exec -u root app apt-get install -y curl","explanation":"Execute with elevated
      privileges for system operations"}]'
    - "[]"
    - "[]"
    - '2025-11-06 03:44:04.252734'
    - '2025-11-06 03:44:04.257876'
    - |
      **Production Debugging Crisis**

      Maria urgently messages you: "The production API container is returning errors but staying running. I need you to exec into the 'api-production' container and check the application logs at /var/log/app/error.log. Also, check if the database connection is working by pinging the database host. Quick!"
    - Access the running api-production container interactively to debug issues
    - '["containers","docker-exec","debugging","interactive","shell-access"]'
    - "[]"
  - - 6
    - 'Docker Logs: Viewing Container Output'
    - docker-basics-logs-command
    - |
      # Mastering docker logs: Container Output Investigation

      ## What is docker logs?
      `docker logs` displays the stdout and stderr output from a container. It's your primary tool for troubleshooting, monitoring, and understanding what's happening inside containers.

      ## Why Logs Matter
      - **Debugging**: Identify errors and exceptions
      - **Monitoring**: Track application behavior
      - **Auditing**: Review access and operations
      - **Performance**: Analyze response times
      - **Security**: Detect suspicious activity

      ## Basic Syntax
      ```bash
      docker logs [OPTIONS] CONTAINER
      ```

      ## Common Use Cases

      ### 1. View All Logs
      ```bash
      docker logs my-container
      ```

      ### 2. Follow Logs in Real-time
      ```bash
      docker logs -f my-container
      ```

      ### 3. Show Recent Logs
      ```bash
      docker logs --tail 100 my-container
      ```

      ### 4. Logs with Timestamps
      ```bash
      docker logs -t my-container
      ```
    - docker logs my-container
    - '["docker logs -f my-container","docker logs --tail 100 my-container","docker
      logs -t my-container","docker logs --since 1h my-container"]'
    - '["View all logs: docker logs \u003ccontainer\u003e","Follow live: docker logs
      -f \u003ccontainer\u003e","Last N lines: docker logs --tail 50 \u003ccontainer\u003e","With
      timestamps: docker logs -t \u003ccontainer\u003e","Since time: docker logs --since
      30m \u003ccontainer\u003e"]'
    -
    - "[]"
    - easy
    - 10
    - 6
    - docker-basics
    - true
    - Which flag makes docker logs follow new output in real-time?
    - mcq
    - '[{"text":"-f","correct":true},{"text":"-t","correct":false},{"text":"--tail","correct":false},{"text":"--follow-new","correct":false}]'
    - "-f"
    - The -f flag follows log output in real-time, similar to tail -f in Unix systems.
    -
    - '[{"title":"View all container logs","code":"docker logs nginx-server","explanation":"Shows
      complete stdout/stderr output since container started"},{"title":"Follow logs
      in real-time","code":"docker logs -f api-server","explanation":"Streams new
      log entries as they occur - great for monitoring"},{"title":"Show last 50 lines","code":"docker
      logs --tail 50 web-app","explanation":"Displays only recent logs - faster for
      large log files"},{"title":"Logs from last hour","code":"docker logs --since
      1h database","explanation":"Filter logs by time - useful for incident investigation"}]'
    - "[]"
    - "[]"
    - '2025-11-06 03:44:04.267743'
    - '2025-11-06 03:44:04.271746'
    - Application is crashing. Check the logs of 'api-server' to find the error.
    - View the last 100 lines of logs from api-server with timestamps
    - '["containers","docker-logs","debugging","monitoring","troubleshooting"]'
    - "[]"
  - - 7
    - 'Docker Inspect: Detailed Container Information'
    - docker-basics-inspect-command
    - View complete configuration details of containers and images in JSON format.
    - docker inspect my-container
    - '["docker inspect --format=\"{{.State.Status}}\" container","docker inspect
      container | jq"]'
    - '["Basic: docker inspect \u003ccontainer\u003e","Format output: --format=\"{{.NetworkSettings.IPAddress}}\""]'
    -
    - "[]"
    - medium
    - 10
    - 7
    - docker-basics
    - true
    - What format does docker inspect output by default?
    - mcq
    - '[{"text":"JSON","correct":true},{"text":"YAML","correct":false},{"text":"XML","correct":false},{"text":"Plain
      text","correct":false}]'
    - JSON
    - docker inspect outputs detailed information in JSON format by default.
    -
    - "[]"
    - "[]"
    - "[]"
    - '2025-11-06 03:44:04.281087'
    - '2025-11-06 03:44:04.281087'
    - Find the IP address and port mappings of the running database container
    - Use docker inspect to find network configuration details
    - '["containers","docker-inspect","configuration","debugging","metadata"]'
    - "[]"
  - - 8
    - 'Docker Version: Check Docker Installation'
    - docker-basics-version-command
    - Display Docker version information for client and server components.
    - docker version
    - '["docker version --format json","docker --version"]'
    - '["Check version: docker version","Short form: docker --version"]'
    -
    - "[]"
    - easy
    - 10
    - 8
    - docker-basics
    - true
    - What does docker version show?
    - mcq
    - '[{"text":"Both client and server versions","correct":true},{"text":"Only client
      version","correct":false},{"text":"Only server version","correct":false},{"text":"Container
      versions","correct":false}]'
    - Both client and server versions
    - docker version displays version information for both the Docker client and Docker
      daemon (server).
    -
    - "[]"
    - "[]"
    - "[]"
    - '2025-11-06 03:44:04.290909'
    - '2025-11-06 03:44:04.290909'
    - Verify Docker installation and check if client can communicate with daemon
    - Display Docker client and server version information
    - '["docker-version","installation","system-info","diagnostics"]'
    - "[]"
  - - 9
    - 'Docker Info: System-Wide Information'
    - docker-basics-info-command
    - Display comprehensive system-wide information about Docker installation, including
      storage driver, kernel version, and resource usage.
    - docker info
    - '["docker info --format json","docker info | grep -i storage"]'
    - '["Full info: docker info","Find storage driver: docker info | grep Storage"]'
    -
    - "[]"
    - easy
    - 10
    - 9
    - docker-basics
    - true
    - What type of information does docker info provide?
    - mcq
    - '[{"text":"System-wide Docker configuration and statistics","correct":true},{"text":"Individual
      container information","correct":false},{"text":"Image layer details","correct":false},{"text":"Network
      configuration only","correct":false}]'
    - System-wide Docker configuration and statistics
    - docker info shows system-wide information including containers, images, storage
      driver, and daemon configuration.
    -
    - "[]"
    - "[]"
    - "[]"
    - '2025-11-06 03:44:04.300472'
    - '2025-11-06 03:44:04.300472'
    - Check Docker system health and available resources before deploying new containers
    - Display Docker daemon configuration and system resources
    - '["docker-info","system-info","diagnostics","monitoring","configuration"]'
    - "[]"
  - - 10
    - 'Docker Help: Getting Command Assistance'
    - docker-basics-help-command
    - Access built-in documentation for Docker commands and options.
    - docker help
    - '["docker run --help","docker help run","docker \u003ccommand\u003e --help"]'
    - '["General help: docker help","Command help: docker run --help","List commands:
      docker --help"]'
    -
    - "[]"
    - easy
    - 10
    - 10
    - docker-basics
    - true
    - How do you get help for a specific Docker command?
    - mcq
    - '[{"text":"docker \u003ccommand\u003e --help","correct":true},{"text":"docker
      man \u003ccommand\u003e","correct":false},{"text":"docker info \u003ccommand\u003e","correct":false},{"text":"help
      docker \u003ccommand\u003e","correct":false}]'
    - docker <command> --help
    - Use docker <command> --help to get detailed help for any specific Docker command.
    -
    - "[]"
    - "[]"
    - "[]"
    - '2025-11-06 03:44:04.309455'
    - '2025-11-06 03:44:04.309455'
    - Learn about available Docker commands and their options using built-in help
    - Use help to find available flags for docker run command
    - '["docker-help","documentation","learning","cli"]'
    - "[]"
  - - 11
    - 'Docker Start: Restart Stopped Containers'
    - docker-basics-start-command
    - Start one or more stopped containers, preserving their state and configuration.
    - docker start my-container
    - '["docker start -a container","docker start -i container"]'
    - '["Start container: docker start \u003cname\u003e","Start and attach: docker
      start -a \u003cname\u003e"]'
    -
    - "[]"
    - easy
    - 10
    - 11
    - docker-basics
    - true
    - What happens to container data when you docker start a stopped container?
    - mcq
    - '[{"text":"Data is preserved from when it was stopped","correct":true},{"text":"Container
      starts fresh with no data","correct":false},{"text":"Data is restored from image","correct":false},{"text":"Data
      is lost permanently","correct":false}]'
    - Data is preserved from when it was stopped
    - docker start restarts a stopped container with all its data and state preserved.
    -
    - "[]"
    - "[]"
    - "[]"
    - '2025-11-06 03:44:04.318382'
    - '2025-11-06 03:44:04.318382'
    - Restart the stopped database container to restore service
    - Start a previously stopped container
    - '["containers","docker-start","lifecycle","restart"]'
    - "[]"
  - - 12
    - 'Docker Restart: Stop and Start Containers'
    - docker-basics-restart-command
    - Restart one or more containers by stopping and starting them.
    - docker restart my-container
    - '["docker restart -t 30 container"]'
    - '["Restart: docker restart \u003cname\u003e","With timeout: docker restart -t
      30 \u003cname\u003e"]'
    -
    - "[]"
    - easy
    - 10
    - 12
    - docker-basics
    - true
    - What does docker restart do?
    - mcq
    - '[{"text":"Stops then starts the container","correct":true},{"text":"Only stops
      the container","correct":false},{"text":"Creates a new container","correct":false},{"text":"Removes
      and recreates container","correct":false}]'
    - Stops then starts the container
    - docker restart is equivalent to running docker stop followed by docker start.
    -
    - "[]"
    - "[]"
    - "[]"
    - '2025-11-06 03:44:04.327557'
    - '2025-11-06 03:44:04.327557'
    - Application is misbehaving, restart it to clear memory leaks
    - Restart a container to resolve temporary issues
    - '["containers","docker-restart","lifecycle","maintenance"]'
    - "[]"
  - - 13
    - 'Docker Pause: Freeze Container Execution'
    - docker-basics-pause-command
    - Suspend all processes in a container using cgroup freezer.
    - docker pause my-container
    - "[]"
    - '["Pause: docker pause \u003cname\u003e","Check status: docker ps (shows \"Paused\")"]'
    -
    - "[]"
    - medium
    - 10
    - 13
    - docker-basics
    - true
    - What happens when you pause a container?
    - mcq
    - '[{"text":"All processes are frozen in place","correct":true},{"text":"Container
      is stopped completely","correct":false},{"text":"Container is removed","correct":false},{"text":"Only
      network is disabled","correct":false}]'
    - All processes are frozen in place
    - docker pause uses cgroups to freeze all processes in the container without stopping
      it.
    -
    - "[]"
    - "[]"
    - "[]"
    - '2025-11-06 03:44:04.336088'
    - '2025-11-06 03:44:04.336088'
    - Temporarily freeze a container during maintenance without stopping it
    - Pause a running container to prevent it from processing requests
    - '["containers","docker-pause","lifecycle","advanced"]'
    - "[]"
  - - 14
    - 'Docker Unpause: Resume Frozen Containers'
    - docker-basics-unpause-command
    - Resume all processes in a paused container.
    - docker unpause my-container
    - "[]"
    - '["Unpause: docker unpause \u003cname\u003e","Resumes from exact point where
      paused"]'
    -
    - "[]"
    - medium
    - 10
    - 14
    - docker-basics
    - true
    - What is the relationship between pause and unpause?
    - mcq
    - '[{"text":"unpause reverses pause, resuming execution","correct":true},{"text":"unpause
      starts a new container","correct":false},{"text":"unpause removes the container","correct":false},{"text":"They
      are unrelated commands","correct":false}]'
    - unpause reverses pause, resuming execution
    - docker unpause resumes a paused container from exactly where it was frozen.
    -
    - "[]"
    - "[]"
    - "[]"
    - '2025-11-06 03:44:04.345965'
    - '2025-11-06 03:44:04.345965'
    - Resume the paused container after maintenance is complete
    - Unpause a container to resume normal operations
    - '["containers","docker-unpause","lifecycle","advanced"]'
    - "[]"
  - - 15
    - 'Docker Attach: Connect to Running Container'
    - docker-basics-attach-command
    - Attach local standard input, output, and error streams to a running container.
    - docker attach my-container
    - '["docker attach --sig-proxy=false container"]'
    - '["Attach: docker attach \u003cname\u003e","Detach: Ctrl+P then Ctrl+Q","Exit
      kills container: Ctrl+C"]'
    -
    - "[]"
    - medium
    - 10
    - 15
    - docker-basics
    - true
    - What is the key difference between attach and exec?
    - mcq
    - '[{"text":"attach connects to main process, exec starts new process","correct":true},{"text":"attach
      creates new shell, exec connects to existing","correct":false},{"text":"They
      are exactly the same","correct":false},{"text":"attach is for stopped containers","correct":false}]'
    - attach connects to main process, exec starts new process
    - docker attach connects to the container's main process (PID 1), while exec starts
      a new process.
    -
    - "[]"
    - "[]"
    - "[]"
    - '2025-11-06 03:44:04.355922'
    - '2025-11-06 03:44:04.355922'
    - Attach to a foreground container to view its live output
    - Connect to a running container to see its stdout in real-time
    - '["containers","docker-attach","debugging","interactive"]'
    - "[]"
  - - 16
    - 'Docker Wait: Block Until Container Stops'
    - docker-basics-wait-command
    - Block until one or more containers stop, then print their exit codes.
    - docker wait my-container
    - '["docker wait container1 container2"]'
    - '["Wait for stop: docker wait \u003cname\u003e","Returns exit code","Useful
      in scripts"]'
    -
    - "[]"
    - medium
    - 10
    - 16
    - docker-basics
    - true
    - What does docker wait return?
    - mcq
    - '[{"text":"Exit code of the container","correct":true},{"text":"Container ID","correct":false},{"text":"Container
      logs","correct":false},{"text":"Time container ran","correct":false}]'
    - Exit code of the container
    - docker wait blocks until the container stops and then returns its exit code
      (0 for success, non-zero for errors).
    -
    - "[]"
    - "[]"
    - "[]"
    - '2025-11-06 03:44:04.364806'
    - '2025-11-06 03:44:04.364806'
    - Wait for a batch job container to finish before proceeding with next step
    - Block script execution until container completes and get its exit code
    - '["containers","docker-wait","scripting","automation","exit-codes"]'
    - "[]"
  - - 17
    - 'Docker Container Prune: Batch Container Cleanup'
    - docker-containers-prune-command
    - |
      # Mastering docker container prune: Efficient Container Cleanup

      ## What is docker container prune?
      `docker container prune` removes all stopped containers in a single command. It's the modern, efficient way to clean up your Docker environment without manually removing containers one by one.

      ## Why Batch Cleanup Matters
      - **Efficiency**: Clean dozens of containers with one command
      - **Disk Space**: Reclaim significant storage quickly
      - **Automation**: Perfect for CI/CD cleanup scripts
      - **Safety**: Only removes stopped containers (running ones are protected)

      ## Common Use Cases

      ### Remove All Stopped Containers
      ```bash
      docker container prune -f
      ```

      ### Filter by Time
      ```bash
      docker container prune --filter "until=24h"
      ```

      ### Safety Features
      The command prompts for confirmation unless you use `-f` flag.

      ## Best Practices
      1. Schedule regular cleanup via cron
      2. Use filters wisely
      3. Label containers for selective cleanup
      4. Test in dev first
    - docker container prune
    - '["docker container prune -f","docker container prune --filter \"until=24h\"","docker
      container prune --filter \"label=env=test\""]'
    - '["Basic prune: docker container prune (with confirmation)","Force prune: docker
      container prune -f","Age filter: docker container prune --filter \"until=24h\""]'
    -
    - "[]"
    - easy
    - 10
    - 17
    - docker-containers
    - true
    - What does docker container prune remove by default?
    - mcq
    - '[{"text":"All stopped containers","correct":true},{"text":"All containers including
      running ones","correct":false},{"text":"All containers and images","correct":false},{"text":"Only
      containers older than 24 hours","correct":false}]'
    - All stopped containers
    - docker container prune removes all stopped containers (exited or created state).
      Running and paused containers are never removed.
    -
    - '[{"title":"Interactive cleanup with confirmation","code":"docker container
      prune","explanation":"Prompts for confirmation before removing all stopped containers"},{"title":"Automated
      cleanup without prompt","code":"docker container prune -f","explanation":"Skips
      confirmation - perfect for scripts and cron jobs"},{"title":"Remove containers
      older than 24 hours","code":"docker container prune --filter \"until=24h\" -f","explanation":"Time-based
      cleanup - keeps recently stopped containers"},{"title":"Clean only test environment
      containers","code":"docker container prune --filter \"label=env=test\" -f","explanation":"Label-based
      cleanup - surgical removal of specific groups"}]'
    - "[]"
    - "[]"
    - '2025-11-06 03:44:04.381305'
    - '2025-11-06 03:44:04.385556'
    - 'Weekly cleanup: Remove all stopped containers older than 48 hours'
    - Remove all stopped containers older than 48 hours without confirmation prompts
    - '["containers","cleanup","docker-prune","maintenance","disk-space"]'
    - "[]"
  - - 18
    - 'Docker CP: Copy Files Between Container and Host'
    - docker-containers-cp-command
    - Copy files and directories bidirectionally between containers and host filesystem,
      even while containers are running.
    - docker cp my-file.txt my-container:/app/
    - '["docker cp host-file.txt container:/path/","docker cp container:/path/file.txt
      ./local/","docker cp ./directory container:/backup/"]'
    - '["Host to container: docker cp /local/file container:/remote/","Container to
      host: docker cp container:/remote/file /local/"]'
    -
    - "[]"
    - medium
    - 10
    - 18
    - docker-containers
    - true
    - Can you use docker cp on a stopped container?
    - mcq
    - '[{"text":"Yes, docker cp works on both running and stopped containers","correct":true},{"text":"No,
      container must be running","correct":false},{"text":"Only for copying FROM container","correct":false},{"text":"Only
      with the --force flag","correct":false}]'
    - Yes, docker cp works on both running and stopped containers
    - docker cp works on containers in any state - useful for data recovery and backup.
    -
    - '[{"title":"Copy file from host to container","code":"docker cp ./config.yml
      web:/etc/app/","explanation":"Deploy configuration without restart"},{"title":"Extract
      log file from container","code":"docker cp app:/var/log/app.log ./logs/","explanation":"Retrieve
      logs for analysis"}]'
    - "[]"
    - "[]"
    - '2025-11-06 03:44:04.395319'
    - '2025-11-06 03:44:04.399941'
    - 'Emergency config update: Copy updated nginx.conf to production without restart'
    - Copy configuration file from host to running container
    - '["containers","docker-cp","file-transfer","deployment","backup"]'
    - "[]"
  - - 19
    - 'Docker Diff: Inspect Container Filesystem Changes'
    - docker-containers-diff-command
    - Show which files and directories have been modified, added, or deleted in a
      container compared to its base image.
    - docker diff my-container
    - '["docker diff container","docker diff container | grep \"^A\"","docker diff
      container | grep /etc"]'
    - '["See all changes: docker diff \u003ccontainer\u003e","Only added files: docker
      diff \u003ccontainer\u003e | grep \"^A\"","Only modified: docker diff \u003ccontainer\u003e
      | grep \"^C\""]'
    -
    - "[]"
    - medium
    - 10
    - 19
    - docker-containers
    - true
    - In docker diff output, what does the "C" prefix indicate?
    - mcq
    - '[{"text":"Changed (modified) file or directory","correct":true},{"text":"Created
      file","correct":false},{"text":"Copied file","correct":false},{"text":"Container
      file","correct":false}]'
    - Changed (modified) file or directory
    - 'In docker diff: "C" = changed/modified, "A" = added, "D" = deleted.'
    -
    - '[{"title":"View all filesystem changes","code":"docker diff web-server","explanation":"Shows
      all files added, modified, or deleted"},{"title":"Find newly added files","code":"docker
      diff app | grep \"^A\"","explanation":"Lists only added files"}]'
    - "[]"
    - "[]"
    - '2025-11-06 03:44:04.409888'
    - '2025-11-06 03:44:04.414328'
    - 'Security audit: Identify all filesystem changes to detect breaches'
    - Use docker diff to identify filesystem changes for security investigation
    - '["containers","docker-diff","filesystem","debugging","security"]'
    - "[]"
  - - 20
    - 'Docker Export: Export Container Filesystem as Archive'
    - docker-containers-export-command
    - Create a tarball archive of a container's entire filesystem for backup, migration,
      or forensic analysis.
    - docker export my-container > backup.tar
    - '["docker export -o backup.tar my-container","docker export my-container | gzip
      \u003e backup.tar.gz","cat backup.tar | docker import - my-image:tag"]'
    - '["Basic export: docker export container \u003e file.tar","Compressed: docker
      export container | gzip \u003e file.tar.gz","Import back: cat file.tar | docker
      import - image:tag"]'
    -
    - "[]"
    - medium
    - 10
    - 20
    - docker-containers
    - true
    - What is the main difference between docker export and docker save?
    - mcq
    - '[{"text":"export creates archive of container filesystem, save preserves image
      layers","correct":true},{"text":"export is for images, save is for containers","correct":false},{"text":"export
      includes metadata, save does not","correct":false},{"text":"They are exactly
      the same","correct":false}]'
    - export creates archive of container filesystem, save preserves image layers
    - docker export creates flat tarball of container (loses layers), docker save
      preserves image with all layers.
    -
    - '[{"title":"Export container to tar file","code":"docker export web-server \u003e
      backup.tar","explanation":"Creates complete filesystem archive"},{"title":"Export
      with compression","code":"docker export database | gzip \u003e backup.tar.gz","explanation":"Compresses
      output to save disk space"}]'
    - "[]"
    - "[]"
    - '2025-11-06 03:44:04.422359'
    - '2025-11-06 03:44:04.426088'
    - 'Pre-migration backup: Export production containers as safety net'
    - Export production containers as compressed backups
    - '["containers","docker-export","backup","migration","archival"]'
    - "[]"
  - - 21
    - 'Docker Stats: Live Resource Usage Statistics'
    - docker-containers-stats-command
    - Display live resource usage statistics including CPU, memory, network I/O, and
      disk I/O for running containers.
    - docker stats
    - '["docker stats --no-stream","docker stats web-server database","docker stats
      --format \"{{.Name}}: {{.CPUPerc}}\""]'
    - '["Live stats: docker stats","One-shot: docker stats --no-stream","Specific
      containers: docker stats web db"]'
    -
    - "[]"
    - easy
    - 10
    - 21
    - docker-containers
    - true
    - What does a CPU percentage of 200% mean in docker stats?
    - mcq
    - '[{"text":"Container is using 2 full CPU cores","correct":true},{"text":"Container
      is overloaded by 100%","correct":false},{"text":"There is an error in measurement","correct":false},{"text":"CPU
      limit has been exceeded","correct":false}]'
    - Container is using 2 full CPU cores
    - CPU percentages can exceed 100% on multi-core systems. 100% = 1 core, 200% =
      2 cores.
    -
    - '[{"title":"Monitor all running containers","code":"docker stats","explanation":"Live-updating
      display of resource usage - press Ctrl+C to exit"},{"title":"One-time snapshot","code":"docker
      stats --no-stream","explanation":"Shows current stats once and exits - perfect
      for scripts"}]'
    - "[]"
    - "[]"
    - '2025-11-06 03:44:04.434448'
    - '2025-11-06 03:44:04.438174'
    - 'Performance investigation: Identify which container is the bottleneck'
    - Monitor container resource usage to identify performance bottlenecks
    - '["containers","docker-stats","monitoring","performance","resources"]'
    - "[]"
  - - 22
    - 'Docker Top: Display Running Processes in Container'
    - docker-containers-top-command
    - Display running processes inside a container, similar to the Unix top command
      but for containerized processes.
    - docker top my-container
    - '["docker top container","docker top container aux"]'
    - '["View processes: docker top \u003ccontainer\u003e","With ps options: docker
      top \u003ccontainer\u003e aux"]'
    -
    - "[]"
    - easy
    - 10
    - 22
    - docker-containers
    - true
    - What does docker top display?
    - mcq
    - '[{"text":"Running processes inside the container","correct":true},{"text":"Top
      resource-consuming containers","correct":false},{"text":"Container configuration","correct":false},{"text":"Container
      logs","correct":false}]'
    - Running processes inside the container
    - docker top shows the running processes inside a specific container.
    -
    - '[{"title":"View container processes","code":"docker top web-server","explanation":"Shows
      all processes running inside container"},{"title":"Detailed process info","code":"docker
      top database aux","explanation":"Uses ps aux format for detailed information"}]'
    - "[]"
    - "[]"
    - '2025-11-06 03:44:04.446149'
    - '2025-11-06 03:44:04.450171'
    - Debug why container is slow by examining running processes
    - List all processes running in a container to identify resource hogs
    - '["containers","docker-top","processes","monitoring","debugging"]'
    - "[]"
  - - 23
    - 'Docker Update: Update Container Configuration'
    - docker-containers-update-command
    - Update resource limits and restart policies of running containers without stopping
      them.
    - docker update --memory="1g" my-container
    - '["docker update --cpus=\"2\" container","docker update --restart=always container","docker
      update --memory=\"512m\" --cpus=\"1.5\" container"]'
    - '["Update memory: docker update --memory=\"1g\" \u003ccontainer\u003e","Update
      CPUs: docker update --cpus=\"2\" \u003ccontainer\u003e","Update restart policy:
      docker update --restart=always \u003ccontainer\u003e"]'
    -
    - "[]"
    - medium
    - 10
    - 23
    - docker-containers
    - true
    - What can you update with docker update command?
    - mcq
    - '[{"text":"Resource limits and restart policies","correct":true},{"text":"Container
      image","correct":false},{"text":"Container name","correct":false},{"text":"Environment
      variables","correct":false}]'
    - Resource limits and restart policies
    - docker update can modify resource limits (CPU, memory) and restart policies
      of running containers.
    -
    - '[{"title":"Increase memory limit","code":"docker update --memory=\"2g\" database","explanation":"Updates
      memory limit without stopping container"},{"title":"Change restart policy","code":"docker
      update --restart=unless-stopped web-server","explanation":"Sets container to
      restart automatically"}]'
    - "[]"
    - "[]"
    - '2025-11-06 03:44:04.458394'
    - '2025-11-06 03:44:04.464339'
    - Increase memory limit for database without downtime
    - Update container resource limits without stopping it
    - '["containers","docker-update","resources","configuration","runtime"]'
    - "[]"
  - - 24
    - 'Docker Port: List Port Mappings'
    - docker-containers-port-command
    - Display port mappings for a container showing how container ports are exposed
      on the host.
    - docker port my-container
    - '["docker port container","docker port container 80"]'
    - '["All mappings: docker port \u003ccontainer\u003e","Specific port: docker port
      \u003ccontainer\u003e 80"]'
    -
    - "[]"
    - easy
    - 10
    - 24
    - docker-containers
    - true
    - What information does docker port provide?
    - mcq
    - '[{"text":"Port mappings between container and host","correct":true},{"text":"Open
      ports in container","correct":false},{"text":"Network configuration","correct":false},{"text":"Firewall
      rules","correct":false}]'
    - Port mappings between container and host
    - docker port shows which host ports are mapped to container ports.
    -
    - '[{"title":"View all port mappings","code":"docker port web-server","explanation":"Shows
      all ports mapped from container to host"},{"title":"Check specific port","code":"docker
      port nginx 80","explanation":"Shows which host port maps to container port 80"}]'
    - "[]"
    - "[]"
    - '2025-11-06 03:44:04.473409'
    - '2025-11-06 03:44:04.477452'
    - Find which host port maps to container port 80 for nginx
    - Identify port mappings to access containerized service
    - '["containers","docker-port","networking","port-mapping","configuration"]'
    - "[]"
  - - 25
    - 'Docker Rename: Rename a Container'
    - docker-containers-rename-command
    - Change the name of a container to something more meaningful or to resolve naming
      conflicts.
    - docker rename old-name new-name
    - '["docker rename container-name new-name"]'
    - '["Rename: docker rename \u003cold-name\u003e \u003cnew-name\u003e","Works on
      running or stopped containers"]'
    -
    - "[]"
    - easy
    - 10
    - 25
    - docker-containers
    - true
    - Can you rename a running container?
    - mcq
    - '[{"text":"Yes, containers can be renamed while running","correct":true},{"text":"No,
      must stop first","correct":false},{"text":"Only if no connections exist","correct":false},{"text":"Only
      with --force flag","correct":false}]'
    - Yes, containers can be renamed while running
    - docker rename works on both running and stopped containers without affecting
      their operation.
    -
    - '[{"title":"Rename container","code":"docker rename quirky_pascal production-api","explanation":"Changes
      auto-generated name to meaningful one"},{"title":"Fix naming conflict","code":"docker
      rename old-web web-backup","explanation":"Frees up name for new container"}]'
    - "[]"
    - "[]"
    - '2025-11-06 03:44:04.485277'
    - '2025-11-06 03:44:04.489409'
    - Rename randomly-named container to meaningful production name
    - Rename container for better identification and management
    - '["containers","docker-rename","management","naming","organization"]'
    - "[]"
  - - 26
    - 'Docker Container LS: List Containers'
    - docker-containers-ls-command
    - List containers with various filters - modern alternative to docker ps command.
    - docker container ls
    - '["docker container ls -a","docker container ls --filter \"status=running\"","docker
      container ls -q"]'
    - '["List running: docker container ls","List all: docker container ls -a","Filter
      by status: docker container ls --filter \"status=exited\""]'
    -
    - "[]"
    - easy
    - 10
    - 26
    - docker-containers
    - true
    - What is the difference between "docker container ls" and "docker ps"?
    - mcq
    - '[{"text":"They are equivalent commands with same functionality","correct":true},{"text":"ls
      shows more details","correct":false},{"text":"ps is for running only","correct":false},{"text":"ls
      is deprecated","correct":false}]'
    - They are equivalent commands with same functionality
    - docker container ls is the modern form, docker ps is legacy shorthand - both
      work identically.
    -
    - '[{"title":"List running containers","code":"docker container ls","explanation":"Shows
      currently running containers"},{"title":"List all containers","code":"docker
      container ls -a","explanation":"Includes stopped containers"}]'
    - "[]"
    - "[]"
    - '2025-11-06 03:44:04.498042'
    - '2025-11-06 03:44:04.502823'
    - Inventory all containers on system including stopped ones
    - List all containers and filter by specific criteria
    - '["containers","docker-ls","listing","inspection","management"]'
    - "[]"
  - - 27
    - 'Docker Container Create: Create Container Without Starting'
    - docker-containers-create-command
    - Create a container from an image without starting it - useful for configuration
      before launch.
    - docker container create --name my-app nginx
    - '["docker container create -p 8080:80 nginx","docker container create --name
      app -e KEY=value image"]'
    - '["Create: docker container create \u003cimage\u003e","With name: docker container
      create --name \u003cname\u003e \u003cimage\u003e","Start later: docker container
      start \u003cname\u003e"]'
    -
    - "[]"
    - medium
    - 10
    - 27
    - docker-containers
    - true
    - What is the difference between docker create and docker run?
    - mcq
    - '[{"text":"create makes container but doesn''t start it, run creates and starts","correct":true},{"text":"create
      is faster","correct":false},{"text":"run doesn''t save the container","correct":false},{"text":"They
      are identical","correct":false}]'
    - create makes container but doesn't start it, run creates and starts
    - docker create prepares container without starting, docker run = create + start
      in one command.
    -
    - '[{"title":"Create container","code":"docker container create --name web nginx","explanation":"Creates
      container in stopped state"},{"title":"Create with ports","code":"docker container
      create -p 8080:80 nginx","explanation":"Pre-configures port mapping before start"}]'
    - "[]"
    - "[]"
    - '2025-11-06 03:44:04.511202'
    - '2025-11-06 03:44:04.514901'
    - Pre-configure container before starting it in production
    - Create container with specific configuration without starting it
    - '["containers","docker-create","lifecycle","initialization","configuration"]'
    - "[]"
  - - 28
    - 'Docker Container Start: Start Stopped Containers'
    - docker-containers-start-command
    - Start one or more stopped containers, preserving their state and configuration.
    - docker container start my-container
    - '["docker container start -a container"]'
    - '["Start: docker container start \u003cname\u003e"]'
    -
    - "[]"
    - easy
    - 10
    - 28
    - docker-containers
    - true
    - What happens to container data when you start a stopped container?
    - mcq
    - '[{"text":"Data is preserved from when it was stopped","correct":true},{"text":"Container
      starts fresh","correct":false}]'
    - Data is preserved from when it was stopped
    - docker start restarts container with all data and state preserved.
    -
    - '[{"title":"Start container","code":"docker container start web","explanation":"Restarts
      stopped container"}]'
    - "[]"
    - "[]"
    - '2025-11-06 03:44:04.522889'
    - '2025-11-06 03:44:04.526515'
    - Restart stopped database to restore service
    - Start previously stopped container
    - '["containers","docker-start","lifecycle"]'
    - "[]"
  - - 29
    - 'Docker Container Stop: Gracefully Stop Containers'
    - docker-containers-stop-command
    - Gracefully stop running containers by sending SIGTERM, then SIGKILL if needed.
    - docker container stop my-container
    - '["docker container stop -t 30 container"]'
    - '["Stop: docker container stop \u003cname\u003e","Timeout: docker container
      stop -t 30 \u003cname\u003e"]'
    -
    - "[]"
    - easy
    - 10
    - 29
    - docker-containers
    - true
    - What signal does docker stop send first?
    - mcq
    - '[{"text":"SIGTERM","correct":true},{"text":"SIGKILL","correct":false}]'
    - SIGTERM
    - docker stop sends SIGTERM first for graceful shutdown, then SIGKILL if timeout
      exceeded.
    -
    - '[{"title":"Stop container","code":"docker container stop web","explanation":"Graceful
      shutdown with 10s timeout"}]'
    - "[]"
    - "[]"
    - '2025-11-06 03:44:04.533961'
    - '2025-11-06 03:44:04.538341'
    - Stop API server gracefully with 30-second timeout
    - Stop container gracefully allowing proper cleanup
    - '["containers","docker-stop","lifecycle","signals"]'
    - "[]"
  - - 30
    - 'Docker Container Restart: Stop and Start Containers'
    - docker-containers-restart-command
    - Restart containers by stopping and starting them - equivalent to stop + start.
    - docker container restart my-container
    - '["docker container restart -t 30 container"]'
    - '["Restart: docker container restart \u003cname\u003e"]'
    -
    - "[]"
    - easy
    - 10
    - 30
    - docker-containers
    - true
    - What does docker restart do?
    - mcq
    - '[{"text":"Stops then starts the container","correct":true},{"text":"Only stops","correct":false}]'
    - Stops then starts the container
    - docker restart = docker stop + docker start in one command.
    -
    - '[{"title":"Restart container","code":"docker container restart api","explanation":"Stop
      and start in one command"}]'
    - "[]"
    - "[]"
    - '2025-11-06 03:44:04.545729'
    - '2025-11-06 03:44:04.549293'
    - Restart misbehaving application to clear memory leaks
    - Restart container to resolve temporary issues
    - '["containers","docker-restart","lifecycle"]'
    - "[]"
  - - 31
    - 'Docker Container Kill: Forcefully Stop Containers'
    - docker-containers-kill-command
    - Immediately kill container by sending SIGKILL - use when docker stop fails.
    - docker container kill my-container
    - '["docker container kill -s SIGTERM container"]'
    - '["Kill: docker container kill \u003cname\u003e","Custom signal: docker container
      kill -s SIGTERM \u003cname\u003e"]'
    -
    - "[]"
    - medium
    - 10
    - 31
    - docker-containers
    - true
    - When should you use docker kill instead of docker stop?
    - mcq
    - '[{"text":"When container is hung and won''t respond to stop","correct":true},{"text":"Always","correct":false}]'
    - When container is hung and won't respond to stop
    - Use docker stop first for graceful shutdown. Use kill only when container is
      unresponsive.
    -
    - '[{"title":"Force kill","code":"docker container kill hung-app","explanation":"Immediately
      stops unresponsive container"}]'
    - "[]"
    - "[]"
    - '2025-11-06 03:44:04.556919'
    - '2025-11-06 03:44:04.560653'
    - Force-kill hung container that won't respond to stop
    - Forcefully terminate unresponsive container
    - '["containers","docker-kill","lifecycle","emergency"]'
    - "[]"
  - - 32
    - 'Docker Container RM: Remove Containers'
    - docker-containers-rm-command
    - Permanently delete stopped containers to free disk space and names.
    - docker container rm my-container
    - '["docker container rm -f container","docker container rm -v container"]'
    - '["Remove: docker container rm \u003cname\u003e","Force: docker container rm
      -f \u003cname\u003e"]'
    -
    - "[]"
    - easy
    - 10
    - 32
    - docker-containers
    - true
    - Can you remove a running container without -f flag?
    - mcq
    - '[{"text":"No, must stop first or use -f","correct":true},{"text":"Yes","correct":false}]'
    - No, must stop first or use -f
    - Docker requires containers to be stopped before removal, unless using -f to
      force.
    -
    - '[{"title":"Remove container","code":"docker container rm old-test","explanation":"Deletes
      stopped container"}]'
    - "[]"
    - "[]"
    - '2025-11-06 03:44:04.568637'
    - '2025-11-06 03:44:04.572906'
    - Clean up old test containers to free disk space
    - Remove stopped containers including their volumes
    - '["containers","docker-rm","cleanup","lifecycle"]'
    - "[]"
  - - 33
    - 'Docker Container Inspect: Detailed Container Information'
    - docker-containers-inspect-command
    - View complete container configuration and state in JSON format.
    - docker container inspect my-container
    - '["docker container inspect --format=\"{{.State.Status}}\" container"]'
    - '["Inspect: docker container inspect \u003cname\u003e","Format: --format=\"{{.NetworkSettings.IPAddress}}\""]'
    -
    - "[]"
    - medium
    - 10
    - 33
    - docker-containers
    - true
    - What format does docker inspect output?
    - mcq
    - '[{"text":"JSON","correct":true},{"text":"YAML","correct":false}]'
    - JSON
    - docker inspect outputs detailed information in JSON format.
    -
    - '[{"title":"Inspect container","code":"docker container inspect web","explanation":"Shows
      complete configuration as JSON"}]'
    - "[]"
    - "[]"
    - '2025-11-06 03:44:04.580834'
    - '2025-11-06 03:44:04.584706'
    - Find IP address and network configuration of container
    - Extract specific configuration details using inspect
    - '["containers","docker-inspect","configuration","debugging"]'
    - "[]"
  - - 34
    - 'Docker Container Logs: View Container Output'
    - docker-containers-logs-command
    - Display stdout and stderr output from containers for debugging and monitoring.
    - docker container logs my-container
    - '["docker container logs -f container","docker container logs --tail 100 container"]'
    - '["View logs: docker container logs \u003cname\u003e","Follow: docker container
      logs -f \u003cname\u003e"]'
    -
    - "[]"
    - easy
    - 10
    - 34
    - docker-containers
    - true
    - Which flag makes docker logs follow new output?
    - mcq
    - '[{"text":"-f","correct":true},{"text":"-t","correct":false}]'
    - "-f"
    - The -f flag follows log output in real-time, like tail -f.
    -
    - '[{"title":"View logs","code":"docker container logs api","explanation":"Shows
      all container output"}]'
    - "[]"
    - "[]"
    - '2025-11-06 03:44:04.592637'
    - '2025-11-06 03:44:04.596780'
    - Debug application crash by examining container logs
    - View and follow container logs to identify errors
    - '["containers","docker-logs","debugging","monitoring"]'
    - "[]"
  - - 35
    - 'Docker Container Exec: Run Commands in Container'
    - docker-containers-exec-command
    - Execute commands inside running containers for debugging and maintenance.
    - docker container exec -it my-container bash
    - '["docker container exec container ls -la","docker container exec -u root container
      apt-get update"]'
    - '["Shell: docker container exec -it \u003cname\u003e bash","Command: docker
      container exec \u003cname\u003e \u003ccommand\u003e"]'
    -
    - "[]"
    - easy
    - 10
    - 35
    - docker-containers
    - true
    - What does -it flag do in docker exec?
    - mcq
    - '[{"text":"Provides interactive terminal","correct":true},{"text":"Installs
      tools","correct":false}]'
    - Provides interactive terminal
    - "-i keeps STDIN open, -t allocates TTY - together they create interactive terminal."
    -
    - '[{"title":"Interactive shell","code":"docker container exec -it web bash","explanation":"Opens
      bash shell in container"}]'
    - "[]"
    - "[]"
    - '2025-11-06 03:44:04.605158'
    - '2025-11-06 03:44:04.609036'
    - Access production container to debug live issues
    - Execute commands in running container for troubleshooting
    - '["containers","docker-exec","debugging","interactive"]'
    - "[]"
  - - 36
    - 'Docker Container Attach: Connect to Container'
    - docker-containers-attach-command
    - Attach to container's main process to view output and send input.
    - docker container attach my-container
    - '["docker container attach --sig-proxy=false container"]'
    - '["Attach: docker container attach \u003cname\u003e","Detach: Ctrl+P then Ctrl+Q"]'
    -
    - "[]"
    - medium
    - 10
    - 36
    - docker-containers
    - true
    - Difference between attach and exec?
    - mcq
    - '[{"text":"attach connects to main process, exec starts new","correct":true},{"text":"They
      are same","correct":false}]'
    - attach connects to main process, exec starts new
    - attach connects to PID 1, exec starts new process in container.
    -
    - '[{"title":"Attach to container","code":"docker container attach app","explanation":"Connects
      to main process output"}]'
    - "[]"
    - "[]"
    - '2025-11-06 03:44:04.617941'
    - '2025-11-06 03:44:04.621522'
    - Attach to foreground container to view live output
    - Connect to container to see stdout in real-time
    - '["containers","docker-attach","debugging","interactive"]'
    - "[]"
  - - 37
    - 'Docker Container Wait: Block Until Container Stops'
    - docker-containers-wait-command
    - Block until container stops and return its exit code - useful in scripts.
    - docker container wait my-container
    - '["docker container wait container1 container2"]'
    - '["Wait: docker container wait \u003cname\u003e","Returns exit code when stopped"]'
    -
    - "[]"
    - medium
    - 10
    - 37
    - docker-containers
    - true
    - What does docker wait return?
    - mcq
    - '[{"text":"Exit code of container","correct":true},{"text":"Container ID","correct":false}]'
    - Exit code of container
    - docker wait blocks until container stops and returns exit code (0=success).
    -
    - '[{"title":"Wait for completion","code":"docker container wait batch-job","explanation":"Blocks
      until container exits"}]'
    - "[]"
    - "[]"
    - '2025-11-06 03:44:04.628942'
    - '2025-11-06 03:44:04.632368'
    - Wait for batch job to complete before next step
    - Block script until container completes and get exit code
    - '["containers","docker-wait","scripting","automation"]'
    - "[]"
  - - 38
    - 'Docker Build: Building Images from Dockerfile'
    - docker-images-build-command
    - |
      # Mastering docker build: Creating Custom Docker Images

      ## What is docker build?
      `docker build` creates Docker images from a Dockerfile and a build context. This is how you package your applications into portable, reproducible containers - transforming source code and dependencies into ready-to-run images.

      ## Why Building Images Matters
      - **Customization**: Create images tailored to your application needs
      - **Reproducibility**: Same Dockerfile produces identical images everywhere
      - **Version Control**: Track image changes through Dockerfile history
      - **Automation**: Integrate into CI/CD pipelines for automated builds
      - **Efficiency**: Layer caching speeds up repeated builds

      ## Basic Syntax
      ```bash
      docker build [OPTIONS] PATH | URL | -
      ```

      ## Common Use Cases

      ### 1. Basic Build from Current Directory
      ```bash
      docker build .
      ```
      Builds image using Dockerfile in current directory.

      ### 2. Build and Tag Image
      ```bash
      docker build -t myapp:1.0 .
      ```
      Creates image with name and version tag.

      ### 3. Build with Custom Dockerfile
      ```bash
      docker build -f Dockerfile.prod -t myapp:prod .
      ```
      Uses different Dockerfile for production builds.

      ### 4. Build with Build Arguments
      ```bash
      docker build --build-arg NODE_VERSION=14 -t myapp .
      ```
      Passes variables to Dockerfile during build.

      ## How Docker Build Works

      ```
      1. Read Dockerfile
         ↓
      2. Send build context to Docker daemon
         ↓
      3. Execute each instruction sequentially
         ↓
      4. Create layer for each instruction
         ↓
      5. Cache layers for reuse
         ↓
      6. Tag final image
         ↓
      7. Return image ID
      ```

      ## Build Context Explained

      The build context is the set of files Docker can access during build:
      ```bash
      docker build .
                   └─ Build context (current directory)
      ```

      **Important**: Large contexts slow builds. Use `.dockerignore` to exclude files!

      ## Layer Caching

      Docker caches each layer. If nothing changes, cached layer is reused:
      ```
      Step 1/5 : FROM node:14        ← Using cache
      Step 2/5 : COPY package.json   ← Using cache
      Step 3/5 : RUN npm install     ← Using cache
      Step 4/5 : COPY . .            ← Changed! Rebuild from here
      Step 5/5 : CMD ["node", "app"] ← Rebuild
      ```

      ## Essential Build Options

      | Option | Description | Example |
      |--------|-------------|---------|
      | `-t` | Tag image with name:version | `docker build -t app:1.0 .` |
      | `-f` | Specify Dockerfile path | `docker build -f custom.Dockerfile .` |
      | `--build-arg` | Set build-time variables | `docker build --build-arg VERSION=1.0 .` |
      | `--no-cache` | Build without using cache | `docker build --no-cache .` |
      | `--target` | Build specific stage in multi-stage | `docker build --target production .` |

      ## Multi-Stage Builds

      Build multiple images in one Dockerfile:
      ```dockerfile
      # Build stage
      FROM node:14 AS builder
      COPY . .
      RUN npm install && npm run build

      # Production stage
      FROM node:14-alpine
      COPY --from=builder /app/dist /app
      CMD ["node", "app"]
      ```

      Build specific stage:
      ```bash
      docker build --target builder -t myapp:build .
      ```

      ## Common Mistakes to Avoid

      1. **Large build context**: Sending unnecessary files slows builds
      2. **No .dockerignore**: Including node_modules, .git, etc.
      3. **Poor layer ordering**: Put frequently changing layers last
      4. **Not using cache wisely**: Copy package.json before source code
      5. **Running as root**: Always specify USER in Dockerfile

      ## Optimizing Build Performance

      ### Bad Layer Order
      ```dockerfile
      FROM node:14
      COPY . .              ← Changes often, invalidates cache
      RUN npm install       ← Reinstalls every time
      ```

      ### Good Layer Order
      ```dockerfile
      FROM node:14
      COPY package*.json ./ ← Rarely changes
      RUN npm install       ← Cached until package.json changes
      COPY . .              ← Source changes don't affect npm install
      ```

      ## .dockerignore File

      Exclude files from build context:
      ```
      node_modules
      .git
      .env
      *.log
      .DS_Store
      README.md
      ```

      ## Build Arguments vs Environment Variables

      **Build Arguments (--build-arg)**
      - Available only during build
      - Set with ARG in Dockerfile
      - Example: versions, build modes

      **Environment Variables (ENV)**
      - Available at runtime
      - Set with ENV in Dockerfile
      - Example: API URLs, ports

      ## Practical Build Patterns

      ### Development Build
      ```bash
      docker build -t myapp:dev --target development .
      ```

      ### Production Build with Version
      ```bash
      docker build -t myapp:1.0.3 -t myapp:latest .
      ```

      ### Build with Secrets (BuildKit)
      ```bash
      DOCKER_BUILDKIT=1 docker build --secret id=npmrc,src=$HOME/.npmrc .
      ```

      ## Troubleshooting Builds

      ### Build Fails Midway
      ```bash
      # Check intermediate containers
      docker ps -a

      # Debug failed layer
      docker run -it <intermediate-container-id> sh
      ```

      ### Clear Build Cache
      ```bash
      docker builder prune
      ```

      ### Verbose Build Output
      ```bash
      docker build --progress=plain --no-cache .
      ```

      ## Pro Tips

      1. **Use specific base image tags**: `node:14.17-alpine` not `node:latest`
      2. **Leverage multi-stage builds**: Smaller production images
      3. **Order layers by change frequency**: Least to most frequent
      4. **Use .dockerignore**: Essential for large projects
      5. **Enable BuildKit**: `export DOCKER_BUILDKIT=1` for better performance
      6. **Tag semantic versions**: `app:1.0.0`, `app:1.0`, `app:latest`

      ## When to Use docker build

      - Creating custom application images
      - Packaging microservices
      - Building CI/CD pipeline artifacts
      - Creating development environments
      - Preparing deployment artifacts
    - docker build -t myapp:1.0 .
    - '["docker build .","docker build -t myapp:latest .","docker build -f Dockerfile.prod
      -t myapp:prod .","docker build --build-arg VERSION=1.0 -t myapp .","docker build
      --no-cache -t myapp ."]'
    - '["Basic build: docker build .","Tag image: docker build -t myapp:1.0 .","Custom
      Dockerfile: docker build -f Dockerfile.prod .","With build args: docker build
      --build-arg NODE_VERSION=14 .","No cache: docker build --no-cache ."]'
    -
    - "[]"
    - easy
    - 10
    - 38
    - docker-images
    - true
    - What does the dot (.) represent in "docker build -t myapp ."?
    - mcq
    - '[{"text":"The build context (current directory)","correct":true},{"text":"The
      Dockerfile name","correct":false},{"text":"The output directory","correct":false},{"text":"The
      cache location","correct":false}]'
    - The build context (current directory)
    - The dot (.) specifies the build context - the directory containing files Docker
      can access during build. Docker sends this context to the daemon.
    -
    - '[{"title":"Simple build from current directory","code":"docker build .","explanation":"Builds
      image using Dockerfile in current directory - no tag assigned"},{"title":"Build
      and tag with version","code":"docker build -t myapp:1.0.3 .","explanation":"Creates
      image with specific version tag for deployment tracking"},{"title":"Production
      build with custom Dockerfile","code":"docker build -f Dockerfile.prod -t myapp:prod
      .","explanation":"Uses production-specific Dockerfile for optimized builds"},{"title":"Build
      with arguments and multiple tags","code":"docker build --build-arg NODE_ENV=production
      -t myapp:1.0 -t myapp:latest .","explanation":"Passes build-time variable and
      creates two tags for same image"}]'
    - "[]"
    - "[]"
    - '2025-11-06 03:44:04.645500'
    - '2025-11-06 03:44:04.649208'
    - |
      **First Production Build**

      Maria assigns you: "We need to containerize our Node.js API. I've created a Dockerfile in the project root. Build an image tagged 'api-server:1.0' and make sure to use build argument API_ENV=production. The application is in /app/api-server directory."
    - Build a Docker image from Dockerfile, tag it as api-server:1.0, and pass API_ENV=production
      as build argument
    - '["images","docker-build","dockerfile","creation","deployment"]'
    - "[]"
  - - 39
    - 'Docker Images: List Local Images'
    - docker-images-list-command
    - "# Understanding docker images: Your Local Image Repository\n\n## What is docker
      images?\n`docker images` displays all Docker images stored locally on your system.
      It's your inventory management tool for tracking downloaded and built images,
      their sizes, and when they were created.\n\n## Why Image Management Matters\n-
      **Disk Space**: Images can consume significant storage\n- **Version Tracking**:
      See which versions you have locally\n- **Cleanup Planning**: Identify old or
      unused images\n- **Build Verification**: Confirm images were created successfully\n\n##
      Common Use Cases\n\n### 1. List All Images\n```bash\ndocker images\n```\nShows
      all locally available images.\n\n### 2. List Images for Specific Repository\n```bash\ndocker
      images nginx\n```\nShows only nginx images with different tags.\n\n### 3. Show
      Image IDs Only\n```bash\ndocker images -q\n```\nReturns just image IDs for scripting.\n\n###
      4. Show All Including Intermediates\n```bash\ndocker images -a\n```\nIncludes
      intermediate layers used during builds.\n\n## Output Columns Explained\n\n```\nREPOSITORY
      \   TAG       IMAGE ID       CREATED        SIZE\nnginx         alpine    ae2feff98a0c
      \  2 weeks ago    23.4MB\nmyapp         1.0       f6d82d3d3a1b   1 hour ago
      \    156MB\n```\n\n- **REPOSITORY**: Image name (e.g., nginx, myapp)\n- **TAG**:
      Version/variant (e.g., latest, 1.0, alpine)\n- **IMAGE ID**: Unique identifier
      (first 12 chars of SHA256)\n- **CREATED**: When image was built or pulled\n-
      **SIZE**: Disk space consumed\n\n## Understanding Image Tags\n\nSame image can
      have multiple tags:\n```bash\nmyapp    1.0      abc123...   1 hour ago   156MB\nmyapp
      \   latest   abc123...   1 hour ago   156MB\n```\nBoth tags point to the same
      image ID!\n\n## Dangling Images\n\nUntagged images from failed builds or replaced
      tags:\n```bash\n<none>   <none>   def456...   3 days ago   200MB\n```\n\nView
      only dangling images:\n```bash\ndocker images -f dangling=true\n```\n\n## Common
      Patterns\n\n### Find Large Images\n```bash\ndocker images --format \"{{.Size}}\t{{.Repository}}:{{.Tag}}\"
      | sort -h\n```\n\n### List Images by Date\n```bash\ndocker images --format \"{{.CreatedAt}}\t{{.Repository}}:{{.Tag}}\"\n```\n\n###
      Count Total Images\n```bash\ndocker images | wc -l\n```\n\n## Pro Tips\n\n1.
      Use `-q` flag for piping to other commands\n2. Filter by repository name to
      find specific images\n3. Check dangling images regularly for cleanup\n4. Use
      `--format` for custom output in scripts\n5. Sort by size to find storage hogs\n"
    - docker images
    - '["docker images -a","docker images -q","docker images nginx","docker images
      --filter \"dangling=true\""]'
    - '["List all images: docker images","Only IDs: docker images -q","Specific repo:
      docker images \u003cname\u003e","Include intermediates: docker images -a"]'
    -
    - "[]"
    - easy
    - 10
    - 39
    - docker-images
    - true
    - What does it mean when two images have the same IMAGE ID?
    - mcq
    - '[{"text":"They are the same image with different tags","correct":true},{"text":"It
      is an error condition","correct":false},{"text":"They are duplicates wasting
      space","correct":false},{"text":"They have the same size","correct":false}]'
    - They are the same image with different tags
    - Multiple tags can point to the same image. For example, myapp:1.0 and myapp:latest
      can share the same IMAGE ID, using no extra disk space.
    -
    - '[{"title":"List all local images","code":"docker images","explanation":"Shows
      complete inventory of images on your system"},{"title":"List only image IDs","code":"docker
      images -q","explanation":"Useful for scripting - pipe to removal commands"},{"title":"Filter
      by repository name","code":"docker images nginx","explanation":"Shows all nginx
      images with different tags"},{"title":"Find dangling images","code":"docker
      images -f dangling=true","explanation":"Lists untagged images that can be cleaned
      up"}]'
    - "[]"
    - "[]"
    - '2025-11-06 03:44:04.657083'
    - '2025-11-06 03:44:04.660495'
    - 'Inventory check: List all local images and identify which are consuming the
      most disk space'
    - Display all locally stored Docker images and their sizes
    - '["images","docker-images","listing","inventory","management"]'
    - "[]"
  - - 40
    - 'Docker Pull: Download Images from Registry'
    - docker-images-pull-command
    - |
      # Mastering docker pull: Downloading Images from Registries

      ## What is docker pull?
      `docker pull` downloads Docker images from a registry (like Docker Hub) to your local system. It's how you get pre-built images for databases, web servers, programming languages, and other services.

      ## Why Pulling Images Matters
      - **Quick Start**: Use production-ready software instantly
      - **Consistency**: Same image across development, staging, production
      - **Updates**: Get security patches and new versions
      - **Base Images**: Foundation for building custom images

      ## Basic Syntax
      ```bash
      docker pull [OPTIONS] NAME[:TAG|@DIGEST]
      ```

      ## Common Use Cases

      ### 1. Pull Latest Version
      ```bash
      docker pull nginx
      ```
      Downloads nginx:latest (default tag).

      ### 2. Pull Specific Version
      ```bash
      docker pull nginx:1.21-alpine
      ```
      Downloads exact version for reproducibility.

      ### 3. Pull from Private Registry
      ```bash
      docker pull myregistry.com/myapp:1.0
      ```
      Pulls from custom registry (requires authentication).

      ### 4. Pull by Digest
      ```bash
      docker pull nginx@sha256:abc123...
      ```
      Guarantees exact image, even if tags change.

      ## How Docker Pull Works

      ```
      1. Parse image name and tag
         ↓
      2. Connect to registry (Docker Hub by default)
         ↓
      3. Check authentication if required
         ↓
      4. Download image manifest
         ↓
      5. Download each layer (with progress bars)
         ↓
      6. Extract and store layers locally
         ↓
      7. Tag image in local repository
      ```

      ## Image Naming Convention

      ```
      [REGISTRY/]REPOSITORY[:TAG|@DIGEST]

      Examples:
      nginx                          → docker.io/library/nginx:latest
      nginx:alpine                   → docker.io/library/nginx:alpine
      myuser/myapp:1.0              → docker.io/myuser/myapp:1.0
      gcr.io/project/image:v1       → gcr.io/project/image:v1
      ```

      ## Layer Reuse

      Docker pulls only missing layers:
      ```bash
      docker pull nginx:1.21
      # Later...
      docker pull nginx:1.21-alpine
      # Only downloads alpine-specific layers!
      ```

      ## Common Tags

      | Tag | Meaning | Use Case |
      |-----|---------|----------|
      | `latest` | Most recent build | Development (not production!) |
      | `1.21` | Major.minor version | Production |
      | `1.21.3` | Specific patch | Critical stability |
      | `alpine` | Minimal Alpine Linux base | Smaller images |
      | `slim` | Reduced size variant | Balance size/features |

      ## Pull Strategies

      ### Development
      ```bash
      docker pull nginx:alpine
      # Small, fast, good for testing
      ```

      ### Production
      ```bash
      docker pull nginx:1.21.3-alpine
      # Specific version for reproducibility
      ```

      ### Security-Critical
      ```bash
      docker pull nginx@sha256:abc123def456...
      # Immutable digest ensures exact image
      ```

      ## Private Registries

      Login first:
      ```bash
      docker login myregistry.com
      docker pull myregistry.com/private-app:1.0
      ```

      ## Common Mistakes

      1. **Using :latest in production**: Version drifts cause issues
      2. **Not specifying tags**: Gets unpredictable :latest
      3. **Pulling repeatedly**: Wastes bandwidth, use local cache
      4. **Large images over slow connections**: Consider smaller variants
      5. **Not checking image authenticity**: Verify official images

      ## Pro Tips

      1. **Always specify version tags in production**
      2. **Use Alpine variants for smaller sizes**
      3. **Pull during build/deploy, not at runtime**
      4. **Check Docker Hub for official images**
      5. **Use digests for critical deployments**
      6. **Cache images in CI/CD pipelines**
    - docker pull nginx:alpine
    - '["docker pull nginx","docker pull nginx:1.21","docker pull postgres:13-alpine","docker
      pull myregistry.com/myapp:1.0"]'
    - '["Pull latest: docker pull nginx","Specific version: docker pull nginx:1.21","Alpine
      variant: docker pull nginx:alpine","From registry: docker pull registry.com/image:tag"]'
    -
    - "[]"
    - easy
    - 10
    - 40
    - docker-images
    - true
    - What happens if you don't specify a tag when pulling an image?
    - mcq
    - '[{"text":"Docker automatically pulls the :latest tag","correct":true},{"text":"Docker
      pulls all available tags","correct":false},{"text":"The command fails with an
      error","correct":false},{"text":"Docker prompts you to choose a tag","correct":false}]'
    - Docker automatically pulls the :latest tag
    - When no tag is specified, Docker defaults to :latest. This is why you should
      always specify explicit version tags in production to avoid unexpected updates.
    -
    - '[{"title":"Pull latest nginx","code":"docker pull nginx","explanation":"Downloads
      most recent nginx image (nginx:latest)"},{"title":"Pull specific version","code":"docker
      pull postgres:13.4-alpine","explanation":"Gets exact PostgreSQL version - reproducible
      deployments"},{"title":"Pull from Docker Hub user repository","code":"docker
      pull username/custom-app:2.0","explanation":"Downloads from personal Docker
      Hub repository"},{"title":"Pull using image digest","code":"docker pull nginx@sha256:2bcabc23b45489fb0885d69a06ba1d648aeda973fae7bb981bafbb884165e514","explanation":"Guarantees
      exact image content - immutable reference"}]'
    - "[]"
    - "[]"
    - '2025-11-06 03:44:04.668001'
    - '2025-11-06 03:44:04.671620'
    - 'Setup task: Pull the official PostgreSQL 13 Alpine image for the new database
      service'
    - Download PostgreSQL version 13 with Alpine Linux base image from Docker Hub
    - '["images","docker-pull","registry","download","docker-hub"]'
    - "[]"
  - - 41
    - 'Docker Push: Upload Images to Registry'
    - docker-images-push-command
    - |
      # Mastering docker push: Sharing Images via Registries

      ## What is docker push?
      `docker push` uploads your local Docker images to a registry (Docker Hub, AWS ECR, Google GCR, etc.). This enables sharing images across teams, deploying to production servers, and distributing applications.

      ## Why Pushing Images Matters
      - **Deployment**: Ship images to production servers
      - **Collaboration**: Share images with team members
      - **CI/CD**: Automate build and deployment pipelines
      - **Backup**: Store images in centralized location
      - **Distribution**: Make images publicly available

      ## Basic Syntax
      ```bash
      docker push [OPTIONS] NAME[:TAG]
      ```

      ## Prerequisites

      1. **Tag image with registry prefix**:
      ```bash
      docker tag myapp:1.0 username/myapp:1.0
      ```

      2. **Login to registry**:
      ```bash
      docker login
      ```

      3. **Push image**:
      ```bash
      docker push username/myapp:1.0
      ```

      ## Common Use Cases

      ### Push to Docker Hub
      ```bash
      docker login
      docker tag myapp:1.0 username/myapp:1.0
      docker push username/myapp:1.0
      ```

      ### Push Multiple Tags
      ```bash
      docker push username/myapp:1.0
      docker push username/myapp:latest
      ```

      ### Push to Private Registry
      ```bash
      docker login myregistry.com
      docker tag myapp:1.0 myregistry.com/myapp:1.0
      docker push myregistry.com/myapp:1.0
      ```

      ## How Docker Push Works

      ```
      1. Check image exists locally
         ↓
      2. Verify authentication token
         ↓
      3. Check which layers already exist on registry
         ↓
      4. Upload only new/changed layers
         ↓
      5. Upload image manifest
         ↓
      6. Tag image in registry
      ```

      ## Layer Optimization

      Docker only uploads layers that don't exist on the registry:
      ```bash
      docker push myapp:1.0    # Uploads all layers
      docker push myapp:1.1    # Only uploads changed layers!
      ```

      ## Registry Types

      ### Docker Hub (Default)
      ```bash
      docker push username/image:tag
      ```

      ### AWS ECR
      ```bash
      aws ecr get-login-password | docker login --username AWS --password-stdin 123456.dkr.ecr.region.amazonaws.com
      docker push 123456.dkr.ecr.region.amazonaws.com/myapp:1.0
      ```

      ### Google GCR
      ```bash
      docker push gcr.io/project-id/myapp:1.0
      ```

      ### Private Registry
      ```bash
      docker push registry.company.com:5000/myapp:1.0
      ```

      ## Common Patterns

      ### CI/CD Pipeline Push
      ```bash
      # Build
      docker build -t myapp:${BUILD_NUMBER} .

      # Tag for registry
      docker tag myapp:${BUILD_NUMBER} username/myapp:${BUILD_NUMBER}
      docker tag myapp:${BUILD_NUMBER} username/myapp:latest

      # Push both tags
      docker push username/myapp:${BUILD_NUMBER}
      docker push username/myapp:latest
      ```

      ### Multi-Architecture Push
      ```bash
      docker buildx build --platform linux/amd64,linux/arm64 -t username/myapp:1.0 --push .
      ```

      ## Common Mistakes

      1. **Forgetting to tag with registry prefix**: Must include username/registry
      2. **Not logged in**: Login first with `docker login`
      3. **Wrong repository name**: Case-sensitive on some registries
      4. **Missing tag**: Defaults to :latest if not specified
      5. **Large images over slow connections**: Consider layer optimization

      ## Security Best Practices

      1. **Never commit credentials**: Use CI/CD secrets
      2. **Use access tokens**: Not passwords when possible
      3. **Limit push permissions**: Use read-only tokens for pulls
      4. **Scan images before pushing**: Check for vulnerabilities
      5. **Use private registries for sensitive code**

      ## Pro Tips

      1. **Push multiple tags in CI/CD**: version + latest
      2. **Use .dockerignore**: Reduce image size before building
      3. **Leverage layer caching**: Organize Dockerfile for efficiency
      4. **Tag with semantic versions**: 1.0.0, 1.0, 1, latest
      5. **Automate pushes in pipelines**: Don't push manually
      6. **Clean up old tags**: Implement retention policies
    - docker push username/myapp:1.0
    - '["docker push myregistry.com/myapp:1.0","docker push username/myapp:latest","docker
      push gcr.io/project/myapp:1.0"]'
    - '["Tag for registry: docker tag myapp username/myapp:1.0","Login: docker login","Push:
      docker push username/myapp:1.0","Push to private: docker push registry.com/myapp:1.0"]'
    -
    - "[]"
    - medium
    - 10
    - 41
    - docker-images
    - true
    - Why must you tag an image with a registry prefix before pushing?
    - mcq
    - '[{"text":"The tag tells Docker which registry to push to and where to store
      it","correct":true},{"text":"It is just a naming convention with no functional
      purpose","correct":false},{"text":"To make the image larger for better quality","correct":false},{"text":"Docker
      Hub requires it for security scanning","correct":false}]'
    - The tag tells Docker which registry to push to and where to store it
    - The image tag format registry/repository:version tells Docker where to push
      the image. For Docker Hub, username/myapp:1.0 means push to Docker Hub under
      that username's repository.
    -
    - '[{"title":"Push to Docker Hub","code":"docker push username/myapp:1.0","explanation":"Uploads
      image to Docker Hub public registry"},{"title":"Push to AWS ECR","code":"docker
      push 123456789.dkr.ecr.us-east-1.amazonaws.com/myapp:1.0","explanation":"Deploys
      to private AWS Elastic Container Registry"},{"title":"Push multiple tags","code":"docker
      push username/myapp:1.0 \u0026\u0026 docker push username/myapp:latest","explanation":"Pushes
      both version tag and latest tag for same image"}]'
    - "[]"
    - "[]"
    - '2025-11-06 03:44:04.679183'
    - '2025-11-06 03:44:04.684136'
    - 'Deployment prep: Push your built api-server:1.0 image to Docker Hub as username/api-server:1.0
      for production deployment'
    - Tag and push local image to Docker Hub registry for team access
    - '["images","docker-push","registry","deployment","sharing"]'
    - "[]"
  - - 42
    - 'Docker Tag: Create Image Aliases'
    - docker-images-tag-command
    - |
      # Mastering docker tag: Version Control for Images

      ## What is docker tag?
      `docker tag` creates a new tag (alias) for an existing image. It doesn't copy the image - both tags point to the same image ID, consuming no extra disk space. Essential for version management and registry operations.

      ## Why Tagging Matters
      - **Version Control**: Track different versions of same application
      - **Registry Preparation**: Add registry prefix before pushing
      - **Environment Management**: Tag same image for dev/staging/prod
      - **Release Management**: Mark stable versions as :latest
      - **No Duplication**: Multiple tags, single image storage

      ## Basic Syntax
      ```bash
      docker tag SOURCE_IMAGE[:TAG] TARGET_IMAGE[:TAG]
      ```

      ## Common Use Cases

      ### 1. Add Version Tag
      ```bash
      docker tag myapp:latest myapp:1.0.0
      ```

      ### 2. Prepare for Registry Push
      ```bash
      docker tag myapp:1.0 username/myapp:1.0
      ```

      ### 3. Mark as Latest
      ```bash
      docker tag myapp:1.5.0 myapp:latest
      ```

      ### 4. Create Environment Tag
      ```bash
      docker tag myapp:build myapp:production
      ```

      ## How Tagging Works

      ```
      Before:
      myapp:1.0  → Image ID: abc123

      After: docker tag myapp:1.0 myapp:latest
      myapp:1.0     → Image ID: abc123
      myapp:latest  → Image ID: abc123 (same image!)

      Disk usage: No increase!
      ```

      ## Semantic Versioning Strategy

      ```bash
      # Build version 1.5.3
      docker build -t myapp:1.5.3 .

      # Tag additional versions
      docker tag myapp:1.5.3 myapp:1.5    # Minor version
      docker tag myapp:1.5.3 myapp:1      # Major version
      docker tag myapp:1.5.3 myapp:latest # Latest stable
      ```

      ## Registry Tagging Pattern

      ```bash
      # Local image
      docker build -t myapp:1.0 .

      # Tag for Docker Hub
      docker tag myapp:1.0 username/myapp:1.0
      docker tag myapp:1.0 username/myapp:latest

      # Tag for private registry
      docker tag myapp:1.0 registry.company.com/myapp:1.0

      # Now push
      docker push username/myapp:1.0
      docker push username/myapp:latest
      ```

      ## Multi-Registry Strategy

      Tag same image for multiple registries:
      ```bash
      # Original local image
      docker build -t myapp:1.0 .

      # Docker Hub
      docker tag myapp:1.0 dockerhub-user/myapp:1.0

      # AWS ECR
      docker tag myapp:1.0 123456.dkr.ecr.us-east-1.amazonaws.com/myapp:1.0

      # Google GCR
      docker tag myapp:1.0 gcr.io/my-project/myapp:1.0
      ```

      ## Environment-Based Tagging

      ```bash
      # Build once
      docker build -t myapp:${GIT_COMMIT} .

      # Tag for environments
      docker tag myapp:${GIT_COMMIT} myapp:dev
      docker tag myapp:${GIT_COMMIT} myapp:staging
      docker tag myapp:${GIT_COMMIT} myapp:production
      ```

      ## Common Mistakes

      1. **Thinking tag creates a copy**: It's an alias, not duplication
      2. **Overwriting important tags**: :latest changes frequently
      3. **Not using semantic versions**: Hard to track releases
      4. **Missing registry prefix**: Required for pushing
      5. **Forgetting to tag :latest**: Some tools expect it

      ## Best Practices

      ### Development
      ```bash
      docker tag myapp:dev myapp:$(git rev-parse --short HEAD)
      ```

      ### Release
      ```bash
      docker tag myapp:rc myapp:1.0.0
      docker tag myapp:rc myapp:latest
      ```

      ### Hotfix
      ```bash
      docker tag myapp:1.0.0 myapp:1.0.1
      docker tag myapp:1.0.1 myapp:latest
      ```

      ## Pro Tips

      1. **Use semantic versioning**: major.minor.patch
      2. **Tag before pushing**: Add registry prefix
      3. **Automate in CI/CD**: Tag based on git tags/branches
      4. **Keep :latest updated**: Point to most stable version
      5. **Document tagging strategy**: Team consistency
      6. **Use build metadata**: Include commit hash in tags
    - docker tag myapp:1.0 username/myapp:1.0
    - '["docker tag myapp:latest myapp:1.0.0","docker tag abc123 myapp:production","docker
      tag myapp:1.0 registry.io/myapp:1.0"]'
    - '["Basic tag: docker tag source:tag target:tag","Add version: docker tag myapp:latest
      myapp:1.0","For registry: docker tag myapp username/myapp:1.0","By ID: docker
      tag \u003cimage-id\u003e newname:tag"]'
    -
    - "[]"
    - easy
    - 10
    - 42
    - docker-images
    - true
    - When you tag an image, what happens to disk space usage?
    - mcq
    - '[{"text":"No change - tags are aliases to the same image","correct":true},{"text":"Disk
      usage doubles with each tag","correct":false},{"text":"Disk usage increases
      slightly for metadata","correct":false},{"text":"Depends on the size of the
      tag name","correct":false}]'
    - No change - tags are aliases to the same image
    - Docker tags are just names pointing to the same image ID. Multiple tags reference
      the same layers on disk, using no additional space.
    -
    - '[{"title":"Create version tag","code":"docker tag myapp:latest myapp:1.0.0","explanation":"Adds
      version tag to latest build - same image, new name"},{"title":"Prepare for Docker
      Hub push","code":"docker tag myapp:1.0 username/myapp:1.0","explanation":"Adds
      registry prefix required for pushing to Docker Hub"},{"title":"Tag for multiple
      registries","code":"docker tag myapp:1.0 gcr.io/project/myapp:1.0","explanation":"Same
      image tagged for Google Container Registry"}]'
    - "[]"
    - "[]"
    - '2025-11-06 03:44:04.692406'
    - '2025-11-06 03:44:04.696133'
    - 'Release management: Tag your tested myapp:staging image as myapp:1.0.0 and
      myapp:latest for production release'
    - Create version and latest tags for staging image before production deployment
    - '["images","docker-tag","versioning","naming","registry"]'
    - "[]"
  - - 43
    - 'Docker RMI: Remove Images'
    - docker-images-rmi-command
    - Remove one or more images from local storage to free disk space. Cannot remove
      images being used by containers unless forced.
    - docker rmi myapp:1.0
    - '["docker rmi -f myapp:old","docker rmi $(docker images -q)","docker rmi myapp:1.0
      myapp:2.0"]'
    - '["Remove image: docker rmi \u003cimage:tag\u003e","Force remove: docker rmi
      -f \u003cimage\u003e","Remove multiple: docker rmi image1 image2","Remove by
      ID: docker rmi \u003cimage-id\u003e"]'
    -
    - "[]"
    - easy
    - 10
    - 43
    - docker-images
    - true
    - Can you remove an image that has a running container?
    - mcq
    - '[{"text":"No, unless you use -f flag to force removal","correct":true},{"text":"Yes,
      Docker automatically stops the container","correct":false},{"text":"Yes, but
      the container will fail","correct":false},{"text":"No, it is never possible","correct":false}]'
    - No, unless you use -f flag to force removal
    - Docker prevents removing images in use by containers. Use -f to force, but this
      can cause running containers to fail.
    -
    - '[{"title":"Remove single image","code":"docker rmi nginx:alpine","explanation":"Deletes
      image and its unused layers"},{"title":"Force remove","code":"docker rmi -f
      myapp:old","explanation":"Removes even if containers exist (use with caution)"},{"title":"Remove
      multiple images","code":"docker rmi myapp:1.0 myapp:2.0 myapp:3.0","explanation":"Batch
      removal of multiple versions"}]'
    - "[]"
    - "[]"
    - '2025-11-06 03:44:04.703734'
    - '2025-11-06 03:44:04.707409'
    - 'Cleanup: Remove old image versions to free 5GB of disk space'
    - Remove unused images to reclaim disk space
    - '["images","docker-rmi","cleanup","removal","disk-space"]'
    - "[]"
  - - 44
    - 'Docker Image Prune: Clean Unused Images'
    - docker-images-prune-command
    - Remove unused (dangling) images in batch to reclaim disk space. Use -a to remove
      all images not used by containers.
    - docker image prune
    - '["docker image prune -f","docker image prune -a","docker image prune -a --filter
      \"until=24h\""]'
    - '["Remove dangling: docker image prune","Skip confirmation: docker image prune
      -f","Remove all unused: docker image prune -a","Age filter: docker image prune
      --filter \"until=24h\""]'
    -
    - "[]"
    - easy
    - 10
    - 44
    - docker-images
    - true
    - What are "dangling" images?
    - mcq
    - '[{"text":"Untagged images from builds or replaced tags","correct":true},{"text":"Images
      that are corrupted","correct":false},{"text":"Images over 1GB in size","correct":false},{"text":"Images
      from untrusted sources","correct":false}]'
    - Untagged images from builds or replaced tags
    - Dangling images are those with <none>:<none> tags - intermediate layers or old
      images replaced by new tags.
    -
    - '[{"title":"Remove dangling images","code":"docker image prune -f","explanation":"Cleans
      untagged images without confirmation"},{"title":"Remove all unused images","code":"docker
      image prune -a -f","explanation":"Removes all images not used by any container"},{"title":"Time-based
      cleanup","code":"docker image prune -a --filter \"until=168h\" -f","explanation":"Removes
      images unused for over 7 days"}]'
    - "[]"
    - "[]"
    - '2025-11-06 03:44:04.714981'
    - '2025-11-06 03:44:04.718661'
    - 'Weekly maintenance: Clean all dangling images and unused images older than
      7 days'
    - Automate cleanup of unused Docker images to maintain system health
    - '["images","docker-prune","cleanup","maintenance","disk-space"]'
    - "[]"
  - - 45
    - 'Docker Image LS: List Images'
    - docker-images-ls-command
    - Modern command to list Docker images - equivalent to docker images but follows
      new CLI structure.
    - docker image ls
    - '["docker image ls -a","docker image ls --filter \"dangling=true\"","docker
      image ls --format \"{{.Repository}}:{{.Tag}}\""]'
    - '["List images: docker image ls","All including intermediates: docker image
      ls -a","Filter dangling: docker image ls -f dangling=true","Custom format: docker
      image ls --format \"table {{.Repository}}\\t{{.Tag}}\""]'
    -
    - "[]"
    - easy
    - 10
    - 45
    - docker-images
    - true
    - What is the difference between "docker images" and "docker image ls"?
    - mcq
    - '[{"text":"They are equivalent - same functionality","correct":true},{"text":"docker
      image ls shows more details","correct":false},{"text":"docker images is deprecated","correct":false},{"text":"docker
      image ls is faster","correct":false}]'
    - They are equivalent - same functionality
    - docker image ls is the modern form of docker images - both work identically,
      new syntax follows consistent CLI structure.
    -
    - '[{"title":"List all images","code":"docker image ls","explanation":"Shows local
      image repository inventory"},{"title":"Filter by name","code":"docker image
      ls nginx","explanation":"Lists only nginx images"}]'
    - "[]"
    - "[]"
    - '2025-11-06 03:44:04.726235'
    - '2025-11-06 03:44:04.730042'
    - 'Audit: Generate report of all images on production servers'
    - List all images with custom formatting for audit report
    - '["images","docker-ls","listing","inventory"]'
    - "[]"
  - - 46
    - 'Docker Image RM: Remove Images'
    - docker-images-rm-command
    - Modern syntax for removing images - equivalent to docker rmi but follows new
      CLI structure.
    - docker image rm myapp:1.0
    - '["docker image rm -f myapp:old","docker image rm myapp:1.0 myapp:2.0"]'
    - '["Remove: docker image rm \u003cimage\u003e","Force: docker image rm -f \u003cimage\u003e","Multiple:
      docker image rm img1 img2"]'
    -
    - "[]"
    - easy
    - 10
    - 46
    - docker-images
    - true
    - What happens to containers when you force remove their image?
    - mcq
    - '[{"text":"Running containers may fail when restarted","correct":true},{"text":"Containers
      are automatically stopped","correct":false},{"text":"Nothing - containers are
      unaffected","correct":false},{"text":"Containers are recreated from backup","correct":false}]'
    - Running containers may fail when restarted
    - Force removing an image in use can cause containers to fail on restart since
      the image layers are deleted.
    -
    - '[{"title":"Remove image","code":"docker image rm myapp:old","explanation":"Deletes
      specific image version"},{"title":"Force removal","code":"docker image rm -f
      myapp:1.0","explanation":"Removes even if containers exist"}]'
    - "[]"
    - "[]"
    - '2025-11-06 03:44:04.737890'
    - '2025-11-06 03:44:04.741549'
    - Cleanup old development images to free disk space
    - Remove specific image versions no longer needed
    - '["images","docker-rm","cleanup","removal"]'
    - "[]"
  - - 47
    - 'Docker Image Inspect: Detailed Image Information'
    - docker-images-inspect-command
    - Display detailed image information in JSON format including layers, configuration,
      environment variables, and metadata.
    - docker image inspect nginx:alpine
    - '["docker image inspect --format=\"{{.Size}}\" nginx","docker image inspect
      --format=\"{{.Config.Env}}\" myapp"]'
    - '["Inspect: docker image inspect \u003cimage\u003e","Extract field: docker image
      inspect --format=\"{{.Architecture}}\" \u003cimage\u003e","Multiple images:
      docker image inspect img1 img2"]'
    -
    - "[]"
    - medium
    - 10
    - 47
    - docker-images
    - true
    - What information can you find with docker image inspect?
    - mcq
    - '[{"text":"Layers, environment variables, exposed ports, and creation date","correct":true},{"text":"Only
      the image size","correct":false},{"text":"Running container information","correct":false},{"text":"Network
      connections","correct":false}]'
    - Layers, environment variables, exposed ports, and creation date
    - docker image inspect shows complete image metadata including layers, config,
      env vars, exposed ports, labels, and more.
    -
    - '[{"title":"Full image details","code":"docker image inspect nginx:alpine","explanation":"Complete
      JSON output of image configuration"},{"title":"Extract specific field","code":"docker
      image inspect --format=\"{{.Architecture}}\" nginx","explanation":"Shows just
      the CPU architecture"},{"title":"Get image layers","code":"docker image inspect
      --format=\"{{.RootFS.Layers}}\" myapp","explanation":"Lists all layer SHA256
      hashes"}]'
    - "[]"
    - "[]"
    - '2025-11-06 03:44:04.748587'
    - '2025-11-06 03:44:04.752900'
    - 'Investigation: Find base OS and installed packages in production image'
    - Extract detailed configuration from image for security audit
    - '["images","docker-inspect","metadata","debugging","configuration"]'
    - "[]"
  - - 48
    - 'Docker History: Show Image Build History'
    - docker-images-history-command
    - Display the history of an image showing all layers, commands that created them,
      and their sizes. Essential for understanding image composition and optimization.
    - docker history nginx:alpine
    - '["docker history --no-trunc nginx","docker history --human=false myapp","docker
      history --format \"{{.CreatedBy}}\" myapp"]'
    - '["View history: docker history \u003cimage\u003e","Full commands: docker history
      --no-trunc \u003cimage\u003e","Size analysis: docker history \u003cimage\u003e
      | head","Custom format: docker history --format \"table {{.Size}}\\t{{.CreatedBy}}\""]'
    -
    - "[]"
    - medium
    - 10
    - 48
    - docker-images
    - true
    - What does each line in docker history output represent?
    - mcq
    - '[{"text":"A layer in the image with the command that created it","correct":true},{"text":"A
      version of the image","correct":false},{"text":"A container created from the
      image","correct":false},{"text":"A backup of the image","correct":false}]'
    - A layer in the image with the command that created it
    - Each line shows a layer created by a Dockerfile instruction, displaying the
      command, size, and creation time.
    -
    - '[{"title":"View image history","code":"docker history nginx:alpine","explanation":"Shows
      all layers and commands that built the image"},{"title":"Full command text","code":"docker
      history --no-trunc myapp:1.0","explanation":"Displays complete Dockerfile commands
      without truncation"},{"title":"Find large layers","code":"docker history myapp
      | sort -k2 -h","explanation":"Sorts layers by size to identify optimization
      targets"}]'
    - "[]"
    - "[]"
    - '2025-11-06 03:44:04.760980'
    - '2025-11-06 03:44:04.764783'
    - 'Optimization: Analyze image history to identify large layers for size reduction'
    - Examine image layers to find optimization opportunities
    - '["images","docker-history","layers","optimization","analysis"]'
    - "[]"
  - - 49
    - 'Docker Compose Up: Start Multi-Container Applications'
    - docker-compose-up-command
    - |
      # Mastering docker-compose up: Orchestrating Multi-Service Applications

      ## What is docker-compose up?
      `docker-compose up` reads your `docker-compose.yml` file and creates, starts, and connects all defined services in one command. It's the primary way to launch complete application stacks with all their dependencies, networks, and volumes configured automatically.

      ## Why Compose Matters
      - **Simplicity**: Start complex stacks with one command
      - **Reproducibility**: Same configuration works everywhere
      - **Development Speed**: No manual container management
      - **Service Dependencies**: Automatic service ordering and networking
      - **Configuration as Code**: docker-compose.yml is version-controlled

      ## Basic Syntax
      ```bash
      docker-compose up [OPTIONS] [SERVICE...]
      ```

      ## Common Use Cases

      ### 1. Start All Services
      ```bash
      docker-compose up
      ```
      Starts all services in foreground, showing logs from all containers.

      ### 2. Start in Background (Detached)
      ```bash
      docker-compose up -d
      ```
      Most common for development - starts services in background.

      ### 3. Rebuild Images Before Starting
      ```bash
      docker-compose up --build
      ```
      Forces rebuild of images defined with `build:` in compose file.

      ### 4. Start Specific Services
      ```bash
      docker-compose up web database
      ```
      Only starts web and database services (plus their dependencies).

      ## How docker-compose up Works

      ```
      1. Read docker-compose.yml
         ↓
      2. Create custom network (if not exists)
         ↓
      3. Create volumes (if not exists)
         ↓
      4. Pull/build images as needed
         ↓
      5. Create containers with configurations
         ↓
      6. Start services in dependency order
         ↓
      7. Attach to logs (unless -d used)
      ```

      ## Sample docker-compose.yml

      ```yaml
      version: '3.8'
      services:
        web:
          image: nginx:alpine
          ports:
            - "8080:80"
          depends_on:
            - api
        api:
          build: ./api
          environment:
            - DB_HOST=database
          depends_on:
            - database
        database:
          image: postgres:13
          environment:
            - POSTGRES_PASSWORD=secret
          volumes:
            - db-data:/var/lib/postgresql/data
      volumes:
        db-data:
      ```

      ## Service Dependencies

      Compose respects `depends_on` to start services in correct order:
      ```yaml
      web:
        depends_on:
          - api
          - cache
      ```
      Starts cache and api before web (but doesn't wait for "ready").

      ## Common Options

      | Option | Description | Example |
      |--------|-------------|---------|
      | `-d` | Detached mode | `docker-compose up -d` |
      | `--build` | Force rebuild images | `docker-compose up --build` |
      | `--force-recreate` | Recreate containers | `docker-compose up --force-recreate` |
      | `--no-deps` | Don't start dependencies | `docker-compose up --no-deps web` |
      | `--scale` | Scale services | `docker-compose up --scale api=3` |

      ## Networking Magic

      Compose creates a default network where services can reach each other by name:
      ```yaml
      api:
        environment:
          - DB_HOST=database  # Uses service name as hostname!
      ```

      ## Watching Logs

      ### Foreground Mode (Default)
      ```bash
      docker-compose up
      ```
      Shows interleaved logs from all services. Press Ctrl+C to stop.

      ### Detached Mode
      ```bash
      docker-compose up -d
      docker-compose logs -f  # Follow logs separately
      ```

      ## Incremental Changes

      Compose detects changes and only recreates affected containers:
      ```bash
      # Edit docker-compose.yml
      docker-compose up -d  # Only affected services restart!
      ```

      ## Common Mistakes to Avoid

      1. **Forgetting -d in scripts**: Blocks terminal without detached mode
      2. **Not rebuilding after code changes**: Use `--build` flag
      3. **Wrong working directory**: Must be in directory with docker-compose.yml
      4. **Port conflicts**: Ensure ports in compose file aren't already used
      5. **Missing env files**: Create `.env` if compose references environment variables

      ## Development Workflow

      ### First Time Setup
      ```bash
      docker-compose up --build  # Build and start
      ```

      ### Daily Development
      ```bash
      docker-compose up -d       # Start in background
      docker-compose logs -f web # Watch specific service logs
      ```

      ### After Code Changes
      ```bash
      docker-compose up -d --build web  # Rebuild and restart only web
      ```

      ## Pro Tips

      1. **Use detached mode for CI/CD**: `docker-compose up -d` doesn't block pipelines
      2. **Override compose files**: Use `-f` to stack configurations
      3. **Health checks matter**: Add healthchecks in compose file for readiness
      4. **Named volumes for data**: Don't lose database data between restarts
      5. **Environment files**: Use `.env` for sensitive configuration
      6. **Service names as hostnames**: Inter-service communication is seamless

      ## When to Use docker-compose up

      - Starting complete application stacks for development
      - Running integration tests with all dependencies
      - Demo environments with multiple services
      - Local replication of production architectures
      - CI/CD pipeline test environments
    - docker-compose up -d
    - '["docker-compose up","docker-compose up --build","docker-compose up -d web
      api","docker-compose up --scale api=3 -d"]'
    - '["Start all services: docker-compose up -d","With rebuild: docker-compose up
      --build -d","Specific services: docker-compose up -d web","Watch logs: docker-compose
      up (without -d)"]'
    -
    - "[]"
    - medium
    - 10
    - 49
    - docker-compose
    - true
    - What does docker-compose up create automatically?
    - mcq
    - '[{"text":"Networks, volumes, and containers for all services","correct":true},{"text":"Only
      containers","correct":false},{"text":"Only networks","correct":false},{"text":"Nothing
      - you must create them manually","correct":false}]'
    - Networks, volumes, and containers for all services
    - docker-compose up automatically creates networks, volumes, and containers defined
      in docker-compose.yml, connecting everything together.
    -
    - '[{"title":"Start all services in foreground","code":"docker-compose up","explanation":"Starts
      all services and displays interleaved logs - great for debugging"},{"title":"Start
      in detached mode","code":"docker-compose up -d","explanation":"Most common -
      starts services in background, frees terminal"},{"title":"Rebuild and start","code":"docker-compose
      up --build -d","explanation":"Forces image rebuild before starting - use after
      code changes"},{"title":"Start with scaling","code":"docker-compose up -d --scale
      api=3","explanation":"Starts 3 instances of api service for load balancing"}]'
    - "[]"
    - "[]"
    - '2025-11-06 03:44:04.774269'
    - '2025-11-06 03:44:04.778095'
    - |
      **First Production Deploy**

      Tech lead assigns you: "We have a new microservices stack - web frontend, API backend, and PostgreSQL database. Everything is defined in docker-compose.yml. Start the entire stack in detached mode so we can test the deployment."
    - Start complete application stack with all services running in background
    - '["docker-compose","orchestration","multi-container","deployment","services"]'
    - "[]"
  - - 50
    - 'Docker Compose Down: Stop and Remove Stack'
    - docker-compose-down-command
    - |
      # Mastering docker-compose down: Clean Stack Teardown

      ## What is docker-compose down?
      `docker-compose down` stops all services and removes containers, networks, and optionally volumes created by `docker-compose up`. It's the clean way to tear down your entire application stack, returning to a clean slate.

      ## Why Down Matters
      - **Complete Cleanup**: Removes containers AND networks
      - **Resource Management**: Frees ports, memory, and disk
      - **Fresh Start**: Ensures clean state for next deployment
      - **CI/CD Essential**: Cleanup step in automated pipelines
      - **Safer than docker stop**: Handles dependencies and networks properly

      ## Basic Syntax
      ```bash
      docker-compose down [OPTIONS]
      ```

      ## Common Use Cases

      ### 1. Standard Teardown
      ```bash
      docker-compose down
      ```
      Stops and removes containers and networks (keeps volumes and images).

      ### 2. Remove Volumes Too
      ```bash
      docker-compose down -v
      ```
      **DANGER**: Also removes named volumes, deleting all data!

      ### 3. Remove Images
      ```bash
      docker-compose down --rmi all
      ```
      Removes all images used by services (thorough cleanup).

      ### 4. Remove Orphans
      ```bash
      docker-compose down --remove-orphans
      ```
      Removes containers for services not in current compose file.

      ## How docker-compose down Works

      ```
      1. Stop all containers gracefully (SIGTERM)
         ↓
      2. Wait for graceful shutdown (10s timeout)
         ↓
      3. Force kill if needed (SIGKILL)
         ↓
      4. Remove all containers
         ↓
      5. Remove custom networks
         ↓
      6. Remove volumes (if -v flag used)
         ↓
      7. Remove images (if --rmi flag used)
      ```

      ## What Gets Removed vs Kept

      ### Always Removed
      - Containers created by up
      - Networks created by up
      - Internal networks

      ### Kept by Default
      - Volumes (data persistence)
      - Images (avoid re-downloading)
      - External networks

      ### Removed with Flags
      - Volumes: use `-v` or `--volumes`
      - Images: use `--rmi all` or `--rmi local`

      ## Common Options

      | Option | Description | Use Case |
      |--------|-------------|----------|
      | `-v, --volumes` | Remove named volumes | Clean slate, delete data |
      | `--rmi all` | Remove all images | Complete cleanup |
      | `--rmi local` | Remove images without tags | Cleanup build artifacts |
      | `--remove-orphans` | Remove unlisted containers | After compose file changes |
      | `-t, --timeout` | Shutdown timeout seconds | Graceful shutdown control |

      ## Volume Preservation Example

      ```bash
      # First run
      docker-compose up -d
      # Database writes data to volume

      # Teardown
      docker-compose down
      # Volume still exists with data!

      # Next run
      docker-compose up -d
      # Database finds existing data - no loss!
      ```

      ## Dangerous Operations

      ### Delete All Data (Volumes)
      ```bash
      docker-compose down -v
      ```
      ⚠️ **WARNING**: Deletes database data, uploaded files, etc.!

      ### Complete Cleanup
      ```bash
      docker-compose down -v --rmi all --remove-orphans
      ```
      ⚠️ **WARNING**: Nuclear option - removes everything!

      ## vs docker-compose stop

      ### docker-compose stop
      - Stops containers
      - **Keeps** containers
      - **Keeps** networks
      - Fast restart with `docker-compose start`

      ### docker-compose down
      - Stops containers
      - **Removes** containers
      - **Removes** networks
      - Must use `docker-compose up` to restart

      ## Common Mistakes

      1. **Using down -v in production**: Accidentally deletes all data
      2. **Forgetting --remove-orphans**: Old containers linger after config changes
      3. **Not specifying timeout**: Long-running tasks get killed abruptly
      4. **Wrong directory**: Must be in same directory as docker-compose.yml

      ## Best Practices

      ### Development Workflow
      ```bash
      # End of day
      docker-compose down  # Clean shutdown, keep data

      # Fresh start (no data)
      docker-compose down -v  # Remove data for testing
      ```

      ### CI/CD Cleanup
      ```bash
      # After tests
      docker-compose down -v --remove-orphans  # Complete cleanup
      ```

      ### Production Deployment
      ```bash
      # NEVER use -v in production!
      docker-compose down  # Keeps volumes with data
      ```

      ## Pro Tips

      1. **Preserve data**: Never use `-v` in production
      2. **Use in scripts**: Add `|| true` to ignore errors if nothing running
      3. **Increase timeout**: Use `-t 30` for services needing graceful shutdown
      4. **Check before down -v**: Verify you want to delete all data
      5. **Remove orphans regularly**: Clean up after compose file changes
      6. **Combine with up**: `docker-compose down && docker-compose up -d` for fresh restart

      ## When to Use docker-compose down

      - End of development session
      - Before major configuration changes
      - CI/CD pipeline cleanup steps
      - When you need to free ports
      - Switching between different projects
      - Complete environment reset
    - docker-compose down
    - '["docker-compose down -v","docker-compose down --rmi all","docker-compose down
      --remove-orphans","docker-compose down -v --rmi all"]'
    - '["Standard cleanup: docker-compose down","Remove volumes too: docker-compose
      down -v","Remove images: docker-compose down --rmi all","After config changes:
      docker-compose down --remove-orphans"]'
    -
    - "[]"
    - medium
    - 10
    - 50
    - docker-compose
    - true
    - What is the difference between docker-compose down and docker-compose stop?
    - mcq
    - '[{"text":"down removes containers and networks, stop only stops containers","correct":true},{"text":"They
      are identical commands","correct":false},{"text":"stop is faster than down","correct":false},{"text":"down
      only works in production","correct":false}]'
    - down removes containers and networks, stop only stops containers
    - docker-compose down performs complete cleanup removing containers and networks,
      while stop only stops containers leaving them and networks intact.
    -
    - '[{"title":"Standard teardown","code":"docker-compose down","explanation":"Stops
      and removes containers and networks, keeps volumes and images"},{"title":"Remove
      data volumes","code":"docker-compose down -v","explanation":"Complete cleanup
      including volumes - DELETES ALL DATA"},{"title":"Remove everything","code":"docker-compose
      down -v --rmi all --remove-orphans","explanation":"Nuclear option - removes
      containers, networks, volumes, images, and orphans"}]'
    - "[]"
    - "[]"
    - '2025-11-06 03:44:04.786263'
    - '2025-11-06 03:44:04.790114'
    - 'End of sprint cleanup: Tear down the entire development stack but preserve
      database volumes for next sprint'
    - Stop and remove all services while keeping persistent data volumes intact
    - '["docker-compose","cleanup","teardown","lifecycle","management"]'
    - "[]"
  - - 51
    - 'Docker Compose Build: Build or Rebuild Service Images'
    - docker-compose-build-command
    - "# Mastering docker-compose build: Building Service Images\n\n## What is docker-compose
      build?\n`docker-compose build` builds or rebuilds images for services that have
      a `build:` configuration in docker-compose.yml. Essential for services using
      custom Dockerfiles rather than pre-built images from registries.\n\n## Why Building
      with Compose Matters\n- **Custom Services**: Build your application images\n-
      **Consistency**: Same build process across team\n- **Build Arguments**: Pass
      variables during build\n- **Parallel Builds**: Build multiple services simultaneously\n-
      **Cache Control**: Force fresh builds when needed\n\n## Basic Syntax\n```bash\ndocker-compose
      build [OPTIONS] [SERVICE...]\n```\n\n## Common Use Cases\n\n### 1. Build All
      Services\n```bash\ndocker-compose build\n```\nBuilds all services with `build:`
      configuration.\n\n### 2. Force Rebuild (No Cache)\n```bash\ndocker-compose build
      --no-cache\n```\nRebuilds from scratch ignoring Docker layer cache.\n\n### 3.
      Build Specific Service\n```bash\ndocker-compose build api\n```\nBuilds only
      the api service.\n\n### 4. Parallel Builds\n```bash\ndocker-compose build --parallel\n```\nBuilds
      multiple services simultaneously for speed.\n\n## Sample docker-compose.yml
      with Build\n\n```yaml\nversion: '3.8'\nservices:\n  web:\n    build:\n      context:
      ./frontend\n      dockerfile: Dockerfile\n      args:\n        NODE_ENV: production\n
      \   ports:\n      - \"3000:3000\"\n  \n  api:\n    build:\n      context: ./backend\n
      \     target: production\n    environment:\n      - DB_HOST=database\n  \n  database:\n
      \   image: postgres:13  # Not built, pulled from registry\n```\n\n## Build Context
      Explained\n\n```yaml\nweb:\n  build:\n    context: ./frontend    # Directory
      with source code\n    dockerfile: Dockerfile  # Optional, defaults to Dockerfile\n```\n\nThe
      context is sent to Docker daemon - use .dockerignore to exclude files!\n\n##
      Build Arguments\n\nPass variables to Dockerfile during build:\n\n```yaml\nservices:\n
      \ api:\n    build:\n      context: ./api\n      args:\n        VERSION: \"1.0.0\"\n
      \       NODE_ENV: production\n```\n\nIn Dockerfile:\n```dockerfile\nARG VERSION\nARG
      NODE_ENV\nRUN echo \"Building version ${VERSION}\"\n```\n\n## Multi-Stage Builds\n\nTarget
      specific build stage:\n\n```yaml\napi:\n  build:\n    context: ./api\n    target:
      production  # Stops at 'production' stage\n```\n\n## Common Options\n\n| Option
      | Description | Example |\n|--------|-------------|---------|\n| `--no-cache`
      | Build without using cache | `docker-compose build --no-cache` |\n| `--pull`
      | Always pull newer base images | `docker-compose build --pull` |\n| `--parallel`
      | Build in parallel | `docker-compose build --parallel` |\n| `--build-arg` |
      Set build arguments | `docker-compose build --build-arg VERSION=2.0` |\n| `--progress`
      | Set progress output type | `docker-compose build --progress plain` |\n\n##
      Build vs Up --build\n\n### docker-compose build\n- Only builds images\n- Doesn't
      start containers\n- Use for CI/CD pipelines\n\n### docker-compose up --build\n-
      Builds images first\n- Then starts containers\n- Convenience for development\n\n##
      When Images Get Built\n\n### Automatic Build\n```bash\ndocker-compose up --build
      \ # Builds then starts\n```\n\n### Manual Build\n```bash\ndocker-compose build
      \      # Build only\ndocker-compose up -d       # Start separately\n```\n\n##
      Pro Tips\n\n1. **Use .dockerignore**: Exclude node_modules, .git, etc.\n2. **Parallel
      builds in CI**: Use `--parallel` for speed\n3. **Pull base images**: Use `--pull`
      to get latest base images\n4. **Build arguments for config**: Pass environment-specific
      values\n5. **Name your builds**: Tag images in compose file\n6. **Cache strategically**:
      Use `--no-cache` only when needed\n"
    - docker-compose build
    - '["docker-compose build --no-cache","docker-compose build --parallel","docker-compose
      build api web"]'
    - '["Build all: docker-compose build","Force rebuild: docker-compose build --no-cache","Specific
      service: docker-compose build api","Fast builds: docker-compose build --parallel"]'
    -
    - "[]"
    - medium
    - 10
    - 51
    - docker-compose
    - true
    - When should you use --no-cache flag?
    - mcq
    - '[{"text":"When you need a clean build without layer caching","correct":true},{"text":"Always,
      it makes builds faster","correct":false},{"text":"Only in production","correct":false},{"text":"When
      images are corrupted","correct":false}]'
    - When you need a clean build without layer caching
    - "--no-cache forces Docker to rebuild every layer from scratch, useful when cache
      might contain stale artifacts or after major dependency changes."
    -
    - '[{"title":"Build all services with build config","code":"docker-compose build","explanation":"Builds
      all services that have build: section in compose file"},{"title":"Force clean
      rebuild","code":"docker-compose build --no-cache --pull","explanation":"Rebuilds
      from scratch and pulls latest base images"},{"title":"Fast parallel builds","code":"docker-compose
      build --parallel","explanation":"Builds multiple services simultaneously - faster
      on multi-core systems"}]'
    - "[]"
    - "[]"
    - '2025-11-06 03:44:04.798439'
    - '2025-11-06 03:44:04.802136'
    - 'After major code changes: Rebuild all application services without cache to
      ensure clean builds'
    - Rebuild application services from scratch for production deployment
    - '["docker-compose","build","images","dockerfile","compilation"]'
    - "[]"
  - - 52
    - 'Docker Compose Logs: View Service Output'
    - docker-compose-logs-command
    - |
      # Mastering docker-compose logs: Monitoring Service Output

      ## What is docker-compose logs?
      `docker-compose logs` displays output from all services or specific ones, with timestamps and service names. Essential for debugging multi-service applications where logs from different containers need correlation.

      ## Why Compose Logs Matter
      - **Unified View**: See all service logs in one place
      - **Service Identification**: Color-coded by service name
      - **Follow Mode**: Real-time log streaming
      - **Time Correlation**: Timestamps for debugging
      - **Filtering**: View specific services only

      ## Common Use Cases

      ### 1. View All Logs
      ```bash
      docker-compose logs
      ```
      Shows logs from all services with service name prefix.

      ### 2. Follow Logs in Real-Time
      ```bash
      docker-compose logs -f
      ```
      Continuously streams new log output (like tail -f).

      ### 3. Specific Service Logs
      ```bash
      docker-compose logs -f api
      ```
      Shows only api service logs in real-time.

      ### 4. Last N Lines
      ```bash
      docker-compose logs --tail=100
      ```
      Shows last 100 lines from each service.

      ## Common Options

      | Option | Description | Example |
      |--------|-------------|---------|
      | `-f` | Follow log output | `docker-compose logs -f` |
      | `--tail=N` | Show last N lines | `docker-compose logs --tail=50` |
      | `-t` | Show timestamps | `docker-compose logs -t` |
      | `--no-color` | No color output | `docker-compose logs --no-color` |

      ## Pro Tips

      1. **Follow specific services**: `docker-compose logs -f api database`
      2. **Timestamps for debugging**: Use `-t` flag
      3. **Limit output**: Use `--tail` to avoid overwhelming output
      4. **Grep logs**: Pipe to grep for filtering
      5. **Multiple terminals**: Open separate terminals for different services
    - docker-compose logs -f
    - '["docker-compose logs","docker-compose logs --tail=100","docker-compose logs
      -f api","docker-compose logs -t -f"]'
    - '["All logs: docker-compose logs","Follow: docker-compose logs -f","Specific
      service: docker-compose logs -f api","Last 100 lines: docker-compose logs --tail=100"]'
    -
    - "[]"
    - easy
    - 10
    - 52
    - docker-compose
    - true
    - What does the -f flag do in docker-compose logs?
    - mcq
    - '[{"text":"Follows logs in real-time like tail -f","correct":true},{"text":"Filters
      logs by pattern","correct":false},{"text":"Shows full timestamps","correct":false},{"text":"Forces
      log rotation","correct":false}]'
    - Follows logs in real-time like tail -f
    - The -f flag continuously streams new log output from services, similar to tail
      -f for regular files.
    -
    - '[{"title":"View all service logs","code":"docker-compose logs","explanation":"Shows
      historical logs from all services"},{"title":"Follow logs in real-time","code":"docker-compose
      logs -f","explanation":"Streams new output from all services continuously"},{"title":"Specific
      service with timestamps","code":"docker-compose logs -f -t api","explanation":"Follows
      api service logs with timestamps for debugging"}]'
    - "[]"
    - "[]"
    - '2025-11-06 03:44:04.811401'
    - '2025-11-06 03:44:04.816299'
    - 'Production debugging: Follow logs from web and api services to debug intermittent
      connection errors'
    - Monitor real-time logs from multiple services to identify error patterns
    - '["docker-compose","logs","debugging","monitoring","troubleshooting"]'
    - "[]"
  - - 53
    - 'Docker Compose PS: List Service Containers'
    - docker-compose-ps-command
    - List containers for services defined in docker-compose.yml, showing status,
      ports, and commands. Quick overview of stack health.
    - docker-compose ps
    - '["docker-compose ps -a","docker-compose ps web api"]'
    - '["List running: docker-compose ps","Include stopped: docker-compose ps -a","Specific
      services: docker-compose ps web"]'
    -
    - "[]"
    - easy
    - 10
    - 53
    - docker-compose
    - true
    - What information does docker-compose ps show?
    - mcq
    - '[{"text":"Container names, status, ports, and commands","correct":true},{"text":"Only
      container IDs","correct":false},{"text":"Full container logs","correct":false},{"text":"Image
      sizes only","correct":false}]'
    - Container names, status, ports, and commands
    - docker-compose ps provides overview including container state, port mappings,
      and running commands.
    -
    - '[{"title":"List running services","code":"docker-compose ps","explanation":"Shows
      status of all services in compose file"},{"title":"Include stopped containers","code":"docker-compose
      ps -a","explanation":"Lists all containers including stopped ones"},{"title":"Check
      specific services","code":"docker-compose ps web api","explanation":"Shows status
      of only web and api services"}]'
    - "[]"
    - "[]"
    - '2025-11-06 03:44:04.824964'
    - '2025-11-06 03:44:04.828991'
    - 'Health check: Verify all services in the stack are running correctly'
    - List all service containers and verify their running status
    - '["docker-compose","listing","status","monitoring","containers"]'
    - "[]"
  - - 54
    - 'Docker Compose Restart: Restart Services'
    - docker-compose-restart-command
    - Restart one or more services without rebuilding or recreating containers. Useful
      for applying configuration changes or recovering from errors.
    - docker-compose restart
    - '["docker-compose restart api","docker-compose restart -t 30 database"]'
    - '["Restart all: docker-compose restart","Specific service: docker-compose restart
      api","Custom timeout: docker-compose restart -t 30 service"]'
    -
    - "[]"
    - medium
    - 10
    - 54
    - docker-compose
    - true
    - Does docker-compose restart rebuild images?
    - mcq
    - '[{"text":"No, it only stops and starts existing containers","correct":true},{"text":"Yes,
      it rebuilds images first","correct":false},{"text":"Only if --build flag is
      used","correct":false},{"text":"Only for services with build: config","correct":false}]'
    - No, it only stops and starts existing containers
    - docker-compose restart is equivalent to stop + start, it does not rebuild images
      or recreate containers.
    -
    - '[{"title":"Restart all services","code":"docker-compose restart","explanation":"Stops
      and starts all services in compose file"},{"title":"Restart specific service","code":"docker-compose
      restart api","explanation":"Restarts only api service quickly"},{"title":"Restart
      with timeout","code":"docker-compose restart -t 60 database","explanation":"Gives
      database 60 seconds for graceful shutdown"}]'
    - "[]"
    - "[]"
    - '2025-11-06 03:44:04.836922'
    - '2025-11-06 03:44:04.840582'
    - 'Service recovery: Restart the API service after configuration file update'
    - Restart specific service to apply new configuration without full teardown
    - '["docker-compose","restart","lifecycle","recovery","maintenance"]'
    - "[]"
  - - 55
    - 'Docker Compose Scale: Scale Service Instances'
    - docker-compose-scale-command
    - 'Scale services to run multiple container instances for load distribution. Note:
      deprecated in favor of --scale flag in up command, but still useful.'
    - docker-compose up -d --scale api=3
    - '["docker-compose up -d --scale web=2 --scale api=4","docker-compose scale api=3"]'
    - '["Modern syntax: docker-compose up -d --scale api=3","Multiple services: docker-compose
      up -d --scale web=2 --scale api=4","Scale down: docker-compose up -d --scale
      api=1"]'
    -
    - "[]"
    - medium
    - 10
    - 55
    - docker-compose
    - true
    - What happens when you scale a service to 3 instances?
    - mcq
    - '[{"text":"Three containers run the same service with load distribution","correct":true},{"text":"The
      service becomes 3x faster","correct":false},{"text":"Data is split across 3
      containers","correct":false},{"text":"Only one container runs at a time","correct":false}]'
    - Three containers run the same service with load distribution
    - Scaling creates multiple container instances of the same service, useful for
      load balancing and high availability.
    -
    - '[{"title":"Scale service to 3 instances","code":"docker-compose up -d --scale
      api=3","explanation":"Runs 3 copies of api service for load distribution"},{"title":"Scale
      multiple services","code":"docker-compose up -d --scale web=2 --scale api=4","explanation":"Scales
      both web and api services simultaneously"},{"title":"Scale down to single instance","code":"docker-compose
      up -d --scale api=1","explanation":"Reduces api service back to single container"}]'
    - "[]"
    - "[]"
    - '2025-11-06 03:44:04.848352'
    - '2025-11-06 03:44:04.852101'
    - 'Load handling: Scale API service to 3 instances to handle increased traffic
      during product launch'
    - Scale API service to multiple instances for high availability
    - '["docker-compose","scaling","load-balancing","high-availability","performance"]'
    - "[]"
  - - 56
    - 'Docker Compose Exec: Execute Commands in Services'
    - docker-compose-exec-command
    - Execute commands in running service containers using service name instead of
      container ID. Essential for debugging and maintenance tasks.
    - docker-compose exec api bash
    - '["docker-compose exec database psql -U postgres","docker-compose exec -T api
      npm test","docker-compose exec web sh"]'
    - '["Interactive shell: docker-compose exec api bash","Run command: docker-compose
      exec api npm test","Non-interactive: docker-compose exec -T api command","As
      specific user: docker-compose exec -u root api apt-get update"]'
    -
    - "[]"
    - medium
    - 10
    - 56
    - docker-compose
    - true
    - What advantage does docker-compose exec have over docker exec?
    - mcq
    - '[{"text":"Uses service names instead of container IDs","correct":true},{"text":"Runs
      faster than docker exec","correct":false},{"text":"Can execute on stopped containers","correct":false},{"text":"Automatically
      restarts services","correct":false}]'
    - Uses service names instead of container IDs
    - docker-compose exec uses friendly service names from compose file instead of
      cryptic container IDs, making commands more readable and maintainable.
    -
    - '[{"title":"Open bash shell in service","code":"docker-compose exec api bash","explanation":"Opens
      interactive bash shell in api service container"},{"title":"Run database command","code":"docker-compose
      exec database psql -U postgres -c \"SELECT * FROM users\"","explanation":"Executes
      SQL query in database service"},{"title":"Non-interactive command","code":"docker-compose
      exec -T api npm test","explanation":"Runs tests without TTY allocation - useful
      in CI/CD"}]'
    - "[]"
    - "[]"
    - '2025-11-06 03:44:04.859688'
    - '2025-11-06 03:44:04.863375'
    - 'Database maintenance: Connect to database service and run SQL migrations directly'
    - Execute commands inside running service containers for debugging and maintenance
    - '["docker-compose","exec","debugging","interactive","maintenance"]'
    - "[]"
  - - 57
    - Docker Network Create
    - docker-network-create
    - Create custom Docker networks for container communication
    - docker network create my-network
    - '["docker network create --driver bridge my-network","docker network create
      --subnet 172.18.0.0/16 my-network"]'
    - '["Create network: docker network create \u003cname\u003e","Specify driver:
      --driver bridge","Set subnet: --subnet \u003ccidr\u003e"]'
    -
    - "[]"
    - medium
    - 10
    - 57
    - docker-networks
    - true
    - What is the default network driver in Docker?
    - mcq
    - '[{"text":"bridge","correct":true},{"text":"host","correct":false},{"text":"overlay","correct":false},{"text":"macvlan","correct":false}]'
    - bridge
    - The bridge driver is the default network driver. If you don't specify a driver,
      this is the type of network you are creating.
    -
    - '[{"title":"Create basic network","code":"docker network create my-app-network","explanation":"Creates
      a bridge network with default settings"},{"title":"Create with subnet","code":"docker
      network create --subnet 172.18.0.0/16 --gateway 172.18.0.1 my-network","explanation":"Specifies
      custom IP range for the network"}]'
    - "[]"
    - "[]"
    - '2025-11-06 04:01:39.811399'
    - '2025-11-06 04:01:39.821087'
    - Create an isolated network for microservices
    - Create a custom bridge network for service isolation
    - '["networking","docker-network","bridge","isolation"]'
    - "[]"
  - - 58
    - Docker Network List
    - docker-network-ls
    - List all Docker networks on the system
    - docker network ls
    - '["docker network list","docker network ls --filter driver=bridge"]'
    - '["List networks: docker network ls","Filter by driver: --filter driver=\u003ctype\u003e"]'
    -
    - "[]"
    - easy
    - 10
    - 58
    - docker-networks
    - true
    - Which default networks are created by Docker?
    - mcq
    - '[{"text":"bridge, host, none","correct":true},{"text":"default, public, private","correct":false},{"text":"bridge,
      overlay","correct":false},{"text":"nat, bridge","correct":false}]'
    - bridge, host, none
    - 'Docker creates three default networks: bridge (default for containers), host
      (no isolation), and none (no networking).'
    -
    - '[{"title":"List all networks","code":"docker network ls","explanation":"Shows
      all networks with their driver types"},{"title":"Filter by driver","code":"docker
      network ls --filter driver=bridge","explanation":"Shows only bridge networks"}]'
    - "[]"
    - "[]"
    - '2025-11-06 04:01:39.831618'
    - '2025-11-06 04:01:39.833875'
    - Check what networks exist before creating new ones
    - Display all available Docker networks
    - '["networking","docker-network","listing","inspection"]'
    - "[]"
  - - 59
    - Docker Network Inspect
    - docker-network-inspect
    - View detailed network configuration and connected containers
    - docker network inspect my-network
    - '["docker network inspect --format=\"{{.IPAM.Config}}\" my-network"]'
    - '["Inspect network: docker network inspect \u003cname\u003e","Format output:
      --format=\"{{.Field}}\""]'
    -
    - "[]"
    - medium
    - 10
    - 59
    - docker-networks
    - true
    - What information does docker network inspect provide?
    - mcq
    - '[{"text":"Network configuration, subnet, and connected containers","correct":true},{"text":"Only
      container names","correct":false},{"text":"Only IP addresses","correct":false},{"text":"Only
      network driver","correct":false}]'
    - Network configuration, subnet, and connected containers
    - docker network inspect shows complete network details including subnet, gateway,
      connected containers, and their IP addresses.
    -
    - '[{"title":"Inspect network","code":"docker network inspect bridge","explanation":"Shows
      full JSON configuration of bridge network"},{"title":"Get subnet info","code":"docker
      network inspect --format=\"{{range .IPAM.Config}}{{.Subnet}}{{end}}\" my-network","explanation":"Extracts
      just the subnet information"}]'
    - "[]"
    - "[]"
    - '2025-11-06 04:01:39.838855'
    - '2025-11-06 04:01:39.841167'
    - Debug connectivity issues by inspecting network details
    - View network configuration and connected containers
    - '["networking","docker-network","inspection","debugging"]'
    - "[]"
  - - 60
    - Docker Network Connect
    - docker-network-connect
    - Connect a running container to a network
    - docker network connect my-network my-container
    - '["docker network connect --ip 172.18.0.22 my-network my-container","docker
      network connect --alias db my-network my-container"]'
    - '["Connect container: docker network connect \u003cnetwork\u003e \u003ccontainer\u003e","Assign
      IP: --ip \u003caddress\u003e","Add alias: --alias \u003cname\u003e"]'
    -
    - "[]"
    - medium
    - 10
    - 60
    - docker-networks
    - true
    - Can a container be connected to multiple networks?
    - mcq
    - '[{"text":"Yes, containers can join multiple networks","correct":true},{"text":"No,
      only one network per container","correct":false},{"text":"Only in swarm mode","correct":false},{"text":"Only
      with overlay networks","correct":false}]'
    - Yes, containers can join multiple networks
    - Containers can be connected to multiple networks simultaneously, allowing flexible
      network topologies.
    -
    - '[{"title":"Connect to network","code":"docker network connect frontend-net
      web-server","explanation":"Connects web-server container to frontend-net network"},{"title":"Connect
      with IP","code":"docker network connect --ip 172.18.0.10 app-net api-server","explanation":"Connects
      with specific IP address assignment"}]'
    - "[]"
    - "[]"
    - '2025-11-06 04:01:39.845566'
    - '2025-11-06 04:01:39.847566'
    - Add a container to an additional network for multi-network communication
    - Connect a running container to a custom network
    - '["networking","docker-network","connect","multi-network"]'
    - "[]"
  - - 61
    - Docker Network Disconnect
    - docker-network-disconnect
    - Disconnect a container from a network
    - docker network disconnect my-network my-container
    - '["docker network disconnect -f my-network my-container"]'
    - '["Disconnect: docker network disconnect \u003cnetwork\u003e \u003ccontainer\u003e","Force
      disconnect: -f flag"]'
    -
    - "[]"
    - medium
    - 10
    - 61
    - docker-networks
    - true
    - What happens when you disconnect a container from its only network?
    - mcq
    - '[{"text":"Container loses all network connectivity","correct":true},{"text":"Container
      is automatically stopped","correct":false},{"text":"Container joins the bridge
      network","correct":false},{"text":"Operation fails","correct":false}]'
    - Container loses all network connectivity
    - Disconnecting a container from its only network leaves it without any network
      connectivity until connected to another network.
    -
    - '[{"title":"Disconnect from network","code":"docker network disconnect backend-net
      api-server","explanation":"Removes api-server from backend-net network"},{"title":"Force
      disconnect","code":"docker network disconnect -f frontend-net web-server","explanation":"Forces
      disconnection even if container is running"}]'
    - "[]"
    - "[]"
    - '2025-11-06 04:01:39.851879'
    - '2025-11-06 04:01:39.854088'
    - Remove container from network for security isolation
    - Disconnect a container from a specific network
    - '["networking","docker-network","disconnect","isolation"]'
    - "[]"
  - - 62
    - Docker Network Remove
    - docker-network-rm
    - Delete one or more Docker networks
    - docker network rm my-network
    - '["docker network rm network1 network2 network3","docker network prune"]'
    - '["Remove network: docker network rm \u003cname\u003e","Remove multiple: docker
      network rm \u003cname1\u003e \u003cname2\u003e","Remove unused: docker network
      prune"]'
    -
    - "[]"
    - easy
    - 10
    - 62
    - docker-networks
    - true
    - Can you remove a network with containers still connected?
    - mcq
    - '[{"text":"No, must disconnect all containers first","correct":true},{"text":"Yes,
      containers auto-disconnect","correct":false},{"text":"Yes, with -f flag","correct":false},{"text":"Only
      if containers are stopped","correct":false}]'
    - No, must disconnect all containers first
    - Docker will not remove a network that has active container connections. All
      containers must be disconnected or removed first.
    -
    - '[{"title":"Remove network","code":"docker network rm test-network","explanation":"Deletes
      the test-network if no containers are connected"},{"title":"Remove unused networks","code":"docker
      network prune -f","explanation":"Removes all networks not used by any container"}]'
    - "[]"
    - "[]"
    - '2025-11-06 04:01:39.858559'
    - '2025-11-06 04:01:39.860927'
    - Clean up unused networks to free resources
    - Remove a Docker network that is no longer needed
    - '["networking","docker-network","cleanup","removal"]'
    - "[]"
  - - 63
    - Docker Network Prune
    - docker-network-prune
    - Remove all unused Docker networks in one command
    - docker network prune
    - '["docker network prune -f","docker network prune --filter until=24h"]'
    - '["Prune networks: docker network prune","Skip confirmation: -f flag","Filter
      by age: --filter until=\u003ctime\u003e"]'
    -
    - "[]"
    - easy
    - 10
    - 63
    - docker-networks
    - true
    - What does docker network prune remove?
    - mcq
    - '[{"text":"Only networks not used by any container","correct":true},{"text":"All
      custom networks","correct":false},{"text":"All networks including defaults","correct":false},{"text":"Only
      networks older than 1 day","correct":false}]'
    - Only networks not used by any container
    - docker network prune only removes networks that are not currently connected
      to any container. Default networks and active networks are preserved.
    -
    - '[{"title":"Prune unused networks","code":"docker network prune","explanation":"Interactively
      removes all unused networks"},{"title":"Force prune","code":"docker network
      prune -f","explanation":"Removes unused networks without confirmation prompt"}]'
    - "[]"
    - "[]"
    - '2025-11-06 04:01:39.866042'
    - '2025-11-06 04:01:39.868462'
    - Perform routine cleanup of unused networks
    - Remove all unused networks to reclaim resources
    - '["networking","docker-network","cleanup","prune","maintenance"]'
    - "[]"
  - - 64
    - Docker Volume Create
    - docker-volume-create
    - Create named volumes for persistent data storage
    - docker volume create my-volume
    - '["docker volume create --driver local my-volume","docker volume create --label
      env=production my-volume"]'
    - '["Create volume: docker volume create \u003cname\u003e","Specify driver: --driver
      \u003ctype\u003e","Add labels: --label \u003ckey\u003e=\u003cvalue\u003e"]'
    -
    - "[]"
    - easy
    - 10
    - 64
    - docker-volumes
    - true
    - Why use named volumes instead of bind mounts?
    - mcq
    - '[{"text":"Volumes are managed by Docker and work across platforms","correct":true},{"text":"Bind
      mounts are slower","correct":false},{"text":"Volumes require root access","correct":false},{"text":"Bind
      mounts cannot be shared","correct":false}]'
    - Volumes are managed by Docker and work across platforms
    - Named volumes are managed by Docker, work consistently across different platforms,
      and can be easily backed up and migrated.
    -
    - '[{"title":"Create basic volume","code":"docker volume create data-volume","explanation":"Creates
      a named volume managed by Docker"},{"title":"Create with labels","code":"docker
      volume create --label app=database --label env=prod db-data","explanation":"Creates
      volume with metadata labels for organization"}]'
    - "[]"
    - "[]"
    - '2025-11-06 04:02:24.128221'
    - '2025-11-06 04:02:24.130884'
    - Create a persistent volume for database data
    - Create a named volume for data persistence
    - '["volumes","docker-volume","persistence","storage"]'
    - "[]"
  - - 65
    - Docker Volume List
    - docker-volume-ls
    - List all Docker volumes on the system
    - docker volume ls
    - '["docker volume list","docker volume ls --filter dangling=true"]'
    - '["List volumes: docker volume ls","Find dangling: --filter dangling=true","Filter
      by label: --filter label=\u003ckey\u003e=\u003cvalue\u003e"]'
    -
    - "[]"
    - easy
    - 10
    - 65
    - docker-volumes
    - true
    - What is a dangling volume?
    - mcq
    - '[{"text":"A volume not attached to any container","correct":true},{"text":"A
      volume with corrupted data","correct":false},{"text":"A volume that is full","correct":false},{"text":"A
      volume without a name","correct":false}]'
    - A volume not attached to any container
    - Dangling volumes are volumes that are no longer referenced by any container
      and can be safely removed.
    -
    - '[{"title":"List all volumes","code":"docker volume ls","explanation":"Shows
      all volumes with driver and name"},{"title":"List dangling volumes","code":"docker
      volume ls --filter dangling=true","explanation":"Shows only volumes not used
      by any container"}]'
    - "[]"
    - "[]"
    - '2025-11-06 04:02:24.139309'
    - '2025-11-06 04:02:24.141534'
    - Check existing volumes before creating new ones
    - Display all Docker volumes on the system
    - '["volumes","docker-volume","listing","inspection"]'
    - "[]"
  - - 66
    - Docker Volume Inspect
    - docker-volume-inspect
    - View detailed information about a volume
    - docker volume inspect my-volume
    - '["docker volume inspect --format=\"{{.Mountpoint}}\" my-volume"]'
    - '["Inspect volume: docker volume inspect \u003cname\u003e","Get mountpoint:
      --format=\"{{.Mountpoint}}\""]'
    -
    - "[]"
    - medium
    - 10
    - 66
    - docker-volumes
    - true
    - Where does Docker store volume data by default?
    - mcq
    - '[{"text":"/var/lib/docker/volumes/","correct":true},{"text":"/docker/volumes/","correct":false},{"text":"/tmp/docker/volumes/","correct":false},{"text":"/opt/docker/volumes/","correct":false}]'
    - "/var/lib/docker/volumes/"
    - Docker stores volume data in /var/lib/docker/volumes/ by default on Linux systems.
    -
    - '[{"title":"Inspect volume","code":"docker volume inspect data-volume","explanation":"Shows
      full JSON details of the volume"},{"title":"Get mountpoint","code":"docker volume
      inspect --format=\"{{.Mountpoint}}\" data-volume","explanation":"Extracts just
      the filesystem path"}]'
    - "[]"
    - "[]"
    - '2025-11-06 04:02:24.145954'
    - '2025-11-06 04:02:24.148065'
    - Find the physical location of volume data for backup
    - View volume configuration and mountpoint location
    - '["volumes","docker-volume","inspection","debugging"]'
    - "[]"
  - - 67
    - Docker Volume Remove
    - docker-volume-rm
    - Delete one or more Docker volumes
    - docker volume rm my-volume
    - '["docker volume rm volume1 volume2 volume3"]'
    - '["Remove volume: docker volume rm \u003cname\u003e","Remove multiple: docker
      volume rm \u003cname1\u003e \u003cname2\u003e","Cannot remove if in use"]'
    -
    - "[]"
    - easy
    - 10
    - 67
    - docker-volumes
    - true
    - Can you remove a volume that is currently mounted to a container?
    - mcq
    - '[{"text":"No, must remove/stop container first","correct":true},{"text":"Yes,
      container will auto-recreate it","correct":false},{"text":"Yes, with -f flag","correct":false},{"text":"Only
      if container is stopped","correct":false}]'
    - No, must remove/stop container first
    - Docker will not remove a volume that is mounted to a running or stopped container.
      The container must be removed first.
    -
    - '[{"title":"Remove volume","code":"docker volume rm old-data","explanation":"Permanently
      deletes the volume and its data"},{"title":"Remove multiple","code":"docker
      volume rm vol1 vol2 vol3","explanation":"Removes multiple volumes in one command"}]'
    - "[]"
    - "[]"
    - '2025-11-06 04:02:24.157419'
    - '2025-11-06 04:02:24.159510'
    - Clean up old volumes to free disk space
    - Remove unused Docker volumes
    - '["volumes","docker-volume","cleanup","removal"]'
    - "[]"
  - - 68
    - Docker Volume Prune
    - docker-volume-prune
    - Remove all unused volumes in one command
    - docker volume prune
    - '["docker volume prune -f","docker volume prune --filter label=temporary=true"]'
    - '["Prune volumes: docker volume prune","Skip confirmation: -f flag","Filter
      by label: --filter label=\u003ckey\u003e=\u003cvalue\u003e"]'
    -
    - "[]"
    - easy
    - 10
    - 68
    - docker-volumes
    - true
    - What volumes does docker volume prune remove?
    - mcq
    - '[{"text":"Only volumes not referenced by any container","correct":true},{"text":"All
      anonymous volumes","correct":false},{"text":"All named volumes","correct":false},{"text":"Volumes
      older than 24 hours","correct":false}]'
    - Only volumes not referenced by any container
    - docker volume prune only removes volumes that are not currently mounted to any
      container (dangling volumes).
    -
    - '[{"title":"Prune unused volumes","code":"docker volume prune","explanation":"Interactively
      removes all dangling volumes"},{"title":"Force prune","code":"docker volume
      prune -f","explanation":"Removes dangling volumes without confirmation"}]'
    - "[]"
    - "[]"
    - '2025-11-06 04:02:24.163779'
    - '2025-11-06 04:02:24.166064'
    - Perform routine cleanup of dangling volumes
    - Remove all unused volumes to reclaim disk space
    - '["volumes","docker-volume","cleanup","prune","maintenance"]'
    - "[]"
  - - 69
    - Docker Run with Volumes
    - docker-run-with-volume
    - Mount volumes to containers for persistent data
    - docker run -v my-volume:/data nginx
    - '["docker run -v my-volume:/app/data:ro nginx","docker run --mount source=my-volume,target=/data
      nginx"]'
    - '["Mount volume: -v \u003cvolume\u003e:\u003ccontainer-path\u003e","Read-only:
      -v \u003cvolume\u003e:\u003cpath\u003e:ro","New syntax: --mount source=\u003cvol\u003e,target=\u003cpath\u003e"]'
    -
    - "[]"
    - medium
    - 10
    - 69
    - docker-volumes
    - true
    - What happens to data in a volume when you remove the container?
    - mcq
    - '[{"text":"Data persists in the volume","correct":true},{"text":"Data is deleted
      automatically","correct":false},{"text":"Data is backed up first","correct":false},{"text":"Depends
      on the --rm flag","correct":false}]'
    - Data persists in the volume
    - Volume data persists independently of container lifecycle. Even when containers
      are removed, the data remains in the volume.
    -
    - '[{"title":"Mount named volume","code":"docker run -d -v db-data:/var/lib/mysql
      mysql","explanation":"Mounts db-data volume to MySQL data directory"},{"title":"Read-only
      mount","code":"docker run -v config-vol:/app/config:ro nginx","explanation":"Mounts
      volume as read-only to prevent modifications"}]'
    - "[]"
    - "[]"
    - '2025-11-06 04:02:24.170304'
    - '2025-11-06 04:02:24.172475'
    - Run a database container with persistent storage
    - Mount a volume to a container for data persistence
    - '["volumes","docker-run","persistence","mounting"]'
    - "[]"
  - - 70
    - Bind Mounts vs Volumes
    - docker-bind-mounts-vs-volumes
    - Understand the differences between bind mounts and volumes
    - docker run -v /host/path:/container/path nginx
    - '["docker run -v $(pwd):/app nginx","docker run --mount type=bind,source=/host/path,target=/container/path
      nginx"]'
    - '["Bind mount: -v /absolute/host/path:/container/path","Current dir: -v $(pwd):/app","Explicit:
      --mount type=bind,source=...,target=..."]'
    -
    - "[]"
    - medium
    - 10
    - 70
    - docker-volumes
    - true
    - When should you use bind mounts instead of volumes?
    - mcq
    - '[{"text":"During development to sync code changes","correct":true},{"text":"For
      production databases","correct":false},{"text":"For better performance","correct":false},{"text":"For
      cross-platform compatibility","correct":false}]'
    - During development to sync code changes
    - Bind mounts are ideal for development when you want file changes to immediately
      reflect in containers. Volumes are better for production data.
    -
    - '[{"title":"Bind mount current directory","code":"docker run -v $(pwd):/app
      node:14 npm start","explanation":"Mounts current directory for live code updates
      during development"},{"title":"Named volume for data","code":"docker run -v
      postgres-data:/var/lib/postgresql/data postgres","explanation":"Uses managed
      volume for database persistence in production"}]'
    - "[]"
    - "[]"
    - '2025-11-06 04:02:24.177180'
    - '2025-11-06 04:02:24.179600'
    - Choose between bind mounts for development and volumes for production
    - Understand when to use bind mounts vs volumes
    - '["volumes","bind-mounts","comparison","best-practices"]'
    - "[]"
  - - 71
    - 'CodeSprout: Exposing Containers with Port Mapping'
    - codesprout-docker-run
    - "**Port Mapping Challenge** \U0001F310\n\nYour team lead Sarah has a problem:\n\n>
      \"We deployed our marketing site in a container, but no one can access it! The
      container is running\n> but when we try to visit the site, nothing loads. Can
      you figure out why?\"\n\n### The Problem\nContainers are **isolated by default**.
      Even if nginx is running perfectly inside the container on port 80,\nyour browser
      on your host machine can't reach it. You need to **map** (publish) the container's
      port to your host.\n\n### Port Mapping Explained\nPort mapping connects a port
      on your **host machine** to a port inside the **container**:\n\n```bash\ndocker
      run -p HOST_PORT:CONTAINER_PORT image\n```\n\n- **HOST_PORT** (e.g., `8080`)
      → Port on your computer\n- **CONTAINER_PORT** (e.g., `80`) → Port inside the
      container where the app listens\n- **Format**: `-p 8080:80` means \"send traffic
      from host port 8080 to container port 80\"\n\n### Visual Example\n```\nYour
      Browser → http://localhost:8080 → Docker NAT → Container Port 80 → nginx\n```\n\n###
      The Solution\nTo make the CodeSprout site accessible, we need to:\n1. Map host
      port `8080` to container port `80` (where nginx listens)\n2. Run in detached
      mode (`-d`) so the terminal isn't blocked\n3. Name it `codesprout-web` for easy
      reference\n\n```bash\ndocker run -d -p 8080:80 --name codesprout-web nginx:alpine\n```\n\nAfter
      this, anyone can visit `http://localhost:8080` and see the site!\n\n### Common
      Mistakes\n- **Swapping ports**: `-p 80:8080` would try to map your host's port
      80 to container 8080 (wrong direction!)\n- **Forgetting `-p`**: Container runs
      but can't be accessed from outside\n- **Port conflicts**: If port 8080 is already
      in use, Docker will error - try a different port like 8081\n"
    - docker run -d -p 8080:80 --name codesprout-web nginx:alpine
    - '["docker run -d --name codesprout-web -p 8080:80 nginx:alpine","docker run
      --name codesprout-web -d -p 8080:80 nginx:alpine"]'
    - '["Port mapping format: -p HOST:CONTAINER → -p 8080:80","Remember: first number
      (8080) is your host, second (80) is the container","Use -d to run in background
      and free your terminal","Full command: docker run -d -p 8080:80 --name codesprout-web
      nginx:alpine"]'
    -
    - "[]"
    - easy
    - 8
    - 100
    - networking
    - true
    - In "docker run -p 8080:80 nginx", what does 8080 represent?
    - mcq
    - '[{"text":"The port on the host machine","correct":true},{"text":"The port inside
      the container","correct":false},{"text":"The container ID","correct":false},{"text":"The
      process ID","correct":false}]'
    - The port on the host machine
    - In -p HOST:CONTAINER format, the first number (8080) is the host port, second
      (80) is container port
    -
    - '[{"title":"Map different host port to same container port","code":"docker run
      -d -p 9000:80 --name web-alt nginx:alpine","explanation":"You can map any available
      host port (9000) to container port 80. Access it at http://localhost:9000"},{"title":"Map
      multiple ports for services with HTTP and HTTPS","code":"docker run -d -p 8080:80
      -p 8443:443 --name web-secure nginx:alpine","explanation":"Map multiple ports:
      HTTP (8080→80) and HTTPS (8443→443). Useful for services that need both."},{"title":"Auto-restart
      on reboot or crash","code":"docker run -d --restart unless-stopped --name web
      -p 8080:80 nginx:alpine","explanation":"Keeps your service up across daemon
      restarts or machine reboots."},{"title":"Bind to specific host interface","code":"docker
      run -d -p 127.0.0.1:8080:80 --name web-local nginx:alpine","explanation":"Only
      accessible from localhost (127.0.0.1), not from other machines on the network.
      More secure."},{"title":"Let Docker assign random host port","code":"docker
      run -d -p 80 --name web-random nginx:alpine","explanation":"Docker picks an
      available host port automatically. Check with: docker port web-random"},{"title":"Verify
      port mappings","code":"docker port codesprout-web","explanation":"Shows which
      host ports are mapped to container ports. Useful for debugging connectivity
      issues."}]'
    - "[]"
    - "[]"
    - '2025-11-06 04:12:16.915073'
    - '2025-11-06 04:12:16.918336'
    - "Sarah: \"The site is running but we can't access it from our browsers. \nWe
      need to expose port 80 from the container to port 8080 on the host.\nOnce you
      map the ports, we should be able to visit http://localhost:8080\"\n"
    - Expose the nginx container on port 80 so it can be accessed via http://localhost:8080
    - '["docker-run","port-mapping","networking","container-exposure","publishing-ports"]'
    - "[]"
  - - 72
    - Run Nginx in the Background
    - codesprout-detached-nginx
    - Run services without blocking your terminal using detached mode (-d).
    - docker run -d nginx:alpine
    - "[]"
    - '["Use the -d flag for detached mode"]'
    -
    - "[]"
    - easy
    - 3
    - 101
    - containers
    - true
    - What does -d do?
    - mcq
    - '[{"text":"Runs in detached mode","correct":true},{"text":"Deletes the container","correct":false},{"text":"Downloads
      image only","correct":false},{"text":"Debug mode","correct":false}]'
    - Runs in detached mode
    - Detached mode frees your terminal for other commands.
    -
    - "[]"
    - "[]"
    - "[]"
    - '2025-11-06 04:12:16.947605'
    - '2025-11-06 04:12:16.947605'
    - '> Sarah: "When I run our server, I can''t type anything else. Help me run it
      in the background."'
    -
    - '["detached-mode","docker-run"]'
    - "[]"
  - - 73
    - Naming Your Containers
    - codesprout-naming-containers
    - Use --name to assign a friendly name to containers.
    - docker run -d --name codesprout-web nginx:alpine
    - "[]"
    - '["Use --name codesprout-web"]'
    -
    - "[]"
    - easy
    - 3
    - 102
    - containers
    - true
    - Why is naming containers helpful?
    - mcq
    - '[{"text":"Easier management","correct":true},{"text":"Faster containers","correct":false},{"text":"Smaller
      images","correct":false},{"text":"Free TLS","correct":false}]'
    - Easier management
    - Names make scripting, logs, and teamwork easier.
    -
    - "[]"
    - "[]"
    - "[]"
    - '2025-11-06 04:12:16.952944'
    - '2025-11-06 04:12:16.952944'
    - '> Sarah: "Please name the web container codesprout-web so everyone knows what
      it is."'
    -
    - '["naming-containers"]'
    - "[]"
  - - 74
    - Listing Containers
    - codesprout-docker-ps
    - Use docker ps to list running containers, and docker ps -a for all containers.
    - docker ps
    - "[]"
    - '["Try docker ps -a to include stopped ones"]'
    -
    - "[]"
    - easy
    - 2
    - 103
    - containers
    - true
    - Which command lists all containers including stopped ones?
    - mcq
    - '[{"text":"docker ps -a","correct":true},{"text":"docker list --all","correct":false},{"text":"docker
      containers","correct":false},{"text":"docker ps --running","correct":false}]'
    -
    - Use -a to include stopped containers.
    -
    - "[]"
    - "[]"
    - "[]"
    - '2025-11-06 04:12:16.958405'
    - '2025-11-06 04:12:16.958405'
    - '> Sarah: "Can you check if codesprout-web is running and share the status?"'
    -
    - '["docker-ps"]'
    - "[]"
  - - 77
    - Executing Commands in Containers
    - codesprout-docker-exec
    - Use docker exec -it <container> sh to get a shell (bash may not exist).
    - docker exec -it codesprout-web sh
    - "[]"
    - '["Use -it for interactive terminals"]'
    -
    - "[]"
    - easy
    - 3
    - 104
    - containers
    - true
    - What does -it stand for in docker exec?
    - mcq
    - '[{"text":"Interactive + TTY","correct":true},{"text":"Internal + Test","correct":false},{"text":"Init
      + Terminal","correct":false},{"text":"Immediate + TTY","correct":false}]'
    -
    - "-i keeps STDIN open; -t allocates a pseudo-TTY."
    -
    - "[]"
    - "[]"
    - "[]"
    - '2025-11-06 04:12:16.978347'
    - '2025-11-06 04:12:16.978347'
    - '> Sarah: "Jump into the container and check /usr/share/nginx/html."'
    -
    - '["docker-exec"]'
    - "[]"
  - - 78
    - Viewing Container Logs
    - codesprout-docker-logs
    - docker logs shows container stdout/stderr; use -f to follow new output.
    - docker logs codesprout-web
    - "[]"
    - '["Use -f to follow the logs in real-time"]'
    -
    - "[]"
    - easy
    - 2
    - 105
    - containers
    - true
    - Which flag follows logs as they are written?
    - mcq
    - '[{"text":"-f","correct":true},{"text":"-t","correct":false},{"text":"--tail
      100","correct":false},{"text":"-F","correct":false}]'
    -
    - Use -f (follow) to stream logs.
    -
    - "[]"
    - "[]"
    - "[]"
    - '2025-11-06 04:12:16.983740'
    - '2025-11-06 04:12:16.983740'
    - '> Sarah: "Check the web server logs for errors."'
    -
    - '["docker-logs"]'
    - "[]"
  - - 75
    - Stopping Containers
    - codesprout-docker-stop
    - docker stop sends SIGTERM then SIGKILL after a timeout to gracefully stop a
      container.
    - docker stop codesprout-web
    - "[]"
    - '["docker stop \u003cname\u003e"]'
    -
    - "[]"
    - easy
    - 2
    - 106
    - containers
    - true
    - What signal does docker stop send first?
    - mcq
    - '[{"text":"SIGTERM","correct":true},{"text":"SIGKILL","correct":false},{"text":"SIGHUP","correct":false},{"text":"SIGINT","correct":false}]'
    -
    - SIGTERM allows for graceful shutdown before SIGKILL.
    -
    - "[]"
    - "[]"
    - "[]"
    - '2025-11-06 04:12:16.968486'
    - '2025-11-06 04:12:16.968486'
    - '> Sarah: "Pause the server—we''re deploying a config change."'
    -
    - '["docker-stop"]'
    - "[]"
  - - 76
    - Removing Containers
    - codesprout-docker-rm
    - docker rm removes stopped containers; use -f to force-remove running ones (not
      recommended).
    - docker rm codesprout-web
    - "[]"
    - '["Remove only after stopping the container"]'
    -
    - "[]"
    - easy
    - 2
    - 107
    - containers
    - true
    - Can docker rm remove a running container without -f?
    - mcq
    - '[{"text":"No","correct":true},{"text":"Yes","correct":false}]'
    -
    - docker rm works on stopped containers unless -f is used.
    -
    - "[]"
    - "[]"
    - "[]"
    - '2025-11-06 04:12:16.973358'
    - '2025-11-06 04:12:16.973358'
    - '> Sarah: "We keep a clean house—remove any stopped containers you created."'
    -
    - '["docker-rm"]'
    - "[]"
  - - 79
    - Building the CodeSprout Frontend
    - codesprout-build-frontend
    - |
      # Building the Frontend Image

      Sarah: "Alright team, let's start deploying CodeSprout! First up: the frontend.
      Our users will interact with a React web application that needs to be containerized."

      ## What We're Building
      CodeSprout is a task management application with three components:
      - **Frontend**: React app (what users see)
      - **Backend**: Node.js API (business logic)
      - **Database**: PostgreSQL (data storage)

      ## Building the Frontend

      The frontend is a React application. To containerize it, we need a Dockerfile that:
      1. Uses a Node.js base image
      2. Copies the application code
      3. Installs dependencies (`npm install`)
      4. Builds the React app (`npm run build`)
      5. Serves it with a lightweight server

      **Command**: `docker build -t codesprout/frontend:1.0 ./frontend`

      This creates an image tagged `codesprout/frontend:1.0` from the code in `./frontend` directory.
    - docker build -t codesprout/frontend:1.0 ./frontend
    - '["docker build --tag codesprout/frontend:1.0 ./frontend","docker image build
      -t codesprout/frontend:1.0 ./frontend"]'
    - '["Use -t to tag the image with a name and version","Format: docker build -t
      NAME:TAG PATH","The path (./frontend) points to the directory with the Dockerfile","Try:
      docker build -t codesprout/frontend:1.0 ./frontend"]'
    -
    - "[]"
    - medium
    - 4
    - 108
    - images
    - true
    - What does the -t flag do in 'docker build'?
    - mcq
    - '[{"text":"Tags the image with a name and version","correct":true},{"text":"Sets
      build timeout","correct":false},{"text":"Runs tests after building","correct":false},{"text":"Creates
      a temporary image","correct":false}]'
    - Tags the image with a name and version
    - The -t flag tags the built image, making it easy to reference with a meaningful
      name like 'codesprout/frontend:1.0'
    -
    - "[]"
    - '["Build Docker images from Dockerfiles","Tag images with names and versions"]'
    - '["running-nginx-detached"]'
    - '2025-11-06 04:12:46.218345'
    - '2025-11-06 04:12:46.218345'
    - Build the CodeSprout frontend image so we can run the web interface.
    -
    - '["docker-build","image-tagging","dockerfiles"]'
    - "[]"
  - - 80
    - Running the Frontend on Port 3000
    - codesprout-run-frontend
    - |
      # Exposing the Frontend

      Sarah: "Great! Now let's run the frontend and make it accessible at localhost:3000."

      ## Why Port 3000?

      The React development server traditionally runs on port 3000. Users expect to access
      web applications at familiar ports:
      - Port 80/443: Production web servers
      - Port 3000: Development React/Node apps
      - Port 8080: Alternative web server port

      ## Running with Port Mapping

      **Command**: `docker run -d -p 3000:3000 --name codesprout-web codesprout/frontend:1.0`

      Breaking it down:
      - `-d`: Run in background (detached mode)
      - `-p 3000:3000`: Map host port 3000 to container port 3000
      - `--name codesprout-web`: Give it a memorable name
      - `codesprout/frontend:1.0`: The image we just built

      Now visit http://localhost:3000 and you'll see the CodeSprout interface!
    - docker run -d -p 3000:3000 --name codesprout-web codesprout/frontend:1.0
    - '["docker run --detach -p 3000:3000 --name codesprout-web codesprout/frontend:1.0","docker
      run -d --name codesprout-web -p 3000:3000 codesprout/frontend:1.0"]'
    - '["Map port 3000 on host to port 3000 in container","Use -d to run in background","Name
      it ''codesprout-web'' for easy reference","Try: docker run -d -p 3000:3000 --name
      codesprout-web codesprout/frontend:1.0"]'
    -
    - "[]"
    - easy
    - 3
    - 109
    - networking
    - true
    - Why do we map port 3000:3000?
    - mcq
    - '[{"text":"To access the container''s port 3000 from the host''s port 3000","correct":true},{"text":"To
      run two instances on the same port","correct":false},{"text":"To create a port
      range","correct":false},{"text":"For security purposes only","correct":false}]'
    - To access the container's port 3000 from the host's port 3000
    - Port mapping makes services inside containers accessible from your host machine.
    -
    - "[]"
    - '["Map container ports to host","Run web applications in containers"]'
    - '["codesprout-build-frontend"]'
    - '2025-11-06 04:12:46.221633'
    - '2025-11-06 04:12:46.221633'
    - Run the CodeSprout frontend container so users can access it at localhost:3000.
    -
    - '["port-mapping","docker-run","web-servers"]'
    - "[]"
  - - 81
    - Configuring with Environment Variables
    - codesprout-frontend-env
    - |
      # Environment Variables for Configuration

      Sarah: "The frontend needs to know where the backend API is. Let's pass that as an environment variable."

      ## Why Environment Variables?

      Environment variables let you configure containers without rebuilding images:
      - **API endpoints**: Where to find the backend
      - **Feature flags**: Enable/disable features
      - **Debug modes**: Control logging levels

      ## Setting Environment Variables

      **Command**: `docker run -d -p 3000:3000 -e API_URL=http://localhost:8080 --name codesprout-web codesprout/frontend:1.0`

      The `-e` flag sets environment variables:
      - `-e API_URL=http://localhost:8080`: Backend API location
      - Multiple `-e` flags for multiple variables
      - Variables are accessible inside the container

      Now the React app knows to send API requests to http://localhost:8080!
    - docker run -d -p 3000:3000 -e API_URL=http://localhost:8080 --name codesprout-web
      codesprout/frontend:1.0
    - '["docker run -d -p 3000:3000 --env API_URL=http://localhost:8080 --name codesprout-web
      codesprout/frontend:1.0","docker run -d -e API_URL=http://localhost:8080 -p
      3000:3000 --name codesprout-web codesprout/frontend:1.0"]'
    - '["Use -e to set environment variables","Format: -e VARIABLE=value","Set API_URL
      to http://localhost:8080","Try: docker run -d -p 3000:3000 -e API_URL=http://localhost:8080
      --name codesprout-web codesprout/frontend:1.0"]'
    -
    - "[]"
    - easy
    - 3
    - 110
    - configuration
    - true
    - What is the purpose of environment variables in containers?
    - mcq
    - '[{"text":"To configure containers without rebuilding images","correct":true},{"text":"To
      improve container performance","correct":false},{"text":"To secure the container","correct":false},{"text":"To
      set the container name","correct":false}]'
    - To configure containers without rebuilding images
    - Environment variables provide runtime configuration, making containers flexible
      and reusable across different environments.
    -
    - "[]"
    - '["Use environment variables for configuration","Configure multi-tier applications"]'
    - '["codesprout-run-frontend"]'
    - '2025-11-06 04:12:46.223691'
    - '2025-11-06 04:12:46.223691'
    - Configure the frontend to connect to the backend API using environment variables.
    -
    - '["environment-variables","configuration","docker-run"]'
    - "[]"
  - - 82
    - Building the Backend API
    - codesprout-build-backend
    - |
      # Building the Backend Service

      Sarah: "The frontend looks great, but it's lonely without data! Let's build the backend API."

      ## The Backend API

      The backend is a Node.js Express server that:
      - Provides REST API endpoints (`/api/tasks`, `/api/users`)
      - Handles business logic
      - Connects to the database
      - Runs on port 8080

      ## Building the Backend Image

      **Command**: `docker build -t codesprout/backend:1.0 ./backend`

      This backend Dockerfile:
      1. Uses `node:16-alpine` as base
      2. Copies `package.json` and installs dependencies
      3. Copies application code
      4. Exposes port 8080
      5. Starts the server with `npm start`
    - docker build -t codesprout/backend:1.0 ./backend
    - '["docker build --tag codesprout/backend:1.0 ./backend","docker image build
      -t codesprout/backend:1.0 ./backend"]'
    - '["Build from the ./backend directory","Tag as codesprout/backend:1.0","Format:
      docker build -t NAME:TAG PATH","Try: docker build -t codesprout/backend:1.0
      ./backend"]'
    -
    - "[]"
    - easy
    - 4
    - 111
    - images
    - true
    - Why do we tag both frontend and backend with version '1.0'?
    - mcq
    - '[{"text":"To track versions and allow rollbacks","correct":true},{"text":"Because
      Docker requires version numbers","correct":false},{"text":"To improve build
      performance","correct":false},{"text":"For security scanning","correct":false}]'
    - To track versions and allow rollbacks
    - Version tags help you manage different releases and roll back if needed.
    -
    - "[]"
    - '["Build backend API images","Understand multi-service architecture"]'
    - '["codesprout-frontend-env"]'
    - '2025-11-06 04:12:46.230659'
    - '2025-11-06 04:12:46.230659'
    - Build the CodeSprout backend API image.
    -
    - '["docker-build","backend-services","apis"]'
    - "[]"
  - - 83
    - Connecting Frontend to Backend
    - codesprout-connect-services
    - |
      # Service-to-Service Communication

      Sarah: "Now we need the frontend and backend to talk to each other. But there's a problem..."

      ## The Problem

      Right now:
      - Frontend: localhost:3000 (on host machine)
      - Backend: localhost:8080 (on host machine)

      But containers are isolated! The frontend container can't reach "localhost:8080"
      because that's the *host* machine, not the backend *container*.

      ## The Solution: Docker Networks

      We need to:
      1. Create a custom Docker network
      2. Connect both containers to it
      3. Use container names as hostnames

      **Command**: `docker run -d -p 8080:8080 --name codesprout-api --network codesprout-net codesprout/backend:1.0`

      Now the frontend can reach the backend at `http://codesprout-api:8080` instead of `localhost:8080`!
    - docker run -d -p 8080:8080 --name codesprout-api --network codesprout-net codesprout/backend:1.0
    - '["docker run -d --name codesprout-api -p 8080:8080 --network codesprout-net
      codesprout/backend:1.0","docker run --detach -p 8080:8080 --name codesprout-api
      --network codesprout-net codesprout/backend:1.0"]'
    - '["Connect to the network with --network codesprout-net","Name it ''codesprout-api''
      so other containers can find it","Expose port 8080 for the API","Try: docker
      run -d -p 8080:8080 --name codesprout-api --network codesprout-net codesprout/backend:1.0"]'
    -
    - "[]"
    - medium
    - 4
    - 112
    - networking
    - true
    - How do containers on the same network find each other?
    - mcq
    - '[{"text":"By container name as hostname","correct":true},{"text":"By IP address
      only","correct":false},{"text":"Through port mapping","correct":false},{"text":"They
      cannot communicate","correct":false}]'
    - By container name as hostname
    - Docker provides automatic DNS resolution, allowing containers on the same network
      to reach each other by name.
    -
    - "[]"
    - '["Connect services using Docker networks","Understand container-to-container
      communication"]'
    - '["codesprout-build-backend"]'
    - '2025-11-06 04:12:46.233382'
    - '2025-11-06 04:12:46.233382'
    - Run the backend API and connect it to the same network as the frontend.
    -
    - '["docker-networks","service-discovery","multi-container"]'
    - "[]"
  - - 84
    - Creating Custom Docker Networks
    - codesprout-create-network
    - |
      # Custom Networks for Isolation

      Sarah: "Before we connect services, we need to create a dedicated network for CodeSprout."

      ## Why Custom Networks?

      Default Docker networking has limitations:
      - All containers can potentially see each other
      - No isolation between different applications
      - Limited DNS features

      Custom networks provide:
      - **Isolation**: Only connected containers can communicate
      - **DNS**: Automatic service discovery by container name
      - **Flexibility**: Multiple isolated networks on one host

      ## Creating a Network

      **Command**: `docker network create codesprout-net`

      This creates a bridge network named `codesprout-net`. Now we can connect
      containers to it with `--network codesprout-net`.

      **Check networks**: `docker network ls`
    - docker network create codesprout-net
    - '["docker network create --driver bridge codesprout-net"]'
    - '["Create a network named ''codesprout-net''","Format: docker network create
      NETWORK_NAME","Try: docker network create codesprout-net"]'
    -
    - "[]"
    - easy
    - 3
    - 113
    - networking
    - true
    - What is the benefit of using custom networks?
    - mcq
    - '[{"text":"Isolation and automatic DNS between connected containers","correct":true},{"text":"Faster
      network speeds","correct":false},{"text":"Encrypted traffic automatically","correct":false},{"text":"Required
      for port mapping","correct":false}]'
    - Isolation and automatic DNS between connected containers
    - Custom networks isolate containers and provide DNS resolution so services can
      find each other by name.
    -
    - "[]"
    - '["Create Docker networks","Understand network isolation"]'
    - '["codesprout-connect-services"]'
    - '2025-11-06 04:12:46.235570'
    - '2025-11-06 04:12:46.235570'
    - Create a dedicated network for all CodeSprout services to communicate securely.
    -
    - '["docker-network","isolation","dns"]'
    - "[]"
  - - 85
    - Running the Database
    - codesprout-run-database
    - |
      # Adding PostgreSQL Database

      Sarah: "Time to add the database! Our backend needs somewhere to store all the tasks."

      ## Database Requirements

      The backend API needs PostgreSQL to:
      - Store user accounts
      - Save tasks and projects
      - Track completion status

      ## Running PostgreSQL

      **Command**: `docker run -d --name codesprout-db --network codesprout-net -e POSTGRES_PASSWORD=secret123 -e POSTGRES_DB=codesprout postgres:15`

      Breaking it down:
      - `--name codesprout-db`: Backend will connect to this hostname
      - `--network codesprout-net`: Same network as frontend/backend
      - `-e POSTGRES_PASSWORD=secret123`: Database password
      - `-e POSTGRES_DB=codesprout`: Create database named "codesprout"
      - `postgres:15`: Official PostgreSQL image, version 15

      No port mapping needed! The database is only accessed by the backend, not the host.
    - docker run -d --name codesprout-db --network codesprout-net -e POSTGRES_PASSWORD=secret123
      -e POSTGRES_DB=codesprout postgres:15
    - '["docker run -d --network codesprout-net --name codesprout-db -e POSTGRES_PASSWORD=secret123
      -e POSTGRES_DB=codesprout postgres:15","docker run --detach --name codesprout-db
      --network codesprout-net -e POSTGRES_DB=codesprout -e POSTGRES_PASSWORD=secret123
      postgres:15"]'
    - '["Connect to codesprout-net network","Set POSTGRES_PASSWORD and POSTGRES_DB
      environment variables","Name it ''codesprout-db'' for the backend to find","Try:
      docker run -d --name codesprout-db --network codesprout-net -e POSTGRES_PASSWORD=secret123
      -e POSTGRES_DB=codesprout postgres:15"]'
    -
    - "[]"
    - medium
    - 4
    - 114
    - data
    - true
    - Why don't we need -p for the database container?
    - mcq
    - '[{"text":"Only the backend needs access, not the host machine","correct":true},{"text":"PostgreSQL
      doesn''t use ports","correct":false},{"text":"The network flag handles ports
      automatically","correct":false},{"text":"It''s a security vulnerability","correct":false}]'
    - Only the backend needs access, not the host machine
    - Port mapping is only needed when you want to access a service from your host.
      Internal services only need to be on the same network.
    -
    - "[]"
    - '["Run database containers","Understand internal vs external services"]'
    - '["codesprout-create-network"]'
    - '2025-11-06 04:12:46.238111'
    - '2025-11-06 04:12:46.238111'
    - Add a PostgreSQL database to store CodeSprout's data.
    -
    - '["databases","postgres","internal-services"]'
    - "[]"
  - - 86
    - Persisting Database Data
    - codesprout-db-volume
    - |
      # Persistent Storage with Volumes

      Sarah: "Houston, we have a problem! If the database container restarts, all data is lost!"

      ## The Container Data Problem

      Containers are ephemeral:
      - Data written inside a container disappears when it's removed
      - Database restarts = data loss
      - This is unacceptable for production!

      ## The Solution: Docker Volumes

      Volumes persist data outside containers:
      - Survive container restarts and removals
      - Can be backed up
      - Shared between containers if needed

      **Command**: `docker run -d --name codesprout-db --network codesprout-net -v codesprout-data:/var/lib/postgresql/data -e POSTGRES_PASSWORD=secret123 -e POSTGRES_DB=codesprout postgres:15`

      The `-v codesprout-data:/var/lib/postgresql/data` means:
      - `codesprout-data`: Named volume (Docker manages storage location)
      - `/var/lib/postgresql/data`: Where PostgreSQL stores its data inside the container

      Now your data survives container restarts!
    - docker run -d --name codesprout-db --network codesprout-net -v codesprout-data:/var/lib/postgresql/data
      -e POSTGRES_PASSWORD=secret123 -e POSTGRES_DB=codesprout postgres:15
    - '["docker run -d --network codesprout-net --name codesprout-db --volume codesprout-data:/var/lib/postgresql/data
      -e POSTGRES_PASSWORD=secret123 -e POSTGRES_DB=codesprout postgres:15","docker
      run -d --name codesprout-db -v codesprout-data:/var/lib/postgresql/data --network
      codesprout-net -e POSTGRES_DB=codesprout -e POSTGRES_PASSWORD=secret123 postgres:15"]'
    - '["Use -v to mount a volume","Format: -v VOLUME_NAME:CONTAINER_PATH","Mount
      codesprout-data to /var/lib/postgresql/data","Try: docker run -d --name codesprout-db
      --network codesprout-net -v codesprout-data:/var/lib/postgresql/data -e POSTGRES_PASSWORD=secret123
      -e POSTGRES_DB=codesprout postgres:15"]'
    -
    - "[]"
    - medium
    - 3
    - 115
    - volumes
    - true
    - What happens to data in a volume when you remove the container?
    - mcq
    - '[{"text":"The data persists and can be used by a new container","correct":true},{"text":"The
      data is deleted","correct":false},{"text":"The data becomes read-only","correct":false},{"text":"The
      volume is automatically deleted","correct":false}]'
    - The data persists and can be used by a new container
    - Volumes persist independently of container lifecycle, making them perfect for
      databases and important data.
    -
    - "[]"
    - '["Use volumes for persistent data","Understand container data lifecycle"]'
    - '["codesprout-run-database"]'
    - '2025-11-06 04:12:46.240300'
    - '2025-11-06 04:12:46.240300'
    - Add persistent storage to the database so data survives container restarts.
    -
    - '["volumes","persistence","databases"]'
    - "[]"
  - - 87
    - Configuring Database Credentials
    - codesprout-db-credentials
    - |
      # Connecting Backend to Database

      Sarah: "The database is running, but the backend doesn't know how to connect to it yet!"

      ## Database Connection Configuration

      The backend needs to know:
      - **Host**: Where is the database? (`codesprout-db`)
      - **Port**: What port? (`5432` - PostgreSQL default)
      - **Database name**: Which database? (`codesprout`)
      - **Username**: Who to login as? (`postgres` - default)
      - **Password**: What's the password? (`secret123`)

      ## Passing Connection Info

      We'll pass all this via environment variables to the backend:

      **Command**: `docker run -d -p 8080:8080 --name codesprout-api --network codesprout-net -e DB_HOST=codesprout-db -e DB_PORT=5432 -e DB_NAME=codesprout -e DB_USER=postgres -e DB_PASSWORD=secret123 codesprout/backend:1.0`

      Now the backend can connect to PostgreSQL!
    - docker run -d -p 8080:8080 --name codesprout-api --network codesprout-net -e
      DB_HOST=codesprout-db -e DB_PORT=5432 -e DB_NAME=codesprout -e DB_USER=postgres
      -e DB_PASSWORD=secret123 codesprout/backend:1.0
    - '["docker run -d --name codesprout-api -p 8080:8080 --network codesprout-net
      -e DB_HOST=codesprout-db -e DB_PORT=5432 -e DB_NAME=codesprout -e DB_USER=postgres
      -e DB_PASSWORD=secret123 codesprout/backend:1.0"]'
    - '["Pass 5 environment variables for database connection","DB_HOST should be
      ''codesprout-db'' (container name)","Use multiple -e flags for multiple variables","Try:
      docker run -d -p 8080:8080 --name codesprout-api --network codesprout-net -e
      DB_HOST=codesprout-db -e DB_PORT=5432 -e DB_NAME=codesprout -e DB_USER=postgres
      -e DB_PASSWORD=secret123 codesprout/backend:1.0"]'
    -
    - "[]"
    - medium
    - 3
    - 116
    - configuration
    - true
    - Why use 'codesprout-db' as DB_HOST instead of 'localhost'?
    - mcq
    - '[{"text":"Container name provides DNS resolution on the Docker network","correct":true},{"text":"localhost
      doesn''t work in Docker","correct":false},{"text":"It''s required by PostgreSQL","correct":false},{"text":"For
      security reasons","correct":false}]'
    - Container name provides DNS resolution on the Docker network
    - On a Docker network, containers can reach each other by name. 'localhost' would
      refer to the backend container itself, not the database.
    -
    - "[]"
    - '["Configure multi-tier applications","Understand service discovery in Docker"]'
    - '["codesprout-db-volume"]'
    - '2025-11-06 04:12:46.242311'
    - '2025-11-06 04:12:46.242311'
    - Configure the backend with database credentials so it can connect to PostgreSQL.
    -
    - '["environment-variables","service-discovery","configuration"]'
    - "[]"
  - - 88
    - Creating docker-compose.yml
    - codesprout-compose-file
    - |
      # Orchestrating with Docker Compose

      Sarah: "Running three containers with those long commands is tedious! Let's use Docker Compose."

      ## The Problem

      Currently we need to run:
      1. `docker network create...`
      2. `docker run...` (database with volumes and env vars)
      3. `docker run...` (backend with network and 5 env vars)
      4. `docker run...` (frontend with network and env vars)

      That's a lot to remember and type!

      ## The Solution: docker-compose.yml

      Docker Compose lets you define all services in one YAML file:

      ```yaml
      version: '3.8'
      services:
        frontend:
          build: ./frontend
          ports:
            - "3000:3000"
          environment:
            - API_URL=http://backend:8080
        backend:
          build: ./backend
          ports:
            - "8080:8080"
          environment:
            - DB_HOST=database
        database:
          image: postgres:15
          volumes:
            - codesprout-data:/var/lib/postgresql/data
      ```

      **Command**: `docker-compose up -d`

      That's it! One command starts everything.
    - docker-compose up -d
    - '["docker-compose up --detach","docker compose up -d"]'
    - '["Use ''docker-compose up'' to start all services","Add -d to run in detached
      mode","Try: docker-compose up -d"]'
    -
    - "[]"
    - easy
    - 5
    - 117
    - orchestration
    - true
    - What does 'docker-compose up -d' do?
    - mcq
    - '[{"text":"Starts all services defined in docker-compose.yml in detached mode","correct":true},{"text":"Updates
      all containers to latest versions","correct":false},{"text":"Uploads containers
      to a registry","correct":false},{"text":"Deletes all running containers","correct":false}]'
    - Starts all services defined in docker-compose.yml in detached mode
    - docker-compose up reads the compose file and starts all defined services. The
      -d flag runs them in the background.
    -
    - "[]"
    - '["Use Docker Compose for multi-container applications","Define services in
      docker-compose.yml"]'
    - '["codesprout-db-credentials"]'
    - '2025-11-06 04:12:46.244363'
    - '2025-11-06 04:12:46.244363'
    - Use Docker Compose to start the entire CodeSprout stack with one command.
    -
    - '["docker-compose","orchestration","yaml"]'
    - "[]"
  - - 89
    - Managing Service Dependencies
    - codesprout-compose-depends
    - |
      # Service Startup Order

      Sarah: "Sometimes the backend starts before the database is ready. Let's fix that!"

      ## The Dependency Problem

      Services start in parallel, which can cause issues:
      - Backend tries to connect to database before it's ready
      - Frontend loads before backend is available
      - Connection errors during startup

      ## Using `depends_on`

      Docker Compose provides `depends_on` to control startup order:

      ```yaml
      services:
        backend:
          depends_on:
            - database
        frontend:
          depends_on:
            - backend
      ```

      This ensures:
      1. Database starts first
      2. Backend waits for database
      3. Frontend waits for backend

      **Note**: `depends_on` only waits for the container to start, not for the service to be fully ready.
      For production, you'd add health checks!
    - docker-compose up -d
    - '["docker compose up -d","docker-compose up --detach"]'
    - '["Add depends_on to your docker-compose.yml","Start services with docker-compose
      up -d","Try: docker-compose up -d"]'
    -
    - "[]"
    - medium
    - 4
    - 118
    - orchestration
    - true
    - What does 'depends_on' do in docker-compose.yml?
    - mcq
    - '[{"text":"Controls the startup order of services","correct":true},{"text":"Shares
      data between services","correct":false},{"text":"Creates network connections","correct":false},{"text":"Sets
      environment variables","correct":false}]'
    - Controls the startup order of services
    - depends_on ensures dependent services start after their dependencies, preventing
      startup race conditions.
    -
    - "[]"
    - '["Manage service dependencies","Control startup order"]'
    - '["codesprout-compose-file"]'
    - '2025-11-06 04:12:46.246432'
    - '2025-11-06 04:12:46.246432'
    - Configure service dependencies so containers start in the correct order.
    -
    - '["docker-compose","dependencies","startup-order"]'
    - "[]"
  - - 90
    - Managing the Compose Stack
    - codesprout-compose-manage
    - |
      # Docker Compose Commands

      Sarah: "Now that everything is running, let's learn how to manage the stack!"

      ## Essential Compose Commands

      **Start services**: `docker-compose up -d`
      - Starts all services in detached mode

      **Stop services**: `docker-compose down`
      - Stops and removes all containers
      - Networks are removed
      - Volumes are preserved (unless you add `-v`)

      **View logs**: `docker-compose logs -f`
      - See logs from all services
      - `-f` follows logs in real-time
      - Add service name for specific logs: `docker-compose logs -f backend`

      **Check status**: `docker-compose ps`
      - Shows status of all services

      **Restart services**: `docker-compose restart`
      - Restart all or specific services

      **Command**: `docker-compose down`

      This cleanly stops everything when you're done working on CodeSprout.
    - docker-compose down
    - '["docker compose down"]'
    - '["Use ''docker-compose down'' to stop all services","This removes containers
      and networks but preserves volumes","Try: docker-compose down"]'
    -
    - "[]"
    - easy
    - 3
    - 119
    - orchestration
    - true
    - What does 'docker-compose down' remove?
    - mcq
    - '[{"text":"Containers and networks, but preserves volumes","correct":true},{"text":"Everything
      including volumes","correct":false},{"text":"Only stops containers without removing
      them","correct":false},{"text":"Only networks","correct":false}]'
    - Containers and networks, but preserves volumes
    - docker-compose down cleans up containers and networks but keeps volumes safe
      by default. Use -v to also remove volumes.
    -
    - "[]"
    - '["Manage Docker Compose stacks","Start and stop multi-container applications"]'
    - '["codesprout-compose-depends"]'
    - '2025-11-06 04:12:46.248565'
    - '2025-11-06 04:12:46.248565'
    - Stop the CodeSprout stack when you're done working.
    -
    - '["docker-compose","lifecycle-management"]'
    - "[]"
  - - 91
    - Debugging with Logs
    - codesprout-compose-logs
    - |
      # Viewing Application Logs

      Sarah: "Something's not working? Let's check the logs to debug!"

      ## Why Logs Matter

      Logs help you:
      - Debug errors and exceptions
      - Monitor application behavior
      - Track API requests
      - Diagnose performance issues

      ## Viewing Compose Logs

      **All services**: `docker-compose logs -f`
      - Shows logs from all containers
      - `-f` follows logs in real-time (like `tail -f`)
      - Color-coded by service

      **Specific service**: `docker-compose logs -f backend`
      - Only shows backend logs
      - Useful for isolating issues

      **Last N lines**: `docker-compose logs --tail=100 backend`
      - Shows last 100 lines only

      **Command**: `docker-compose logs -f backend`

      This shows real-time logs from the backend service to help debug API issues.
    - docker-compose logs -f backend
    - '["docker compose logs -f backend","docker-compose logs --follow backend"]'
    - '["Use ''docker-compose logs'' to view logs","Add -f to follow logs in real-time","Specify
      ''backend'' to see only backend logs","Try: docker-compose logs -f backend"]'
    -
    - "[]"
    - easy
    - 3
    - 120
    - debugging
    - true
    - What does the -f flag do in 'docker-compose logs -f'?
    - mcq
    - '[{"text":"Follows logs in real-time like tail -f","correct":true},{"text":"Filters
      logs by level","correct":false},{"text":"Forces log output","correct":false},{"text":"Formats
      logs as JSON","correct":false}]'
    - Follows logs in real-time like tail -f
    - The -f flag streams logs continuously, updating as new log entries are written.
    -
    - "[]"
    - '["Debug applications using logs","Monitor service behavior"]'
    - '["codesprout-compose-manage"]'
    - '2025-11-06 04:12:46.250737'
    - '2025-11-06 04:12:46.250737'
    - Check the backend logs to debug API errors.
    -
    - '["logging","debugging","docker-compose"]'
    - "[]"
  - - 92
    - Updating Services
    - codesprout-compose-update
    - |
      # Updating Running Services

      Sarah: "You just fixed a bug in the backend code. Let's deploy the update!"

      ## Updating Services

      When you change code, you need to:
      1. Rebuild the image (if code changed)
      2. Recreate the container with the new image

      **Command**: `docker-compose up -d --build backend`

      Breaking it down:
      - `up`: Start services
      - `-d`: Detached mode
      - `--build`: Rebuild images before starting
      - `backend`: Only update this service

      This rebuilds the backend image and recreates the container while keeping
      the database and frontend running!

      ## Alternative: Restart Without Rebuilding

      If you only changed environment variables or want to restart:

      **Command**: `docker-compose restart backend`

      This just restarts the container without rebuilding.
    - docker-compose up -d --build backend
    - '["docker compose up -d --build backend","docker-compose up --detach --build
      backend"]'
    - '["Use --build to rebuild images before starting","Specify ''backend'' to only
      update that service","Other services keep running","Try: docker-compose up -d
      --build backend"]'
    -
    - "[]"
    - medium
    - 4
    - 121
    - orchestration
    - true
    - What does '--build' do in 'docker-compose up --build'?
    - mcq
    - '[{"text":"Rebuilds images before starting containers","correct":true},{"text":"Only
      builds images without starting","correct":false},{"text":"Builds the project
      source code","correct":false},{"text":"Downloads images from a registry","correct":false}]'
    - Rebuilds images before starting containers
    - The --build flag forces Docker Compose to rebuild images from Dockerfiles before
      starting containers, ensuring code changes are included.
    -
    - "[]"
    - '["Update running services","Deploy code changes"]'
    - '["codesprout-compose-logs"]'
    - '2025-11-06 04:12:46.252947'
    - '2025-11-06 04:12:46.252947'
    - Deploy an updated version of the backend after fixing a bug.
    -
    - '["docker-compose","deployment","updates"]'
    - "[]"
  - - 93
    - Scaling Services
    - codesprout-compose-scale
    - |
      # Scaling for More Traffic

      Sarah: "CodeSprout is getting popular! Let's run 3 backend instances to handle the load."

      ## Why Scale?

      Single container limitations:
      - Can only use one CPU core fully
      - Limited throughput
      - No redundancy if it crashes

      Multiple instances provide:
      - **Higher throughput**: Handle more requests
      - **Load balancing**: Distribute work across instances
      - **Redundancy**: One crash doesn't take down everything

      ## Scaling with Compose

      **Command**: `docker-compose up -d --scale backend=3`

      This runs 3 backend containers:
      - `codesprout_backend_1`
      - `codesprout_backend_2`
      - `codesprout_backend_3`

      Docker Compose load balances requests across all 3!

      **Check status**: `docker-compose ps`

      You'll see all 3 backend instances running.

      **Note**: You can't map the same host port for multiple containers, so remove
      explicit port mapping for scaled services (use a load balancer instead).
    - docker-compose up -d --scale backend=3
    - '["docker compose up -d --scale backend=3","docker-compose up --detach --scale
      backend=3"]'
    - '["Use --scale SERVICE=COUNT to run multiple instances","Run 3 backend instances
      with --scale backend=3","Try: docker-compose up -d --scale backend=3"]'
    -
    - "[]"
    - medium
    - 3
    - 122
    - scaling
    - true
    - Why might you want to scale a service to multiple instances?
    - mcq
    - '[{"text":"To handle more traffic and provide redundancy","correct":true},{"text":"To
      use more disk space","correct":false},{"text":"To reduce memory usage","correct":false},{"text":"Required
      by Docker Compose","correct":false}]'
    - To handle more traffic and provide redundancy
    - Scaling services horizontally increases capacity and resilience, allowing your
      application to handle more load and survive instance failures.
    -
    - "[]"
    - '["Scale services horizontally","Understand load distribution"]'
    - '["codesprout-compose-update"]'
    - '2025-11-06 04:12:46.255063'
    - '2025-11-06 04:12:46.255063'
    - Scale the backend to 3 instances to handle increased traffic.
    -
    - '["docker-compose","scaling","performance"]'
    - "[]"

---
kubernetes_resources:
  columns:
  - id
  - resource_type
  - name
  - yaml_template
  - explanation
  - difficulty
  - category
  - exam_frequency
  - key_fields
  - common_errors
  - certification_exam
  - best_practices
  - related_resources
  - times_practiced
  - average_success_rate
  - is_deprecated
  - kubernetes_version_min
  - api_version
  - created_at
  - updated_at
  records: 
  - - 1
    - pod
    - basic-pod
    - |
      apiVersion: v1
      kind: Pod
      metadata:
        name: nginx-pod
        labels:
          app: nginx
      spec:
        containers:
        - name: nginx
          image: nginx:1.21
          ports:
          - containerPort: 80
    - Basic pod with single nginx container
    - easy
    - workloads
    - 10
    - '{"spec.containers":"container definitions","metadata.labels":"labels for selection"}'
    - Missing apiVersion or kind, incorrect indentation
    - CKAD
    - Always add labels for service selection
    - "[]"
    - 0
    - 0.0
    - false
    -
    - v1
    - '2025-11-06 03:44:02.707246'
    - '2025-11-06 03:44:02.707246'
  - - 2
    - pod
    - multi-container-pod
    - |
      apiVersion: v1
      kind: Pod
      metadata:
        name: multi-container-pod
      spec:
        containers:
        - name: app
          image: myapp:latest
        - name: sidecar
          image: logging-agent:latest
    - Pod with multiple containers (sidecar pattern)
    - medium
    - workloads
    - 9
    - '{"spec.containers[]":"array of containers"}'
    - Containers must be array with dash prefix
    - CKAD
    - Use sidecar pattern for logging, monitoring
    - "[]"
    - 0
    - 0.0
    - false
    -
    - v1
    - '2025-11-06 03:44:02.711751'
    - '2025-11-06 03:44:02.711751'
  - - 3
    - pod
    - pod-with-resources
    - |
      apiVersion: v1
      kind: Pod
      metadata:
        name: resource-pod
      spec:
        containers:
        - name: app
          image: nginx
          resources:
            requests:
              memory: "64Mi"
              cpu: "250m"
            limits:
              memory: "128Mi"
              cpu: "500m"
    - Pod with resource requests and limits
    - medium
    - workloads
    - 10
    - '{"resources.requests":"minimum resources","resources.limits":"maximum resources"}'
    - Memory without unit (Mi/Gi), CPU without m suffix
    - CKA
    - Always set requests and limits for production
    - "[]"
    - 0
    - 0.0
    - false
    -
    - v1
    - '2025-11-06 03:44:02.717407'
    - '2025-11-06 03:44:02.717407'
  - - 4
    - pod
    - pod-with-env-vars
    - |
      apiVersion: v1
      kind: Pod
      metadata:
        name: env-pod
      spec:
        containers:
        - name: app
          image: nginx
          env:
          - name: DATABASE_URL
            value: "postgres://localhost:5432"
          - name: SECRET_KEY
            valueFrom:
              secretKeyRef:
                name: app-secret
                key: api-key
    - Pod with environment variables from values and secrets
    - medium
    - configuration
    - 9
    - '{"env":"environment variables","valueFrom":"reference to ConfigMap/Secret"}'
    - Incorrect indentation for valueFrom
    - CKAD
    - Use secrets for sensitive data
    - "[]"
    - 0
    - 0.0
    - false
    -
    - v1
    - '2025-11-06 03:44:02.721499'
    - '2025-11-06 03:44:02.721499'
  - - 5
    - pod
    - pod-with-volumes
    - |
      apiVersion: v1
      kind: Pod
      metadata:
        name: volume-pod
      spec:
        containers:
        - name: app
          image: nginx
          volumeMounts:
          - name: data
            mountPath: /data
        volumes:
        - name: data
          emptyDir: {}
    - Pod with emptyDir volume mounted
    - medium
    - storage
    - 9
    - '{"volumeMounts":"mount points in container","volumes":"volume definitions"}'
    - Volume name mismatch between volumes and volumeMounts
    - CKAD
    - emptyDir is temporary, use PV for persistence
    - "[]"
    - 0
    - 0.0
    - false
    -
    - v1
    - '2025-11-06 03:44:02.725611'
    - '2025-11-06 03:44:02.725611'
  - - 6
    - pod
    - pod-with-configmap
    - |
      apiVersion: v1
      kind: Pod
      metadata:
        name: configmap-pod
      spec:
        containers:
        - name: app
          image: nginx
          volumeMounts:
          - name: config
            mountPath: /etc/config
        volumes:
        - name: config
          configMap:
            name: app-config
    - Pod mounting ConfigMap as volume
    - medium
    - configuration
    - 9
    - '{"configMap":"reference to ConfigMap"}'
    - ConfigMap must exist before pod creation
    - CKAD
    - Use ConfigMaps for non-sensitive configuration
    - "[]"
    - 0
    - 0.0
    - false
    -
    - v1
    - '2025-11-06 03:44:02.729558'
    - '2025-11-06 03:44:02.729558'
  - - 7
    - pod
    - pod-with-init-container
    - |
      apiVersion: v1
      kind: Pod
      metadata:
        name: init-pod
      spec:
        initContainers:
        - name: init-db
          image: busybox
          command: ['sh', '-c', 'until nc -z db 5432; do sleep 2; done']
        containers:
        - name: app
          image: myapp
    - Pod with init container that runs before main container
    - medium
    - workloads
    - 8
    - '{"initContainers":"containers that run sequentially before main containers"}'
    - Init containers must complete successfully
    - CKAD
    - Use init containers for setup tasks
    - "[]"
    - 0
    - 0.0
    - false
    -
    - v1
    - '2025-11-06 03:44:02.733671'
    - '2025-11-06 03:44:02.733671'
  - - 8
    - pod
    - pod-with-liveness-probe
    - |
      apiVersion: v1
      kind: Pod
      metadata:
        name: liveness-pod
      spec:
        containers:
        - name: app
          image: nginx
          livenessProbe:
            httpGet:
              path: /healthz
              port: 8080
            initialDelaySeconds: 30
            periodSeconds: 10
    - Pod with HTTP liveness probe
    - medium
    - workloads
    - 9
    - '{"livenessProbe":"health check that restarts container on failure"}'
    - Probe fails during startup, set initialDelaySeconds
    - CKAD
    - Always add probes for production workloads
    - "[]"
    - 0
    - 0.0
    - false
    -
    - v1
    - '2025-11-06 03:44:02.737674'
    - '2025-11-06 03:44:02.737674'
  - - 9
    - pod
    - pod-with-readiness-probe
    - |
      apiVersion: v1
      kind: Pod
      metadata:
        name: readiness-pod
      spec:
        containers:
        - name: app
          image: nginx
          readinessProbe:
            httpGet:
              path: /ready
              port: 8080
            initialDelaySeconds: 5
            periodSeconds: 5
    - Pod with readiness probe to control traffic
    - medium
    - workloads
    - 8
    - '{"readinessProbe":"health check that controls service endpoints"}'
    - Probe must succeed before pod receives traffic
    - CKAD
    - Readiness probe prevents routing to unready pods
    - "[]"
    - 0
    - 0.0
    - false
    -
    - v1
    - '2025-11-06 03:44:02.741689'
    - '2025-11-06 03:44:02.741689'
  - - 10
    - pod
    - pod-with-security-context
    - |
      apiVersion: v1
      kind: Pod
      metadata:
        name: security-pod
      spec:
        securityContext:
          runAsUser: 1000
          runAsGroup: 3000
          fsGroup: 2000
        containers:
        - name: app
          image: nginx
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
    - Pod with security context for user and filesystem permissions
    - medium
    - security
    - 8
    - '{"securityContext":"security settings","runAsUser":"UID to run container"}'
    - Permission denied errors if UID doesn't match image requirements
    - CKA
    - Run as non-root user, use readOnlyRootFilesystem
    - "[]"
    - 0
    - 0.0
    - false
    -
    - v1
    - '2025-11-06 03:44:02.745268'
    - '2025-11-06 03:44:02.745268'
  - - 11
    - deployment
    - basic-deployment
    - |
      apiVersion: apps/v1
      kind: Deployment
      metadata:
        name: nginx-deployment
        labels:
          app: nginx
      spec:
        replicas: 3
        selector:
          matchLabels:
            app: nginx
        template:
          metadata:
            labels:
              app: nginx
          spec:
            containers:
            - name: nginx
              image: nginx:1.21
              ports:
              - containerPort: 80
    - Basic deployment with 3 nginx replicas
    - easy
    - workloads
    - 10
    - '{"spec.replicas":"number of pods","spec.selector":"label selector for pods","spec.template":"pod
      template"}'
    - Selector must match template labels exactly
    - CKAD
    - Use deployments instead of bare pods for production
    - "[]"
    - 0
    - 0.0
    - false
    -
    - apps/v1
    - '2025-11-06 03:44:02.749245'
    - '2025-11-06 03:44:02.749245'
  - - 12
    - deployment
    - deployment-with-rolling-update
    - |
      apiVersion: apps/v1
      kind: Deployment
      metadata:
        name: rolling-deployment
      spec:
        replicas: 5
        strategy:
          type: RollingUpdate
          rollingUpdate:
            maxSurge: 1
            maxUnavailable: 1
        selector:
          matchLabels:
            app: web
        template:
          metadata:
            labels:
              app: web
          spec:
            containers:
            - name: web
              image: nginx:1.21
    - Deployment with rolling update strategy configuration
    - medium
    - workloads
    - 9
    - '{"strategy":"update strategy","maxSurge":"extra pods during update","maxUnavailable":"pods
      that can be unavailable"}'
    - maxSurge and maxUnavailable cannot both be 0
    - CKA
    - Configure rolling update for zero-downtime deploys
    - "[]"
    - 0
    - 0.0
    - false
    -
    - apps/v1
    - '2025-11-06 03:44:02.786133'
    - '2025-11-06 03:44:02.786133'
  - - 13
    - deployment
    - deployment-with-resources
    - |
      apiVersion: apps/v1
      kind: Deployment
      metadata:
        name: resource-deployment
      spec:
        replicas: 3
        selector:
          matchLabels:
            app: api
        template:
          metadata:
            labels:
              app: api
          spec:
            containers:
            - name: api
              image: myapi:latest
              resources:
                requests:
                  memory: "128Mi"
                  cpu: "250m"
                limits:
                  memory: "256Mi"
                  cpu: "500m"
    - Deployment with resource requests and limits per pod
    - medium
    - workloads
    - 10
    - '{"resources":"resource management"}'
    - Pods won't schedule if node lacks requested resources
    - CKA
    - Set appropriate limits to prevent resource starvation
    - "[]"
    - 0
    - 0.0
    - false
    -
    - apps/v1
    - '2025-11-06 03:44:02.790768'
    - '2025-11-06 03:44:02.790768'
  - - 14
    - service
    - clusterip-service
    - |
      apiVersion: v1
      kind: Service
      metadata:
        name: nginx-service
      spec:
        type: ClusterIP
        selector:
          app: nginx
        ports:
        - port: 80
          targetPort: 80
          protocol: TCP
    - ClusterIP service for internal cluster communication
    - easy
    - networking
    - 10
    - '{"spec.selector":"pod selector","spec.ports":"port mappings","spec.type":"service
      type"}'
    - Selector must match pod labels, targetPort must match container port
    - CKAD
    - ClusterIP is default, use for internal services
    - "[]"
    - 0
    - 0.0
    - false
    -
    - v1
    - '2025-11-06 03:44:02.794716'
    - '2025-11-06 03:44:02.794716'
  - - 15
    - service
    - nodeport-service
    - |
      apiVersion: v1
      kind: Service
      metadata:
        name: web-nodeport
      spec:
        type: NodePort
        selector:
          app: web
        ports:
        - port: 80
          targetPort: 80
          nodePort: 30080
    - NodePort service exposing service on static port on each node
    - easy
    - networking
    - 9
    - '{"nodePort":"static port on nodes (30000-32767)"}'
    - nodePort must be in range 30000-32767
    - CKAD
    - Use for development or when LoadBalancer unavailable
    - "[]"
    - 0
    - 0.0
    - false
    -
    - v1
    - '2025-11-06 03:44:02.798933'
    - '2025-11-06 03:44:02.798933'
  - - 16
    - service
    - loadbalancer-service
    - |
      apiVersion: v1
      kind: Service
      metadata:
        name: web-lb
      spec:
        type: LoadBalancer
        selector:
          app: web
        ports:
        - port: 80
          targetPort: 8080
    - LoadBalancer service with cloud provider integration
    - easy
    - networking
    - 8
    - '{"type: LoadBalancer":"provisions cloud load balancer"}'
    - Requires cloud provider support
    - CKAD
    - Use for external production traffic
    - "[]"
    - 0
    - 0.0
    - false
    -
    - v1
    - '2025-11-06 03:44:02.805124'
    - '2025-11-06 03:44:02.805124'
  - - 17
    - service
    - headless-service
    - |
      apiVersion: v1
      kind: Service
      metadata:
        name: db-headless
      spec:
        clusterIP: None
        selector:
          app: database
        ports:
        - port: 5432
          targetPort: 5432
    - Headless service for direct pod DNS resolution
    - medium
    - networking
    - 7
    - '{"clusterIP: None":"makes service headless"}'
    - No load balancing, returns pod IPs directly
    - CKA
    - Use for StatefulSets and databases
    - "[]"
    - 0
    - 0.0
    - false
    -
    - v1
    - '2025-11-06 03:44:02.810029'
    - '2025-11-06 03:44:02.810029'
  - - 18
    - configmap
    - basic-configmap
    - |
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: app-config
      data:
        database.url: "postgres://db:5432"
        app.name: "myapp"
        log.level: "info"
    - ConfigMap with key-value configuration data
    - easy
    - configuration
    - 10
    - '{"data":"key-value pairs"}'
    - Values must be strings, use quotes for numbers
    - CKAD
    - Use ConfigMaps for non-sensitive configuration
    - "[]"
    - 0
    - 0.0
    - false
    -
    - v1
    - '2025-11-06 03:44:02.814206'
    - '2025-11-06 03:44:02.814206'
  - - 19
    - configmap
    - configmap-with-file
    - |
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: nginx-config
      data:
        nginx.conf: |
          server {
            listen 80;
            location / {
              proxy_pass http://backend;
            }
          }
    - ConfigMap with multi-line file content
    - medium
    - configuration
    - 8
    - '{"data.\u003cfilename\u003e":"file content with | for multi-line"}'
    - Indentation must be correct for multi-line content
    - CKAD
    - Use | for multi-line, |- to strip trailing newline
    - "[]"
    - 0
    - 0.0
    - false
    -
    - v1
    - '2025-11-06 03:44:02.820072'
    - '2025-11-06 03:44:02.820072'
  - - 20
    - secret
    - opaque-secret
    - |
      apiVersion: v1
      kind: Secret
      metadata:
        name: app-secret
      type: Opaque
      data:
        username: YWRtaW4=
        password: cGFzc3dvcmQxMjM=
    - Opaque secret with base64 encoded data
    - easy
    - security
    - 10
    - '{"data":"base64 encoded values","type":"secret type"}'
    - Values must be base64 encoded (echo -n 'value' | base64)
    - CKAD
    - Use stringData for plain text during creation
    - "[]"
    - 0
    - 0.0
    - false
    -
    - v1
    - '2025-11-06 03:44:02.824755'
    - '2025-11-06 03:44:02.824755'
  - - 21
    - secret
    - tls-secret
    - |
      apiVersion: v1
      kind: Secret
      metadata:
        name: tls-secret
      type: kubernetes.io/tls
      data:
        tls.crt: LS0tLS1...
        tls.key: LS0tLS1...
    - TLS secret for HTTPS certificates
    - medium
    - security
    - 7
    - '{"type: kubernetes.io/tls":"TLS secret type","tls.crt":"certificate","tls.key":"private
      key"}'
    - Must have tls.crt and tls.key keys
    - CKA
    - Use kubectl create secret tls command
    - "[]"
    - 0
    - 0.0
    - false
    -
    - v1
    - '2025-11-06 03:44:02.831683'
    - '2025-11-06 03:44:02.831683'
  - - 22
    - persistentvolume
    - hostpath-pv
    - |
      apiVersion: v1
      kind: PersistentVolume
      metadata:
        name: pv-hostpath
      spec:
        capacity:
          storage: 10Gi
        accessModes:
        - ReadWriteOnce
        hostPath:
          path: /mnt/data
    - PersistentVolume using hostPath storage
    - medium
    - storage
    - 9
    - '{"capacity":"storage size","accessModes":"RWO/RWX/ROX","hostPath":"node path"}'
    - hostPath only works on single node, not for production
    - CKA
    - Use network storage for production clusters
    - "[]"
    - 0
    - 0.0
    - false
    -
    - v1
    - '2025-11-06 03:44:02.838509'
    - '2025-11-06 03:44:02.838509'
  - - 23
    - persistentvolumeclaim
    - basic-pvc
    - |
      apiVersion: v1
      kind: PersistentVolumeClaim
      metadata:
        name: pvc-claim
      spec:
        accessModes:
        - ReadWriteOnce
        resources:
          requests:
            storage: 5Gi
    - PVC requesting 5Gi storage
    - easy
    - storage
    - 9
    - '{"accessModes":"must match PV","resources.requests.storage":"requested size"}'
    - PVC stays pending if no matching PV available
    - CKAD
    - Use StorageClass for dynamic provisioning
    - "[]"
    - 0
    - 0.0
    - false
    -
    - v1
    - '2025-11-06 03:44:02.854736'
    - '2025-11-06 03:44:02.854736'
  - - 24
    - persistentvolumeclaim
    - pvc-with-storageclass
    - |
      apiVersion: v1
      kind: PersistentVolumeClaim
      metadata:
        name: dynamic-pvc
      spec:
        storageClassName: fast-ssd
        accessModes:
        - ReadWriteOnce
        resources:
          requests:
            storage: 10Gi
    - PVC with specific StorageClass for dynamic provisioning
    - medium
    - storage
    - 8
    - '{"storageClassName":"storage class for dynamic provisioning"}'
    - StorageClass must exist and support dynamic provisioning
    - CKA
    - Use StorageClass for cloud environments
    - "[]"
    - 0
    - 0.0
    - false
    -
    - v1
    - '2025-11-06 03:44:02.870444'
    - '2025-11-06 03:44:02.870444'
  - - 25
    - ingress
    - basic-ingress
    - |
      apiVersion: networking.k8s.io/v1
      kind: Ingress
      metadata:
        name: basic-ingress
      spec:
        rules:
        - host: example.com
          http:
            paths:
            - path: /
              pathType: Prefix
              backend:
                service:
                  name: web-service
                  port:
                    number: 80
    - Basic ingress routing traffic to service based on host
    - medium
    - networking
    - 9
    - '{"rules":"routing rules","host":"domain name","backend":"target service"}'
    - Requires ingress controller to be installed
    - CKAD
    - Use for HTTP/HTTPS routing to multiple services
    - "[]"
    - 0
    - 0.0
    - false
    -
    - networking.k8s.io/v1
    - '2025-11-06 03:44:02.879410'
    - '2025-11-06 03:44:02.879410'
  - - 26
    - ingress
    - ingress-with-tls
    - |
      apiVersion: networking.k8s.io/v1
      kind: Ingress
      metadata:
        name: tls-ingress
      spec:
        tls:
        - hosts:
          - example.com
          secretName: tls-secret
        rules:
        - host: example.com
          http:
            paths:
            - path: /
              pathType: Prefix
              backend:
                service:
                  name: web-service
                  port:
                    number: 443
    - Ingress with TLS termination
    - medium
    - networking
    - 8
    - '{"tls":"TLS configuration","secretName":"TLS secret reference"}'
    - Secret must be type kubernetes.io/tls
    - CKA
    - Use cert-manager for automatic certificate management
    - "[]"
    - 0
    - 0.0
    - false
    -
    - networking.k8s.io/v1
    - '2025-11-06 03:44:02.885032'
    - '2025-11-06 03:44:02.885032'
  - - 27
    - ingress
    - ingress-with-path-based-routing
    - |
      apiVersion: networking.k8s.io/v1
      kind: Ingress
      metadata:
        name: path-ingress
      spec:
        rules:
        - host: example.com
          http:
            paths:
            - path: /api
              pathType: Prefix
              backend:
                service:
                  name: api-service
                  port:
                    number: 8080
            - path: /web
              pathType: Prefix
              backend:
                service:
                  name: web-service
                  port:
                    number: 80
    - Ingress with path-based routing to different services
    - medium
    - networking
    - 8
    - '{"paths":"URL path routing rules"}'
    - pathType must be Prefix, Exact, or ImplementationSpecific
    - CKAD
    - Use path-based routing for microservices
    - "[]"
    - 0
    - 0.0
    - false
    -
    - networking.k8s.io/v1
    - '2025-11-06 03:44:02.892830'
    - '2025-11-06 03:44:02.892830'
  - - 28
    - namespace
    - basic-namespace
    - |
      apiVersion: v1
      kind: Namespace
      metadata:
        name: development
        labels:
          env: dev
    - Basic namespace for logical cluster separation
    - easy
    - configuration
    - 8
    - '{"metadata.name":"namespace name"}'
    - Cannot delete namespace with resources in it
    - CKA
    - Use namespaces to organize resources by team or environment
    - "[]"
    - 0
    - 0.0
    - false
    -
    - v1
    - '2025-11-06 03:44:02.903088'
    - '2025-11-06 03:44:02.903088'
  - - 29
    - resourcequota
    - basic-quota
    - |
      apiVersion: v1
      kind: ResourceQuota
      metadata:
        name: compute-quota
        namespace: development
      spec:
        hard:
          requests.cpu: "4"
          requests.memory: 8Gi
          limits.cpu: "8"
          limits.memory: 16Gi
          pods: "10"
    - ResourceQuota limiting compute resources in namespace
    - medium
    - configuration
    - 7
    - '{"hard":"resource limits"}'
    - Pods must specify requests/limits when quota is set
    - CKA
    - Use quotas to prevent resource monopolization
    - "[]"
    - 0
    - 0.0
    - false
    -
    - v1
    - '2025-11-06 03:44:02.910955'
    - '2025-11-06 03:44:02.910955'
  - - 30
    - limitrange
    - basic-limitrange
    - |
      apiVersion: v1
      kind: LimitRange
      metadata:
        name: resource-limits
        namespace: development
      spec:
        limits:
        - type: Container
          default:
            cpu: 500m
            memory: 512Mi
          defaultRequest:
            cpu: 250m
            memory: 256Mi
          max:
            cpu: 1
            memory: 1Gi
          min:
            cpu: 100m
            memory: 128Mi
    - LimitRange setting default and max resources for containers
    - medium
    - configuration
    - 7
    - '{"default":"default limits","defaultRequest":"default requests","max":"maximum","min":"minimum"}'
    - Applies to new pods only, not existing ones
    - CKA
    - Set reasonable defaults to prevent resource abuse
    - "[]"
    - 0
    - 0.0
    - false
    -
    - v1
    - '2025-11-06 03:44:02.925021'
    - '2025-11-06 03:44:02.925021'
  - - 31
    - statefulset
    - basic-statefulset
    - |
      apiVersion: apps/v1
      kind: StatefulSet
      metadata:
        name: web
      spec:
        serviceName: "nginx"
        replicas: 3
        selector:
          matchLabels:
            app: nginx
        template:
          metadata:
            labels:
              app: nginx
          spec:
            containers:
            - name: nginx
              image: nginx:1.21
              ports:
              - containerPort: 80
              volumeMounts:
              - name: www
                mountPath: /usr/share/nginx/html
        volumeClaimTemplates:
        - metadata:
            name: www
          spec:
            accessModes: [ "ReadWriteOnce" ]
            resources:
              requests:
                storage: 1Gi
    - StatefulSet with persistent storage per pod
    - hard
    - workloads
    - 8
    - '{"serviceName":"headless service name","volumeClaimTemplates":"PVC template
      per pod"}'
    - serviceName must reference existing headless service
    - CKA
    - Use StatefulSets for databases and stateful applications
    - "[]"
    - 0
    - 0.0
    - false
    -
    - apps/v1
    - '2025-11-06 03:44:02.967745'
    - '2025-11-06 03:44:02.967745'
  - - 32
    - daemonset
    - basic-daemonset
    - |
      apiVersion: apps/v1
      kind: DaemonSet
      metadata:
        name: fluentd
      spec:
        selector:
          matchLabels:
            name: fluentd
        template:
          metadata:
            labels:
              name: fluentd
          spec:
            containers:
            - name: fluentd
              image: fluentd:latest
              volumeMounts:
              - name: varlog
                mountPath: /var/log
            volumes:
            - name: varlog
              hostPath:
                path: /var/log
    - DaemonSet running logging agent on every node
    - medium
    - workloads
    - 7
    - '{"DaemonSet":"runs one pod per node"}'
    - Node selector can prevent pods on some nodes
    - CKA
    - Use for logging, monitoring, or node maintenance tasks
    - "[]"
    - 0
    - 0.0
    - false
    -
    - apps/v1
    - '2025-11-06 03:44:02.975941'
    - '2025-11-06 03:44:02.975941'
  - - 33
    - job
    - basic-job
    - |
      apiVersion: batch/v1
      kind: Job
      metadata:
        name: pi-calculation
      spec:
        template:
          spec:
            containers:
            - name: pi
              image: perl
              command: ["perl", "-Mbignum=bpi", "-wle", "print bpi(2000)"]
            restartPolicy: Never
        backoffLimit: 4
    - Job running a task to completion
    - medium
    - workloads
    - 8
    - '{"backoffLimit":"retry attempts","restartPolicy":"must be Never or OnFailure"}'
    - restartPolicy cannot be Always for jobs
    - CKAD
    - Use for batch processing, migrations, backups
    - "[]"
    - 0
    - 0.0
    - false
    -
    - batch/v1
    - '2025-11-06 03:44:02.980617'
    - '2025-11-06 03:44:02.980617'
  - - 34
    - job
    - parallel-job
    - |
      apiVersion: batch/v1
      kind: Job
      metadata:
        name: parallel-job
      spec:
        parallelism: 3
        completions: 6
        template:
          spec:
            containers:
            - name: worker
              image: busybox
              command: ["sh", "-c", "echo Processing item && sleep 10"]
            restartPolicy: Never
    - Job with parallel execution of multiple pods
    - medium
    - workloads
    - 7
    - '{"parallelism":"concurrent pods","completions":"total successful runs needed"}'
    - Job completes when completions count is reached
    - CKA
    - Use for parallel batch processing
    - "[]"
    - 0
    - 0.0
    - false
    -
    - batch/v1
    - '2025-11-06 03:44:02.987103'
    - '2025-11-06 03:44:02.987103'
  - - 35
    - cronjob
    - basic-cronjob
    - |
      apiVersion: batch/v1
      kind: CronJob
      metadata:
        name: backup-job
      spec:
        schedule: "0 2 * * *"
        jobTemplate:
          spec:
            template:
              spec:
                containers:
                - name: backup
                  image: backup-tool:latest
                  command: ["sh", "-c", "backup-script.sh"]
                restartPolicy: OnFailure
    - CronJob running backup at 2 AM daily
    - medium
    - workloads
    - 7
    - '{"schedule":"cron format schedule"}'
    - 'Cron syntax: minute hour day month weekday'
    - CKAD
    - Use for scheduled maintenance, backups, reports
    - "[]"
    - 0
    - 0.0
    - false
    -
    - batch/v1
    - '2025-11-06 03:44:02.992412'
    - '2025-11-06 03:44:02.992412'
  - - 36
    - networkpolicy
    - deny-all-ingress
    - |
      apiVersion: networking.k8s.io/v1
      kind: NetworkPolicy
      metadata:
        name: deny-all-ingress
        namespace: production
      spec:
        podSelector: {}
        policyTypes:
        - Ingress
    - NetworkPolicy denying all ingress traffic to all pods
    - medium
    - security
    - 8
    - '{"podSelector":"target pods","policyTypes":"Ingress/Egress"}'
    - Requires network plugin that supports NetworkPolicy
    - CKA
    - Start with deny-all, then add allow rules
    - "[]"
    - 0
    - 0.0
    - false
    -
    - networking.k8s.io/v1
    - '2025-11-06 03:44:03.001290'
    - '2025-11-06 03:44:03.001290'
  - - 37
    - networkpolicy
    - allow-from-frontend
    - |
      apiVersion: networking.k8s.io/v1
      kind: NetworkPolicy
      metadata:
        name: allow-frontend
      spec:
        podSelector:
          matchLabels:
            app: backend
        policyTypes:
        - Ingress
        ingress:
        - from:
          - podSelector:
              matchLabels:
                app: frontend
          ports:
          - protocol: TCP
            port: 8080
    - NetworkPolicy allowing ingress from frontend to backend
    - medium
    - security
    - 8
    - '{"ingress.from":"source selector","ports":"allowed ports"}'
    - Empty podSelector means all pods in namespace
    - CKA
    - Use labels for fine-grained access control
    - "[]"
    - 0
    - 0.0
    - false
    -
    - networking.k8s.io/v1
    - '2025-11-06 03:44:03.008977'
    - '2025-11-06 03:44:03.008977'
  - - 38
    - serviceaccount
    - basic-serviceaccount
    - |
      apiVersion: v1
      kind: ServiceAccount
      metadata:
        name: app-sa
        namespace: default
    - ServiceAccount for pod authentication
    - easy
    - rbac
    - 7
    - '{"ServiceAccount":"identity for pods"}'
    - Must exist before referencing in pod spec
    - CKA
    - Use separate ServiceAccounts for different applications
    - "[]"
    - 0
    - 0.0
    - false
    -
    - v1
    - '2025-11-06 03:44:03.014410'
    - '2025-11-06 03:44:03.014410'
  - - 39
    - role
    - pod-reader-role
    - |
      apiVersion: rbac.authorization.k8s.io/v1
      kind: Role
      metadata:
        name: pod-reader
        namespace: default
      rules:
      - apiGroups: [""]
        resources: ["pods"]
        verbs: ["get", "list", "watch"]
    - Role granting read-only access to pods in namespace
    - medium
    - rbac
    - 8
    - '{"rules":"permissions","apiGroups":"API groups","resources":"resource types","verbs":"actions"}'
    - Empty apiGroups means core API group
    - CKA
    - Grant least privilege necessary
    - "[]"
    - 0
    - 0.0
    - false
    -
    - rbac.authorization.k8s.io/v1
    - '2025-11-06 03:44:03.021273'
    - '2025-11-06 03:44:03.021273'
  - - 40
    - rolebinding
    - read-pods-binding
    - |
      apiVersion: rbac.authorization.k8s.io/v1
      kind: RoleBinding
      metadata:
        name: read-pods
        namespace: default
      subjects:
      - kind: ServiceAccount
        name: app-sa
        namespace: default
      roleRef:
        kind: Role
        name: pod-reader
        apiGroup: rbac.authorization.k8s.io
    - RoleBinding connecting ServiceAccount to Role
    - medium
    - rbac
    - 8
    - '{"subjects":"who gets permissions","roleRef":"which role"}'
    - roleRef is immutable, delete and recreate to change
    - CKA
    - Bind roles to ServiceAccounts, not users directly
    - "[]"
    - 0
    - 0.0
    - false
    -
    - rbac.authorization.k8s.io/v1
    - '2025-11-06 03:44:03.028049'
    - '2025-11-06 03:44:03.028049'
  - - 41
    - clusterrole
    - node-reader
    - |
      apiVersion: rbac.authorization.k8s.io/v1
      kind: ClusterRole
      metadata:
        name: node-reader
      rules:
      - apiGroups: [""]
        resources: ["nodes"]
        verbs: ["get", "list", "watch"]
    - ClusterRole for cluster-wide node read access
    - medium
    - rbac
    - 7
    - '{"ClusterRole":"cluster-scoped role"}'
    - ClusterRole has no namespace
    - CKA
    - Use ClusterRole for cluster-scoped resources
    - "[]"
    - 0
    - 0.0
    - false
    -
    - rbac.authorization.k8s.io/v1
    - '2025-11-06 03:44:03.033997'
    - '2025-11-06 03:44:03.033997'
  - - 42
    - clusterrolebinding
    - node-reader-binding
    - |
      apiVersion: rbac.authorization.k8s.io/v1
      kind: ClusterRoleBinding
      metadata:
        name: read-nodes-global
      subjects:
      - kind: ServiceAccount
        name: monitoring-sa
        namespace: monitoring
      roleRef:
        kind: ClusterRole
        name: node-reader
        apiGroup: rbac.authorization.k8s.io
    - ClusterRoleBinding granting cluster-wide permissions
    - medium
    - rbac
    - 7
    - '{"ClusterRoleBinding":"cluster-wide binding"}'
    - Grants permissions across all namespaces
    - CKA
    - Use sparingly, prefer namespaced RoleBindings
    - "[]"
    - 0
    - 0.0
    - false
    -
    - rbac.authorization.k8s.io/v1
    - '2025-11-06 03:44:03.053835'
    - '2025-11-06 03:44:03.053835'
  - - 43
    - horizontalpodautoscaler
    - cpu-autoscaler
    - |
      apiVersion: autoscaling/v2
      kind: HorizontalPodAutoscaler
      metadata:
        name: web-hpa
      spec:
        scaleTargetRef:
          apiVersion: apps/v1
          kind: Deployment
          name: web-deployment
        minReplicas: 2
        maxReplicas: 10
        metrics:
        - type: Resource
          resource:
            name: cpu
            target:
              type: Utilization
              averageUtilization: 70
    - HPA scaling deployment based on CPU utilization
    - hard
    - scheduling
    - 7
    - '{"scaleTargetRef":"target workload","metrics":"scaling metrics"}'
    - Requires metrics-server to be running
    - CKA
    - Set appropriate min/max to prevent over/under scaling
    - "[]"
    - 0
    - 0.0
    - false
    -
    - autoscaling/v2
    - '2025-11-06 03:44:03.074947'
    - '2025-11-06 03:44:03.074947'
  - - 44
    - poddisruptionbudget
    - basic-pdb
    - |
      apiVersion: policy/v1
      kind: PodDisruptionBudget
      metadata:
        name: web-pdb
      spec:
        minAvailable: 2
        selector:
          matchLabels:
            app: web
    - PodDisruptionBudget ensuring minimum pods during disruptions
    - medium
    - scheduling
    - 6
    - '{"minAvailable":"minimum pods","maxUnavailable":"maximum unavailable"}'
    - Cannot use both minAvailable and maxUnavailable
    - CKA
    - Use to ensure availability during node maintenance
    - "[]"
    - 0
    - 0.0
    - false
    -
    - policy/v1
    - '2025-11-06 03:44:03.082132'
    - '2025-11-06 03:44:03.082132'
  - - 45
    - priorityclass
    - high-priority
    - |
      apiVersion: scheduling.k8s.io/v1
      kind: PriorityClass
      metadata:
        name: high-priority
      value: 1000000
      globalDefault: false
      description: "High priority class for critical workloads"
    - PriorityClass for pod scheduling priority
    - medium
    - scheduling
    - 5
    - '{"value":"priority value (higher = more important)"}'
    - System classes have values > 1000000000
    - CKA
    - Use for critical system pods
    - "[]"
    - 0
    - 0.0
    - false
    -
    - scheduling.k8s.io/v1
    - '2025-11-06 03:44:03.087741'
    - '2025-11-06 03:44:03.087741'
  - - 46
    - pod
    - pod-with-node-selector
    - |
      apiVersion: v1
      kind: Pod
      metadata:
        name: node-selector-pod
      spec:
        nodeSelector:
          disktype: ssd
        containers:
        - name: app
          image: nginx
    - Pod with node selector for scheduling on specific nodes
    - medium
    - scheduling
    - 8
    - '{"nodeSelector":"label-based node selection"}'
    - Node must have matching labels
    - CKA
    - Use for hardware-specific requirements
    - "[]"
    - 0
    - 0.0
    - false
    -
    - v1
    - '2025-11-06 03:44:03.093799'
    - '2025-11-06 03:44:03.093799'
  - - 47
    - pod
    - pod-with-affinity
    - |
      apiVersion: v1
      kind: Pod
      metadata:
        name: affinity-pod
      spec:
        affinity:
          podAffinity:
            requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - cache
              topologyKey: kubernetes.io/hostname
        containers:
        - name: app
          image: nginx
    - Pod with affinity rules for co-location
    - hard
    - scheduling
    - 7
    - '{"affinity":"affinity/anti-affinity rules"}'
    - topologyKey must reference valid node label
    - CKA
    - Use for performance optimization
    - "[]"
    - 0
    - 0.0
    - false
    -
    - v1
    - '2025-11-06 03:44:03.099487'
    - '2025-11-06 03:44:03.099487'
  - - 48
    - pod
    - pod-with-tolerations
    - |
      apiVersion: v1
      kind: Pod
      metadata:
        name: toleration-pod
      spec:
        tolerations:
        - key: "special"
          operator: "Equal"
          value: "true"
          effect: "NoSchedule"
        containers:
        - name: app
          image: nginx
    - Pod with toleration to schedule on tainted nodes
    - medium
    - scheduling
    - 8
    - '{"tolerations":"tolerate node taints"}'
    - Toleration must match taint key, value, and effect
    - CKA
    - Use with node taints for dedicated nodes
    - "[]"
    - 0
    - 0.0
    - false
    -
    - v1
    - '2025-11-06 03:44:03.105235'
    - '2025-11-06 03:44:03.105235'
  - - 49
    - pod
    - pod-with-host-network
    - |
      apiVersion: v1
      kind: Pod
      metadata:
        name: hostnet-pod
      spec:
        hostNetwork: true
        containers:
        - name: app
          image: nginx
    - Pod using host network namespace
    - medium
    - networking
    - 6
    - '{"hostNetwork":"use host networking"}'
    - Port conflicts with host services
    - CKA
    - Use for network monitoring tools only
    - "[]"
    - 0
    - 0.0
    - false
    -
    - v1
    - '2025-11-06 03:44:03.111995'
    - '2025-11-06 03:44:03.111995'
  - - 50
    - pod
    - pod-with-service-account
    - |
      apiVersion: v1
      kind: Pod
      metadata:
        name: sa-pod
      spec:
        serviceAccountName: custom-sa
        containers:
        - name: app
          image: nginx
    - Pod with custom ServiceAccount
    - easy
    - security
    - 7
    - '{"serviceAccountName":"service account to use"}'
    - ServiceAccount must exist in same namespace
    - CKA
    - Use custom ServiceAccounts for API access
    - "[]"
    - 0
    - 0.0
    - false
    -
    - v1
    - '2025-11-06 03:44:03.116130'
    - '2025-11-06 03:44:03.116130'

---
learning_sessions:
  columns:
  - id
  - user_id
  - session_id
  - state_data
  - items_presented
  - items_correct
  - items_failed
  - started_at
  - last_activity_at
  - completed_at
  - completion_reason
  - performance_metrics
  - created_at
  - updated_at
  records: 
  - - 1
    - 1
    - LS-42fce5e3dc225015-1762401818
    - '{"current_state":"START","current_item_id":null,"current_item_type":null,"current_chapter":null,"current_micro":null,"completed_micros":{},"responses":[],"weakness_areas":[],"review_items":[],"completed_items":[],"skipped_items":[]}'
    - 0
    - 0
    - 0
    - '2025-11-06 04:03:38.465061'
    - '2025-11-06 04:03:38.465062'
    - '2025-11-06 08:13:47.725001'
    - system_ended
    - '{"max_streak":0,"avg_response_time":0,"difficulty_progression":[],"topic_coverage":{},"mastery_improvements":[]}'
    - '2025-11-06 04:03:38.471091'
    - '2025-11-06 04:03:38.471091'
  - - 2
    - 1
    - LS-73d41d184b7ca4a3-1762416827
    - '{"current_state":"START","current_item_id":null,"current_item_type":null,"current_chapter":null,"current_micro":null,"completed_micros":{},"responses":[],"weakness_areas":[],"review_items":[],"completed_items":[],"skipped_items":[]}'
    - 0
    - 0
    - 0
    - '2025-11-06 08:13:47.725426'
    - '2025-11-06 08:13:47.725427'
    - '2025-11-06 18:13:34.288937'
    - system_ended
    - '{"max_streak":0,"avg_response_time":0,"difficulty_progression":[],"topic_coverage":{},"mastery_improvements":[]}'
    - '2025-11-06 08:13:47.726869'
    - '2025-11-06 08:13:47.726869'
  - - 3
    - 1
    - LS-646ce3790c512e68-1762452814
    - '{"current_state":"START","current_item_id":null,"current_item_type":null,"current_chapter":null,"current_micro":null,"completed_micros":{},"responses":[],"weakness_areas":[],"review_items":[],"completed_items":[],"skipped_items":[]}'
    - 0
    - 0
    - 0
    - '2025-11-06 18:13:34.289517'
    - '2025-11-06 18:13:34.289519'
    -
    -
    - '{"max_streak":0,"avg_response_time":0,"difficulty_progression":[],"topic_coverage":{},"mastery_improvements":[]}'
    - '2025-11-06 18:13:34.291171'
    - '2025-11-06 18:13:34.291171'

---
module_interactive_units:
  columns:
  - id
  - course_module_id
  - interactive_learning_unit_id
  - sequence_order
  - required
  - created_at
  - updated_at
  records: 
  - - 1
    - 12
    - 1
    - 1
    - true
    - '2025-11-06 03:44:04.191482'
    - '2025-11-06 03:44:04.191482'
  - - 2
    - 12
    - 2
    - 2
    - true
    - '2025-11-06 03:44:04.213988'
    - '2025-11-06 03:44:04.213988'
  - - 3
    - 12
    - 3
    - 3
    - true
    - '2025-11-06 03:44:04.229572'
    - '2025-11-06 03:44:04.229572'
  - - 4
    - 12
    - 4
    - 4
    - true
    - '2025-11-06 03:44:04.247594'
    - '2025-11-06 03:44:04.247594'
  - - 5
    - 12
    - 5
    - 5
    - true
    - '2025-11-06 03:44:04.263241'
    - '2025-11-06 03:44:04.263241'
  - - 6
    - 12
    - 6
    - 6
    - true
    - '2025-11-06 03:44:04.276898'
    - '2025-11-06 03:44:04.276898'
  - - 7
    - 12
    - 7
    - 7
    - true
    - '2025-11-06 03:44:04.286814'
    - '2025-11-06 03:44:04.286814'
  - - 8
    - 12
    - 8
    - 8
    - true
    - '2025-11-06 03:44:04.295256'
    - '2025-11-06 03:44:04.295256'
  - - 9
    - 12
    - 9
    - 9
    - true
    - '2025-11-06 03:44:04.304765'
    - '2025-11-06 03:44:04.304765'
  - - 10
    - 12
    - 10
    - 10
    - true
    - '2025-11-06 03:44:04.314578'
    - '2025-11-06 03:44:04.314578'
  - - 11
    - 12
    - 11
    - 11
    - true
    - '2025-11-06 03:44:04.323310'
    - '2025-11-06 03:44:04.323310'
  - - 12
    - 12
    - 12
    - 12
    - true
    - '2025-11-06 03:44:04.332126'
    - '2025-11-06 03:44:04.332126'
  - - 13
    - 12
    - 13
    - 13
    - true
    - '2025-11-06 03:44:04.340512'
    - '2025-11-06 03:44:04.340512'
  - - 14
    - 12
    - 14
    - 14
    - true
    - '2025-11-06 03:44:04.351348'
    - '2025-11-06 03:44:04.351348'
  - - 15
    - 12
    - 15
    - 15
    - true
    - '2025-11-06 03:44:04.360090'
    - '2025-11-06 03:44:04.360090'
  - - 16
    - 12
    - 16
    - 16
    - true
    - '2025-11-06 03:44:04.369521'
    - '2025-11-06 03:44:04.369521'
  - - 17
    - 13
    - 17
    - 1
    - true
    - '2025-11-06 03:44:04.390407'
    - '2025-11-06 03:44:04.390407'
  - - 18
    - 13
    - 18
    - 2
    - true
    - '2025-11-06 03:44:04.404662'
    - '2025-11-06 03:44:04.404662'
  - - 19
    - 13
    - 19
    - 3
    - true
    - '2025-11-06 03:44:04.418678'
    - '2025-11-06 03:44:04.418678'
  - - 20
    - 13
    - 20
    - 4
    - true
    - '2025-11-06 03:44:04.430476'
    - '2025-11-06 03:44:04.430476'
  - - 21
    - 13
    - 21
    - 5
    - true
    - '2025-11-06 03:44:04.442338'
    - '2025-11-06 03:44:04.442338'
  - - 22
    - 13
    - 22
    - 6
    - true
    - '2025-11-06 03:44:04.454537'
    - '2025-11-06 03:44:04.454537'
  - - 23
    - 13
    - 23
    - 7
    - true
    - '2025-11-06 03:44:04.469057'
    - '2025-11-06 03:44:04.469057'
  - - 24
    - 13
    - 24
    - 8
    - true
    - '2025-11-06 03:44:04.481380'
    - '2025-11-06 03:44:04.481380'
  - - 25
    - 13
    - 25
    - 9
    - true
    - '2025-11-06 03:44:04.493704'
    - '2025-11-06 03:44:04.493704'
  - - 26
    - 13
    - 26
    - 10
    - true
    - '2025-11-06 03:44:04.507087'
    - '2025-11-06 03:44:04.507087'
  - - 27
    - 13
    - 27
    - 11
    - true
    - '2025-11-06 03:44:04.519053'
    - '2025-11-06 03:44:04.519053'
  - - 28
    - 13
    - 28
    - 12
    - true
    - '2025-11-06 03:44:04.530353'
    - '2025-11-06 03:44:04.530353'
  - - 29
    - 13
    - 29
    - 13
    - true
    - '2025-11-06 03:44:04.542016'
    - '2025-11-06 03:44:04.542016'
  - - 30
    - 13
    - 30
    - 14
    - true
    - '2025-11-06 03:44:04.553098'
    - '2025-11-06 03:44:04.553098'
  - - 31
    - 13
    - 31
    - 15
    - true
    - '2025-11-06 03:44:04.564773'
    - '2025-11-06 03:44:04.564773'
  - - 32
    - 13
    - 32
    - 16
    - true
    - '2025-11-06 03:44:04.576859'
    - '2025-11-06 03:44:04.576859'
  - - 33
    - 13
    - 33
    - 17
    - true
    - '2025-11-06 03:44:04.588793'
    - '2025-11-06 03:44:04.588793'
  - - 34
    - 13
    - 34
    - 18
    - true
    - '2025-11-06 03:44:04.601056'
    - '2025-11-06 03:44:04.601056'
  - - 35
    - 13
    - 35
    - 19
    - true
    - '2025-11-06 03:44:04.613923'
    - '2025-11-06 03:44:04.613923'
  - - 36
    - 13
    - 36
    - 20
    - true
    - '2025-11-06 03:44:04.625196'
    - '2025-11-06 03:44:04.625196'
  - - 37
    - 13
    - 37
    - 21
    - true
    - '2025-11-06 03:44:04.636278'
    - '2025-11-06 03:44:04.636278'
  - - 38
    - 14
    - 38
    - 1
    - true
    - '2025-11-06 03:44:04.653202'
    - '2025-11-06 03:44:04.653202'
  - - 39
    - 14
    - 39
    - 2
    - true
    - '2025-11-06 03:44:04.664326'
    - '2025-11-06 03:44:04.664326'
  - - 40
    - 14
    - 40
    - 3
    - true
    - '2025-11-06 03:44:04.675537'
    - '2025-11-06 03:44:04.675537'
  - - 41
    - 14
    - 41
    - 4
    - true
    - '2025-11-06 03:44:04.688485'
    - '2025-11-06 03:44:04.688485'
  - - 42
    - 14
    - 42
    - 5
    - true
    - '2025-11-06 03:44:04.699930'
    - '2025-11-06 03:44:04.699930'
  - - 43
    - 14
    - 43
    - 6
    - true
    - '2025-11-06 03:44:04.711137'
    - '2025-11-06 03:44:04.711137'
  - - 44
    - 14
    - 44
    - 7
    - true
    - '2025-11-06 03:44:04.722473'
    - '2025-11-06 03:44:04.722473'
  - - 45
    - 14
    - 45
    - 8
    - true
    - '2025-11-06 03:44:04.733935'
    - '2025-11-06 03:44:04.733935'
  - - 46
    - 14
    - 46
    - 9
    - true
    - '2025-11-06 03:44:04.745273'
    - '2025-11-06 03:44:04.745273'
  - - 47
    - 14
    - 47
    - 10
    - true
    - '2025-11-06 03:44:04.757063'
    - '2025-11-06 03:44:04.757063'
  - - 48
    - 14
    - 48
    - 11
    - true
    - '2025-11-06 03:44:04.768527'
    - '2025-11-06 03:44:04.768527'
  - - 49
    - 5
    - 49
    - 1
    - true
    - '2025-11-06 03:44:04.782357'
    - '2025-11-06 03:44:04.782357'
  - - 50
    - 5
    - 50
    - 2
    - true
    - '2025-11-06 03:44:04.794181'
    - '2025-11-06 03:44:04.794181'
  - - 51
    - 5
    - 51
    - 3
    - true
    - '2025-11-06 03:44:04.806853'
    - '2025-11-06 03:44:04.806853'
  - - 52
    - 5
    - 52
    - 4
    - true
    - '2025-11-06 03:44:04.820409'
    - '2025-11-06 03:44:04.820409'
  - - 53
    - 5
    - 53
    - 5
    - true
    - '2025-11-06 03:44:04.833007'
    - '2025-11-06 03:44:04.833007'
  - - 54
    - 5
    - 54
    - 6
    - true
    - '2025-11-06 03:44:04.844444'
    - '2025-11-06 03:44:04.844444'
  - - 55
    - 5
    - 55
    - 7
    - true
    - '2025-11-06 03:44:04.856073'
    - '2025-11-06 03:44:04.856073'
  - - 56
    - 5
    - 56
    - 8
    - true
    - '2025-11-06 03:44:04.867188'
    - '2025-11-06 03:44:04.867188'
  - - 57
    - 16
    - 57
    - 1
    - true
    - '2025-11-06 04:01:39.828405'
    - '2025-11-06 04:01:39.828405'
  - - 58
    - 16
    - 58
    - 2
    - true
    - '2025-11-06 04:01:39.836511'
    - '2025-11-06 04:01:39.836511'
  - - 59
    - 16
    - 59
    - 3
    - true
    - '2025-11-06 04:01:39.843466'
    - '2025-11-06 04:01:39.843466'
  - - 60
    - 16
    - 60
    - 4
    - true
    - '2025-11-06 04:01:39.849850'
    - '2025-11-06 04:01:39.849850'
  - - 61
    - 16
    - 61
    - 5
    - true
    - '2025-11-06 04:01:39.856459'
    - '2025-11-06 04:01:39.856459'
  - - 62
    - 16
    - 62
    - 6
    - true
    - '2025-11-06 04:01:39.863724'
    - '2025-11-06 04:01:39.863724'
  - - 63
    - 16
    - 63
    - 7
    - true
    - '2025-11-06 04:01:39.870881'
    - '2025-11-06 04:01:39.870881'
  - - 64
    - 17
    - 64
    - 1
    - true
    - '2025-11-06 04:02:24.137034'
    - '2025-11-06 04:02:24.137034'
  - - 65
    - 17
    - 65
    - 2
    - true
    - '2025-11-06 04:02:24.143803'
    - '2025-11-06 04:02:24.143803'
  - - 66
    - 17
    - 66
    - 3
    - true
    - '2025-11-06 04:02:24.150427'
    - '2025-11-06 04:02:24.150427'
  - - 67
    - 17
    - 67
    - 4
    - true
    - '2025-11-06 04:02:24.161627'
    - '2025-11-06 04:02:24.161627'
  - - 68
    - 17
    - 68
    - 5
    - true
    - '2025-11-06 04:02:24.168177'
    - '2025-11-06 04:02:24.168177'
  - - 69
    - 17
    - 69
    - 6
    - true
    - '2025-11-06 04:02:24.174921'
    - '2025-11-06 04:02:24.174921'
  - - 70
    - 17
    - 70
    - 7
    - true
    - '2025-11-06 04:02:24.181852'
    - '2025-11-06 04:02:24.181852'
  - - 71
    - 23
    - 71
    - 1
    - true
    - '2025-11-06 04:12:16.924924'
    - '2025-11-06 04:12:16.924924'
  - - 72
    - 23
    - 72
    - 2
    - true
    - '2025-11-06 04:12:16.950685'
    - '2025-11-06 04:12:16.950685'
  - - 73
    - 23
    - 73
    - 3
    - true
    - '2025-11-06 04:12:16.956022'
    - '2025-11-06 04:12:16.956022'
  - - 74
    - 23
    - 74
    - 4
    - true
    - '2025-11-06 04:12:16.965868'
    - '2025-11-06 04:12:16.965868'
  - - 75
    - 23
    - 75
    - 5
    - true
    - '2025-11-06 04:12:16.971089'
    - '2025-11-06 04:12:16.971089'
  - - 76
    - 23
    - 76
    - 6
    - true
    - '2025-11-06 04:12:16.976234'
    - '2025-11-06 04:12:16.976234'
  - - 77
    - 23
    - 77
    - 7
    - true
    - '2025-11-06 04:12:16.980982'
    - '2025-11-06 04:12:16.980982'
  - - 78
    - 23
    - 78
    - 8
    - true
    - '2025-11-06 04:12:16.986265'
    - '2025-11-06 04:12:16.986265'
  - - 79
    - 25
    - 79
    - 1
    - true
    - '2025-11-06 04:14:02.417214'
    - '2025-11-06 04:14:02.417214'
  - - 80
    - 25
    - 80
    - 2
    - true
    - '2025-11-06 04:14:02.420054'
    - '2025-11-06 04:14:02.420054'
  - - 81
    - 25
    - 81
    - 3
    - true
    - '2025-11-06 04:14:02.422142'
    - '2025-11-06 04:14:02.422142'
  - - 82
    - 25
    - 82
    - 4
    - true
    - '2025-11-06 04:14:02.424134'
    - '2025-11-06 04:14:02.424134'
  - - 83
    - 25
    - 83
    - 5
    - true
    - '2025-11-06 04:14:02.431813'
    - '2025-11-06 04:14:02.431813'
  - - 84
    - 25
    - 84
    - 6
    - true
    - '2025-11-06 04:14:02.434069'
    - '2025-11-06 04:14:02.434069'
  - - 85
    - 25
    - 85
    - 7
    - true
    - '2025-11-06 04:14:02.436087'
    - '2025-11-06 04:14:02.436087'
  - - 86
    - 25
    - 86
    - 8
    - true
    - '2025-11-06 04:14:02.438272'
    - '2025-11-06 04:14:02.438272'
  - - 87
    - 25
    - 87
    - 9
    - true
    - '2025-11-06 04:14:02.440209'
    - '2025-11-06 04:14:02.440209'
  - - 88
    - 25
    - 88
    - 10
    - true
    - '2025-11-06 04:14:02.442338'
    - '2025-11-06 04:14:02.442338'
  - - 89
    - 25
    - 89
    - 11
    - true
    - '2025-11-06 04:14:02.444390'
    - '2025-11-06 04:14:02.444390'
  - - 90
    - 25
    - 90
    - 12
    - true
    - '2025-11-06 04:14:02.446385'
    - '2025-11-06 04:14:02.446385'
  - - 91
    - 25
    - 91
    - 13
    - true
    - '2025-11-06 04:14:02.448331'
    - '2025-11-06 04:14:02.448331'
  - - 92
    - 25
    - 92
    - 14
    - true
    - '2025-11-06 04:14:02.450190'
    - '2025-11-06 04:14:02.450190'
  - - 93
    - 25
    - 93
    - 15
    - true
    - '2025-11-06 04:14:02.452436'
    - '2025-11-06 04:14:02.452436'
  - - 94
    - 30
    - 7
    - 7
    - true
    - '2025-11-06 08:52:19.754244'
    - '2025-11-06 08:52:19.754244'
  - - 95
    - 30
    - 8
    - 8
    - true
    - '2025-11-06 08:52:19.756701'
    - '2025-11-06 08:52:19.756701'
  - - 96
    - 30
    - 9
    - 9
    - true
    - '2025-11-06 08:52:19.758972'
    - '2025-11-06 08:52:19.758972'
  - - 97
    - 30
    - 10
    - 10
    - true
    - '2025-11-06 08:52:19.761223'
    - '2025-11-06 08:52:19.761223'
  - - 98
    - 30
    - 33
    - 11
    - true
    - '2025-11-06 08:52:19.763878'
    - '2025-11-06 08:52:19.763878'
  - - 99
    - 30
    - 47
    - 12
    - true
    - '2025-11-06 08:52:19.766224'
    - '2025-11-06 08:52:19.766224'
  - - 100
    - 31
    - 1
    - 8
    - true
    - '2025-11-06 08:52:19.768551'
    - '2025-11-06 08:52:19.768551'
  - - 101
    - 31
    - 2
    - 9
    - true
    - '2025-11-06 08:52:19.770755'
    - '2025-11-06 08:52:19.770755'
  - - 102
    - 31
    - 3
    - 10
    - true
    - '2025-11-06 08:52:19.776121'
    - '2025-11-06 08:52:19.776121'
  - - 103
    - 31
    - 4
    - 11
    - true
    - '2025-11-06 08:52:19.778803'
    - '2025-11-06 08:52:19.778803'
  - - 104
    - 31
    - 5
    - 12
    - true
    - '2025-11-06 08:52:19.781337'
    - '2025-11-06 08:52:19.781337'
  - - 105
    - 31
    - 6
    - 13
    - true
    - '2025-11-06 08:52:19.783806'
    - '2025-11-06 08:52:19.783806'
  - - 106
    - 31
    - 7
    - 14
    - true
    - '2025-11-06 08:52:19.786034'
    - '2025-11-06 08:52:19.786034'
  - - 107
    - 31
    - 9
    - 15
    - true
    - '2025-11-06 08:52:19.788279'
    - '2025-11-06 08:52:19.788279'
  - - 108
    - 31
    - 11
    - 16
    - true
    - '2025-11-06 08:52:19.790729'
    - '2025-11-06 08:52:19.790729'
  - - 109
    - 31
    - 12
    - 17
    - true
    - '2025-11-06 08:52:19.793182'
    - '2025-11-06 08:52:19.793182'
  - - 110
    - 31
    - 13
    - 18
    - true
    - '2025-11-06 08:52:19.795385'
    - '2025-11-06 08:52:19.795385'
  - - 111
    - 31
    - 15
    - 19
    - true
    - '2025-11-06 08:52:19.797739'
    - '2025-11-06 08:52:19.797739'
  - - 112
    - 31
    - 16
    - 20
    - true
    - '2025-11-06 08:52:19.800168'
    - '2025-11-06 08:52:19.800168'
  - - 113
    - 31
    - 17
    - 21
    - true
    - '2025-11-06 08:52:19.802252'
    - '2025-11-06 08:52:19.802252'
  - - 114
    - 31
    - 19
    - 22
    - true
    - '2025-11-06 08:52:19.804305'
    - '2025-11-06 08:52:19.804305'
  - - 115
    - 31
    - 22
    - 23
    - true
    - '2025-11-06 08:52:19.806548'
    - '2025-11-06 08:52:19.806548'
  - - 116
    - 31
    - 27
    - 24
    - true
    - '2025-11-06 08:52:19.809056'
    - '2025-11-06 08:52:19.809056'
  - - 117
    - 31
    - 28
    - 25
    - true
    - '2025-11-06 08:52:19.811490'
    - '2025-11-06 08:52:19.811490'
  - - 118
    - 31
    - 29
    - 26
    - true
    - '2025-11-06 08:52:19.813966'
    - '2025-11-06 08:52:19.813966'
  - - 119
    - 31
    - 30
    - 27
    - true
    - '2025-11-06 08:52:19.816074'
    - '2025-11-06 08:52:19.816074'
  - - 120
    - 31
    - 31
    - 28
    - true
    - '2025-11-06 08:52:19.818259'
    - '2025-11-06 08:52:19.818259'
  - - 121
    - 31
    - 32
    - 29
    - true
    - '2025-11-06 08:52:19.820494'
    - '2025-11-06 08:52:19.820494'
  - - 122
    - 31
    - 33
    - 30
    - true
    - '2025-11-06 08:52:19.822607'
    - '2025-11-06 08:52:19.822607'
  - - 123
    - 31
    - 34
    - 31
    - true
    - '2025-11-06 08:52:19.824877'
    - '2025-11-06 08:52:19.824877'
  - - 124
    - 31
    - 35
    - 32
    - true
    - '2025-11-06 08:52:19.827013'
    - '2025-11-06 08:52:19.827013'
  - - 125
    - 31
    - 36
    - 33
    - true
    - '2025-11-06 08:52:19.829186'
    - '2025-11-06 08:52:19.829186'
  - - 126
    - 31
    - 37
    - 34
    - true
    - '2025-11-06 08:52:19.831349'
    - '2025-11-06 08:52:19.831349'
  - - 127
    - 31
    - 43
    - 35
    - true
    - '2025-11-06 08:52:19.833509'
    - '2025-11-06 08:52:19.833509'
  - - 128
    - 31
    - 44
    - 36
    - true
    - '2025-11-06 08:52:19.835792'
    - '2025-11-06 08:52:19.835792'
  - - 129
    - 31
    - 46
    - 37
    - true
    - '2025-11-06 08:52:19.838030'
    - '2025-11-06 08:52:19.838030'
  - - 130
    - 31
    - 47
    - 38
    - true
    - '2025-11-06 08:52:19.840230'
    - '2025-11-06 08:52:19.840230'
  - - 131
    - 31
    - 49
    - 39
    - true
    - '2025-11-06 08:52:19.842377'
    - '2025-11-06 08:52:19.842377'
  - - 132
    - 31
    - 50
    - 40
    - true
    - '2025-11-06 08:52:19.844583'
    - '2025-11-06 08:52:19.844583'
  - - 133
    - 31
    - 52
    - 41
    - true
    - '2025-11-06 08:52:19.846879'
    - '2025-11-06 08:52:19.846879'
  - - 134
    - 31
    - 53
    - 42
    - true
    - '2025-11-06 08:52:19.849230'
    - '2025-11-06 08:52:19.849230'
  - - 135
    - 31
    - 54
    - 43
    - true
    - '2025-11-06 08:52:19.851390'
    - '2025-11-06 08:52:19.851390'
  - - 136
    - 31
    - 56
    - 44
    - true
    - '2025-11-06 08:52:19.853626'
    - '2025-11-06 08:52:19.853626'
  - - 137
    - 31
    - 59
    - 45
    - true
    - '2025-11-06 08:52:19.855748'
    - '2025-11-06 08:52:19.855748'
  - - 138
    - 31
    - 63
    - 46
    - true
    - '2025-11-06 08:52:19.857847'
    - '2025-11-06 08:52:19.857847'
  - - 139
    - 31
    - 66
    - 47
    - true
    - '2025-11-06 08:52:19.860137'
    - '2025-11-06 08:52:19.860137'
  - - 140
    - 31
    - 68
    - 48
    - true
    - '2025-11-06 08:52:19.862471'
    - '2025-11-06 08:52:19.862471'
  - - 141
    - 31
    - 69
    - 49
    - true
    - '2025-11-06 08:52:19.864717'
    - '2025-11-06 08:52:19.864717'
  - - 142
    - 31
    - 72
    - 50
    - true
    - '2025-11-06 08:52:19.866897'
    - '2025-11-06 08:52:19.866897'
  - - 143
    - 31
    - 75
    - 51
    - true
    - '2025-11-06 08:52:19.870104'
    - '2025-11-06 08:52:19.870104'
  - - 144
    - 31
    - 77
    - 52
    - true
    - '2025-11-06 08:52:19.872791'
    - '2025-11-06 08:52:19.872791'
  - - 145
    - 31
    - 78
    - 53
    - true
    - '2025-11-06 08:52:19.875173'
    - '2025-11-06 08:52:19.875173'
  - - 146
    - 31
    - 80
    - 54
    - true
    - '2025-11-06 08:52:19.877686'
    - '2025-11-06 08:52:19.877686'
  - - 147
    - 31
    - 85
    - 55
    - true
    - '2025-11-06 08:52:19.879960'
    - '2025-11-06 08:52:19.879960'
  - - 148
    - 31
    - 91
    - 56
    - true
    - '2025-11-06 08:52:19.882477'
    - '2025-11-06 08:52:19.882477'
  - - 149
    - 31
    - 14
    - 57
    - true
    - '2025-11-06 08:52:19.884844'
    - '2025-11-06 08:52:19.884844'
  - - 150
    - 31
    - 21
    - 58
    - true
    - '2025-11-06 08:52:19.887223'
    - '2025-11-06 08:52:19.887223'
  - - 151
    - 31
    - 23
    - 59
    - true
    - '2025-11-06 08:52:19.889376'
    - '2025-11-06 08:52:19.889376'
  - - 152
    - 31
    - 25
    - 60
    - true
    - '2025-11-06 08:52:19.891993'
    - '2025-11-06 08:52:19.891993'
  - - 153
    - 31
    - 26
    - 61
    - true
    - '2025-11-06 08:52:19.895043'
    - '2025-11-06 08:52:19.895043'
  - - 154
    - 31
    - 73
    - 62
    - true
    - '2025-11-06 08:52:19.897803'
    - '2025-11-06 08:52:19.897803'
  - - 155
    - 31
    - 74
    - 63
    - true
    - '2025-11-06 08:52:19.900260'
    - '2025-11-06 08:52:19.900260'
  - - 156
    - 32
    - 38
    - 6
    - true
    - '2025-11-06 08:52:19.902671'
    - '2025-11-06 08:52:19.902671'
  - - 157
    - 32
    - 39
    - 7
    - true
    - '2025-11-06 08:52:19.905028'
    - '2025-11-06 08:52:19.905028'
  - - 158
    - 32
    - 40
    - 8
    - true
    - '2025-11-06 08:52:19.907380'
    - '2025-11-06 08:52:19.907380'
  - - 159
    - 32
    - 41
    - 9
    - true
    - '2025-11-06 08:52:19.909629'
    - '2025-11-06 08:52:19.909629'
  - - 160
    - 32
    - 42
    - 10
    - true
    - '2025-11-06 08:52:19.911864'
    - '2025-11-06 08:52:19.911864'
  - - 161
    - 32
    - 43
    - 11
    - true
    - '2025-11-06 08:52:19.914004'
    - '2025-11-06 08:52:19.914004'
  - - 162
    - 32
    - 44
    - 12
    - true
    - '2025-11-06 08:52:19.916164'
    - '2025-11-06 08:52:19.916164'
  - - 163
    - 32
    - 45
    - 13
    - true
    - '2025-11-06 08:52:19.918395'
    - '2025-11-06 08:52:19.918395'
  - - 164
    - 32
    - 46
    - 14
    - true
    - '2025-11-06 08:52:19.920443'
    - '2025-11-06 08:52:19.920443'
  - - 165
    - 32
    - 47
    - 15
    - true
    - '2025-11-06 08:52:19.922671'
    - '2025-11-06 08:52:19.922671'
  - - 166
    - 32
    - 48
    - 16
    - true
    - '2025-11-06 08:52:19.924856'
    - '2025-11-06 08:52:19.924856'
  - - 167
    - 32
    - 51
    - 17
    - true
    - '2025-11-06 08:52:19.927266'
    - '2025-11-06 08:52:19.927266'
  - - 168
    - 32
    - 79
    - 18
    - true
    - '2025-11-06 08:52:19.929776'
    - '2025-11-06 08:52:19.929776'
  - - 169
    - 32
    - 82
    - 19
    - true
    - '2025-11-06 08:52:19.932079'
    - '2025-11-06 08:52:19.932079'
  - - 170
    - 32
    - 76
    - 20
    - true
    - '2025-11-06 08:52:19.934223'
    - '2025-11-06 08:52:19.934223'
  - - 171
    - 32
    - 81
    - 21
    - true
    - '2025-11-06 08:52:19.936388'
    - '2025-11-06 08:52:19.936388'
  - - 172
    - 32
    - 83
    - 22
    - true
    - '2025-11-06 08:52:19.938424'
    - '2025-11-06 08:52:19.938424'
  - - 173
    - 32
    - 86
    - 23
    - true
    - '2025-11-06 08:52:19.940592'
    - '2025-11-06 08:52:19.940592'
  - - 174
    - 32
    - 87
    - 24
    - true
    - '2025-11-06 08:52:19.942722'
    - '2025-11-06 08:52:19.942722'
  - - 175
    - 32
    - 89
    - 25
    - true
    - '2025-11-06 08:52:19.945264'
    - '2025-11-06 08:52:19.945264'
  - - 176
    - 32
    - 92
    - 26
    - true
    - '2025-11-06 08:52:19.948625'
    - '2025-11-06 08:52:19.948625'
  - - 177
    - 32
    - 93
    - 27
    - true
    - '2025-11-06 08:52:19.952021'
    - '2025-11-06 08:52:19.952021'
  - - 178
    - 33
    - 18
    - 4
    - true
    - '2025-11-06 08:52:19.954823'
    - '2025-11-06 08:52:19.954823'
  - - 179
    - 33
    - 64
    - 5
    - true
    - '2025-11-06 08:52:19.957854'
    - '2025-11-06 08:52:19.957854'
  - - 180
    - 33
    - 65
    - 6
    - true
    - '2025-11-06 08:52:19.960391'
    - '2025-11-06 08:52:19.960391'
  - - 181
    - 33
    - 66
    - 7
    - true
    - '2025-11-06 08:52:19.963084'
    - '2025-11-06 08:52:19.963084'
  - - 182
    - 33
    - 67
    - 8
    - true
    - '2025-11-06 08:52:19.965493'
    - '2025-11-06 08:52:19.965493'
  - - 183
    - 33
    - 68
    - 9
    - true
    - '2025-11-06 08:52:19.968682'
    - '2025-11-06 08:52:19.968682'
  - - 184
    - 33
    - 69
    - 10
    - true
    - '2025-11-06 08:52:19.971793'
    - '2025-11-06 08:52:19.971793'
  - - 185
    - 33
    - 70
    - 11
    - true
    - '2025-11-06 08:52:19.975271'
    - '2025-11-06 08:52:19.975271'
  - - 186
    - 34
    - 20
    - 4
    - true
    - '2025-11-06 08:52:19.978807'
    - '2025-11-06 08:52:19.978807'
  - - 187
    - 34
    - 24
    - 5
    - true
    - '2025-11-06 08:52:19.981978'
    - '2025-11-06 08:52:19.981978'
  - - 188
    - 34
    - 57
    - 6
    - true
    - '2025-11-06 08:52:19.985293'
    - '2025-11-06 08:52:19.985293'
  - - 189
    - 34
    - 58
    - 7
    - true
    - '2025-11-06 08:52:19.988216'
    - '2025-11-06 08:52:19.988216'
  - - 190
    - 34
    - 59
    - 8
    - true
    - '2025-11-06 08:52:19.990796'
    - '2025-11-06 08:52:19.990796'
  - - 191
    - 34
    - 60
    - 9
    - true
    - '2025-11-06 08:52:19.993244'
    - '2025-11-06 08:52:19.993244'
  - - 192
    - 34
    - 61
    - 10
    - true
    - '2025-11-06 08:52:19.995532'
    - '2025-11-06 08:52:19.995532'
  - - 193
    - 34
    - 62
    - 11
    - true
    - '2025-11-06 08:52:19.997977'
    - '2025-11-06 08:52:19.997977'
  - - 194
    - 34
    - 63
    - 12
    - true
    - '2025-11-06 08:52:20.001139'
    - '2025-11-06 08:52:20.001139'
  - - 195
    - 34
    - 71
    - 13
    - true
    - '2025-11-06 08:52:20.003957'
    - '2025-11-06 08:52:20.003957'
  - - 196
    - 34
    - 80
    - 14
    - true
    - '2025-11-06 08:52:20.006793'
    - '2025-11-06 08:52:20.006793'
  - - 197
    - 34
    - 84
    - 15
    - true
    - '2025-11-06 08:52:20.009273'
    - '2025-11-06 08:52:20.009273'
  - - 198
    - 35
    - 49
    - 4
    - true
    - '2025-11-06 08:52:20.011892'
    - '2025-11-06 08:52:20.011892'
  - - 199
    - 35
    - 50
    - 5
    - true
    - '2025-11-06 08:52:20.014200'
    - '2025-11-06 08:52:20.014200'
  - - 200
    - 35
    - 51
    - 6
    - true
    - '2025-11-06 08:52:20.016620'
    - '2025-11-06 08:52:20.016620'
  - - 201
    - 35
    - 52
    - 7
    - true
    - '2025-11-06 08:52:20.018886'
    - '2025-11-06 08:52:20.018886'
  - - 202
    - 35
    - 53
    - 8
    - true
    - '2025-11-06 08:52:20.021116'
    - '2025-11-06 08:52:20.021116'
  - - 203
    - 35
    - 54
    - 9
    - true
    - '2025-11-06 08:52:20.023513'
    - '2025-11-06 08:52:20.023513'
  - - 204
    - 35
    - 55
    - 10
    - true
    - '2025-11-06 08:52:20.025642'
    - '2025-11-06 08:52:20.025642'
  - - 205
    - 35
    - 56
    - 11
    - true
    - '2025-11-06 08:52:20.027882'
    - '2025-11-06 08:52:20.027882'
  - - 206
    - 35
    - 88
    - 12
    - true
    - '2025-11-06 08:52:20.030124'
    - '2025-11-06 08:52:20.030124'
  - - 207
    - 35
    - 90
    - 13
    - true
    - '2025-11-06 08:52:20.032225'
    - '2025-11-06 08:52:20.032225'

---
module_items:
  columns:
  - id
  - course_module_id
  - item_type
  - item_id
  - sequence_order
  - required
  - created_at
  - updated_at
  records: 
  - - 1
    - 1
    - CourseLesson
    - 1
    - 1
    - true
    - '2025-11-06 03:44:03.480107'
    - '2025-11-06 03:44:03.480107'
  - - 2
    - 1
    - Quiz
    - 1
    - 2
    - true
    - '2025-11-06 03:44:03.514902'
    - '2025-11-06 03:44:03.514902'
  - - 3
    - 1
    - HandsOnLab
    - 1
    - 3
    - true
    - '2025-11-06 03:44:03.518736'
    - '2025-11-06 03:44:03.518736'
  - - 4
    - 2
    - CourseLesson
    - 2
    - 1
    - true
    - '2025-11-06 03:44:03.527457'
    - '2025-11-06 03:44:03.527457'
  - - 5
    - 2
    - Quiz
    - 2
    - 2
    - true
    - '2025-11-06 03:44:03.538551'
    - '2025-11-06 03:44:03.538551'
  - - 6
    - 3
    - CourseLesson
    - 3
    - 1
    - true
    - '2025-11-06 03:44:03.546824'
    - '2025-11-06 03:44:03.546824'
  - - 7
    - 3
    - Quiz
    - 3
    - 2
    - true
    - '2025-11-06 03:44:03.561294'
    - '2025-11-06 03:44:03.561294'
  - - 8
    - 3
    - HandsOnLab
    - 2
    - 3
    - true
    - '2025-11-06 03:44:03.564602'
    - '2025-11-06 03:44:03.564602'
  - - 9
    - 4
    - CourseLesson
    - 4
    - 1
    - true
    - '2025-11-06 03:44:03.573349'
    - '2025-11-06 03:44:03.573349'
  - - 10
    - 4
    - Quiz
    - 4
    - 2
    - true
    - '2025-11-06 03:44:03.584263'
    - '2025-11-06 03:44:03.584263'
  - - 11
    - 4
    - HandsOnLab
    - 4
    - 3
    - true
    - '2025-11-06 03:44:03.587342'
    - '2025-11-06 03:44:03.587342'
  - - 12
    - 5
    - CourseLesson
    - 5
    - 1
    - true
    - '2025-11-06 03:44:03.595876'
    - '2025-11-06 03:44:03.595876'
  - - 13
    - 5
    - Quiz
    - 5
    - 2
    - true
    - '2025-11-06 03:44:03.606397'
    - '2025-11-06 03:44:03.606397'
  - - 14
    - 5
    - HandsOnLab
    - 9
    - 3
    - true
    - '2025-11-06 03:44:03.609586'
    - '2025-11-06 03:44:03.609586'
  - - 15
    - 6
    - CourseLesson
    - 6
    - 1
    - true
    - '2025-11-06 03:44:03.626078'
    - '2025-11-06 03:44:03.626078'
  - - 16
    - 6
    - Quiz
    - 6
    - 2
    - true
    - '2025-11-06 03:44:03.634014'
    - '2025-11-06 03:44:03.634014'
  - - 17
    - 6
    - HandsOnLab
    - 13
    - 3
    - true
    - '2025-11-06 03:44:03.637510'
    - '2025-11-06 03:44:03.637510'
  - - 18
    - 6
    - HandsOnLab
    - 16
    - 4
    - false
    - '2025-11-06 03:44:03.640972'
    - '2025-11-06 03:44:03.640972'
  - - 19
    - 7
    - CourseLesson
    - 7
    - 1
    - true
    - '2025-11-06 03:44:03.650910'
    - '2025-11-06 03:44:03.650910'
  - - 20
    - 7
    - Quiz
    - 7
    - 2
    - true
    - '2025-11-06 03:44:03.660282'
    - '2025-11-06 03:44:03.660282'
  - - 21
    - 7
    - HandsOnLab
    - 11
    - 3
    - true
    - '2025-11-06 03:44:03.666482'
    - '2025-11-06 03:44:03.666482'
  - - 22
    - 8
    - Quiz
    - 8
    - 1
    - true
    - '2025-11-06 03:44:03.713260'
    - '2025-11-06 03:44:03.713260'
  - - 23
    - 9
    - Quiz
    - 9
    - 1
    - false
    - '2025-11-06 03:44:03.866185'
    - '2025-11-06 03:44:03.866185'
  - - 24
    - 10
    - Quiz
    - 10
    - 1
    - true
    - '2025-11-06 03:44:04.009133'
    - '2025-11-06 03:44:04.009133'
  - - 25
    - 11
    - Quiz
    - 11
    - 1
    - true
    - '2025-11-06 03:44:04.123212'
    - '2025-11-06 03:44:04.123212'
  - - 26
    - 18
    - CourseLesson
    - 12
    - 1
    - true
    - '2025-11-06 04:09:12.850871'
    - '2025-11-06 04:09:12.850871'
  - - 27
    - 18
    - CourseLesson
    - 13
    - 2
    - true
    - '2025-11-06 04:09:12.852989'
    - '2025-11-06 04:09:12.852989'
  - - 28
    - 18
    - CourseLesson
    - 14
    - 3
    - true
    - '2025-11-06 04:09:12.854901'
    - '2025-11-06 04:09:12.854901'
  - - 29
    - 18
    - HandsOnLab
    - 65
    - 4
    - true
    - '2025-11-06 04:09:12.885201'
    - '2025-11-06 04:09:12.885201'
  - - 30
    - 18
    - HandsOnLab
    - 66
    - 5
    - true
    - '2025-11-06 04:09:12.887035'
    - '2025-11-06 04:09:12.887035'
  - - 31
    - 18
    - HandsOnLab
    - 67
    - 6
    - true
    - '2025-11-06 04:09:12.888779'
    - '2025-11-06 04:09:12.888779'
  - - 32
    - 19
    - CourseLesson
    - 15
    - 1
    - true
    - '2025-11-06 04:09:12.897440'
    - '2025-11-06 04:09:12.897440'
  - - 33
    - 19
    - CourseLesson
    - 16
    - 2
    - true
    - '2025-11-06 04:09:12.899283'
    - '2025-11-06 04:09:12.899283'
  - - 34
    - 19
    - CourseLesson
    - 17
    - 3
    - true
    - '2025-11-06 04:09:12.900961'
    - '2025-11-06 04:09:12.900961'
  - - 35
    - 19
    - HandsOnLab
    - 68
    - 4
    - true
    - '2025-11-06 04:09:12.906492'
    - '2025-11-06 04:09:12.906492'
  - - 36
    - 19
    - HandsOnLab
    - 69
    - 5
    - true
    - '2025-11-06 04:09:12.908792'
    - '2025-11-06 04:09:12.908792'
  - - 37
    - 20
    - CourseLesson
    - 18
    - 1
    - true
    - '2025-11-06 04:09:12.916384'
    - '2025-11-06 04:09:12.916384'
  - - 38
    - 20
    - CourseLesson
    - 19
    - 2
    - true
    - '2025-11-06 04:09:12.918202'
    - '2025-11-06 04:09:12.918202'
  - - 39
    - 20
    - CourseLesson
    - 20
    - 3
    - true
    - '2025-11-06 04:09:12.919943'
    - '2025-11-06 04:09:12.919943'
  - - 40
    - 20
    - HandsOnLab
    - 70
    - 4
    - true
    - '2025-11-06 04:09:12.923385'
    - '2025-11-06 04:09:12.923385'
  - - 41
    - 21
    - CourseLesson
    - 21
    - 1
    - true
    - '2025-11-06 04:09:12.936809'
    - '2025-11-06 04:09:12.936809'
  - - 42
    - 21
    - CourseLesson
    - 22
    - 2
    - true
    - '2025-11-06 04:09:12.938709'
    - '2025-11-06 04:09:12.938709'
  - - 43
    - 21
    - CourseLesson
    - 23
    - 3
    - true
    - '2025-11-06 04:09:12.941054'
    - '2025-11-06 04:09:12.941054'
  - - 44
    - 21
    - CourseLesson
    - 24
    - 4
    - true
    - '2025-11-06 04:09:12.943040'
    - '2025-11-06 04:09:12.943040'
  - - 45
    - 21
    - HandsOnLab
    - 71
    - 5
    - true
    - '2025-11-06 04:09:12.949124'
    - '2025-11-06 04:09:12.949124'
  - - 46
    - 21
    - HandsOnLab
    - 72
    - 6
    - true
    - '2025-11-06 04:09:12.951042'
    - '2025-11-06 04:09:12.951042'
  - - 47
    - 22
    - CourseLesson
    - 25
    - 1
    - true
    - '2025-11-06 04:09:12.957615'
    - '2025-11-06 04:09:12.957615'
  - - 48
    - 22
    - CourseLesson
    - 26
    - 2
    - true
    - '2025-11-06 04:09:12.959521'
    - '2025-11-06 04:09:12.959521'
  - - 49
    - 2
    - HandsOnLab
    - 74
    - 20
    - true
    - '2025-11-06 04:12:16.997255'
    - '2025-11-06 04:12:16.997255'
  - - 50
    - 24
    - HandsOnLab
    - 75
    - 20
    - true
    - '2025-11-06 04:12:17.004284'
    - '2025-11-06 04:12:17.004284'
  - - 51
    - 23
    - HandsOnLab
    - 73
    - 10
    - true
    - '2025-11-06 04:12:17.005874'
    - '2025-11-06 04:12:17.005874'
  - - 52
    - 26
    - CourseLesson
    - 2
    - 1
    - true
    - '2025-11-06 07:32:44.025492'
    - '2025-11-06 07:32:44.025492'
  - - 53
    - 26
    - Quiz
    - 2
    - 2
    - true
    - '2025-11-06 07:32:44.029220'
    - '2025-11-06 07:32:44.029220'
  - - 54
    - 26
    - HandsOnLab
    - 76
    - 3
    - true
    - '2025-11-06 07:32:44.031978'
    - '2025-11-06 07:32:44.031978'
  - - 55
    - 27
    - CourseLesson
    - 27
    - 1
    - true
    - '2025-11-06 07:32:44.035668'
    - '2025-11-06 07:32:44.035668'
  - - 56
    - 27
    - HandsOnLab
    - 2
    - 2
    - true
    - '2025-11-06 07:32:44.038539'
    - '2025-11-06 07:32:44.038539'
  - - 57
    - 28
    - CourseLesson
    - 28
    - 1
    - true
    - '2025-11-06 07:32:44.042109'
    - '2025-11-06 07:32:44.042109'
  - - 58
    - 28
    - HandsOnLab
    - 77
    - 2
    - true
    - '2025-11-06 07:32:44.044268'
    - '2025-11-06 07:32:44.044268'
  - - 59
    - 5
    - CourseLesson
    - 29
    - 1
    - true
    - '2025-11-06 07:32:44.047244'
    - '2025-11-06 07:32:44.047244'
  - - 60
    - 29
    - CourseLesson
    - 30
    - 1
    - true
    - '2025-11-06 07:32:44.055591'
    - '2025-11-06 07:32:44.055591'
  - - 61
    - 30
    - CourseLesson
    - 1
    - 1
    - true
    - '2025-11-06 08:52:19.580589'
    - '2025-11-06 08:52:19.580589'
  - - 62
    - 30
    - CourseLesson
    - 31
    - 2
    - true
    - '2025-11-06 08:52:19.582420'
    - '2025-11-06 08:52:19.582420'
  - - 63
    - 30
    - CourseLesson
    - 32
    - 3
    - true
    - '2025-11-06 08:52:19.584755'
    - '2025-11-06 08:52:19.584755'
  - - 64
    - 30
    - CourseLesson
    - 33
    - 4
    - true
    - '2025-11-06 08:52:19.586873'
    - '2025-11-06 08:52:19.586873'
  - - 65
    - 30
    - HandsOnLab
    - 78
    - 5
    - true
    - '2025-11-06 08:52:19.610623'
    - '2025-11-06 08:52:19.610623'
  - - 66
    - 30
    - Quiz
    - 12
    - 6
    - true
    - '2025-11-06 08:52:19.667317'
    - '2025-11-06 08:52:19.667317'
  - - 67
    - 31
    - CourseLesson
    - 34
    - 1
    - true
    - '2025-11-06 08:52:19.670780'
    - '2025-11-06 08:52:19.670780'
  - - 68
    - 31
    - CourseLesson
    - 35
    - 2
    - true
    - '2025-11-06 08:52:19.672516'
    - '2025-11-06 08:52:19.672516'
  - - 69
    - 31
    - CourseLesson
    - 36
    - 3
    - true
    - '2025-11-06 08:52:19.674294'
    - '2025-11-06 08:52:19.674294'
  - - 70
    - 31
    - CourseLesson
    - 37
    - 4
    - true
    - '2025-11-06 08:52:19.675912'
    - '2025-11-06 08:52:19.675912'
  - - 71
    - 31
    - CourseLesson
    - 38
    - 5
    - true
    - '2025-11-06 08:52:19.677652'
    - '2025-11-06 08:52:19.677652'
  - - 72
    - 31
    - HandsOnLab
    - 79
    - 6
    - true
    - '2025-11-06 08:52:19.679684'
    - '2025-11-06 08:52:19.679684'
  - - 73
    - 31
    - Quiz
    - 13
    - 7
    - true
    - '2025-11-06 08:52:19.684094'
    - '2025-11-06 08:52:19.684094'
  - - 74
    - 32
    - CourseLesson
    - 39
    - 1
    - true
    - '2025-11-06 08:52:19.686922'
    - '2025-11-06 08:52:19.686922'
  - - 75
    - 32
    - CourseLesson
    - 40
    - 2
    - true
    - '2025-11-06 08:52:19.688404'
    - '2025-11-06 08:52:19.688404'
  - - 76
    - 32
    - CourseLesson
    - 41
    - 3
    - true
    - '2025-11-06 08:52:19.690473'
    - '2025-11-06 08:52:19.690473'
  - - 77
    - 32
    - HandsOnLab
    - 80
    - 4
    - true
    - '2025-11-06 08:52:19.692665'
    - '2025-11-06 08:52:19.692665'
  - - 78
    - 32
    - Quiz
    - 14
    - 5
    - true
    - '2025-11-06 08:52:19.696224'
    - '2025-11-06 08:52:19.696224'
  - - 79
    - 33
    - CourseLesson
    - 42
    - 1
    - true
    - '2025-11-06 08:52:19.699348'
    - '2025-11-06 08:52:19.699348'
  - - 80
    - 33
    - HandsOnLab
    - 77
    - 2
    - true
    - '2025-11-06 08:52:19.701209'
    - '2025-11-06 08:52:19.701209'
  - - 81
    - 33
    - Quiz
    - 15
    - 3
    - true
    - '2025-11-06 08:52:19.703447'
    - '2025-11-06 08:52:19.703447'
  - - 82
    - 34
    - CourseLesson
    - 3
    - 1
    - true
    - '2025-11-06 08:52:19.706846'
    - '2025-11-06 08:52:19.706846'
  - - 83
    - 34
    - HandsOnLab
    - 81
    - 2
    - true
    - '2025-11-06 08:52:19.709079'
    - '2025-11-06 08:52:19.709079'
  - - 84
    - 34
    - Quiz
    - 16
    - 3
    - true
    - '2025-11-06 08:52:19.712720'
    - '2025-11-06 08:52:19.712720'
  - - 85
    - 35
    - CourseLesson
    - 29
    - 1
    - true
    - '2025-11-06 08:52:19.716176'
    - '2025-11-06 08:52:19.716176'
  - - 86
    - 35
    - HandsOnLab
    - 82
    - 2
    - true
    - '2025-11-06 08:52:19.718048'
    - '2025-11-06 08:52:19.718048'
  - - 87
    - 35
    - Quiz
    - 17
    - 3
    - true
    - '2025-11-06 08:52:19.720257'
    - '2025-11-06 08:52:19.720257'
  - - 88
    - 36
    - CourseLesson
    - 43
    - 1
    - true
    - '2025-11-06 08:52:19.723976'
    - '2025-11-06 08:52:19.723976'
  - - 89
    - 36
    - CourseLesson
    - 44
    - 2
    - true
    - '2025-11-06 08:52:19.725657'
    - '2025-11-06 08:52:19.725657'
  - - 90
    - 36
    - HandsOnLab
    - 83
    - 3
    - true
    - '2025-11-06 08:52:19.727813'
    - '2025-11-06 08:52:19.727813'
  - - 91
    - 36
    - Quiz
    - 18
    - 4
    - true
    - '2025-11-06 08:52:19.735075'
    - '2025-11-06 08:52:19.735075'

---
quiz_questions:
  columns:
  - id
  - quiz_id
  - question_type
  - question_text
  - options
  - correct_answer
  - explanation
  - points
  - difficulty_level
  - tags
  - sequence_order
  - created_at
  - updated_at
  - difficulty
  - discrimination
  - guessing
  - topic
  - skill_dimension
  - tolerance
  - multiple_correct
  - sequence_items
  - image_url
  records: 
  - - 1
    - 1
    - mcq
    - What is the main difference between containers and virtual machines?
    - '"[{\"text\":\"Containers share the host OS kernel while VMs have their own
      OS\",\"correct\":true},{\"text\":\"Containers are slower than VMs\",\"correct\":false},{\"text\":\"VMs
      are more portable than containers\",\"correct\":false},{\"text\":\"Containers
      require more resources than VMs\",\"correct\":false}]"'
    - Containers share the host OS kernel while VMs have their own OS
    - Containers share the host operating system's kernel, making them lightweight
      and fast. VMs include a complete operating system, making them heavier but more
      isolated.
    - 10
    - easy
    -
    - 1
    - '2025-11-06 03:44:03.495961'
    - '2025-11-06 07:32:43.962382'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 2
    - 1
    - mcq
    - Which Docker component is responsible for managing containers?
    - '"[{\"text\":\"Docker Client\",\"correct\":false},{\"text\":\"Docker Daemon\",\"correct\":true},{\"text\":\"Docker
      Registry\",\"correct\":false},{\"text\":\"Docker Image\",\"correct\":false}]"'
    - Docker Daemon
    - The Docker Daemon (dockerd) is the background service that manages containers,
      images, networks, and volumes.
    - 10
    - easy
    -
    - 2
    - '2025-11-06 03:44:03.498812'
    - '2025-11-06 07:32:43.963454'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 3
    - 1
    - command
    - What command would you use to run a container from the 'nginx' image?
    -
    - docker run nginx
    - 'The ''docker run'' command creates and starts a container from an image. For
      nginx: docker run nginx'
    - 10
    - easy
    -
    - 3
    - '2025-11-06 03:44:03.505270'
    - '2025-11-06 07:32:43.964371'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 4
    - 1
    - true_false
    - Docker images are stored in a Docker Registry like Docker Hub.
    -
    - 'true'
    - Docker images are stored in registries. Docker Hub is the default public registry,
      but you can also use private registries.
    - 5
    - easy
    -
    - 4
    - '2025-11-06 03:44:03.508617'
    - '2025-11-06 03:44:03.508617'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 5
    - 1
    - fill_blank
    - A Docker _____ is a lightweight, standalone executable package that includes
      everything needed to run software.
    -
    - container
    - A container is the runtime instance that packages application code with all
      dependencies.
    - 5
    - easy
    -
    - 5
    - '2025-11-06 03:44:03.511741'
    - '2025-11-06 03:44:03.511741'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 6
    - 2
    - mcq
    - What is the purpose of image layers in Docker?
    - '"[{\"text\":\"To enable caching and faster rebuilds\",\"correct\":true},{\"text\":\"To
      make images larger\",\"correct\":false},{\"text\":\"To slow down builds\",\"correct\":false},{\"text\":\"Layers
      have no purpose\",\"correct\":false}]"'
    - To enable caching and faster rebuilds
    - Layers allow Docker to cache intermediate results, making subsequent builds
      much faster when only later layers change.
    - 10
    - medium
    -
    - 1
    - '2025-11-06 03:44:03.532687'
    - '2025-11-06 07:32:44.027189'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 7
    - 2
    - command
    - What command builds a Docker image from a Dockerfile and tags it as 'myapp:v1'?
    -
    - docker build -t myapp:v1 .
    - The -t flag tags the image, and the dot (.) specifies the build context (current
      directory).
    - 15
    - hard
    -
    - 2
    - '2025-11-06 03:44:03.535559'
    - '2025-11-06 07:32:44.028054'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 8
    - 3
    - mcq
    - Which network mode removes the need for -p when exposing ports?
    - '"[{\"text\":\"bridge\",\"correct\":false},{\"text\":\"host\",\"correct\":true},{\"text\":\"none\",\"correct\":false},{\"text\":\"overlay\",\"correct\":false}]"'
    -
    - Host network shares the host's network namespace; no port mapping is needed.
    - 10
    - easy
    -
    - 1
    - '2025-11-06 03:44:03.551930'
    - '2025-11-06 03:44:03.551930'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 9
    - 3
    - command
    - Map host port 8080 to container port 80 for nginx
    -
    - docker run -d -p 8080:80 nginx|docker container run -d -p 8080:80 nginx
    - Use -p HOST:CONTAINER to publish ports.
    - 10
    - easy
    -
    - 2
    - '2025-11-06 03:44:03.555003'
    - '2025-11-06 03:44:03.555003'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 10
    - 3
    - true_false
    - User-defined bridge networks provide built-in DNS by container name.
    -
    - 'true'
    - User-defined bridges include DNS-based service discovery.
    - 5
    - easy
    -
    - 3
    - '2025-11-06 03:44:03.558145'
    - '2025-11-06 03:44:03.558145'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 11
    - 4
    - mcq
    - Which is managed by Docker and not tied to a host path?
    - '"[{\"text\":\"Bind mount\",\"correct\":false},{\"text\":\"Named volume\",\"correct\":true},{\"text\":\"Tmpfs
      mount\",\"correct\":false},{\"text\":\"Overlay mount\",\"correct\":false}]"'
    -
    - Named volumes are managed by Docker and portable across hosts (with caveats).
    - 10
    - easy
    -
    - 1
    - '2025-11-06 03:44:03.578758'
    - '2025-11-06 03:44:03.578758'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 12
    - 4
    - command
    - Create a named volume called 'appdata'
    -
    - docker volume create appdata
    - Use docker volume create <name> to create a named volume.
    - 10
    - easy
    -
    - 2
    - '2025-11-06 03:44:03.581821'
    - '2025-11-06 03:44:03.581821'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 13
    - 5
    - mcq
    - What is the primary purpose of Docker Compose?
    - '"[{\"text\":\"To define and run multi-container applications\",\"correct\":true},{\"text\":\"To
      build Docker images\",\"correct\":false},{\"text\":\"To replace Docker\",\"correct\":false},{\"text\":\"To
      manage a single container\",\"correct\":false}]"'
    - To define and run multi-container applications
    - Docker Compose allows you to define your entire application stack (multiple
      containers) in a single YAML file.
    - 10
    - medium
    -
    - 1
    - '2025-11-06 03:44:03.602351'
    - '2025-11-06 07:32:44.049662'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 14
    - 6
    - true_false
    - Running as root inside containers is recommended for production.
    -
    - 'false'
    - Use a non-root USER and least privilege.
    - 5
    - easy
    -
    - 1
    - '2025-11-06 03:44:03.631115'
    - '2025-11-06 03:44:03.631115'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 15
    - 7
    - command
    - Tag local image myapp:latest for registry example.com/team/myapp:v1
    -
    - docker tag myapp:latest example.com/team/myapp:v1
    - Tag must include registry/namespace/name:tag
    - 10
    - medium
    -
    - 1
    - '2025-11-06 03:44:03.657007'
    - '2025-11-06 03:44:03.657007'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 16
    - 8
    - mcq
    - Which command lists dangling images?
    - '"[{\"text\":\"docker images -f dangling=true\",\"correct\":true},{\"text\":\"docker
      image prune -a\",\"correct\":false},{\"text\":\"docker ps -a\",\"correct\":false},{\"text\":\"docker
      system df\",\"correct\":false}]"'
    -
    - Use filter dangling=true with docker images.
    - 8
    - medium
    -
    - 1
    - '2025-11-06 03:44:03.683277'
    - '2025-11-06 03:44:03.683277'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 17
    - 8
    - command
    - Limit container to 512MB memory and 1 CPU
    -
    - docker run -m 512m --cpus 1 nginx|docker container run -m 512m --cpus 1 nginx
    - Use -m and --cpus to set resource limits.
    - 10
    - medium
    -
    - 2
    - '2025-11-06 03:44:03.685913'
    - '2025-11-06 03:44:03.685913'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 18
    - 8
    - mcq
    - Preferable base for minimal images?
    - '"[{\"text\":\"alpine\",\"correct\":true},{\"text\":\"ubuntu:latest\",\"correct\":false},{\"text\":\"debian\",\"correct\":false},{\"text\":\"centos\",\"correct\":false}]"'
    -
    - Alpine is commonly used for minimal images.
    - 6
    - easy
    -
    - 3
    - '2025-11-06 03:44:03.688931'
    - '2025-11-06 03:44:03.688931'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 19
    - 8
    - true_false
    - HEALTHCHECK helps detect app failures.
    -
    - 'true'
    - It lets orchestrators restart unhealthy containers.
    - 5
    - easy
    -
    - 4
    - '2025-11-06 03:44:03.691770'
    - '2025-11-06 03:44:03.691770'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 20
    - 8
    - mcq
    - How to share data between two containers across restarts?
    - '"[{\"text\":\"Bind mount a host path\",\"correct\":false},{\"text\":\"Named
      volume attached to both\",\"correct\":true},{\"text\":\"Copy files into both
      images\",\"correct\":false},{\"text\":\"Use tmpfs\",\"correct\":false}]"'
    -
    - Named volumes persist and can be mounted by multiple containers.
    - 8
    - medium
    -
    - 5
    - '2025-11-06 03:44:03.694624'
    - '2025-11-06 03:44:03.694624'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 21
    - 8
    - command
    - Create a user-defined bridge called appnet
    -
    - docker network create appnet
    - docker network create <name>.
    - 6
    - easy
    -
    - 6
    - '2025-11-06 03:44:03.697475'
    - '2025-11-06 03:44:03.697475'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 22
    - 8
    - mcq
    - Which Compose key defines a healthcheck?
    - '"[{\"text\":\"healthcheck\",\"correct\":true},{\"text\":\"probe\",\"correct\":false},{\"text\":\"check\",\"correct\":false},{\"text\":\"status\",\"correct\":false}]"'
    -
    - Compose supports healthcheck under a service.
    - 6
    - medium
    -
    - 7
    - '2025-11-06 03:44:03.700264'
    - '2025-11-06 03:44:03.700264'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 23
    - 8
    - command
    - Push image example.com/acme/api:v2
    -
    - docker push example.com/acme/api:v2
    - Requires prior docker login.
    - 6
    - easy
    -
    - 8
    - '2025-11-06 03:44:03.703205'
    - '2025-11-06 03:44:03.703205'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 24
    - 8
    - mcq
    - Which flag makes root FS read-only?
    - '"[{\"text\":\"--read-only\",\"correct\":true},{\"text\":\"--immutable\",\"correct\":false},{\"text\":\"--no-write\",\"correct\":false},{\"text\":\"--secure\",\"correct\":false}]"'
    -
    - "--read-only sets the container root FS to read-only."
    - 8
    - medium
    -
    - 9
    - '2025-11-06 03:44:03.706195'
    - '2025-11-06 03:44:03.706195'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 25
    - 8
    - true_false
    - host network provides container-name DNS
    -
    - 'false'
    - DNS-based discovery is for user-defined bridge and overlay.
    - 5
    - medium
    -
    - 10
    - '2025-11-06 03:44:03.709220'
    - '2025-11-06 03:44:03.709220'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 26
    - 9
    - mcq
    - Which command tags an existing image? (v1)
    - '"[{\"text\":\"docker tag\",\"correct\":true},{\"text\":\"docker label\",\"correct\":false},{\"text\":\"docker
      rename\",\"correct\":false},{\"text\":\"docker copy\",\"correct\":false}]"'
    -
    - Use docker tag SOURCE[:TAG] TARGET[:TAG] to add a new tag.
    - 8
    - easy
    -
    - 1
    - '2025-11-06 03:44:03.727631'
    - '2025-11-06 03:44:03.727631'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 27
    - 9
    - command
    - Run nginx mapping host 8080 to container 80 (v1)
    -
    - docker run -d -p 8080:80 nginx
    - Use -p HOST:CONTAINER for port publishing.
    - 10
    - medium
    -
    - 2
    - '2025-11-06 03:44:03.732155'
    - '2025-11-06 03:44:03.732155'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 28
    - 9
    - true_false
    - Multi-stage builds can reduce final image size. (v1)
    -
    - 'true'
    - Copy only required artefacts from builder stage.
    - 5
    - easy
    -
    - 3
    - '2025-11-06 03:44:03.736543'
    - '2025-11-06 03:44:03.736543'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 29
    - 9
    - mcq
    - Preferred storage mechanism for persistent data? (v1)
    - '"[{\"text\":\"Named volume\",\"correct\":true},{\"text\":\"Layer changes\",\"correct\":false},{\"text\":\"Tmpfs
      only\",\"correct\":false},{\"text\":\"Editing container root FS\",\"correct\":false}]"'
    -
    - Use named volumes or bind mounts for persistence.
    - 8
    - easy
    -
    - 4
    - '2025-11-06 03:44:03.740474'
    - '2025-11-06 03:44:03.740474'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 30
    - 9
    - command
    - Create a named volume appdata (v1)
    -
    - docker volume create appdata
    - docker volume create <name>.
    - 10
    - medium
    -
    - 5
    - '2025-11-06 03:44:03.744718'
    - '2025-11-06 03:44:03.744718'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 31
    - 9
    - true_false
    - User-defined bridges provide container-name DNS. (v1)
    -
    - 'true'
    - Built-in DNS is available on user-defined bridges.
    - 5
    - easy
    -
    - 6
    - '2025-11-06 03:44:03.748836'
    - '2025-11-06 03:44:03.748836'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 32
    - 9
    - mcq
    - Which Compose command starts services in detached mode? (v1)
    - '"[{\"text\":\"docker compose up -d\",\"correct\":true},{\"text\":\"docker compose
      run -d\",\"correct\":false},{\"text\":\"docker compose build -d\",\"correct\":false},{\"text\":\"docker
      compose start -d\",\"correct\":false}]"'
    -
    - Use up -d to create and start in background.
    - 8
    - easy
    -
    - 7
    - '2025-11-06 03:44:03.752871'
    - '2025-11-06 03:44:03.752871'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 33
    - 9
    - mcq
    - Which flag makes root filesystem read-only? (v1)
    - '"[{\"text\":\"--read-only\",\"correct\":true},{\"text\":\"--immutable\",\"correct\":false},{\"text\":\"--no-write\",\"correct\":false},{\"text\":\"--secure\",\"correct\":false}]"'
    -
    - Use --read-only for runtime hardening.
    - 8
    - easy
    -
    - 8
    - '2025-11-06 03:44:03.757115'
    - '2025-11-06 03:44:03.757115'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 34
    - 9
    - mcq
    - Which command tags an existing image? (v2)
    - '"[{\"text\":\"docker tag\",\"correct\":true},{\"text\":\"docker label\",\"correct\":false},{\"text\":\"docker
      rename\",\"correct\":false},{\"text\":\"docker copy\",\"correct\":false}]"'
    -
    - Use docker tag SOURCE[:TAG] TARGET[:TAG] to add a new tag.
    - 8
    - easy
    -
    - 9
    - '2025-11-06 03:44:03.761945'
    - '2025-11-06 03:44:03.761945'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 35
    - 9
    - command
    - Run nginx mapping host 8080 to container 80 (v2)
    -
    - docker run -d -p 8080:80 nginx
    - Use -p HOST:CONTAINER for port publishing.
    - 10
    - medium
    -
    - 10
    - '2025-11-06 03:44:03.767085'
    - '2025-11-06 03:44:03.767085'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 36
    - 9
    - true_false
    - Multi-stage builds can reduce final image size. (v2)
    -
    - 'true'
    - Copy only required artefacts from builder stage.
    - 5
    - easy
    -
    - 11
    - '2025-11-06 03:44:03.771585'
    - '2025-11-06 03:44:03.771585'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 37
    - 9
    - mcq
    - Preferred storage mechanism for persistent data? (v2)
    - '"[{\"text\":\"Named volume\",\"correct\":true},{\"text\":\"Layer changes\",\"correct\":false},{\"text\":\"Tmpfs
      only\",\"correct\":false},{\"text\":\"Editing container root FS\",\"correct\":false}]"'
    -
    - Use named volumes or bind mounts for persistence.
    - 8
    - easy
    -
    - 12
    - '2025-11-06 03:44:03.775978'
    - '2025-11-06 03:44:03.775978'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 38
    - 9
    - command
    - Create a named volume appdata (v2)
    -
    - docker volume create appdata
    - docker volume create <name>.
    - 10
    - medium
    -
    - 13
    - '2025-11-06 03:44:03.779923'
    - '2025-11-06 03:44:03.779923'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 39
    - 9
    - true_false
    - User-defined bridges provide container-name DNS. (v2)
    -
    - 'true'
    - Built-in DNS is available on user-defined bridges.
    - 5
    - easy
    -
    - 14
    - '2025-11-06 03:44:03.784001'
    - '2025-11-06 03:44:03.784001'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 40
    - 9
    - mcq
    - Which Compose command starts services in detached mode? (v2)
    - '"[{\"text\":\"docker compose up -d\",\"correct\":true},{\"text\":\"docker compose
      run -d\",\"correct\":false},{\"text\":\"docker compose build -d\",\"correct\":false},{\"text\":\"docker
      compose start -d\",\"correct\":false}]"'
    -
    - Use up -d to create and start in background.
    - 8
    - easy
    -
    - 15
    - '2025-11-06 03:44:03.788015'
    - '2025-11-06 03:44:03.788015'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 41
    - 9
    - mcq
    - Which flag makes root filesystem read-only? (v2)
    - '"[{\"text\":\"--read-only\",\"correct\":true},{\"text\":\"--immutable\",\"correct\":false},{\"text\":\"--no-write\",\"correct\":false},{\"text\":\"--secure\",\"correct\":false}]"'
    -
    - Use --read-only for runtime hardening.
    - 8
    - easy
    -
    - 16
    - '2025-11-06 03:44:03.791998'
    - '2025-11-06 03:44:03.791998'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 42
    - 9
    - mcq
    - Which command tags an existing image? (v3)
    - '"[{\"text\":\"docker tag\",\"correct\":true},{\"text\":\"docker label\",\"correct\":false},{\"text\":\"docker
      rename\",\"correct\":false},{\"text\":\"docker copy\",\"correct\":false}]"'
    -
    - Use docker tag SOURCE[:TAG] TARGET[:TAG] to add a new tag.
    - 8
    - medium
    -
    - 17
    - '2025-11-06 03:44:03.796174'
    - '2025-11-06 03:44:03.796174'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 43
    - 9
    - command
    - Run nginx mapping host 8080 to container 80 (v3)
    -
    - docker run -d -p 8080:80 nginx
    - Use -p HOST:CONTAINER for port publishing.
    - 10
    - medium
    -
    - 18
    - '2025-11-06 03:44:03.800274'
    - '2025-11-06 03:44:03.800274'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 44
    - 9
    - true_false
    - Multi-stage builds can reduce final image size. (v3)
    -
    - 'true'
    - Copy only required artefacts from builder stage.
    - 5
    - easy
    -
    - 19
    - '2025-11-06 03:44:03.805225'
    - '2025-11-06 03:44:03.805225'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 45
    - 9
    - mcq
    - Preferred storage mechanism for persistent data? (v3)
    - '"[{\"text\":\"Named volume\",\"correct\":true},{\"text\":\"Layer changes\",\"correct\":false},{\"text\":\"Tmpfs
      only\",\"correct\":false},{\"text\":\"Editing container root FS\",\"correct\":false}]"'
    -
    - Use named volumes or bind mounts for persistence.
    - 8
    - medium
    -
    - 20
    - '2025-11-06 03:44:03.809679'
    - '2025-11-06 03:44:03.809679'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 46
    - 9
    - command
    - Create a named volume appdata (v3)
    -
    - docker volume create appdata
    - docker volume create <name>.
    - 10
    - medium
    -
    - 21
    - '2025-11-06 03:44:03.813988'
    - '2025-11-06 03:44:03.813988'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 47
    - 9
    - true_false
    - User-defined bridges provide container-name DNS. (v3)
    -
    - 'true'
    - Built-in DNS is available on user-defined bridges.
    - 5
    - easy
    -
    - 22
    - '2025-11-06 03:44:03.818274'
    - '2025-11-06 03:44:03.818274'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 48
    - 9
    - mcq
    - Which Compose command starts services in detached mode? (v3)
    - '"[{\"text\":\"docker compose up -d\",\"correct\":true},{\"text\":\"docker compose
      run -d\",\"correct\":false},{\"text\":\"docker compose build -d\",\"correct\":false},{\"text\":\"docker
      compose start -d\",\"correct\":false}]"'
    -
    - Use up -d to create and start in background.
    - 8
    - medium
    -
    - 23
    - '2025-11-06 03:44:03.823305'
    - '2025-11-06 03:44:03.823305'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 49
    - 9
    - mcq
    - Which flag makes root filesystem read-only? (v3)
    - '"[{\"text\":\"--read-only\",\"correct\":true},{\"text\":\"--immutable\",\"correct\":false},{\"text\":\"--no-write\",\"correct\":false},{\"text\":\"--secure\",\"correct\":false}]"'
    -
    - Use --read-only for runtime hardening.
    - 8
    - medium
    -
    - 24
    - '2025-11-06 03:44:03.827992'
    - '2025-11-06 03:44:03.827992'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 50
    - 9
    - mcq
    - Which command tags an existing image? (v4)
    - '"[{\"text\":\"docker tag\",\"correct\":true},{\"text\":\"docker label\",\"correct\":false},{\"text\":\"docker
      rename\",\"correct\":false},{\"text\":\"docker copy\",\"correct\":false}]"'
    -
    - Use docker tag SOURCE[:TAG] TARGET[:TAG] to add a new tag.
    - 8
    - easy
    -
    - 25
    - '2025-11-06 03:44:03.834070'
    - '2025-11-06 03:44:03.834070'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 51
    - 9
    - command
    - Run nginx mapping host 8080 to container 80 (v4)
    -
    - docker run -d -p 8080:80 nginx
    - Use -p HOST:CONTAINER for port publishing.
    - 10
    - medium
    -
    - 26
    - '2025-11-06 03:44:03.840299'
    - '2025-11-06 03:44:03.840299'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 52
    - 9
    - true_false
    - Multi-stage builds can reduce final image size. (v4)
    -
    - 'true'
    - Copy only required artefacts from builder stage.
    - 5
    - easy
    -
    - 27
    - '2025-11-06 03:44:03.846248'
    - '2025-11-06 03:44:03.846248'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 53
    - 9
    - mcq
    - Preferred storage mechanism for persistent data? (v4)
    - '"[{\"text\":\"Named volume\",\"correct\":true},{\"text\":\"Layer changes\",\"correct\":false},{\"text\":\"Tmpfs
      only\",\"correct\":false},{\"text\":\"Editing container root FS\",\"correct\":false}]"'
    -
    - Use named volumes or bind mounts for persistence.
    - 8
    - easy
    -
    - 28
    - '2025-11-06 03:44:03.850320'
    - '2025-11-06 03:44:03.850320'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 54
    - 9
    - command
    - Create a named volume appdata (v4)
    -
    - docker volume create appdata
    - docker volume create <name>.
    - 10
    - medium
    -
    - 29
    - '2025-11-06 03:44:03.854352'
    - '2025-11-06 03:44:03.854352'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 55
    - 9
    - true_false
    - User-defined bridges provide container-name DNS. (v4)
    -
    - 'true'
    - Built-in DNS is available on user-defined bridges.
    - 5
    - easy
    -
    - 30
    - '2025-11-06 03:44:03.859829'
    - '2025-11-06 03:44:03.859829'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 56
    - 10
    - command
    - Create a user-defined bridge network (Q1)
    -
    - docker network create appnet
    - docker network create <name>.
    - 6
    - easy
    -
    - 1
    - '2025-11-06 03:44:03.883027'
    - '2025-11-06 03:44:03.883027'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 57
    - 10
    - true_false
    - Named volumes persist data across container restarts. (Q2)
    -
    - 'true'
    - Volumes survive container lifecycle.
    - 5
    - easy
    -
    - 2
    - '2025-11-06 03:44:03.888442'
    - '2025-11-06 03:44:03.888442'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 58
    - 10
    - mcq
    - In volumes, which command is correct? (Q3)
    - '"[{\"text\":\"docker tag src:1 dst:1\",\"correct\":false},{\"text\":\"docker
      compose up -d\",\"correct\":false},{\"text\":\"docker volume create data\",\"correct\":true},{\"text\":\"docker
      run --read-only nginx\",\"correct\":false}]"'
    -
    - Pick the valid command for the domain.
    - 8
    - medium
    -
    - 3
    - '2025-11-06 03:44:03.892801'
    - '2025-11-06 03:44:03.892801'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 59
    - 10
    - command
    - Create a user-defined bridge network (Q4)
    -
    - docker network create appnet
    - docker network create <name>.
    - 6
    - easy
    -
    - 4
    - '2025-11-06 03:44:03.896411'
    - '2025-11-06 03:44:03.896411'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 60
    - 10
    - true_false
    - Named volumes persist data across container restarts. (Q5)
    -
    - 'true'
    - Volumes survive container lifecycle.
    - 5
    - easy
    -
    - 5
    - '2025-11-06 03:44:03.899975'
    - '2025-11-06 03:44:03.899975'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 61
    - 10
    - mcq
    - In registry, which command is correct? (Q6)
    - '"[{\"text\":\"docker tag src:1 dst:1\",\"correct\":false},{\"text\":\"docker
      compose up -d\",\"correct\":false},{\"text\":\"docker volume create data\",\"correct\":false},{\"text\":\"docker
      run --read-only nginx\",\"correct\":false}]"'
    -
    - Pick the valid command for the domain.
    - 8
    - medium
    -
    - 6
    - '2025-11-06 03:44:03.904495'
    - '2025-11-06 03:44:03.904495'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 62
    - 10
    - command
    - Create a user-defined bridge network (Q7)
    -
    - docker network create appnet
    - docker network create <name>.
    - 6
    - easy
    -
    - 7
    - '2025-11-06 03:44:03.908705'
    - '2025-11-06 03:44:03.908705'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 63
    - 10
    - true_false
    - Named volumes persist data across container restarts. (Q8)
    -
    - 'true'
    - Volumes survive container lifecycle.
    - 5
    - easy
    -
    - 8
    - '2025-11-06 03:44:03.913208'
    - '2025-11-06 03:44:03.913208'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 64
    - 10
    - mcq
    - In networking, which command is correct? (Q9)
    - '"[{\"text\":\"docker tag src:1 dst:1\",\"correct\":false},{\"text\":\"docker
      compose up -d\",\"correct\":false},{\"text\":\"docker volume create data\",\"correct\":false},{\"text\":\"docker
      run --read-only nginx\",\"correct\":false}]"'
    -
    - Pick the valid command for the domain.
    - 8
    - medium
    -
    - 9
    - '2025-11-06 03:44:03.917387'
    - '2025-11-06 03:44:03.917387'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 65
    - 10
    - command
    - Create a user-defined bridge network (Q10)
    -
    - docker network create appnet
    - docker network create <name>.
    - 6
    - easy
    -
    - 10
    - '2025-11-06 03:44:03.920808'
    - '2025-11-06 03:44:03.920808'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 66
    - 10
    - true_false
    - Named volumes persist data across container restarts. (Q11)
    -
    - 'true'
    - Volumes survive container lifecycle.
    - 5
    - easy
    -
    - 11
    - '2025-11-06 03:44:03.925915'
    - '2025-11-06 03:44:03.925915'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 67
    - 10
    - mcq
    - In security, which command is correct? (Q12)
    - '"[{\"text\":\"docker tag src:1 dst:1\",\"correct\":false},{\"text\":\"docker
      compose up -d\",\"correct\":false},{\"text\":\"docker volume create data\",\"correct\":false},{\"text\":\"docker
      run --read-only nginx\",\"correct\":true}]"'
    -
    - Pick the valid command for the domain.
    - 8
    - medium
    -
    - 12
    - '2025-11-06 03:44:03.931306'
    - '2025-11-06 03:44:03.931306'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 68
    - 10
    - command
    - Create a user-defined bridge network (Q13)
    -
    - docker network create appnet
    - docker network create <name>.
    - 6
    - easy
    -
    - 13
    - '2025-11-06 03:44:03.936185'
    - '2025-11-06 03:44:03.936185'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 69
    - 10
    - true_false
    - Named volumes persist data across container restarts. (Q14)
    -
    - 'true'
    - Volumes survive container lifecycle.
    - 5
    - easy
    -
    - 14
    - '2025-11-06 03:44:03.939838'
    - '2025-11-06 03:44:03.939838'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 70
    - 10
    - mcq
    - In containers, which command is correct? (Q15)
    - '"[{\"text\":\"docker tag src:1 dst:1\",\"correct\":false},{\"text\":\"docker
      compose up -d\",\"correct\":false},{\"text\":\"docker volume create data\",\"correct\":false},{\"text\":\"docker
      run --read-only nginx\",\"correct\":false}]"'
    -
    - Pick the valid command for the domain.
    - 8
    - medium
    -
    - 15
    - '2025-11-06 03:44:03.944709'
    - '2025-11-06 03:44:03.944709'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 71
    - 10
    - command
    - Create a user-defined bridge network (Q16)
    -
    - docker network create appnet
    - docker network create <name>.
    - 6
    - easy
    -
    - 16
    - '2025-11-06 03:44:03.948554'
    - '2025-11-06 03:44:03.948554'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 72
    - 10
    - true_false
    - Named volumes persist data across container restarts. (Q17)
    -
    - 'true'
    - Volumes survive container lifecycle.
    - 5
    - easy
    -
    - 17
    - '2025-11-06 03:44:03.951787'
    - '2025-11-06 03:44:03.951787'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 73
    - 10
    - mcq
    - In compose, which command is correct? (Q18)
    - '"[{\"text\":\"docker tag src:1 dst:1\",\"correct\":false},{\"text\":\"docker
      compose up -d\",\"correct\":true},{\"text\":\"docker volume create data\",\"correct\":false},{\"text\":\"docker
      run --read-only nginx\",\"correct\":false}]"'
    -
    - Pick the valid command for the domain.
    - 8
    - medium
    -
    - 18
    - '2025-11-06 03:44:03.955609'
    - '2025-11-06 03:44:03.955609'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 74
    - 10
    - command
    - Create a user-defined bridge network (Q19)
    -
    - docker network create appnet
    - docker network create <name>.
    - 6
    - easy
    -
    - 19
    - '2025-11-06 03:44:03.960152'
    - '2025-11-06 03:44:03.960152'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 75
    - 10
    - true_false
    - Named volumes persist data across container restarts. (Q20)
    -
    - 'true'
    - Volumes survive container lifecycle.
    - 5
    - easy
    -
    - 20
    - '2025-11-06 03:44:03.963557'
    - '2025-11-06 03:44:03.963557'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 76
    - 10
    - mcq
    - In images, which command is correct? (Q21)
    - '"[{\"text\":\"docker tag src:1 dst:1\",\"correct\":true},{\"text\":\"docker
      compose up -d\",\"correct\":false},{\"text\":\"docker volume create data\",\"correct\":false},{\"text\":\"docker
      run --read-only nginx\",\"correct\":false}]"'
    -
    - Pick the valid command for the domain.
    - 8
    - medium
    -
    - 21
    - '2025-11-06 03:44:03.967674'
    - '2025-11-06 03:44:03.967674'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 77
    - 10
    - command
    - Create a user-defined bridge network (Q22)
    -
    - docker network create appnet
    - docker network create <name>.
    - 6
    - easy
    -
    - 22
    - '2025-11-06 03:44:03.971016'
    - '2025-11-06 03:44:03.971016'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 78
    - 10
    - true_false
    - Named volumes persist data across container restarts. (Q23)
    -
    - 'true'
    - Volumes survive container lifecycle.
    - 5
    - easy
    -
    - 23
    - '2025-11-06 03:44:03.974917'
    - '2025-11-06 03:44:03.974917'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 79
    - 10
    - mcq
    - In volumes, which command is correct? (Q24)
    - '"[{\"text\":\"docker tag src:1 dst:1\",\"correct\":false},{\"text\":\"docker
      compose up -d\",\"correct\":false},{\"text\":\"docker volume create data\",\"correct\":true},{\"text\":\"docker
      run --read-only nginx\",\"correct\":false}]"'
    -
    - Pick the valid command for the domain.
    - 8
    - medium
    -
    - 24
    - '2025-11-06 03:44:03.978251'
    - '2025-11-06 03:44:03.978251'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 80
    - 10
    - command
    - Create a user-defined bridge network (Q25)
    -
    - docker network create appnet
    - docker network create <name>.
    - 6
    - easy
    -
    - 25
    - '2025-11-06 03:44:03.982012'
    - '2025-11-06 03:44:03.982012'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 81
    - 10
    - true_false
    - Named volumes persist data across container restarts. (Q26)
    -
    - 'true'
    - Volumes survive container lifecycle.
    - 5
    - easy
    -
    - 26
    - '2025-11-06 03:44:03.985343'
    - '2025-11-06 03:44:03.985343'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 82
    - 10
    - mcq
    - In registry, which command is correct? (Q27)
    - '"[{\"text\":\"docker tag src:1 dst:1\",\"correct\":false},{\"text\":\"docker
      compose up -d\",\"correct\":false},{\"text\":\"docker volume create data\",\"correct\":false},{\"text\":\"docker
      run --read-only nginx\",\"correct\":false}]"'
    -
    - Pick the valid command for the domain.
    - 8
    - medium
    -
    - 27
    - '2025-11-06 03:44:03.989279'
    - '2025-11-06 03:44:03.989279'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 83
    - 10
    - command
    - Create a user-defined bridge network (Q28)
    -
    - docker network create appnet
    - docker network create <name>.
    - 6
    - easy
    -
    - 28
    - '2025-11-06 03:44:03.993222'
    - '2025-11-06 03:44:03.993222'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 84
    - 10
    - true_false
    - Named volumes persist data across container restarts. (Q29)
    -
    - 'true'
    - Volumes survive container lifecycle.
    - 5
    - easy
    -
    - 29
    - '2025-11-06 03:44:03.998168'
    - '2025-11-06 03:44:03.998168'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 85
    - 10
    - mcq
    - In networking, which command is correct? (Q30)
    - '"[{\"text\":\"docker tag src:1 dst:1\",\"correct\":false},{\"text\":\"docker
      compose up -d\",\"correct\":false},{\"text\":\"docker volume create data\",\"correct\":false},{\"text\":\"docker
      run --read-only nginx\",\"correct\":false}]"'
    -
    - Pick the valid command for the domain.
    - 8
    - medium
    -
    - 30
    - '2025-11-06 03:44:04.003011'
    - '2025-11-06 03:44:04.003011'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 86
    - 11
    - mcq
    - Which flag limits memory usage? (Q1)
    - '"[{\"text\":\"-m 512m\",\"correct\":true},{\"text\":\"--limit-mem 512\",\"correct\":false},{\"text\":\"--mem
      512\",\"correct\":false},{\"text\":\"--memory-hard 512m\",\"correct\":false}]"'
    -
    - Use -m/--memory to cap memory.
    - 8
    - medium
    -
    - 1
    - '2025-11-06 03:44:04.020086'
    - '2025-11-06 03:44:04.020086'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 87
    - 11
    - command
    - Run nginx with read-only root filesystem (Q2)
    -
    - docker run --read-only nginx
    - Harden container with --read-only.
    - 10
    - medium
    -
    - 2
    - '2025-11-06 03:44:04.023966'
    - '2025-11-06 03:44:04.023966'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 88
    - 11
    - mcq
    - Which flag limits memory usage? (Q3)
    - '"[{\"text\":\"-m 512m\",\"correct\":true},{\"text\":\"--limit-mem 512\",\"correct\":false},{\"text\":\"--mem
      512\",\"correct\":false},{\"text\":\"--memory-hard 512m\",\"correct\":false}]"'
    -
    - Use -m/--memory to cap memory.
    - 8
    - medium
    -
    - 3
    - '2025-11-06 03:44:04.027416'
    - '2025-11-06 03:44:04.027416'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 89
    - 11
    - command
    - Run nginx with read-only root filesystem (Q4)
    -
    - docker run --read-only nginx
    - Harden container with --read-only.
    - 10
    - medium
    -
    - 4
    - '2025-11-06 03:44:04.030912'
    - '2025-11-06 03:44:04.030912'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 90
    - 11
    - mcq
    - Which flag limits memory usage? (Q5)
    - '"[{\"text\":\"-m 512m\",\"correct\":true},{\"text\":\"--limit-mem 512\",\"correct\":false},{\"text\":\"--mem
      512\",\"correct\":false},{\"text\":\"--memory-hard 512m\",\"correct\":false}]"'
    -
    - Use -m/--memory to cap memory.
    - 8
    - medium
    -
    - 5
    - '2025-11-06 03:44:04.042059'
    - '2025-11-06 03:44:04.042059'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 91
    - 11
    - command
    - Run nginx with read-only root filesystem (Q6)
    -
    - docker run --read-only nginx
    - Harden container with --read-only.
    - 10
    - medium
    -
    - 6
    - '2025-11-06 03:44:04.046083'
    - '2025-11-06 03:44:04.046083'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 92
    - 11
    - mcq
    - Which flag limits memory usage? (Q7)
    - '"[{\"text\":\"-m 512m\",\"correct\":true},{\"text\":\"--limit-mem 512\",\"correct\":false},{\"text\":\"--mem
      512\",\"correct\":false},{\"text\":\"--memory-hard 512m\",\"correct\":false}]"'
    -
    - Use -m/--memory to cap memory.
    - 8
    - medium
    -
    - 7
    - '2025-11-06 03:44:04.050229'
    - '2025-11-06 03:44:04.050229'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 93
    - 11
    - command
    - Run nginx with read-only root filesystem (Q8)
    -
    - docker run --read-only nginx
    - Harden container with --read-only.
    - 10
    - medium
    -
    - 8
    - '2025-11-06 03:44:04.053915'
    - '2025-11-06 03:44:04.053915'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 94
    - 11
    - mcq
    - Which flag limits memory usage? (Q9)
    - '"[{\"text\":\"-m 512m\",\"correct\":true},{\"text\":\"--limit-mem 512\",\"correct\":false},{\"text\":\"--mem
      512\",\"correct\":false},{\"text\":\"--memory-hard 512m\",\"correct\":false}]"'
    -
    - Use -m/--memory to cap memory.
    - 8
    - medium
    -
    - 9
    - '2025-11-06 03:44:04.057602'
    - '2025-11-06 03:44:04.057602'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 95
    - 11
    - command
    - Run nginx with read-only root filesystem (Q10)
    -
    - docker run --read-only nginx
    - Harden container with --read-only.
    - 10
    - medium
    -
    - 10
    - '2025-11-06 03:44:04.061178'
    - '2025-11-06 03:44:04.061178'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 96
    - 11
    - mcq
    - Which flag limits memory usage? (Q11)
    - '"[{\"text\":\"-m 512m\",\"correct\":true},{\"text\":\"--limit-mem 512\",\"correct\":false},{\"text\":\"--mem
      512\",\"correct\":false},{\"text\":\"--memory-hard 512m\",\"correct\":false}]"'
    -
    - Use -m/--memory to cap memory.
    - 8
    - medium
    -
    - 11
    - '2025-11-06 03:44:04.064540'
    - '2025-11-06 03:44:04.064540'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 97
    - 11
    - command
    - Run nginx with read-only root filesystem (Q12)
    -
    - docker run --read-only nginx
    - Harden container with --read-only.
    - 10
    - medium
    -
    - 12
    - '2025-11-06 03:44:04.068549'
    - '2025-11-06 03:44:04.068549'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 98
    - 11
    - mcq
    - Which flag limits memory usage? (Q13)
    - '"[{\"text\":\"-m 512m\",\"correct\":true},{\"text\":\"--limit-mem 512\",\"correct\":false},{\"text\":\"--mem
      512\",\"correct\":false},{\"text\":\"--memory-hard 512m\",\"correct\":false}]"'
    -
    - Use -m/--memory to cap memory.
    - 8
    - medium
    -
    - 13
    - '2025-11-06 03:44:04.072013'
    - '2025-11-06 03:44:04.072013'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 99
    - 11
    - command
    - Run nginx with read-only root filesystem (Q14)
    -
    - docker run --read-only nginx
    - Harden container with --read-only.
    - 10
    - medium
    -
    - 14
    - '2025-11-06 03:44:04.075402'
    - '2025-11-06 03:44:04.075402'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 100
    - 11
    - mcq
    - Which flag limits memory usage? (Q15)
    - '"[{\"text\":\"-m 512m\",\"correct\":true},{\"text\":\"--limit-mem 512\",\"correct\":false},{\"text\":\"--mem
      512\",\"correct\":false},{\"text\":\"--memory-hard 512m\",\"correct\":false}]"'
    -
    - Use -m/--memory to cap memory.
    - 8
    - medium
    -
    - 15
    - '2025-11-06 03:44:04.079194'
    - '2025-11-06 03:44:04.079194'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 101
    - 11
    - command
    - Run nginx with read-only root filesystem (Q16)
    -
    - docker run --read-only nginx
    - Harden container with --read-only.
    - 10
    - medium
    -
    - 16
    - '2025-11-06 03:44:04.082676'
    - '2025-11-06 03:44:04.082676'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 102
    - 11
    - mcq
    - Which flag limits memory usage? (Q17)
    - '"[{\"text\":\"-m 512m\",\"correct\":true},{\"text\":\"--limit-mem 512\",\"correct\":false},{\"text\":\"--mem
      512\",\"correct\":false},{\"text\":\"--memory-hard 512m\",\"correct\":false}]"'
    -
    - Use -m/--memory to cap memory.
    - 8
    - medium
    -
    - 17
    - '2025-11-06 03:44:04.086243'
    - '2025-11-06 03:44:04.086243'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 103
    - 11
    - command
    - Run nginx with read-only root filesystem (Q18)
    -
    - docker run --read-only nginx
    - Harden container with --read-only.
    - 10
    - medium
    -
    - 18
    - '2025-11-06 03:44:04.089919'
    - '2025-11-06 03:44:04.089919'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 104
    - 11
    - mcq
    - Which flag limits memory usage? (Q19)
    - '"[{\"text\":\"-m 512m\",\"correct\":true},{\"text\":\"--limit-mem 512\",\"correct\":false},{\"text\":\"--mem
      512\",\"correct\":false},{\"text\":\"--memory-hard 512m\",\"correct\":false}]"'
    -
    - Use -m/--memory to cap memory.
    - 8
    - medium
    -
    - 19
    - '2025-11-06 03:44:04.094590'
    - '2025-11-06 03:44:04.094590'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 105
    - 11
    - command
    - Run nginx with read-only root filesystem (Q20)
    -
    - docker run --read-only nginx
    - Harden container with --read-only.
    - 10
    - medium
    -
    - 20
    - '2025-11-06 03:44:04.098267'
    - '2025-11-06 03:44:04.098267'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 106
    - 11
    - mcq
    - Which flag limits memory usage? (Q21)
    - '"[{\"text\":\"-m 512m\",\"correct\":true},{\"text\":\"--limit-mem 512\",\"correct\":false},{\"text\":\"--mem
      512\",\"correct\":false},{\"text\":\"--memory-hard 512m\",\"correct\":false}]"'
    -
    - Use -m/--memory to cap memory.
    - 8
    - medium
    -
    - 21
    - '2025-11-06 03:44:04.101909'
    - '2025-11-06 03:44:04.101909'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 107
    - 11
    - command
    - Run nginx with read-only root filesystem (Q22)
    -
    - docker run --read-only nginx
    - Harden container with --read-only.
    - 10
    - medium
    -
    - 22
    - '2025-11-06 03:44:04.106553'
    - '2025-11-06 03:44:04.106553'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 108
    - 11
    - mcq
    - Which flag limits memory usage? (Q23)
    - '"[{\"text\":\"-m 512m\",\"correct\":true},{\"text\":\"--limit-mem 512\",\"correct\":false},{\"text\":\"--mem
      512\",\"correct\":false},{\"text\":\"--memory-hard 512m\",\"correct\":false}]"'
    -
    - Use -m/--memory to cap memory.
    - 8
    - medium
    -
    - 23
    - '2025-11-06 03:44:04.110618'
    - '2025-11-06 03:44:04.110618'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 109
    - 11
    - command
    - Run nginx with read-only root filesystem (Q24)
    -
    - docker run --read-only nginx
    - Harden container with --read-only.
    - 10
    - medium
    -
    - 24
    - '2025-11-06 03:44:04.114721'
    - '2025-11-06 03:44:04.114721'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 110
    - 11
    - mcq
    - Which flag limits memory usage? (Q25)
    - '"[{\"text\":\"-m 512m\",\"correct\":true},{\"text\":\"--limit-mem 512\",\"correct\":false},{\"text\":\"--mem
      512\",\"correct\":false},{\"text\":\"--memory-hard 512m\",\"correct\":false}]"'
    -
    - Use -m/--memory to cap memory.
    - 8
    - medium
    -
    - 25
    - '2025-11-06 03:44:04.118432'
    - '2025-11-06 03:44:04.118432'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 111
    - 5
    - command
    - What command starts all services defined in docker-compose.yml in detached mode?
    -
    - docker-compose up -d
    - The 'up' command starts services, and '-d' runs them in detached (background)
      mode.
    - 15
    - hard
    -
    - 2
    - '2025-11-06 07:32:44.050860'
    - '2025-11-06 07:32:44.050860'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 112
    - 12
    - mcq
    - What is a container?
    - '"[{\"text\":\"A lightweight, standalone package that includes everything needed
      to run software\",\"correct\":true},{\"text\":\"A type of virtual machine with
      its own kernel\",\"correct\":false},{\"text\":\"A cloud storage system for applications\",\"correct\":false},{\"text\":\"A
      programming language for distributed systems\",\"correct\":false}]"'
    - A lightweight, standalone package that includes everything needed to run software
    - Containers are lightweight, standalone packages that include application code,
      runtime, system tools, libraries, and settings - everything needed to run the
      software.
    - 10
    - easy
    -
    - 1
    - '2025-11-06 08:09:17.962704'
    - '2025-11-06 08:09:17.962704'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 113
    - 12
    - mcq
    - What is the main advantage of containers over virtual machines?
    - '"[{\"text\":\"Containers are faster and more lightweight because they share
      the host OS kernel\",\"correct\":true},{\"text\":\"Containers provide better
      security isolation\",\"correct\":false},{\"text\":\"Containers can only run
      on Linux systems\",\"correct\":false},{\"text\":\"Containers require a hypervisor
      to run\",\"correct\":false}]"'
    - Containers are faster and more lightweight because they share the host OS kernel
    - Containers share the host operating system's kernel, making them much lighter
      and faster than VMs which each require a full operating system.
    - 10
    - medium
    -
    - 2
    - '2025-11-06 08:09:17.963959'
    - '2025-11-06 08:09:17.963959'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 114
    - 12
    - mcq
    - What is the Docker daemon responsible for?
    - '"[{\"text\":\"Managing Docker objects like containers, images, networks, and
      volumes\",\"correct\":true},{\"text\":\"Providing the command-line interface
      for users\",\"correct\":false},{\"text\":\"Storing Docker images in the cloud\",\"correct\":false},{\"text\":\"Compiling
      application source code\",\"correct\":false}]"'
    - Managing Docker objects like containers, images, networks, and volumes
    - The Docker daemon (dockerd) is the background service that manages all Docker
      objects including containers, images, networks, and volumes.
    - 10
    - easy
    -
    - 3
    - '2025-11-06 08:09:17.964964'
    - '2025-11-06 08:09:17.964964'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 115
    - 12
    - mcq
    - What is the relationship between Docker images and containers?
    - '"[{\"text\":\"An image is a template, and containers are running instances
      of images\",\"correct\":true},{\"text\":\"Images and containers are the same
      thing\",\"correct\":false},{\"text\":\"Containers are templates for creating
      images\",\"correct\":false},{\"text\":\"Images run inside containers\",\"correct\":false}]"'
    - An image is a template, and containers are running instances of images
    - Docker images are read-only templates, while containers are running instances
      created from those images. One image can create many containers.
    - 10
    - easy
    -
    - 4
    - '2025-11-06 08:09:17.965923'
    - '2025-11-06 08:09:17.965923'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 116
    - 12
    - true_false
    - Docker containers share the host operating system's kernel.
    -
    - 'true'
    - True. Unlike VMs, containers share the host OS kernel, which makes them lightweight
      and fast to start.
    - 5
    - easy
    -
    - 5
    - '2025-11-06 08:09:17.970967'
    - '2025-11-06 08:09:17.970967'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 117
    - 12
    - true_false
    - When you delete a container, the image it was created from is also deleted.
    -
    - 'false'
    - False. Images and containers are independent. Deleting a container does not
      affect the image it was created from.
    - 5
    - easy
    -
    - 6
    - '2025-11-06 08:09:17.972094'
    - '2025-11-06 08:09:17.972094'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 118
    - 12
    - true_false
    - Docker images are mutable and can be changed after creation.
    -
    - 'false'
    - False. Docker images are immutable (read-only). Any changes happen in a container's
      writable layer, not the image itself.
    - 5
    - medium
    -
    - 7
    - '2025-11-06 08:09:17.973084'
    - '2025-11-06 08:09:17.973084'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 119
    - 12
    - mcq
    - What does the command 'docker ps -a' do?
    - '"[{\"text\":\"Lists all containers, both running and stopped\",\"correct\":true},{\"text\":\"Lists
      only running containers\",\"correct\":false},{\"text\":\"Lists all Docker images\",\"correct\":false},{\"text\":\"Shows
      Docker system information\",\"correct\":false}]"'
    - Lists all containers, both running and stopped
    - The -a flag shows all containers regardless of their state (running, stopped,
      exited, etc.).
    - 10
    - easy
    -
    - 8
    - '2025-11-06 08:09:17.974441'
    - '2025-11-06 08:09:17.974441'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 120
    - 12
    - mcq
    - Which Docker component stores Docker images?
    - '"[{\"text\":\"Docker Registry (like Docker Hub)\",\"correct\":true},{\"text\":\"Docker
      Daemon\",\"correct\":false},{\"text\":\"Docker Client\",\"correct\":false},{\"text\":\"Docker
      Engine\",\"correct\":false}]"'
    - Docker Registry (like Docker Hub)
    - Docker registries store Docker images. Docker Hub is the public registry, but
      private registries also exist.
    - 10
    - medium
    -
    - 9
    - '2025-11-06 08:09:17.975844'
    - '2025-11-06 08:09:17.975844'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 121
    - 12
    - mcq
    - What happens when you run 'docker run hello-world' for the first time?
    - '"[{\"text\":\"Docker pulls the image from Docker Hub and runs a container\",\"correct\":true},{\"text\":\"Docker
      only pulls the image but doesn''t run it\",\"correct\":false},{\"text\":\"Docker
      creates an image locally and runs it\",\"correct\":false},{\"text\":\"The command
      fails because the image doesn''t exist\",\"correct\":false}]"'
    - Docker pulls the image from Docker Hub and runs a container
    - When you run a container from an image that doesn't exist locally, Docker automatically
      pulls it from the registry (Docker Hub by default) and then runs it.
    - 10
    - easy
    -
    - 10
    - '2025-11-06 08:09:17.976934'
    - '2025-11-06 08:09:17.976934'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 122
    - 13
    - mcq
    - What does the -d flag do in 'docker run -d nginx'?
    - '"[{\"text\":\"Runs the container in detached mode (background)\",\"correct\":true},{\"text\":\"Deletes
      the container after it stops\",\"correct\":false},{\"text\":\"Downloads the
      image first\",\"correct\":false},{\"text\":\"Enables debugging mode\",\"correct\":false}]"'
    - Runs the container in detached mode (background)
    - The -d flag runs containers in detached mode, freeing up your terminal.
    - 10
    - medium
    -
    - 1
    - '2025-11-06 08:13:01.786399'
    - '2025-11-06 08:13:01.786399'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 123
    - 13
    - true_false
    - docker exec starts a new process inside a running container
    -
    - 'true'
    - True. docker exec launches a new process in an existing container, unlike attach
      which connects to the main process.
    - 5
    - easy
    -
    - 2
    - '2025-11-06 08:13:01.787468'
    - '2025-11-06 08:13:01.787468'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 124
    - 13
    - mcq
    - Which command shows real-time resource usage of containers?
    - '"[{\"text\":\"docker stats\",\"correct\":true},{\"text\":\"docker top\",\"correct\":false},{\"text\":\"docker
      inspect\",\"correct\":false},{\"text\":\"docker ps\",\"correct\":false}]"'
    - docker stats
    - docker stats shows live CPU, memory, network, and disk usage for running containers.
    - 10
    - medium
    -
    - 3
    - '2025-11-06 08:13:01.788395'
    - '2025-11-06 08:13:01.788395'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 125
    - 13
    - mcq
    - What's the difference between 'docker stop' and 'docker kill'?
    - '"[{\"text\":\"stop sends SIGTERM (graceful), kill sends SIGKILL (forceful)\",\"correct\":true},{\"text\":\"They
      do exactly the same thing\",\"correct\":false},{\"text\":\"stop removes the
      container, kill doesn''t\",\"correct\":false},{\"text\":\"kill is slower than
      stop\",\"correct\":false}]"'
    - stop sends SIGTERM (graceful), kill sends SIGKILL (forceful)
    - docker stop allows graceful shutdown (SIGTERM), while docker kill forces immediate
      termination (SIGKILL).
    - 10
    - medium
    -
    - 4
    - '2025-11-06 08:13:01.789231'
    - '2025-11-06 08:13:01.789231'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 126
    - 13
    - true_false
    - Removing a container also removes the image it was created from
    -
    - 'false'
    - False. Containers and images are independent. Removing a container doesn't affect
      its image.
    - 5
    - easy
    -
    - 5
    - '2025-11-06 08:13:01.790177'
    - '2025-11-06 08:13:01.790177'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 127
    - 14
    - mcq
    - What does each instruction in a Dockerfile create?
    - '"[{\"text\":\"A new layer in the image\",\"correct\":true},{\"text\":\"A new
      container\",\"correct\":false},{\"text\":\"A new volume\",\"correct\":false},{\"text\":\"A
      new network\",\"correct\":false}]"'
    - A new layer in the image
    - Each Dockerfile instruction creates a new read-only layer in the image.
    - 10
    - medium
    -
    - 1
    - '2025-11-06 08:20:50.326676'
    - '2025-11-06 08:20:50.326676'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 128
    - 14
    - true_false
    - Docker caches layers during builds to speed up subsequent builds
    -
    - 'true'
    - True. Docker caches unchanged layers, making rebuilds much faster.
    - 5
    - easy
    -
    - 2
    - '2025-11-06 08:20:50.327705'
    - '2025-11-06 08:20:50.327705'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 129
    - 15
    - true_false
    - Data stored in a container's writable layer persists after the container is
      removed
    -
    - 'false'
    - False. Container data is ephemeral by default. Use volumes for persistence.
    - 10
    - easy
    -
    - 1
    - '2025-11-06 08:20:50.341270'
    - '2025-11-06 08:20:50.341270'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 130
    - 16
    - true_false
    - Containers on the same custom network can communicate using container names
    -
    - 'true'
    - True. Docker provides automatic DNS resolution for containers on custom networks.
    - 10
    - easy
    -
    - 1
    - '2025-11-06 08:20:50.351481'
    - '2025-11-06 08:20:50.351481'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 131
    - 17
    - true_false
    - Docker Compose can manage multiple containers with a single YAML file
    -
    - 'true'
    - True. Docker Compose allows you to define entire multi-container applications
      in docker-compose.yml.
    - 10
    - easy
    -
    - 1
    - '2025-11-06 08:20:50.361961'
    - '2025-11-06 08:20:50.361961'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 132
    - 18
    - mcq
    - What is the primary benefit of using multi-stage builds?
    - '"[{\"text\":\"Reduce final image size by excluding build dependencies\",\"correct\":true},{\"text\":\"Build
      multiple images simultaneously\",\"correct\":false},{\"text\":\"Create multiple
      containers from one image\",\"correct\":false},{\"text\":\"Run multiple commands
      in parallel\",\"correct\":false}]"'
    - Reduce final image size by excluding build dependencies
    - Multi-stage builds allow you to use build tools in early stages and copy only
      the final artifacts to the production image.
    - 10
    - medium
    -
    - 1
    - '2025-11-06 08:20:50.373638'
    - '2025-11-06 08:20:50.373638'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 133
    - 18
    - mcq
    - Which command shows real-time resource usage for all containers?
    - '"[{\"text\":\"docker stats\",\"correct\":true},{\"text\":\"docker top\",\"correct\":false},{\"text\":\"docker
      inspect\",\"correct\":false},{\"text\":\"docker system df\",\"correct\":false}]"'
    - docker stats
    - docker stats provides live CPU, memory, network, and disk I/O metrics for running
      containers.
    - 10
    - medium
    -
    - 2
    - '2025-11-06 08:20:50.374795'
    - '2025-11-06 08:20:50.374795'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 134
    - 18
    - mcq
    - What is the difference between CMD and ENTRYPOINT in a Dockerfile?
    - '"[{\"text\":\"ENTRYPOINT sets the main executable, CMD provides default arguments\",\"correct\":true},{\"text\":\"They
      are exactly the same\",\"correct\":false},{\"text\":\"CMD runs at build time,
      ENTRYPOINT at runtime\",\"correct\":false},{\"text\":\"ENTRYPOINT can be overridden,
      CMD cannot\",\"correct\":false}]"'
    - ENTRYPOINT sets the main executable, CMD provides default arguments
    - ENTRYPOINT defines the main command, while CMD provides default arguments that
      can be overridden.
    - 10
    - medium
    -
    - 3
    - '2025-11-06 08:20:50.375860'
    - '2025-11-06 08:20:50.375860'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 135
    - 18
    - mcq
    - How do containers on the same custom network communicate?
    - '"[{\"text\":\"Using container names as hostnames via automatic DNS\",\"correct\":true},{\"text\":\"They
      cannot communicate\",\"correct\":false},{\"text\":\"Only through exposed ports\",\"correct\":false},{\"text\":\"Only
      using IP addresses\",\"correct\":false}]"'
    - Using container names as hostnames via automatic DNS
    - Docker provides automatic service discovery via DNS on custom networks.
    - 10
    - medium
    -
    - 4
    - '2025-11-06 08:20:50.376817'
    - '2025-11-06 08:20:50.376817'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 136
    - 18
    - mcq
    - What does 'docker-compose up -d' do?
    - '"[{\"text\":\"Starts all services in detached mode\",\"correct\":true},{\"text\":\"Stops
      all services\",\"correct\":false},{\"text\":\"Deletes all containers\",\"correct\":false},{\"text\":\"Downloads
      all images\",\"correct\":false}]"'
    - Starts all services in detached mode
    - The -d flag runs services in the background, freeing up your terminal.
    - 10
    - medium
    -
    - 5
    - '2025-11-06 08:20:50.377806'
    - '2025-11-06 08:20:50.377806'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 137
    - 18
    - true_false
    - Docker volumes are managed by Docker and persist data beyond container lifecycle
    -
    - 'true'
    - True. Volumes are the preferred way to persist data in Docker containers.
    - 5
    - easy
    -
    - 6
    - '2025-11-06 08:20:50.378762'
    - '2025-11-06 08:20:50.378762'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 138
    - 18
    - true_false
    - Bind mounts are more portable than Docker volumes
    -
    - 'false'
    - False. Volumes are more portable as they're managed by Docker and work across
      all platforms.
    - 5
    - easy
    -
    - 7
    - '2025-11-06 08:20:50.379761'
    - '2025-11-06 08:20:50.379761'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 139
    - 18
    - mcq
    - Which restart policy ensures a container always restarts unless manually stopped?
    - '"[{\"text\":\"unless-stopped\",\"correct\":true},{\"text\":\"always\",\"correct\":false},{\"text\":\"on-failure\",\"correct\":false},{\"text\":\"no\",\"correct\":false}]"'
    - unless-stopped
    - unless-stopped restarts containers automatically except when manually stopped.
    - 10
    - medium
    -
    - 8
    - '2025-11-06 08:20:50.380659'
    - '2025-11-06 08:20:50.380659'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 140
    - 18
    - mcq
    - What is the purpose of .dockerignore?
    - '"[{\"text\":\"Exclude files from the build context to speed up builds\",\"correct\":true},{\"text\":\"Ignore
      Docker commands\",\"correct\":false},{\"text\":\"Prevent containers from starting\",\"correct\":false},{\"text\":\"Hide
      images from docker images command\",\"correct\":false}]"'
    - Exclude files from the build context to speed up builds
    - ".dockerignore prevents unnecessary files from being sent to the Docker daemon,
      making builds faster."
    - 10
    - medium
    -
    - 9
    - '2025-11-06 08:20:50.381603'
    - '2025-11-06 08:20:50.381603'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -
  - - 141
    - 18
    - mcq
    - In a production environment, which image tag should you use?
    - '"[{\"text\":\"Specific version tags (e.g., nginx:1.21)\",\"correct\":true},{\"text\":\"Always
      use :latest\",\"correct\":false},{\"text\":\"Never use tags\",\"correct\":false},{\"text\":\"Only
      use :stable\",\"correct\":false}]"'
    - Specific version tags (e.g., nginx:1.21)
    - Specific version tags ensure reproducibility and prevent unexpected updates
      in production.
    - 10
    - medium
    -
    - 10
    - '2025-11-06 08:20:50.383108'
    - '2025-11-06 08:20:50.383108'
    - 0
    - 1
    - 0.2
    -
    -
    - 0.01
    - false
    - '"\"\\\"[]\\\"\""'
    -

---
quizzes:
  columns:
  - id
  - title
  - description
  - time_limit_minutes
  - passing_score
  - max_attempts
  - shuffle_questions
  - show_correct_answers
  - created_at
  - updated_at
  - metadata
  - quiz_type
  records: 
  - - 1
    - Container Basics Quiz
    - ''
    - 15
    - 70
    - 3
    - true
    - true
    - '2025-11-06 03:44:03.486349'
    - '2025-11-06 07:32:43.950385'
    -
    - standard
  - - 2
    - Images and Dockerfiles Quiz
    - ''
    -
    - 70
    - 3
    - true
    - true
    - '2025-11-06 03:44:03.529787'
    - '2025-11-06 07:32:44.026201'
    -
    - standard
  - - 3
    - Networking & Ports Quiz
    - Check your knowledge of port mapping and networks
    - 15
    - 70
    - 3
    - true
    - true
    - '2025-11-06 03:44:03.549249'
    - '2025-11-06 03:44:03.549249'
    -
    -
  - - 4
    - Volumes & Storage Quiz
    - Volumes, bind mounts, and persistence
    - 15
    - 70
    - 3
    - true
    - true
    - '2025-11-06 03:44:03.575927'
    - '2025-11-06 03:44:03.575927'
    -
    -
  - - 5
    - Docker Compose Quiz
    - ''
    -
    - 70
    - 3
    - true
    - true
    - '2025-11-06 03:44:03.599598'
    - '2025-11-06 07:32:44.048244'
    -
    - standard
  - - 6
    - Security Quiz
    - Secure-by-default image and runtime settings
    - 15
    - 70
    - 3
    - true
    - true
    - '2025-11-06 03:44:03.628434'
    - '2025-11-06 03:44:03.628434'
    -
    -
  - - 7
    - Registries Quiz
    - Tags, authentication, and push/pull
    - 10
    - 70
    - 3
    - true
    - true
    - '2025-11-06 03:44:03.653667'
    - '2025-11-06 03:44:03.653667'
    -
    -
  - - 8
    - Bridge I Knowledge Check
    - Quick knowledge check to reinforce Docker→K8s mappings
    - 20
    - 70
    - 3
    - true
    - true
    - '2025-11-06 03:44:03.680292'
    - '2025-11-06 03:44:03.680292'
    -
    -
  - - 9
    - Bridge II Knowledge Check
    - Quick checks for Services/DNS, PV/PVC, ConfigMaps & Secrets
    - 0
    - 0
    - 0
    - true
    - true
    - '2025-11-06 03:44:03.721787'
    - '2025-11-06 03:44:03.721787'
    -
    -
  - - 10
    - CKAD Preview Scenarios
    - Hands-on style scenario checks (self-timed)
    - 0
    - 0
    - 0
    - false
    - true
    - '2025-11-06 03:44:03.873704'
    - '2025-11-06 03:44:03.873704'
    -
    -
  - - 11
    - CKA Preview Scenarios
    - Cluster administration scenario previews
    - 0
    - 0
    - 0
    - false
    - true
    - '2025-11-06 03:44:04.016555'
    - '2025-11-06 03:44:04.016555'
    -
    -
  - - 12
    - 'Week 1 Review: Containers & Docker Fundamentals'
    - Test your understanding of containerization concepts, Docker architecture, and
      the relationship between images and containers
    -
    - 70
    - 3
    - true
    - true
    - '2025-11-06 08:09:17.951949'
    - '2025-11-06 08:09:17.951949'
    -
    - standard
  - - 13
    - 'Week 2 Review: Container Management'
    - Test your knowledge of container lifecycle, monitoring, and management
    -
    - 70
    - 3
    - true
    - true
    - '2025-11-06 08:13:01.785282'
    - '2025-11-06 08:13:01.785282'
    -
    - standard
  - - 14
    - 'Week 3 Review: Docker Images and Dockerfiles'
    - Test your knowledge of Dockerfiles, image layers, and building custom images
    -
    - 70
    - 3
    - true
    - true
    - '2025-11-06 08:20:50.325500'
    - '2025-11-06 08:20:50.325500'
    -
    - standard
  - - 15
    - 'Week 4 Review: Data Persistence'
    - Test your understanding of volumes and data management
    -
    - 70
    - 3
    - true
    - true
    - '2025-11-06 08:20:50.340269'
    - '2025-11-06 08:20:50.340269'
    -
    - standard
  - - 16
    - 'Week 5 Review: Networking'
    - Test your knowledge of Docker networking
    -
    - 70
    - 3
    - true
    - true
    - '2025-11-06 08:20:50.350388'
    - '2025-11-06 08:20:50.350388'
    -
    - standard
  - - 17
    - 'Week 6 Review: Docker Compose'
    - Test your understanding of Docker Compose
    -
    - 70
    - 3
    - true
    - true
    - '2025-11-06 08:20:50.360930'
    - '2025-11-06 08:20:50.360930'
    -
    - standard
  - - 18
    - 'Final Assessment: DCA Certification Readiness'
    - Comprehensive exam covering all bootcamp topics - Docker Certified Associate
      aligned
    -
    - 80
    - 2
    - true
    - true
    - '2025-11-06 08:20:50.372163'
    - '2025-11-06 08:20:50.372163'
    -
    - standard

---
users:
  columns:
  - id
  - access_token
  - account_id
  - created_at
  - updated_at
  - associated_data
  - user_data
  - result_data
  - results
  - total_progress_points
  - diagnostic_completed
  - diagnostic_skill_level
  - diagnostic_score
  records: 
  - - 1
    -
    - demo-0176cc11
    - '2025-11-06 04:03:38.458709'
    - '2025-11-06 04:03:38.458709'
    -
    -
    -
    -
    - 0
    - false
    -
    -
